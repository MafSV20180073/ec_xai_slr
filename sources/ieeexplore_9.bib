@INPROCEEDINGS{10475646,
  author={Nuppnau, Mark and Kattan, Khalid and Reynolds, Robert G.},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={Guided Evolution of Dense Blocks with Attention for CheXpert with Cultural Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={355-368},
  abstract={This study focuses on utilizing neuroevolution for the task of pathology detection in chest radiographs using the CheXpert dataset. The principal objective will be to adapt and extend the TensorFlow-NeuroEvolution (tfne) framework to the CheXpert dataset, dense blocks, and cultural algorithms. This involves the integration of a dense block module that emulates the dense blocks and transition layers found in DenseNet as well as an attention mechanism, into the tfne framework. Like the original DenseNet architecture, this module will include the definition of a dense block, and a transition layer. Unlike the original DenseNet architecture, the dense block module will include an attention mechanism. Further, a custom CheXpert environment will be created to train the evolved networks on the task of chest pathology detection. Utilizing the CoDeep-NEAT algorithm and cultural algorithms, the study will evolve a neural network equipped for handling the CheXpert dataset using the dense block module. Cultural algorithms will help guide the CoDeepNEAT algorithm by providing belief space, and influencing the mutation, crossover, and selection processes. The belief space will also serve as a method of maintaining diversity in the population.},
  keywords={Radiography;Pathology;Sociology;Semantics;Neural networks;Computer architecture;Diversity methods;DenseNet;Neuroevolution;Cultural Algorithms},
  doi={10.1109/ICSC59802.2024.00066},
  ISSN={2472-9671},
  month={Feb},}@ARTICLE{10552075,
  author={Han, Yunhai and Yu, Kelin and Batra, Rahul and Boyd, Nathan and Mehta, Chaitanya and Zhao, Tuo and She, Yu and Hutchinson, Seth and Zhao, Ye},
  journal={IEEE/ASME Transactions on Mechatronics}, 
  title={Learning Generalizable Vision-Tactile Robotic Grasping Strategy for Deformable Objects via Transformer}, 
  year={2025},
  volume={30},
  number={1},
  pages={554-566},
  abstract={Reliable robotic grasping, especially with deformable objects such as fruits, remains a challenging task due to underactuated contact interactions with a gripper, unknown object dynamics and geometries. In this study, we propose a transformer-based robotic grasping framework for rigid grippers that leverage tactile and visual information for safe object grasping. Specifically, the transformer models learn physical feature embeddings with sensor feedback through performing two predefined explorative actions (pinching and sliding) and predict a grasping outcome through a multilayer perceptron with a given grasping strength. Using these predictions, the gripper predicts a safe grasping strength via inference. Compared with convolutional recurrent networks, the transformer models can capture the long-term dependencies across the image sequences and process spatial–temporal features simultaneously. We first benchmark the transformer models on a public dataset for slip detection. Following that, we show that the transformer models outperform a CNN + LSTM model in terms of grasping accuracy and computational efficiency. We also collect a new fruit grasping dataset and conduct online grasping experiments using the proposed framework for both seen and unseen fruits. In addition, we extend our model to objects with different shapes and demonstrate the effectiveness of our pretrained model trained on our large-scale fruit dataset.},
  keywords={Grasping;Robot sensing systems;Transformers;Robots;Task analysis;Grippers;Force;Deep learning;perception for grasping and manipulation;visual and tactile sensing},
  doi={10.1109/TMECH.2024.3400789},
  ISSN={1941-014X},
  month={Feb},}@ARTICLE{10757440,
  author={Brown, Robert and Adams, Julie A.},
  journal={IEEE Transactions on Field Robotics}, 
  title={Congestion Analysis for the DARPA OFFSET CCAST Swarm}, 
  year={2025},
  volume={2},
  number={},
  pages={21-45},
  abstract={The Defense Advanced Research Projects Agency’s (DARPA) OFFensive Swam-Enabled Tactics (OFFSET) program’s goal of launching 250 unmanned aerial and ground vehicles from a limited-sized launch zone was a daunting challenge. The swarm’s aerial vehicles were primarily multi-rotor platforms, which can efficiently be launched en mass. Each field exercise (FX) expected the deployment of an even larger swarm. While the launch zone’s spatial area increased with each FX, the relative space for each vehicle was not necessarily increased considering the increasing size of the swarm and the vehicles’ associated GPS error. However, safe mission deployment and execution were expected. At the same time, achieving the mission goals required maximizing the efficiency of the swarm’s performance, by reducing congestion that blocked vehicles from completing tactic assignments. Congestion analysis conducted before the final FX focused on adjusting various constraints to optimize the swarm’s deployment without reducing safety. During the FX, data was collected that permitted analyzing the number and durations of individual vehicle blockages’ impact on the resulting congestion. After the FX, additional analyses used the mission plan to validate the use of simulation for analyzing congestion.},
  keywords={Navigation;Long Term Evolution;Global Positioning System;Sensors;Planning;Payloads;Batteries;US Department of Defense;Particle swarm optimization;Autonomous robots;Traffic congestion;Command and control systems;Congestion;Defense Advanced Research Projects Agency (DARPA) OFFensive Swam-Enabled Tactics (OFFSET);swarms},
  doi={10.1109/TFR.2024.3502312},
  ISSN={2997-1101},
  month={},}@INPROCEEDINGS{10483935,
  author={Liu, Ran and Khose, Sahil and Xiao, Jingyun and Sathidevi, Lakshmi and Ramnath, Keerthan and Kira, Zsolt and Dyer, Eva L.},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={LatentDR: Improving Model Generalization Through Sample-Aware Latent Degradation and Restoration}, 
  year={2024},
  volume={},
  number={},
  pages={2657-2667},
  abstract={Despite significant advances in deep learning, models often struggle to generalize well to new, unseen domains, especially when training data is limited. To address this challenge, we propose a novel approach for distribution-aware latent augmentation that leverages the relationships across samples to guide the augmentation procedure. Our approach first degrades the samples stochastically in the latent space, mapping them to augmented labels, and then restores the samples from their corrupted versions during training. This process confuses the classifier in the degradation step and restores the overall class distribution of the original samples, promoting diverse intra-class/cross-domain variability. We extensively evaluate our approach on a diverse set of datasets and tasks, including domain generalization benchmarks and medical imaging datasets with strong domain shift, where we show our approach achieves significant improvements over existing methods for latent space augmentation. We further show that our method can be flexibly adapted to long-tail recognition tasks, demonstrating its versatility in building more generalizable models. https://github.com/nerdslab/LatentDR.},
  keywords={Degradation;Deep learning;Training;Adaptation models;Training data;Space mapping;Self-supervised learning;Algorithms;Machine learning architectures;formulations;and algorithms;Algorithms;Image recognition and understanding;Applications;Biomedical / healthcare / medicine},
  doi={10.1109/WACV57701.2024.00265},
  ISSN={2642-9381},
  month={Jan},}@INPROCEEDINGS{10796552,
  author={Gerardini, Katusha and Sarcinella, Eleonora Diletta and Borghesi, Francesca and Pozzi, Andrea and Gaggioli, Andrea and Chirico, Alice},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Comparing UX Profile of Generative Artificial Intelligence Tools and Traditional Tools in Brainstorming Sessions: A Pilot Study}, 
  year={2024},
  volume={},
  number={},
  pages={1059-1064},
  abstract={Brainstorming, originally conceived by Alex Osborn in 1953, is widely recognized as an effective tool for promoting creativity and innovation within teams. However, as technologies advance and new tools emerge, such as duels of generative artificial intelligence, the brainstorming landscape is evolving. This study aims to investigate the use of Chat GPT, DALL-E and Miro in brainstorming sessions in presence, to evaluate the user experience of users depending on the tool used and their influence on human group creativity. It was followed by a design of repeated measurements research, where each group of participants carried out in succession the three sessions of brainstorming with the help of different tools. The methodology used is mixed qualitative and quantitative, through three online surveys. The key indicators considered include the total number of ideas generated, the uniqueness and feasibility of the same, as well as the subjective perception of participants on the effectiveness of the brainstorming process. In conclusion, this study aims to provide meaningful information on the use of artificial intelligence tools to facilitate or not collaborative creative processes, offering progression for future research in artificial intelligence-assisted innovation.},
  keywords={Surveys;Technological innovation;Generative AI;Heuristic algorithms;Neural engineering;Metrology;Particle measurements;User experience;Particle swarm optimization;Creativity;creativity;brainstorming;generative artificial intelligence;dall-e;chat gpt;miro},
  doi={10.1109/MetroXRAINE62247.2024.10796552},
  ISSN={},
  month={Oct},}@ARTICLE{10049168,
  author={Divasón, Jose and Martínez-de-Pisón, Francisco Javier and Romero, Ana and Sáenz-de-Cabezón, Eduardo},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Artificial Intelligence Models for Assessing the Evaluation Process of Complex Student Projects}, 
  year={2023},
  volume={16},
  number={5},
  pages={694-707},
  abstract={The evaluation of student projects is a difficult task, especially when they involve both a technical and a creative component. We propose an artificial intelligence (AI)-based methodology to help in the evaluation of complex projects in engineering and computer science courses. This methodology is intended to evaluate the assessment process itself allowing to analyze the influence of each variable in the final grade, to discover possible biases, inconsistencies and discrepancies, and to generate appropriate rubrics that help to avoid them. As an example of its application, we consider the evaluation of the projects submitted in an undergraduate introductory course on computer science. Using data collected from the evaluation during five academic years, we follow the proposed methodology to create AI models and analyze the main variables which are involved in the assessment of the projects. The proposed methodology can be applied to other courses and degrees, where both technical and creative components are considered to evaluate the projects.},
  keywords={Complexity theory;Task analysis;Computer science;Biological cells;Training;Feature extraction;Computational modeling;Automated grading;computer science;evolutionary algorithms;machine learning (ML);rubric},
  doi={10.1109/TLT.2023.3246589},
  ISSN={1939-1382},
  month={Oct},}@INPROCEEDINGS{10008436,
  author={Shammasi, Mohammadmehdi and Baharloo, Mohammad and Abdollahi, Meisam and Baniasadi, Amirali},
  booktitle={2022 IEEE 15th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)}, 
  title={Turn-aware Application Mapping using Reinforcement Learning in Power Gating-enabled Network on Chip}, 
  year={2022},
  volume={},
  number={},
  pages={345-352},
  abstract={As the backbone for many-core chips, Network-on-chips (NoCs) consume a significant share of total chip power. As a result, decreasing the power consumption in these components can reduce the total chip's power significantly. NoC's routers can be powered down using power-gating, a promising technique for reducing static power consumption. In some advanced methods, routers are put in sleep mode and only wake up when they are needed to turn/inject packets. Since waking up the router takes several cycles to complete, packets will experience high latency. In this regard, application mapping significantly impacts the number of turns. This article proposes a reinforcement learning (RL) framework based on Actor-Critic architecture to optimize the application mapping problem to minimize the number of turn packets as well as communication cost. Our RL framework learns the heuristic of the mapping problem and outputs a near-optimal mapping. A 2-opt local search algorithm fine-tunes this strategy and provides an improved mapping. Our simulations show that the proposed RL framework can achieve better cost and algorithm run-time performance compared to other heuristic algorithms such as Simulated Annealing (SA) and Genetic Algorithm (GA).},
  keywords={Costs;Power demand;Multicore processing;Heuristic algorithms;Reinforcement learning;Simulated annealing;Logic gates;Network on Chip;Application mapping;Turn-aware;Power Gating;Reinforcement Learning},
  doi={10.1109/MCSoC57363.2022.00061},
  ISSN={2771-3075},
  month={Dec},}@ARTICLE{10701612,
  author={Lin, Fanfan and Li, Xinze and Lei, Weihao and Rodriguez-Andina, Juan J. and Guerrero, Josep M. and Wen, Changyun and Zhang, Xin and Ma, Hao},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={PE-GPT: A New Paradigm for Power Electronics Design}, 
  year={2025},
  volume={72},
  number={4},
  pages={3778-3791},
  abstract={Large language models (LLMs) have shown exciting potential in powering the growth of many industries, yet their adoption in the power electronics (PE) sector is hindered by a lack of specialized PE technical expertise and challenges in processing PE-specific data. This study presents a pioneering approach to establish a multimodal LLM tailored for PE design applications, named PE-GPT. The methodology involves enhancing PE-GPT with retrieval augmented generation from a PE knowledge base, and proposes a hybrid framework that integrates an LLM agent with metaheuristic algorithms, Model Zoo, and Simulation Repository. This enhances its multimodal processing capabilities and enables integration into the existing design workflow. The PE-GPT methodology is demonstrated with two case studies: modulation design of the dual-active bridge (DAB) converter and circuit parameter design of the buck converter. PE-GPT demonstrates a 22.2% increase in correctness compared to human experts. Against other leading LLMs, PE-GPT shows a 35.6% improvement in correctness and a 15.4% enhancement in consistency, reducing hallucination. Hardware experiments validate PE-GPT’s multimodal capabilities in optimizing a five-degree-of-freedom modulation strategy for the DAB converter. The generalization of PE-GPT to other PE design applications and associated AI ethical considerations are also discussed. This research concludes by outlining inspiring future research directions, encouraging researchers to expand the boundaries of the PE industry and advance toward a more intelligent era.},
  keywords={Modulation;Knowledge based systems;Integrated circuit modeling;Vectors;Metaheuristics;Data models;Power electronics;Analytical models;Adaptation models;Physics;Large language model (LLM);multimodal AI;physics-informed AI;power electronics (PE) design;power converter design},
  doi={10.1109/TIE.2024.3454408},
  ISSN={1557-9948},
  month={April},}@INPROCEEDINGS{10137925,
  author={Gao, Hao and Xu, Xin and Zhang, Changxin and Zhou, Xing},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={A Bidirectional Parameter Transfer Reinforcement Learning Approach for Bi-Objectives Traveling Salesman Problem}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, learning-based approaches for solving combinational optimization problems have received increasing research interest. However, it is still challenging to solve multi-objective optimization problems (MOPs). In this paper, we proposed a bidirectional parameter transfer attention-based reinforcement learning approach for solving bi-objective traveling salesman problem (BOTSP), which is based on dynamic context attention neural network trained by the rollout reinforce algorithm. Specifically, BOTSP is decomposed into a series of static sub-tasks at first, then, bidirectional parameter transfer methods are proposed for training each subproblem sequentially. Once the model has been learned, Pareto optimal solutions can be obtained on different scale problem instances. Extensive experiments on BOTSP were conducted to illustrate the effectiveness and advantages of the proposed approach. Compared with several algorithms, our proposed method achieves the state-of-the-art performance in hypervolume and inference efficiency. In particular, our method is suitable for different scale problem instances without extra learning, and experimental results demonstrate it realizes powerful generalization ability across tasks.},
  keywords={Training;Heuristic algorithms;Scalability;Neural networks;Reinforcement learning;Traveling salesman problems;Pareto optimization;Reinforcement learning;Multi-objective optimization problems;Traveling salesmen problem;Attention mechanism},
  doi={10.1109/ACAIT56212.2022.10137925},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10900289,
  author={Zhang, Jinhu and Sun, Bin and Sun, Jianpeng and Yu, Hao and Xie, Xiguo},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={Auto-tuning of Large-Scale Parallel Computing Applications Based on Bayesian Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={650-659},
  abstract={The performance of large-scale parallel computing applications is highly dependent on the parameter settings within complex systems. Due to the high-dimensional and nonlinear nature of kernel environment parameter spaces, traditional manual tuning methods are both labor-intensive and inefficient when exploring optimal parameter combinations, often leading to suboptimal performance. To address this issue, this paper proposes an automated parameter tuning framework based on Bayesian optimization, aimed at efficiently exploring complex high-dimensional parameter spaces and predicting better-performing parameter combinations. This framework builds a surrogate model, iteratively selects potentially efficient parameter configurations, and integrates SHAP to analyze the influence of each parameter on performance optimization. We validated the effectiveness of this framework in several typical large-scale parallel computing application scenarios, including NAS Parallel Benchmarks (NPB), quantum chemistry simulation software Quantum ESPRESSO and VASP, and the Weather Research and Forecasting model (WRF). Experimental results show that Bayesian optimization significantly shortens the overall tuning time and performs traditional methods such as genetic algorithms in terms of performance optimization. Experimental results show that Bayesian optimization significantly shortens the overall tuning time by 50% and improves application performance by up to 11%, outperforming traditional methods such as genetic algorithms in terms of performance optimization. Furthermore, SHAP analysis reveals the importance of key kernel parameters in enhancing application performance.},
  keywords={Computational modeling;Parallel processing;Bayes methods;Computational efficiency;Kernel;Complex systems;Optimization;Tuning;Genetic algorithms;Convergence;Machine Learning;Bayesian Optimization;Parameter Tuning;Large-Scale Parallel Computing;Genetic Algorithm},
  doi={10.1109/ICAIRC64177.2024.10900289},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10845662,
  author={Varun.B.P, Sai and Jonnalagadda, Ishita and Ch, Vishnu Vardhan and C S, Vasavi and Sahay, Apurvanand},
  booktitle={2024 11th International Conference on Advances in Computing and Communications (ICACC)}, 
  title={The Impact of Optimization Techniques on Cancer Classification with Gene Expression Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Cancer classification using gene expression profiling is a fundamental component of cancer research and development, because it contributes to the identification of cancer subtypes as well as the identification of proper treatments for patients. The purpose of this paper is to assess the efficiency in classification of different optimization algorithms. PCA, GA, FI, SFS, and VT methods are applied for the feature selection on gene expression data. The selected features are then passed into a Gaussian Naive Bayes classifier to classify it into a particular class. In order to compare the efficiency of each presented optimization technique we calculate various evaluation metrices, and CPU time. To overcome the shortcomings of both the high accuracy methods, we proposed a new approach that integrates VT and GA. The outcomes of this work help to contribute to the research of the best combination of optimization tools for accurate classification of cancer, which will help further develop the concept of precision medicine and individualized therapy.},
  keywords={Analytical models;Accuracy;Computational modeling;Precision medicine;Feature extraction;Data models;Classification algorithms;Gene expression;Cancer;Principal component analysis;Feature Importance;Gene expression data;Genetic Algorithm;Optimization Techniques;Principal Component Analysis;Sequential Feature Selection},
  doi={10.1109/ICACC63692.2024.10845662},
  ISSN={2766-2829},
  month={Nov},}@INPROCEEDINGS{10631952,
  author={Meydani, Amir and Shahinzadeh, Hossein and Ramezani, Ali and Moazzami, Majid and Nafisi, Hamed and Askarian-Abyaneh, Hossein},
  booktitle={2024 9th International Conference on Technology and Energy Management (ICTEM)}, 
  title={Comprehensive Review of Artificial Intelligence Applications in Smart Grid Operations}, 
  year={2024},
  volume={},
  number={},
  pages={1-13},
  abstract={The present electric power system is seeing a significant transition towards the adoption of Smart Grids (SGs), which are viewed as a potential approach to improve grid stability and optimize management of energy. The current state of transition is characterized by dynamic and swift alterations, necessitating the utilization of numerous sophisticated approaches to effectively analyze the substantial volume of data produced by diverse entities. In this particular context, SG is closely associated with AI as an emerging technology that aim to establish a decentralized and intelligent energy paradigm. Artificial intelligence is intended to enhance the level of intelligence in both supervisory and operational decision-making processes. This article provides a comprehensive introduction to AI techniques and methods, followed by a detailed examination of how they are applied in the context of SG and microgrid (MG) systems. This analysis is conducted through a comprehensive examination of more than 90 recent scholarly articles. The aim of this paper is to enhance the reader’s comprehension regarding the potentials of AI within the context of SG and MG.},
  keywords={Reviews;Power system dynamics;Microgrids;Learning (artificial intelligence);Power system stability;Stability analysis;Smart grids;Artificial Intelligence (AI);Smart Grid (SG);Microgrid (MG);Machine Learning;Deep Learning (DL);Distribution Network (DN);Power System (PS)},
  doi={10.1109/ICTEM60690.2024.10631952},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10647584,
  author={Shaik, Nagur Shareef and Cherukuri, Teja Krishna and Ye, Dong Hye},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={M3T: Multi-Modal Medical Transformer To Bridge Clinical Context With Visual Insights For Retinal Image Medical Description Generation}, 
  year={2024},
  volume={},
  number={},
  pages={3037-3043},
  abstract={Automated retinal image medical description generation is crucial for streamlining medical diagnosis and treatment planning. Existing challenges include the reliance on learned retinal image representations, difficulties in handling multiple imaging modalities, and the lack of clinical context in visual representations. Addressing these issues, we propose the Multi-Modal Medical Transformer (M3T), a novel deep learning architecture that integrates visual representations with diagnostic keywords. Unlike previous studies focusing on specific aspects, our approach efficiently learns contextual information and semantics from both modalities, enabling the generation of precise and coherent medical descriptions for retinal images. Experimental studies on the DeepEyeNet dataset validate the success of M3T in meeting ophthalmologists’ standards, demonstrating a substantial 13.5% improvement in BLEU@4 over the best-performing baseline model.},
  keywords={Visualization;Visual impairment;Semantics;Streaming media;Retina;Transformers;Planning;Medical Description Generation;MultiModal Learning;Medical Image Analysis;Transformer},
  doi={10.1109/ICIP51287.2024.10647584},
  ISSN={2381-8549},
  month={Oct},}@INPROCEEDINGS{11066054,
  author={Jiang, Fangyuan},
  booktitle={2025 5th International Symposium on Computer Technology and Information Science (ISCTIS)}, 
  title={Research on Multimodal Interaction Design for UAV Operating Systems Based on Safety and Emotional Considerations}, 
  year={2025},
  volume={},
  number={},
  pages={1320-1323},
  abstract={With the wide application of unmanned aerial vehicle (UAV) technology in multiple fields, the existing interaction technologies have problems such as insufficient accuracy, large response delay and lack of emotional design in complex dynamic environments. The research focuses on constructing a multimodal fusion algorithm based on the Transformer network and optimizing the hyperparameters through the genetic algorithm. The experimental results show that the improved GATransformer model is significantly superior to the traditional methods in terms of fusion accuracy, convergence efficiency and performance in actual tasks. The GA-Transformer proposed by the research institute can provide an efficient, secure and emotionally responsive technical solution for the multimodal interaction design of unmanned aerial vehicles.},
  keywords={Information science;Accuracy;Operating systems;Heuristic algorithms;Autonomous aerial vehicles;Transformers;Safety;Vehicle dynamics;Optimization;Genetic algorithms;unmanned aerial vehicle (UAV) operating system;multimodal interaction;deep learning algorithm;safety optimization;emotional design},
  doi={10.1109/ISCTIS65944.2025.11066054},
  ISSN={},
  month={May},}@INPROCEEDINGS{10604536,
  author={Chen, Jiantao and Shu, Xin and Chen, Zhichen},
  booktitle={2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Emotion-Cause Pair Extraction with Graph Attention Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={518-522},
  abstract={Emotion-cause pair extraction (ECPE) is a method that aims to extract emotion-cause pairs of the emotions expressed in a document and their corresponding causes. By identifying emotions and their causes, ECPE can help decision-makers gain a more complete understanding of the emotional drivers of social issues and hot topics. The traditional emotional cause extraction task requires the emotional clauses to be annotated in advance, while the ECPE task breaks through this limitation. However, the existing research on the ECPE task is still insufficient in mining the deep emotional information in the emotional cause clauses. Therefore, this paper proposes a model for emotion-cause pair extraction based on Graph Neural Network and Attention Mechanism (GA-ECPE). The graph convolution operation is used to propagate semantic information by constructing heterogeneous graphs of emotional causes and emotions. Attention mechanism combined with score constraint and orthogonal constraint is used to enhance the weight of important clauses on the sentiment expression of the text. Experiments on a benchmark Chinese emotion-cause pair extraction corpus demonstrate the effectiveness of the model in mining the deep emotion of the text.},
  keywords={Attention mechanisms;Correlation;Convolution;Semantics;Feature extraction;Graph neural networks;Complexity theory;emotion-cause pair extraction;graph neural network;attention mechanism},
  doi={10.1109/ICAIBD62003.2024.10604536},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{10864230,
  author={Ma, Ge and Han, Hui and Gao, Motong and Bai, Xiaoming},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={The AOA-CNN-Attention-GRU Model for Predicting PM2.5 Concentration}, 
  year={2024},
  volume={},
  number={},
  pages={716-719},
  abstract={A bstract-One of the key variables in determining air pollution indicators is PM2.5 concentration, and accurate forecasting of PM2.5 levels is essential for mitigating air pollution and protecting public health. However, currently, available PM2.5 concentration prediction models are often simple combinations or single models. In this paper, a PM2.5 concentration prediction model based on an AOA-CNN-Attention-GRU (ACAG) combined neural network is constructed by using the pollutant concentration, meteorological factors, and NDVI time-by-time data from 2019 to 2023 in Lanzhou City, combining AOA, attention mechanism, CNN and GRU. The findings indicate that the ACAG model has the greatest accuracy in making predictions when compared to the control model, with an RMSE of 7.937 $\mu \mathrm{g}/\mathrm{m}^{3}$, an improvement of 13.6%~31.1%, an MAE of 3.329 $\mu \mathrm{g}/\mathrm{m}^{3}$, an improvement of 32.7~57.7%, and an R2 of 0.936, an improvement in goodness-of-fit by 2.3%~7.5%. This demonstrates that compared to the comparison models, the ACAG model suggested in this research performs better in terms of prediction, and can effectively predict PM2.5 concentration, to provide a scientific basis for environmental pollution control.},
  keywords={Accuracy;Attention mechanisms;Computational modeling;Atmospheric modeling;Urban areas;Neural networks;Pollution control;Predictive models;Air pollution;Public healthcare;PM2.5 concentration;Predictive model;Combined neural networks},
  doi={10.1109/ICAICE63571.2024.10864230},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10696016,
  author={Hou, Xu and Wang, Shubin},
  booktitle={2024 6th International Conference on Electronic Engineering and Informatics (EEI)}, 
  title={Research on Fault Diagnosis Method of Rotating Machinery Based on Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={203-208},
  abstract={Precise diagnosis of faults is the key to maintaining rotating machinery. Traditional fault diagnosis methods face several challenges, such as the need for manual feature extraction, difficulty in fully exploring nonlinear features, and low accuracy in noisy environments. To address these issues, this paper introduces a multi-scale fault diagnosis model called GA-Res-LSTM, which integrates the Ghost Module and attention mechanism, and incorporates residual connections in the Long Short-Term Memory (LSTM) network. This model leverages an enhanced ghost module to automatically and adaptively extract multiscale features from the original signal. The attention mechanism assigns weights to these features, focusing the model on the most critical ones. Subsequently, feature learning and enhancement are performed using residual connected LSTM networks. The Global Average Pooling (GAP) method is employed to mitigate overfitting, leading to effective fault classification of rotating machinery through the fully connected (Fc) layer. The results from our experiments indicate that the proposed method can attain high diagnostic performances in low Signal-To-Noise Ratio (SNR) environments with small operating costs. The recognition accuracy of the network under resource-constrained conditions is guaranteed.},
  keywords={Fault diagnosis;Training;Adaptation models;Accuracy;Attention mechanisms;Computational modeling;Feature extraction;Machinery;Long short term memory;Signal to noise ratio;fault diagnosis;attention mechanism;LSTM;residual connection;SNR},
  doi={10.1109/EEI63073.2024.10696016},
  ISSN={},
  month={June},}@ARTICLE{10756603,
  author={Sovatzidi, Georgia and Iakovidis, Dimitris K.},
  journal={IEEE Access}, 
  title={FCMCoach: Personalized Virtual Coaching Based on Fuzzy Cognitive Maps}, 
  year={2024},
  volume={12},
  number={},
  pages={174413-174423},
  abstract={Exercise has a major impact on quality of life, as it improves mental health by reducing stress and negative emotions. Exercise should be personalized in order to be both effective and safe for the target individual, as excessive and high-intensity training may cause health problems, such as immune or respiratory system dysfunction. Although deep learning approaches have been proposed for exercise recommendations, it still remains a challenge to design a personalized coaching system that provides interpretations about its decisions, thereby gaining user trust. This paper introduces a novel user-centered virtual coaching (VC) framework for physical exercise. In this framework a Fuzzy Cognitive Map (FCM) plays the role of a virtual coach; it configures suitable paths for users to navigate, based on their desired exercise intensity, as well as their physiological measurements obtained from wearable sensors, during their exercise. The contributions of the proposed framework, named FCMCoach, include the following: i) a novel VC FCM that automatically determines its structure through a supervised process; ii) a dynamic personalized adaptation mechanism enabling the FCM graph to change its parameters based on the evoked physiological measurements and adapt to any desired path the users want to navigate, iii) an inherent interpretation mechanism capable of explaining the decisions of the FCM to the users, thus gaining their trust. The effectiveness of the proposed framework is demonstrated on a dataset representing a population of 200 subjects, created using measurements from a real recreational area in Greece, with several nature trails. The results validate its capacity to determine suitable paths personalized to the users’ needs with an accuracy of 83%.},
  keywords={Training;Navigation;Heart rate;Physiology;Fuzzy cognitive maps;Vectors;Testing;Particle swarm optimization;Mathematical models;Heuristic algorithms;Virtual coaching;exercise;fuzzy cognitive maps (FCMs);interpretability;decision support},
  doi={10.1109/ACCESS.2024.3501675},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9746895,
  author={Zhuang, Cheng and Sun, Yunlian},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Ganet: Unary Attention Reaches Pairwise Attention Via Implicit Group Clustering in Light-Weight CNNs}, 
  year={2022},
  volume={},
  number={},
  pages={2140-2144},
  abstract={The attention mechanism has been widely explored to construct a long-range connection which is beyond the realm of convolutions. The two groups of attention, unary and pair-wise attention, seem like being incompatible as fire and water due to the completely different operations. In this paper, we propose a Group Attention (GA) block to bridge the gap between these two attentions and merely leverage unary attention to lightweightly reach the effect of pairwise attention, based on the implicit group clustering of light-weight CNNs. Compared with the conventional pairwise attention, i.e, Non-Local networks, our method artfully bypasses the burdensome pixel-pair calculation to save a huge computational cost, that is a big advantage of our work. Experiments on the task of image classification demontrate the effectiveness and efficiency of our GA block to enhance the light-weight models. Code will be released at https://github.com/ChiSuWq/GANet.},
  keywords={Convolutional codes;Convolution;Conferences;Computational modeling;Acoustics;Computational efficiency;Task analysis;Non-Local networks;attention mechanism;light-weight CNNs;image classification},
  doi={10.1109/ICASSP43922.2022.9746895},
  ISSN={2379-190X},
  month={May},}@ARTICLE{10339663,
  author={Lin, Jiabin and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Evolutionary Multitasking for Multiobjective Feature Selection in Classification}, 
  year={2024},
  volume={28},
  number={6},
  pages={1852-1866},
  abstract={Evolutionary multiobjective optimization has shown success in feature selection. However, existing methods often address these tasks independently, disregarding their potential interconnections and shared knowledge. On the other hand, evolutionary multitasking (EMT) has been utilized to address multiple related tasks simultaneously and transfer common knowledge. However, most EMTL-based feature selection methods prioritize a single task, and treat it as the main task and the other tasks as auxiliary or secondary tasks. To overcome this limitation, we propose a novel multiobjective feature selection method based on EMT in this article. The new method introduces a novel representation that consolidates the solutions of multiple interconnected feature selection tasks into a single solution. It enables these tasks to share a common population, thereby enhancing the effectiveness and efficiency of transferring common knowledge across them. In addition, a novel searching method is devised to facilitate the evolution of the population across multiple tasks, enabling effective knowledge transfer between them. Finally, a transformation method is introduced to transfer valuable genes among the solutions for multiple tasks, thereby enhancing the overall performance of the proposed algorithm when confronted with tasks characterized by distinct features. This method effectively addresses multiple feature selection tasks simultaneously, offering a comprehensive solution to the aforementioned issue. Compared with four single-task multiobjective feature selection methods and a state-of-the-art EMT-based feature selection method, the proposed method demonstrates superior feature selection performance across the majority of benchmark datasets.},
  keywords={Task analysis;Feature extraction;Statistics;Sociology;Optimization;Multitasking;Search problems;Evolutionary multitasking (EMT);feature selection;multiobjective optimization},
  doi={10.1109/TEVC.2023.3338740},
  ISSN={1941-0026},
  month={Dec},}@ARTICLE{10531647,
  author={Zhao, Jianwei and Chang, Dingjun and Cao, Bin and Liu, Xin and Lyu, Zhihan},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Multiobjective Evolution of the Deep Fuzzy Rough Neural Network}, 
  year={2025},
  volume={33},
  number={1},
  pages={242-254},
  abstract={Deep learning has made remarkable achievements in many fields. However, although fuzzy neural networks with natural interpretability are widely used in prediction and control scenarios, there are very few studies on the deepening of fuzzy systems. By integrating rough set theory, fuzzy rough neural network has unique advantages benefiting from the complementarity of the fuzzy set theory and the rough set theory as well as the powerful learning ability of neural networks. Similarly, research on deep fuzzy rough neural networks is even rarer. In this article, in order to improve the performance of the fuzzy rough neural network and expand its application range, the deep fuzzy rough neural network model is constructed and optimized by stacking blocks of fuzzy rough neural network to imitate the deepening deep neural network based on multiobjective evolution. Each fuzzy rough neural network block is interpretable, and its stacked architecture also has high interpretability. To automatically generate deep fuzzy rough neural network models with high efficiency, a distributed parallel multiobjective neuroevolution framework is developed, thus blocks can be stacked flexibly and deep architecture can be optimized considering multiple optimization objectives of accuracy, interpretability, and generalization simultaneously. In addition, multiobjective evolution is combined with Wang–Mendel method, pseudoinverse, and backpropagation to effectively learn specific parameters. Finally, based on the time series prediction problems, the superiority of the multiobjective deep fuzzy rough neural network evolutionary framework is verified.},
  keywords={Rough sets;Fuzzy neural networks;Fuzzy systems;Fuzzy set theory;Optimization;Artificial neural networks;Fuzzy sets;Deep fuzzy rough neural network (DFRNN);deep learning (DL);multiobjective evolution;neuroevolution;time series prediction},
  doi={10.1109/TFUZZ.2024.3397728},
  ISSN={1941-0034},
  month={Jan},}@INPROCEEDINGS{10071388,
  author={Zhang, Kun and Xu, Chi},
  booktitle={2022 4th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM)}, 
  title={A Evolutionary Behavior Tree AI for Neural MMO Challenge}, 
  year={2022},
  volume={},
  number={},
  pages={327-332},
  abstract={The Neural MMO Challenge aims to study robustness and teamwork in large-scale multi-agent environments. AI needs to explore, search and fight in large-scale environments, and get higher scores than other competitors. Therefore, we developed AI based on evolutionary behavior tree, which has the advantages of strong interpretability, low coupling between modules and strong robustness. Specifically, the AI adopts the idea of divide and conquer, divides the decision-making into two levels: team and individual, divides the four task achievements into several subtasks, finds appropriate agents for each subtask according to the current advantages, and then completes specific actions such as attack, foraging, avoidance and collaboration, and optimizes the parameters with evolutionary strategy algorithm.AI won the silver medal in IJCAI 2022 Neural MMO Challenge.},
  keywords={Couplings;Silver;Machine learning algorithms;Decision making;Neural networks;Robustness;Behavioral sciences;Behavior tree;evolutionary algorithm;nmmo;multi-agent decision-making},
  doi={10.1109/AIAM57466.2022.00069},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10780038,
  author={Dhayanithi, A and Bala, K.},
  booktitle={2024 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, 
  title={Enhanced Detection of Eye Coloboma through Global Attention U-Net (GA-UNet) for Accurate Ophthalmic Image Segmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Eye coloboma is classified as a congenital eye disease that results in developmental anomalies of the eye that may result in eye diseases that essentially alter visions. Fractional and timely diagnosis still matter significantly in its effective managing and treating. This work presents a solution with a Transformer-Enhanced U-Net model that was developed with Transfer Learning to help augment the market’s ability to identify and delineate eye coloboma from medical images. This work further extend the gains made in U-Net, that has achieved fairly well especially in the biomedical image segmentation problem, with the inclusion of transformer modules for the incorporation of the long range dependencies and contextual information. This enhancement help the model to attend more on such small features as coloboma and overall diagnostic accuracy in addition. By using Transfer Learning with a pretrained backbone such as Efficient Net, feature representations from large pre-existing datasets are fed to the system as a solution to the reduction of training time and while the performance of the system drops no further effect is experienced.The approach involves the use of fine-tuning with Transformer-Enhanced U-Net model utilizing a subset of the eye images, which are labelled according to the existence of coloboma. Next, by adopting the self-attention mechanism, the model becomes able to pay attention to the relevant areas in the image, and hence is sensitive to any form of coloboma. In initial experiments, this scheme outperforms the standard convolutional networks for segmenting complex regions with minimal false negative rates. Moreover, by comparing the features extracted at deep layers with ground truth, the effectiveness of the model to realistic clinical usage is established given that the model is robust to changes in imaging conditions. The purpose of this research therefore is to develop an Auto-Generated diagnostic tool that will be more reliable as it assists the ophthalmologists in identifying early symptoms of the illnesses relating to the eye thus promoting improved positive results for eye patients.},
  keywords={Training;Image segmentation;Visualization;Accuracy;Biological system modeling;Transfer learning;Transformers;Feature extraction;Eye diseases;Standards;Eye Coloboma;Deep Learning;Image Segmentation;Attention Mechanism;Transfer Learning;Medical Imaging;Automated Diagnosis},
  doi={10.1109/ICPECTS62210.2024.10780038},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10947849,
  author={Pamulaparthyvenkata, Saigurudatta and Balakrishnan, Anandaganesh and Desani, Nithin Reddy and Palanisamy, Preethi},
  booktitle={2024 International Conference on Artificial Intelligence and Emerging Technology (Global AI Summit)}, 
  title={Optimized Hybrid Deep Neural Networks for Efficient Alzheimer's Disease Classification}, 
  year={2024},
  volume={},
  number={},
  pages={463-468},
  abstract={Artificial Neural Networks (ANNs) tuned with least square optimization PSO are used in the present training to take on the problem of Alzheimer's disease prediction. Several studies have demonstrated the reliability of ANN-based techniques in estimating LSM. However, most ANN training methods face significant challenges, such as low learning rates and being unable to move beyond the indigenous minimal amount. The visibility of ANN is improved by resquare optimization techniques algorithms (ROA) such as the PSO container. Typical practitioners don't undertake any sort of success planning to identify network design or pertinent components before applying PSO prototypes to ANN training. This led us to focus on a mock-up ANN mixing request for a fuzzy-based forecast in the present investigation. After the Alzheimer's disease was discovered, a substantial quantity of data was collected for the ICA-SVM-ANN and AD-ICA-PSO-ROA-ANN network models. The total number of records collected was 9467 for preparation and 45175 for testing. Exercise and difficult datasets were created using these data. The PSO algorithm's settings (such as system limits and loads) were kept at their optimal levels to guarantee the highest possible return on investment. One numerical catalogue, A method known as Real Root-Mean-Squared Error (RRMSE) was utilised in order to determine the predicted outcomes of a model for both the training data set and the testing data set. Therefore, the combined replicas gave a good performance, but the hybrid ANN model may be more effective than ANN, as measured by the scoring system developed. In addition, the inferential results showed that the AD-ROA-PSO-ANN prototype performed better than both the ANN and mixed Neural models at the same time.},
  keywords={Training;Prototypes;Artificial neural networks;Prediction algorithms;Numerical models;Planning;Alzheimer's disease;Optimization;Testing;Load modeling;Discrete wavelet transform;Deep Learning;clinical data;operational magnetic resonance imaging and radiation therapy},
  doi={10.1109/GlobalAISummit62156.2024.10947849},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11034073,
  author={Feng, Yuanyuan and Liang, Xiaojiao and Li, Pengfei and Kang, Jian and Wang, Jianhua and Yu, Wenyan and Geng, Haowen},
  booktitle={2025 8th International Conference on Energy, Electrical and Power Engineering (CEEPE)}, 
  title={Research on Air Conditioning Energy-Saving Optimization Method Based on Multidimensional Data Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={540-545},
  abstract={With the intensifying global climate change and the continuous rise in energy consumption, optimizing energy efficiency in building air conditioning systems has become a key measure for enhancing building performance and reducing carbon emissions. Against this backdrop, accurate air conditioning load prediction is not only the foundation for intelligent control and energy-saving optimization of air conditioning systems but also a crucial step in improving overall energy management efficiency. Firstly, this study utilizes deep learning techniques, including a three-layer pyramid convolutional neural network (CNN3-P), an attention mechanism(Attention), and a gated recurrent unit (GRU), to effectively extract multi-level features from air conditioning load data. Next, the non-dominated sorting genetic algorithm II (NSGA-II) is employed for multi-objective optimization to maximize energy efficiency and system stability. Finally, this study proposes an air conditioning energy-saving optimization strategy that integrates the three-layer pyramid convolutional neural network-attention mechanism- gated recurrent unit (CNN3P-Attention-GRU) prediction model with the NSGA-II multi-objective optimization method. Experimental results demonstrate that the proposed prediction model significantly outperforms traditional long short-term memory (LSTM), GRU, and convolutional neural network- long short-term memory (CNN-LSTM) models across multiple performance metrics, achieving higher prediction accuracy and better adaptability.},
  keywords={Air conditioning;Adaptation models;Energy consumption;Accuracy;Atmospheric modeling;Optimization methods;Predictive models;Energy efficiency;Convolutional neural networks;Long short term memory;Attention mechanism;GRU;NSGA-II;Multi-objective optimization},
  doi={10.1109/CEEPE64987.2025.11034073},
  ISSN={},
  month={April},}@ARTICLE{10064013,
  author={Li, Lingjie and Xuan, Manlin and Lin, Qiuzhen and Jiang, Min and Ming, Zhong and Tan, Kay Chen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={An Evolutionary Multitasking Algorithm With Multiple Filtering for High-Dimensional Feature Selection}, 
  year={2023},
  volume={27},
  number={4},
  pages={802-816},
  abstract={Recently, evolutionary multitasking (EMT) has been successfully used in the field of high-dimensional classification. However, the generation of multiple tasks in the existing EMT-based feature selection (FS) methods is relatively simple, using only the Relief- ${F}$  method to collect related features with similar importance into one task, which cannot provide more diversified tasks for knowledge transfer. Thus, this article devises a new EMT algorithm for FS in high-dimensional classification, which first adopts different filtering methods to produce multiple tasks and then modifies a competitive swarm optimizer (CSO) to efficiently solve these related tasks via knowledge transfer. First, a diversified multiple task generation method is designed based on multiple filtering methods, which generates several relevant low-dimensional FS tasks by eliminating irrelevant features. In this way, useful knowledge for solving simple and relevant tasks can be transferred to simplify and speed up the solution of the original high-dimensional FS task. Then, a CSO is modified to simultaneously solve these relevant FS tasks by transferring useful knowledge among them. Numerous empirical results demonstrate that the proposed EMT-based FS method can obtain a better feature subset than several state-of-the-art FS methods on 18 high-dimensional datasets.},
  keywords={Task analysis;Knowledge transfer;Convergence;Filtering;Feature extraction;Multitasking;Search problems;Competitive swarm optimizer (CSO);evolutionary algorithm (EA);evolutionary multitasking (EMT);feature selection (FS);high-dimensional classification},
  doi={10.1109/TEVC.2023.3254155},
  ISSN={1941-0026},
  month={Aug},}@ARTICLE{10242063,
  author={Nijaguna, G. S. and Lal, N. Dayananda and Divakarachari, Parameshachari Bidare and Prado, Rocío Pérez de and Woźniak, Marcin and Patra, Raj Kumar},
  journal={IEEE Access}, 
  title={Feature Selection Using Selective Opposition Based Artificial Rabbits Optimization for Arrhythmia Classification on Internet of Medical Things Environment}, 
  year={2023},
  volume={11},
  number={},
  pages={100052-100069},
  abstract={An Electrocardiogram (ECG) is a non-invasive test that is broadly utilized for monitoring and diagnosing the cardiac arrhythmia. An irregularity of the heartbeat is generally defined as arrhythmia, which potentially causes the fatal difficulties that creates an instantaneous life risk. Therefore, the arrhythmia classification is a challenging task because of the overfitting issue caused by high dimensional feature space of ECG signal. In this research, the incorporation of the Internet of Medical Things (IoMT) is developed with artificial intelligence to provide the health monitoring for people who are having arrhythmia. In this work, the time, time-frequency, entropy, nonlinearity features of ECG and deep features of ECG from Convolutional Neural Network (CNN) are extracted to obtain different categories of ECG signal features. The Selective Opposition (SO) strategy based Artificial Rabbits Optimization (SOARO) is proposed for selecting the optimal feature subset from the overall features to avoid the overfitting issue. The chosen features are used to improve the classification done by Auto Encoder (AE). Further, the Shapley additive explanations (SHAP) based model is used to interpret the classified output from AE. The MIT-BIH arrhythmia database is used for evaluating the proposed SOARO-AE. The performance of the proposed SOARO-AE is evaluated by using the accuracy, sensitivity, specificity, recall and F1-Measure. The existing researches such as C-LSTM, DL-LAC-CNN, CNN-DNN, MC-ECG, FC and MEAHA-CNN are used to evaluate the SOARO-AE method. The accuracy of SOARO-AE is 98.89% which is high when compared to the C-LSTM, DL-LAC-CNN, CNN-DNN, FC and MEAHA-CNN.},
  keywords={Electrocardiography;Arrhythmia;Feature extraction;Monitoring;Diseases;Heart;Optimization;Encoding;Biomedical monitoring;Internet of Medical Things;Arrhythmia;artificial rabbits optimization;auto encoder;electrocardiogram;health monitoring;internet of medical things;selective oppositio},
  doi={10.1109/ACCESS.2023.3312537},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10590020,
  author={Wan, Zishen and Liu, Che-Kai and Yang, Hanchen and Raj, Ritik and Li, Chaojian and You, Haoran and Fu, Yonggan and Wan, Cheng and Samajdar, Ananda and Lin, Yingyan Celine and Krishna, Tushar and Raychowdhury, Arijit},
  booktitle={2024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Towards Cognitive AI Systems: Workload and Characterization of Neuro-Symbolic AI}, 
  year={2024},
  volume={},
  number={},
  pages={268-279},
  abstract={The remarkable advancements in artificial intel-ligence (AI), primarily driven by deep neural networks, are facing challenges surrounding unsustainable computational tra-jectories, limited robustness, and a lack of explainability. To develop next-generation cognitive AI systems, neuro-symbolic AI emerges as a promising paradigm, fusing neural and symbolic approaches to enhance interpretability, robustness, and trustwor-thiness, while facilitating learning from much less data. Recent neuro-symbolic systems have demonstrated great potential in collaborative human-AI scenarios with reasoning and cognitive capabilities. In this paper, we aim to understand the workload characteristics and potential architectures for neuro-symbolic AI. We first systematically categorize neuro-symbolic AI algorithms, and then experimentally evaluate and analyze them in terms of runtime, memory, computational operators, sparsity, and system characteristics on CPUs, GPUs, and edge SoCs. Our studies reveal that neuro-symbolic models suffer from inefficiencies on off-the-shelf hardware, due to the memory-bound nature of vector-symbolic and logical operations, complex flow control, data dependencies, sparsity variations, and limited scalability. Based on profiling insights, we suggest cross-layer optimization solutions to improve the performance, efficiency, and scalability of neuro-symbolic computing. Finally, we discuss the challenges and potential future directions of neuro-symbolic AI from both system and architectural perspectives.},
  keywords={Runtime;Scalability;System performance;Robustness;Software;Hardware;Performance analysis},
  doi={10.1109/ISPASS61541.2024.00033},
  ISSN={2766-0486},
  month={May},}@ARTICLE{10452805,
  author={Parra, Daniel and Joedicke, David and Velasco, J. Manuel and Kronberger, Gabriel and Hidalgo, J. Ignacio},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Learning Difference Equations With Structured Grammatical Evolution for Postprandial Glycaemia Prediction}, 
  year={2024},
  volume={28},
  number={5},
  pages={3067-3078},
  abstract={People with diabetes must carefully monitor their blood glucose levels, especially after eating. Blood glucose management requires a proper combination of food intake and insulin boluses. Glucose prediction is vital to avoid dangerous post-meal complications in treating individuals with diabetes. Although traditional methods, and also artificial neural networks, have shown high accuracy rates, sometimes they are not suitable for developing personalised treatments by physicians due to their lack of interpretability. This study proposes a novel glucose prediction method emphasising interpretability: Interpretable Sparse Identification by Grammatical Evolution. Combined with a previous clustering stage, our approach provides finite difference equations to predict postprandial glucose levels up to two hours after meals. We divide the dataset into four-hour segments and perform clustering based on blood glucose values for the two-hour window before the meal. Prediction models are trained for each cluster for the two-hour windows after meals, allowing predictions in 15-minute steps, yielding up to eight predictions at different time horizons. Prediction safety was evaluated based on Parkes Error Grid regions. Our technique produces safe predictions through explainable expressions, avoiding zones D (0.2% average) and E (0%) and reducing predictions on zone C (6.2%). In addition, our proposal has slightly better accuracy than other techniques, including sparse identification of non-linear dynamics and artificial neural networks. The results demonstrate that our proposal provides interpretable solutions without sacrificing prediction accuracy, offering a promising approach to glucose prediction in diabetes management that balances accuracy, interpretability, and computational efficiency.},
  keywords={Glucose;Mathematical models;Predictive models;Blood;Diabetes;Insulin;Computational modeling;Diabetes;machine learning;system dynamics;symbolic regression;evolutionary computation;neural networks},
  doi={10.1109/JBHI.2024.3371108},
  ISSN={2168-2208},
  month={May},}@INPROCEEDINGS{10534415,
  author={Chy, Nishat Soultana and Biswas, Sourav and Chy, Abu Nowshed and Halim, Mohammad A. and Seddiqui, Md. Hanif},
  booktitle={2024 6th International Conference on Electrical Engineering and Information & Communication Technology (ICEEICT)}, 
  title={Machine Learning Based Prediction of Anti-dengue Drugs Using Structure-activity Relationship Study}, 
  year={2024},
  volume={},
  number={},
  pages={499-504},
  abstract={Dengue fever has emerged as a critical health threat in Bangladesh and recorded the highest mortality rate in 2023. It is also a global concern, impacting 390 million people annually. No FDA-approved drug is available yet to treat dengue. The Structure-activity relationship (SAR) can be a significant approach for predicting novel inhibitors and repurposing existing drugs against dengue. This study aims to develop a machine-learning model that can predict the pIC50 (M) value of novel inhibitors against the dengue NS2B-NS3 protein. In this connection, this methodology uses a structure-activity dataset of 1141 compounds. Each compound contains 1544 molecular descriptors (ID and 2D) considered as structural features and their effective percentage inhibition concentration at 50% (pIC50), against 'DENV-2 NS2B-NS3‘. This research implements 9 tree-based, and 9 other distinct machine learning algorithms considering all features to identify the best-performing algorithm. In the baseline test, the tree-based algorithms outperform the other conventional algorithms where the Extra Trees algorithm performs the best among the tree-based algorithms. Furthermore, the study utilizes the Random Forest algorithm to extract individual features' importance against pIC50. The features are fed into 6 different tree-based algorithms in the chronology of feature importance. The experiments depict an impressive result that some of the features have a negative impact on prediction. Eventually, the work eliminates 1502 molecular descriptors to differentiate only 42 important features that can produce the lowest RMSE of 0.3035, MSE of 0.0924 MAPE of 0.0515, and MAE of 0.2309. This optimized model has outperformed the baseline model evidently.},
  keywords={Drugs;Proteins;Machine learning algorithms;Inhibitors;Predictive models;Prediction algorithms;Feature extraction;Machine learning;Dengue;DENV2 NS3-NS2B;Drug discovery;Structure-Activity Relationship;Extra trees;Random forest feature importance},
  doi={10.1109/ICEEICT62016.2024.10534415},
  ISSN={2769-5700},
  month={May},}@ARTICLE{9716889,
  author={Umar Bin Farooq, Muhammad and Manalastas, Marvin and Raza, Waseem and Zaidi, Syed Muhammad Asad and Rizwan, Ali and Abu-Dayya, Adnan and Imran, Ali},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={A Data-Driven Self-Optimization Solution for Inter-Frequency Mobility Parameters in Emerging Networks}, 
  year={2022},
  volume={8},
  number={2},
  pages={570-583},
  abstract={Densification and multi-band operation means inter-frequency handovers can become a bottleneck for mobile user experience in emerging cellular networks. The challenge is aggravated by the fact that there does not exist a method to optimize key inter-frequency handover parameters namely A5 time-to-trigger, A5-threshold1 and A5-threshold2. This paper presents a first study to analyze and optimize the three A5 parameters for jointly maximizing three key performance indicators that reflect mobile user experience: handover success rate (HOSR), reference signal received power (RSRP), and signal-to-interference-plus-noise-ratio (SINR). As analytical modeling cannot capture the system-level complexity, we exploit a data-driven approach. To minimize the training data generation time, we exploit shapley additive explanations (SHAP) sensitivity analysis. The insights from SHAP analysis allow the selective collection of the training data thereby enabling the easier implementation of the proposed solution in a real network. We show that joint RSRP, SINR and HOSR optimization problem is non-convex and solve it using genetic algorithm (GA). We then propose an intelligent mutation scheme for GA, which makes the solution 5x times faster than the legacy GA and 21x faster than the brute force search. This paper thus presents first solution to implement computationally efficient closed-loop self-optimization of inter-frequency mobility parameters.},
  keywords={Optimization;Handover;Hysteresis;Signal to noise ratio;Interference;5G mobile communication;Cellular networks;Mobility Management;Handover Optimization;5G;6G;Machine Learning},
  doi={10.1109/TCCN.2022.3152510},
  ISSN={2332-7731},
  month={June},}@ARTICLE{9950311,
  author={Juang, Chia-Feng and Pan, Guan-Ren and Huang, Wei-Chang and Wen, Chih-Yu and Wu, Ming-Feng},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Multiobjective Optimization of Interpretable Fuzzy Systems and Applicable Subjects for Fast Estimation of Obstructive Sleep Apnea-Hypopnea Severity}, 
  year={2023},
  volume={31},
  number={7},
  pages={2225-2237},
  abstract={This article proposes an interpretable fuzzy estimation system (IFES) for fast estimation of severity of obstructive sleep apnea-hypopnea syndrome (OSAHS) using three easily available physiological variables: neck circumference, waist circumference, and average blood pressure after waking up. The IFES aims to decrease the waiting list of polysomnography so that OSAHS treatment can be performed as soon as possible. The IFES is optimized to achieve the following three objectives: high estimation accuracy, the largest number of applicable subjects, and high model interpretability. The applicable subjects are determined by evaluating the influence of six screening factors, such as smoking, hypertension, and sleep efficiency, on the estimation performance. This article finds solutions of this multiobjective optimization problem using a multiobjective genetic algorithm. A total of 1197 participants are enrolled with the five-fold cross-validation scheme employed to evaluate an estimation performance. Experimental results show that the proposed method successfully finds the influence of different screening factors and the found IFESs outperform different estimation models used for comparison.},
  keywords={Estimation;Optimization;Medical diagnostic imaging;Indexes;Hypertension;Sleep apnea;Fuzzy neural networks;Apnea-hypopnea index (AHI);evolutionary fuzzy systems;fuzzy systems;interpretable AI;multiobjective optimization;obstructive sleep apnea},
  doi={10.1109/TFUZZ.2022.3222033},
  ISSN={1941-0034},
  month={July},}@INPROCEEDINGS{10216762,
  author={Farahani, Abolfazl and Tonekaboni, Navid Hashemi and Rasheed, Khaled and Arabnia, Hamid R.},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={HPGER: Integrating Human Perception Into Group Emotion Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={1442-1446},
  abstract={Over the past few years, deep neural networks have been widely employed for representation learning and achieved remarkable success in many computer vision tasks, such as visual sentiment analysis and emotion recognition. However, identifying image sentiments similar to what humans do is challenging due to the complexity of raw images and the intangible nature of human visual perception. Besides, training a deep learning model from scratch for a complex task such as group emotion recognition is very time-consuming and requires a large amount of labeled data representing the total population which is practically infeasible. In addition, creating annotated data for each specific task is costly and sometimes impossible. So instead, we can use the knowledge extracted by a model trained on related existing labeled datasets. To address the above challenges, we propose an end-to-end group emotion recognition framework that integrates human perception learned from human eye fixation data to efficiently and effectively extract the sentiment of input images and classify them as positive, negative, or neutral. The proposed architecture aims to leverage the information in eye fixation data to learn how humans perceive and interpret the visual world in a free-viewing task. Our framework can be utilized in any free-viewing task, potentially reducing the need for a large amount of labeled data and speeding up the training phase. In the following sections, The following sections outline the initial steps and describe different parts of our architecture.},
  keywords={Training;Emotion recognition;Visualization;Analytical models;Computational modeling;Computer architecture;Predictive models;Sentiment Analysis;Group Emotion Recognition;Visual Attention;Visual Saliency;Object Detection;Eye-tracking;Human Perception},
  doi={10.1109/CSCI58124.2022.00257},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{11071045,
  author={K, Pradeep and Farooqui, Yassir and Ramkumar, K. Bharat and Divekar, Rajiv},
  booktitle={2025 3rd International Conference on Data Science and Information System (ICDSIS)}, 
  title={Hybrid Deep Learning Optimization for Predicting the Spread of Emerging Infectious Diseases}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The accurate prediction of emerging infectious disease spread is essential for timely public health interventions, yet traditional models often fall short in capturing the complex spatial-temporal dynamics involved. This study introduces a Hybrid Deep Learning Optimization (HDLO) framework that integrates Convolutional Neural Networks (CNNs) for spatial feature extraction, Long Short-Term Memory (LSTM) networks for temporal sequence modeling, and Particle Swarm Optimization (PSO) for hyperparameter tuning. The framework processes heterogeneous data—including epidemiological records, environmental indicators, and mobility patterns—through preprocessing steps such as normalization, handling missing values, and class balancing using SMOTE. The CNN and LSTM outputs are fused and optimized by PSO to enhance predictive performance while maintaining computational efficiency. Evaluated on real-world datasets, including COVID-19 case trends, the HDLO achieved superior results with lower Mean Absolute Error (2.41), Root Mean Squared Error (3.85), and a higher F1-Score (0.91) compared to SEIR and standalone deep learning models. Visualization tools such as spatial heatmaps and trend graphs aid interpretability, and uncertainty intervals enhance decision-making. The HDLO framework demonstrates strong potential for dynamic, realtime forecasting of infectious diseases, offering a accurate, solution that sets a new benchmark for predictive modelling in epidemiology.},
  keywords={Deep learning;Accuracy;Infectious diseases;Computational modeling;Predictive models;Market research;Data models;Convolutional neural networks;Epidemiology;Long short term memory;emerging infectious diseases;hybrid deep learning;predictive modelling;epidemiology;metaheuristic optimization},
  doi={10.1109/ICDSIS65355.2025.11071045},
  ISSN={},
  month={May},}@INPROCEEDINGS{10939596,
  author={Kumar, Manish and Kumar, J. Lalith and Nikam, Rahul J and Hudar, Jayant Maruti and Hasan, Sameena and Padhee, Sandipta},
  booktitle={2025 First International Conference on Advances in Computer Science, Electrical, Electronics, and Communication Technologies (CE2CT)}, 
  title={Artificial Intelligence in Legal Practice: Enhancing Case Prediction and Legal Research}, 
  year={2025},
  volume={},
  number={},
  pages={279-283},
  abstract={Legal case prediction (LCP) and decision assistance strive to allow systems to forecast the outcome of legal cases after comprehending an explanation of the evidence, using artificial intelligence (AI) in legal practices. This work offers an enhanced supervision-based LCP framework that accounts for the consecutive dependency of every sub-task in the LCP activity. The empirical outcomes confirm the efficiency of the conceptual paradigm and the procedure surveillance process used in this structure. Initially, textual characteristics were extracted using the convolutional neural network (CNN) technique, and then data characteristics were reduced in size using the principal component assessment method. The predictive paradigm built around supervision analysis is then presented initially. When simulating the dependent connection between consecutive sub-data collections, supervision analysis is used to assure the accuracy of the acquired dependent data, while a genetic algorithm is used to maximize the variables and enhance the final case prediction efficiency. When evaluated with the standard approach, the proposed method produced outstanding outcomes on 4 separate publicly accessible legal databases. The implementation of autonomous LCP can not just help lawyers, attorneys, and other specialists make more effective legal decisions, but it additionally offers legal assistance to persons who lack legal understanding.},
  keywords={Training;Accuracy;Law;Databases;Surveillance;Transforms;Convolutional neural networks;Artificial intelligence;Standards;Genetic algorithms;Legal Case Prediction;Artificial intelligence;Convolution neural network;Genetic algorithm;Legal practices},
  doi={10.1109/CE2CT64011.2025.10939596},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10690852,
  author={Singh, Indu and Desugari, Hemanth Siddharth and Wadehra, Shaurya and Karthik, Venkata Sai},
  booktitle={2024 International Conference on Data Science and Network Security (ICDSNS)}, 
  title={Spam Email Detection Using HAN-LSTM Network Optimized with Novel Hybrid Bonobo Optimizer and Hunger Games Search Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In today's digital world, spam email has grown to be a serious problem that causes problems for email service providers as well as subscribers. Creating a reliable system that can effectively filter out spam emails is required to address this problem. This paper proposes a novel approach to spam email detection that combines advanced feature engineering and hybrid metaheuristic optimization. The proposed method employs Bidirectional Encoder Representations from Transformers (BERT) to derive dense feature vectors, followed by a HAN-LSTM network for improved feature representation and classification. Additionally, we introduce a novel hybrid metaheuristic optimization algorithm comprising of Bonobo Optimizer and Hunger Games Search (hBOHGS) that combines the collaborative exploration of Bonobo Optimizer with the competitive selection of Hunger Games Search to efficiently find optimal values for the parameters in the HAN-LSTM network. Our experimental evaluation on the Enron 1 spam dataset demonstrates the effectiveness of our methodology, achieving an accuracy of 98.04%, a recall of 0.99, and a precision of 0.98. These findings highlight the practical applicability of our system in effectively detecting spam emails, providing a promising alternative in the field of spam email detection.},
  keywords={Unsolicited e-mail;Games;Network security;Filtering algorithms;Data science;Transformers;Feature extraction;Vectors;Encoding;Reliability;Spam Email Filtering;Semantic Embedding;Hierarchical Attention Network;Long-Short Term Memory;bonobo optimizer;Hunger Games Search},
  doi={10.1109/ICDSNS62112.2024.10690852},
  ISSN={},
  month={July},}@ARTICLE{10509639,
  author={Zhang, Weishan and Wang, Yue and Chen, Xiang and Cai, Zhipeng and Tian, Zhi},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Spectrum Transformer: An Attention-Based Wideband Spectrum Detector}, 
  year={2024},
  volume={23},
  number={9},
  pages={12343-12353},
  abstract={Data-driven machine learning techniques have been advocated for signal detection in complex wireless environments. However, when applied to wideband spectrum sensing scenarios, they face practical challenges including very large data dimensionality, insufficient training data, and implicit inter-band dependencies. Current literature focuses on deep convolutional models, whose inherent model structure is not well suited for representing the diverse spectrum occupancy patterns of practical wideband networks, causing inefficient performance-complexity tradeoff and excessive sensing time. To address these issues, this paper develops a novel Spectrum Transformer with multi-task learning for wideband spectrum sensing at high sample efficiency. Empowered by the multi-head self-attention mechanism, the transformer architecture is designed to effectively learn both the inner-band spectral features and the inter-band spectrum occupancy correlations in the wideband regime. Simulations show that the proposed Spectrum Transformer outperforms the existing methods based on convolutional neural networks especially in the small-data case, by achieving higher sensing accuracy with an 89% reduction in model complexity.},
  keywords={Wideband;Sensors;Transformers;Detectors;Computational modeling;Correlation;Convolutional neural networks;Spectrum transformer;cognitive radio;wideband spectrum sensing;deep neural network;multi-head self-attention mechanism},
  doi={10.1109/TWC.2024.3391515},
  ISSN={1558-2248},
  month={Sep.},}@ARTICLE{9514445,
  author={Abid, Chaima and Rzig, Dhia Elhaq and Ferreira, Thiago do Nascimento and Kessentini, Marouane and Sharma, Tushar},
  journal={IEEE Transactions on Software Engineering}, 
  title={X-SBR: On the Use of the History of Refactorings for Explainable Search-Based Refactoring and Intelligent Change Operators}, 
  year={2022},
  volume={48},
  number={10},
  pages={3753-3770},
  abstract={Refactoring is widely adopted nowadays in industry to restructure the code and meet high quality while preserving the external behavior. Many of the existing refactoring tools and research are based on search-based techniques to find relevant recommendations by finding trade-offs between different quality attributes. While these techniques show promising results on open-source and industry projects, they lack explanations of the recommended changes which can impact their trustworthiness when adopted in practice by developers. Furthermore, most of the adopted search-based techniques are based on random population generation and random change operators (e.g., crossover and mutation). However, it is critical to understand which good refactoring patterns may exist when applying change operators to either keep them or exchange with other solutions rather than destroying them with random changes. In this paper, we propose knowledge-informed change operators and an improved seeding mechanism that we integrated in a multi-objective genetic algorithm. We also provide explanations for refactoring solutions. First, we generate association rules using the Apriori algorithm to find relationships between applied refactorings in previous commits, their locations, and their rationale (quality improvements). Then, we use these rules to 1) initialize the population, 2) improve the change operators and seeding mechanisms of the multi-objective search in order to preserve and exchange good patterns in the refactoring solutions, and 3) explain how a sequence of refactorings collaborate in order to improve the quality of the system (e.g., fitness functions). The validation on large open-source systems shows that X-SBR provides refactoring solutions of a better quality than those given by the state-of-the-art techniques in terms of reducing the invalid refactorings, improving the quality, and increasing trustworthiness of the developers in the suggested refactorings via the provided explanations.},
  keywords={Measurement;Statistics;Sociology;Tools;History;Software systems;Software engineering;Refactoring recommendations;search-based software engineering;QMOOD metrics;multi-objective search},
  doi={10.1109/TSE.2021.3105037},
  ISSN={1939-3520},
  month={Oct},}@ARTICLE{10190569,
  author={Alamro, Hayam and Mahmood, Khalid and Aljameel, Sumayh S. and Yafoz, Ayman and Alsini, Raed and Mohamed, Abdullah},
  journal={IEEE Access}, 
  title={Modified Red Fox Optimizer With Deep Learning Enabled False Data Injection Attack Detection}, 
  year={2023},
  volume={11},
  number={},
  pages={79256-79264},
  abstract={Recently, power systems are drastically developed and shifted towards cyber-physical power systems (CPPS). The CPPS involve numerous sensor devices which generates enormous quantities of information. The data gathered from each sensing component needs to accomplish to reliability which are highly prone to attacks. Amongst various kinds of attacks, false data injection attack (FDIA) can seriously affects energy efficiency of CPPS. Current data driven approach utilized for designing FDIA frequently depends on distinct environmental and assumption conditions making them unrealistic and ineffective. In this paper, we present a modified Red Fox Optimizer with Deep Learning enabled FDIA detection (MRFODL-FDIAD) in the CPPS environment. The presented MRFODL-FDIAD technique mainly detects and classifies FDIAs in the CPPS environment. It encompasses a three stage process namely pre-processing, detection, and parameter tuning. For FDIA detection, the MRFODL-FDIAD technique uses multihead attention-based long short term memory (MBALSTM) technique. To improve the detection performance of the MBALSTM model, the MRFO technique can be exploited in this study. The experimental evaluation of the MRFODL-FDIAD approach was performed on standard IEEE bus system. Extensive set of experimentations highlighted the supremacy of the MRFODL-FDIAD technique.},
  keywords={Tuning;Power system stability;Logic gates;Microprocessors;Long short term memory;Information technology;Information systems;Cyber-physical systems;Fake news;Machine learning;Sustainable development;Metaheuristics;Cyber physical power system;false data injecton attack;machine learning;sustainability;metaheuristics},
  doi={10.1109/ACCESS.2023.3298056},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9925875,
  author={Stringer, Alexander and Sun, Brian and Schley, Lacey and Hougen, Dean F. and Antonio, John K.},
  booktitle={2022 IEEE/AIAA 41st Digital Avionics Systems Conference (DASC)}, 
  title={Causality-Aware Machine Learning for Path Correction}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  abstract={Path identification and prediction are key challenges in many modern aerospace applications. Path identification has broad applications to both the routing and tracking of systems and is crucial to the navigation of autonomous systems. Machine learning (ML) has proven to be effective at learning complex patterns and relationships in tracking data and using them to make sophisticated predictions about future entity motion. However, ML agents performing these tasks typically rely on knowledge of the past motion of entities to help predict their future locations. While the true path traversed by an entity in motion may be used in simulation studies, in practice this is not the case. Position and motion data of entities is often estimated from information collected by sensors that have inherent error sources. These error sources impede a system’s ability to accurately track entity motion. As motion tracking and path prediction are recursive processes, the errors can be further amplified and compounded over time. Existing approaches to correct for track errors generally focus on either solely correcting current measurements or use overly simplistic interpolation to correct for past errors, both of which often fail to maintain sufficient track integrity to allow for accurately predicting future states. Here, we propose a new method for repairing tracks based on causality-aware ML through the evaluation of counterfactual scenarios. Approaching track repair in this way allows a system to examine suspect sections of a track in their entirety and correct errors in them in a way that is consistent with both an entity’s location and its past motion, producing significantly improved results. We have implemented this approach to create a track repair tool using a combination of recurrent neural networks (RNNs) to predict target motion and the non-dominated sorting genetic algorithm II (NSGA-II) to identify and evaluate counterfactual paths. We have evaluated the performance of our track repair tool on simulated motion data and found that it drastically reduces track errors and improves predictions of an entity’s future location for multiple time steps.},
  keywords={Target tracking;Recurrent neural networks;Prototypes;Machine learning;Maintenance engineering;Linear programming;Task analysis;Machine Learning;Causal Learning;Tracking},
  doi={10.1109/DASC55683.2022.9925875},
  ISSN={2155-7209},
  month={Sep.},}@INPROCEEDINGS{11065308,
  author={Luo, Dan and Liang, Shaojun and Wang, Yanwei and Zheng, Ying},
  booktitle={2025 IEEE 14th Data Driven Control and Learning Systems (DDCLS)}, 
  title={Graph-based Deep Reinforcement Learning Approach for UAV Multi-Warehouse Delivery Problem}, 
  year={2025},
  volume={},
  number={},
  pages={1246-1251},
  abstract={With the rapid development of Unmanned Aerial Vehicle (UAV) technology, its application in logistics and distribution has become increasing widespread. Efficient task planning to minimize both time and cost has emerged as a critical challenge. However, traditional heuristic algorithms often suffer from limitations such as low search efficiency, inadequate solution accuracy, and a lack of flexibility in practical applications. To address these challenges, we propose a graph-based deep reinforcement learning (DRL) approach for solving the UAV multi-warehouse delivery problem. Firstly, the problem is formulated as a graph and subsequently transformed into a Markov decision process. Next, we design an encoder-decoder architecture, where GraphSAGE is employed as the encoder for node features embedding, and an attention mechanism is designed as the decoder to generate a feasible solution sequence step by step. Finally, we introduce a reinforcement learning approach enhanced by curriculum learning (CL) to update the model parameters, and the effectiveness and generalization of the proposed framework are verified through experiments on multi-warehouse delivery problem with varying scales.},
  keywords={Training;Attention mechanisms;Accuracy;Markov decision processes;Metaheuristics;Autonomous aerial vehicles;Deep reinforcement learning;Planning;Resource management;Logistics;GraphSAGE;Deep Reinforcement Learning;UAV;multi-warehouse distribution},
  doi={10.1109/DDCLS66240.2025.11065308},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10405351,
  author={Bhargava, Neeraj and Rathore, Pramod Singh and Rajput, Deepsh and Goswami, Ankur},
  booktitle={2023 2nd International Conference on Automation, Computing and Renewable Systems (ICACRS)}, 
  title={Unveiling Feature Significance: Enhancing Classification Accuracy using Chi-Squared Weighted Feature Selection}, 
  year={2023},
  volume={},
  number={},
  pages={12-17},
  abstract={This study delves into the realm of feature selection and its profound impact on enhancing classification accuracy. Leveraging the renowned Fisher's Iris dataset as a well-established benchmark, our investigation revolves around the application of Chi-squared weights to identify attributes crucial for species classification. The Chi-squared weights are a powerful tool, quantifying the associations between features and species labels. Through this approach, we discern the most pivotal attribute, suggesting its pivotal role in distinguishing iris flower species. By selecting features with elevated Chi-squared weights, we curate a focused feature subset that significantly bolsters classification accuracy.The visualization of Chi-squared weights through intuitive bar graphs emerges as an influential tool for gauging feature importance. This graphical representation aids in identifying attributes that possess strong discriminatory capabilities, thereby empowering informed decision-making during feature selection. The study emphasizes the imperative role of feature selection in the domain of machine learning and classification tasks. By incorporating statistical methodologies like the Chi-squared test, we unravel the essence of attribute significance and streamline the process of crafting potent feature subsets. As datasets evolve in complexity, the identification of pivotal attributes becomes indispensable. The proposed methodology provides a valuable approach to address this challenge.In essence, the study advances feature selection techniques by showcasing the potency of Chi-squared weights and their visual representation in enhancing classification outcomes. Our exploration within the Fisher's Iris dataset manifests the broader potential of informed feature selection strategies in elevating the performance of machine learning models.},
  keywords={Iris;Visualization;Renewable energy sources;Statistical analysis;Machine learning;Feature extraction;Task analysis;Chi-Square;Fisher’s Iris;IHFS;feature ranking},
  doi={10.1109/ICACRS58579.2023.10405351},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10398777,
  author={Liu, Xiaolu and Jia, Li and Li, Yang},
  booktitle={2023 6th International Conference on Robotics, Control and Automation Engineering (RCAE)}, 
  title={A Genetic-Firefly Algorithm Based CNN-LSTM for Lithium-Ion Battery Fault Diagnosis}, 
  year={2023},
  volume={},
  number={},
  pages={377-382},
  abstract={Lithium-ion batteries are a crucial component of new energy. Studying the fault diagnosis method of the batteries can ensure the safety of the system during operation. In this paper, a diagnosis method is studied based on the efficient channel attention (ECA) mechanism. The ECA is combined with convolutional neural network (CNN) and long short-term memory (LSTM) to design the diagnosis model. To determine the values of hyperparameters, a hyperparameter selection method based on genetic-firefly algorithm is implemented. The hyperparameter optimization methods are illustrated by the simulated battery fault data. The results show that the proposed method can make the classification accuracy reach 100%.},
  keywords={Fault diagnosis;Lithium-ion batteries;Sociology;Classification algorithms;Convolutional neural networks;Statistics;Genetic algorithms;lithium-ion battery;fault diagnosis;neural network;genetic-firefly algorithm},
  doi={10.1109/RCAE59706.2023.10398777},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10894839,
  author={V S, Stency},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Hierarchical Probabilistic Feature Extraction for Optimized Feature Selection in Intrusion Detection Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Intrusion Detection Systems (IDS) requires the effective feature selection to enhance accuracy and efficiency, especially when handling the extensive datasets. This paper introduces a novel algorithm, Hierarchical Probabilistic Feature Extraction (HPFE) designed to optimize the feature selection for IDS applications using NSL-KDD dataset. HPFE integrates the hierarchical clustering with probabilistic weighting to systematically identify and prioritize the relevant features, reducing redundancy and improving classification accuracy. Initially, HPFE organizes the features into clusters based on statistical similarity, forming a hierarchical structure that highlights the distinct feature groups. Within each cluster, a probabilistic weight is assigned to each feature which is calculated using a combined metric of information gain and variance, capturing its significance in intrusion detection. An iterative feature pruning process, coupled with threshold adjustments and a feedback loop from model-based feature importance progressively refines the feature subset by maximizing relevance and minimizing computational requirement. Experimental results demonstrate HPFE’s effectiveness in accurately identifying the critical features while reducing the computational load, making it highly suitable for the NSL-KDD dataset. By addressing the limitations in traditional feature selection methods, HPFE provides a scalable and efficient solution for network security applications in IDS with the potential for adapting in the other data-intensive security domains.},
  keywords={Measurement;Accuracy;Scientific computing;Redundancy;Intrusion detection;Network security;Feature extraction;Probabilistic logic;NSL-KDD;Load modeling;Hierarchical Probabilistic Feature Extraction (HPFE);NSL-KDD dataset;IDS;Feature Selection},
  doi={10.1109/ICERCS63125.2024.10894839},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10497194,
  author={Lamsaf, Asmae and Samale, Pranita and Proença, Hugo and Neves, João C. and Hambarde, Kailash},
  booktitle={2024 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Advancing Manufacturing Energy Efficiency: The Role of AI and Web-Based Tools}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces a web-based application that simplifies the data analysis processing chain by automating the analysis of arbitrary variables. In particular, our application allows users to easily upload and process data for the analysis of a target variable by exploiting machine learning and evo-lutionary algorithms for precise forecasting and optimization. We demonstrate the system's efficacy using a dataset from a textile company, where our application successfully predicted the target variables with a high level of R-squared of 0.78, using the best regression model. These results not only highlight its real-world applicability but also played an important role in enhancing sustainable manufacturing practices. This innovative application offers a significant step towards sustainable and efficient manufacturing, addressing the challenges of high energy consumption and environmental impact in the industry.},
  keywords={Industries;Energy consumption;Machine learning algorithms;Machine learning;Prediction algorithms;Manufacturing;Forecasting;Artificial Intelligence;Machine Learning;En-ergy Efficiency;Manufacturing Sector;Web-Based Application;Data Analysis;Optimization;Genetic Algorithms;Industrial Energy Management;Sustainable Manufacturing},
  doi={10.1109/ESCI59607.2024.10497194},
  ISSN={},
  month={March},}@INPROCEEDINGS{11065938,
  author={Yang, Jie and Yu, Tianyue and Zhang, Yasheng},
  booktitle={2025 5th International Symposium on Computer Technology and Information Science (ISCTIS)}, 
  title={Search Planning Problem for Lost Targets at Sea Based on Historical Trajectory Information}, 
  year={2025},
  volume={},
  number={},
  pages={703-711},
  abstract={Satellite mission planning is an important prerequisite for satellite Earth observation. Traditional satellite mission planning is mainly aimed at fixed ground targets and cannot meet the increasingly complex mission requirements. Aiming at the problem of search planning for lost targets at sea, a satellite search planning method for lost targets based on historical track information is proposed. Based on a large amount of historical trajectory information, the method predicts the target’s future trajectory through an improved attention mechanism long and short-term memory network, and utilizes a multi-prediction trajectory assignment grid for search planning of lost target positions. In view of the constraint complexity of satellite search planning with historical trajectory information, the constraintsatisfying genetic algorithm is embedded in the genetic algorithm in the form of conditions, and an adaptive factor is designed in the algorithm to solve the problem of uncertainty of dynamic target trajectories. The simulation results show that the method has excellent efficiency in solving the satellite search task planning problem for lost targets at sea under the availability of trajectory information, and a high benefit ratio is obtained.},
  keywords={Satellites;Attention mechanisms;Simulation;Predictive models;Search problems;Prediction algorithms;Trajectory;Planning;Long short term memory;Genetic algorithms;Mission planning;historical trajectory;LSTM;Genetic Algorithm},
  doi={10.1109/ISCTIS65944.2025.11065938},
  ISSN={},
  month={May},}@INPROCEEDINGS{10364167,
  author={Bocanegra, Álvaro José and Espinoso, Anaïs and Andrzejak, Ralph G and Camara, Oscar},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={EEG-Based Cardiac Arrest Outcome Estimation with Highly Interpretable Features}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={The following is the solution proposed by the team UPFantastic for the Predicting Neurological Recovery from Coma After Cardiac Arrest: The George B. Moody PhysioNet Challenge 2023. The team was unable to be scored on the test set for the official phase of the challenge. Nevertheless, in our view, the methods proposed merit consideration, since the approach focused on interpretable features and analysis of the relevance and distribution of the data. We used synchrony and relative EEG band power measurements, along with patient data to feed a tree-based machine learning algorithm. We also used Multiple Kernel Learning in a subset to analyze the tendency of the patients during the monitoring in a dimensional reduced space.},
  keywords={Power measurement;Machine learning algorithms;Estimation;Cardiac arrest;Electroencephalography;Feeds;Cardiology},
  doi={10.22489/CinC.2023.324},
  ISSN={2325-887X},
  month={Oct},}@INPROCEEDINGS{10890310,
  author={Cherukuri, Teja Krishna and Shaik, Nagur Shareef and Bodapati, Jyostna Devi and Ye, Dong Hye},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={GCS-M3VLT: Guided Context Self-Attention based Multi-modal Medical Vision Language Transformer for Retinal Image Captioning}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Retinal image analysis is crucial for diagnosing and treating eye diseases, yet generating accurate medical reports from images remains challenging due to variability in image quality and pathology, especially with limited labeled data. Previous Transformer-based models struggled to integrate visual and textual information under limited supervision. In response, we propose a novel vision-language model for retinal image captioning that combines visual and textual features through a guided context self-attention mechanism. This approach captures both intricate details and the global clinical context, even in data-scarce scenarios. Extensive experiments on the DeepEyeNet dataset demonstrate a 0.023 BLEU@4 improvement, along with significant qualitative advancements, highlighting the effectiveness of our model in generating comprehensive medical captions.},
  keywords={Visualization;Pathology;Accuracy;Signal processing;Retina;Transformers;Speech processing;Medical diagnostic imaging;Space heating;Context modeling;Retinal Image Captioning;Vision Language Model;Guided Context Attention;Self-Attention;Transformer},
  doi={10.1109/ICASSP49660.2025.10890310},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10518139,
  author={Zhu, Xinshan and Xu, Chengqian and Song, Tianbao and Huang, Zhen and Zhang, Yun},
  journal={IEEE Transactions on Power Electronics}, 
  title={Sparse Self-Attentive Transformer With Multiscale Feature Fusion on Long-Term SOH Forecasting}, 
  year={2024},
  volume={39},
  number={8},
  pages={10399-10408},
  abstract={The estimation of the state of health (SOH) of lithium-ion batteries (LIBs) plays an important role in ensuring the safe and stable operation of LIB management systems. In order to more accurately predict SOH, a model based on a sparse self-attentive transformer (SSAT) with multitimescale feature fusion is proposed. The SSAT follows an encoder-decoder structure construction, and the model inputs are the extracted health indicators and SOH sequences. The encoder stacks three cross-stage partial (CSP)-ProbSparse attention self-attention blocks, between every two CSP-ProbSparse attention blocks, connections are made by dilated causal convolution and max-pooling layers to obtain exponential growth of the sensory field. All the feature maps output from the self-attention blocks are integrated by multiscale feature fusion, and finally, the appropriate feature dimensions are fed to the decoder through a transition layer to obtain the estimation of SOH. Numerous comparative and ablation experiments have demonstrated that the SSAT model achieves superior performance in a wide range of situations.},
  keywords={Batteries;Integrated circuit modeling;Feature extraction;Lithium-ion batteries;Adaptation models;Load modeling;Transformers;Cross-stage partial (CSP)-ProbSparse attention;lithium battery;multiscale feature fusion;state of health (SOH);transformer},
  doi={10.1109/TPEL.2024.3395180},
  ISSN={1941-0107},
  month={Aug},}@ARTICLE{10533261,
  author={Alqushaibi, Alawi and Hilmi Hasan, Mohd and Jadid Abdulkadir, Said and Usman Danyaro, Kamaluddeen and Gamal Ragab, Moham1med and Mahmood Al-Selwi, Safwan and Hamid Sumiea, Ebrahim and Alhussian, Hitham},
  journal={IEEE Access}, 
  title={Enhanced Colon Cancer Segmentation and Image Synthesis Through Advanced Generative Adversarial Networks Based-Sine Cosine Algorithm}, 
  year={2024},
  volume={12},
  number={},
  pages={105354-105369},
  abstract={Colorectal cancer (CRC) is a prevalent and life-threatening malignancy, demanding early diagnosis and effective treatment for improved patient outcomes. Accurate segmentation of colon cancer in medical images is a challenging task due to the complexity of its morphology and limited annotated data availability. This paper presents an efficient approach for colon cancer segmentation and image synthesis, combining an Attention U-Net and Pix2Pix Generative Adversarial Network (Pix2Pix-GAN) guided by Sine Cosine Algorithm (SCA) for hyperparameter tuning within the GAN framework. The utilization of SCA plays a pivotal role in optimizing the delicate balance between generator and discriminator dynamics, resulting in enhanced convergence and stability. Our method achieved state-of-the-art results with a mean Dice score of 0.9514, mean Intersection over Union of 0.9123, F beta score of 0.9636, and similarity index of 0.9430 outperforming existing methods. Moreover, the Mean Absolute Error reached a minimal value of 0.01583. This proposed approach shows promise in enhancing the accuracy and robustness of colon cancer diagnosis and treatment which could lead to better diagnosis and treatment of colon cancer.},
  keywords={Image segmentation;Generative adversarial networks;Generators;Training;Medical diagnostic imaging;Image synthesis;Task analysis;Medical services;Metaheuristics;Generative adversarial networks;medical applications;medical imaging;sine cosine optimization;GAN convergence;metaheuristic},
  doi={10.1109/ACCESS.2024.3402262},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10623108,
  author={Kim, Yongjun and Seo, Sejin and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun and Choi, Junil},
  booktitle={ICC 2024 - IEEE International Conference on Communications}, 
  title={Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control}, 
  year={2024},
  volume={},
  number={},
  pages={2962-2967},
  abstract={In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.},
  keywords={Training;Costs;Navigation;Computational modeling;Large language models;Semantics;Trajectory;Semantic communication (SC);language- oriented SC;emergent communication;large language model (LLM);knowledge distillation},
  doi={10.1109/ICC51166.2024.10623108},
  ISSN={1938-1883},
  month={June},}@ARTICLE{10670707,
  author={Wang, Longjian and Yu, Jianwu and Huang, Liang and Qian, Jun and Luo, Hong},
  journal={IEEE Access}, 
  title={Bending Strength Prediction of the Cu-Sn Alloy Through a Visual Quantization Model Integrated With Microstructure Characterization and Machine Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={127390-127404},
  abstract={The multimodal properties of the grinding wheel matrix significantly impact grinding performance, while research on the interactions among these properties remains notably limited. To investigate the latent relationship between the microstructure and the bending strength of the bronze matrix, a visual quantization model based on the microstructure of the Cu-Sn alloy samples was established. The proposed model integrated a image segmentation network module, a quantitative characterization module, and a multivariate prediction module. The enhancement of the segmentation network is based on the synergistic combination of full-scale feature fusion with attention mechanism. The quantitative characterization parameters of metallographic microstructure features are proposed, and the most prominent intercorrelation between these parameters is studied from multiple dimensions. The results show that the modified image segmentation network exhibits superior performance compared to Unet, as evidenced by a 3% increase in Mean Intersection over Union (MIOU). The optimized output strategy ( $\eta Dd$ -PSO-SVR) can contribute to the model’s prediction accuracy of material bending strength (MSE = 23.558,R $^{2}=0.934$ ). Finally, this work shows that the microscopic information demonstrates great adaptability for the machine learning models in predicting bending strength.},
  keywords={Bending;Wheels;Microstructure;Metals;Heating systems;Diamonds;Sintering;Machine learning;Grinding machines;Performance evaluation;Bending strength prediction;Cu-Sn alloy;grinding wheel;machine learning;microscopic feature},
  doi={10.1109/ACCESS.2024.3408319},
  ISSN={2169-3536},
  month={},}@ARTICLE{10716760,
  author={Zhang, Qing and Shao, Dan and Lin, Lin and Gong, Guoliang and Xu, Rui and Kido, Shoji and Cui, HongWei},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Feature Separation in Diffuse Lung Disease Image Classification by Using Evolutionary Algorithm-Based NAS}, 
  year={2025},
  volume={29},
  number={4},
  pages={2706-2717},
  abstract={In the field of diagnosing lung diseases, the application of neural networks (NNs) in image classification exhibits significant potential. However, NNs are considered “black boxes,” making it difficult to discern their decision-making processes, thereby leading to skepticism and concern regarding NNs. This compromises model reliability and hampers intelligent medicine's development. To tackle this issue, we introduce the Evolutionary Neural Architecture Search (EvoNAS). In image classification tasks, EvoNAS initially utilizes an Evolutionary Algorithm to explore various Convolutional Neural Networks, ultimately yielding an optimized network that excels at separating between redundant texture features and the most discriminative ones. Retaining the most discriminative features improves classification accuracy, particularly in distinguishing similar features. This approach illuminates the intrinsic mechanics of classification, thereby enhancing the accuracy of the results. Subsequently, we incorporate a Differential Evolution algorithm based on distribution estimation, significantly enhancing search efficiency. Employing visualization techniques, we demonstrate the effectiveness of EvoNAS, endowing the model with interpretability. Finally, we conduct experiments on the diffuse lung disease texture dataset using EvoNAS. Compared to the original network, the classification accuracy increases by 0.56%. Moreover, our EvoNAS approach demonstrates significant advantages over existing methods in the same dataset.},
  keywords={Pulmonary diseases;Accuracy;Lung;Image classification;Visualization;Kernel;Bioinformatics;Medical diagnostic imaging;Diseases;Convolutional neural networks;Diffuse lung disease image classification;evolutionary algorithm;feature separation;neural archi- tecture search},
  doi={10.1109/JBHI.2024.3481012},
  ISSN={2168-2208},
  month={April},}@INPROCEEDINGS{10793187,
  author={Wang, Tuowei and Li, Kun and Hao, Zixu and Bai, Donglin and Ren, Ju and Zhang, Yaoxue and Cao, Ting and Yang, Mao},
  booktitle={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={LONG EXPOSURE: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity}, 
  year={2024},
  volume={},
  number={},
  pages={1-18},
  abstract={The adaptation of pre-trained large language models (LLMs) to diverse downstream tasks via fine-tuning is critical for numerous applications. However, the inefficiency of parameterefficient fine-tuning (PEFT) techniques presents significant challenges in terms of time investments and operational costs. In this paper, we first introduce a nuanced form of sparsity, termed Shadowy Sparsity, which is distinctive in fine-tuning and has not been adequately addressed for acceleration. Under Shadowy Sparsity, we propose Long Exposure 1, an efficient system to accelerate PEFT for LLMs. Long Exposure comprises three key components: Shadowy-sparsity Exposer employs a prolonged sensing range to capture more sparsity details under shadowy sparsity; Sequence-oriented Predictor provides efficient yet accurate predictions to handle large sequence inputs and constantly-evolving parameters; and Dynamic-aware Operator facilitates more structured computational patterns and coalesced memory accesses, addressing dynamic sparse operations. Extensive evaluations show that Long Exposure outperforms state-of-the-arts with up to a $2.49 \times$ speedup in end-to-end fine-tuning, offering promising advancements in accelerating PEFT for LLMs.1Long Exposure is available at https://github.com/HPHEX/LongExposure.},
  keywords={Analytical models;Costs;Accuracy;Large language models;High performance computing;Computational modeling;Memory management;Sensors;Computational efficiency;Investment;Large Language Model;Fine-tuning;Sparsity},
  doi={10.1109/SC41406.2024.00081},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11043054,
  author={Zhai, Yuejing and Li, Yiping and Li, Huijie and Luo, Wuman},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={The Dual-Focus Dynamic Multiple Imputation Approach For MNAR Missing Values In Medical Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Missing value imputation in medical datasets is an important research topic. Most studies assume that missing values are Missing at Random (MAR), but verifying whether data are MAR or Missing Not at Random (MNAR) is challenging because it is impossible to evaluate whether the unobserved data is related to the missing data. Besides, the possible evaluation method sensitivity analysis has many limitations and shortcomings. Therefore, considering the extreme complexity of the human body, treating missing values as MNAR is preferable. Existing MNAR imputation methods require assumptions about the distribution of unobserved variables and establish joint probabilities, so they rely on experience and may lead to bias. In addition, these methods also struggle with complex relationships and distributions. To address these problems, this paper proposes the Dual-Focus Dynamic Multiple Imputation (DDMI) model for MNAR missing values in medical data. The DDMI uses piece-wise approximation to decompose complex relationships and directly calculates the impact of unobserved variables on patient indicators, avoiding distribution assumptions. In addition, the DDMI captures both population and individual-level information to predict missing values and then refines the results through multiple iterations, and the original information is combined in each iteration to mitigate information loss and improve convergence. We test DDMI on two real-world datasets. Results show that DDMI outperforms other methods.},
  keywords={Deep learning;Sensitivity analysis;Computational modeling;Neural networks;Evolutionary computation;Predictive models;Feature extraction;Data models;Imputation;Iterative methods;Missing Value;Model Interpretability;Iterative Calculation;MNAR},
  doi={10.1109/CEC65147.2025.11043054},
  ISSN={},
  month={June},}@INPROCEEDINGS{11026931,
  author={Hsu, Po-Kai and Cho, Sungwon and Sharda, Janak and Park, Hyeonwoo and Datta, Suman and Yu, Shimeng},
  booktitle={2025 IEEE International Memory Workshop (IMW)}, 
  title={Monolithic 3D Stackable DRAM Design with BEOL-Compatible Oxide Channel Access Transistor}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Monolithic 3D stackable DRAM has emerged as a promising solution to extend the scaling for DRAM technology. The silicon access transistor channel length has limited scaling potential in a horizontal 1T1C configuration due to leakage current constraint. In this work, we propose a BEOL-compatible W-doped In2O3 (IWO) channel field-effect transistor (FET) as an alternative access transistor for 3D DRAM, enabling further horizontal scaling. By integrating the IWO nanosheet FET process with a horizontal 1T1C 3D DRAM process, we demonstrate low leakage and improved memory bit density. Through TCAD simulations, we analyze parasitic effects, retention characteristics, and sense margins. The bank-level simulation results show that 128-layer IWO-based 3D DRAM achieves 1.7× higher bit density (Mb/mm2) than its silicon counterpart. Furthermore, we evaluate processing-in-memory (PIM) architecture by hybrid bonding of 3D DRAM on top of TPU-like accelerators for large language model (LLM), showing 3× throughput and 14× energy efficiency compared to contemporary GPU with 2.5D integrated HBM.},
  keywords={Solid modeling;Three-dimensional displays;Simulation;Field effect transistors;Stacking;Random access memory;Throughput;Energy efficiency;Silicon;Semiconductor process modeling;3D DRAM;Oxide semiconductor;Processing-in-memory},
  doi={10.1109/IMW61990.2025.11026931},
  ISSN={2573-7503},
  month={May},}@INPROCEEDINGS{10827969,
  author={Nie, Heng and Jiao, Jiye},
  booktitle={2024 IEEE 6th International Conference on Civil Aviation Safety and Information Technology (ICCASIT)}, 
  title={Research on battery balance based on multi-modal information fusion and representation learning based on deep learning}, 
  year={2024},
  volume={},
  number={},
  pages={1707-1712},
  abstract={This paper introduces a battery balance algorithm model based on multimodal information fusion and deep learning representation learning. The model integrates BP neural networks, transformers, and genetic algorithms for comprehensive analysis using various battery data types. Initially, BP neural networks capture the nonlinear dynamics of the battery data to establish a basic understanding of its behavior. These extracted features are then fed into Transformer, where a self-focused mechanism recognizes complex relationships between different data patterns for effective information fusion. This method ensures a comprehensive assessment of SOC influencing factors, thus improving the accuracy of prediction. In addition, to optimize model performance, genetic algorithms fine-tune hyperparameters such as learning rate and hidden layer counts, and use fitness functions to evaluate performance on validation sets. The reliability of the proposed model is verified by real world experiments.},
  keywords={Representation learning;Deep learning;Neural networks;Transformers;Feature extraction;Batteries;Safety;State of charge;Reliability;Genetic algorithms;BP neural network;Transformer;Model prediction},
  doi={10.1109/ICCASIT62299.2024.10827969},
  ISSN={},
  month={Oct},}@ARTICLE{9819829,
  author={Ain, Qurrat Ul and Al-Sahaf, Harith and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Cybernetics}, 
  title={Automatically Diagnosing Skin Cancers From Multimodality Images Using Two-Stage Genetic Programming}, 
  year={2023},
  volume={53},
  number={5},
  pages={2727-2740},
  abstract={Developing a computer-aided diagnostic system for detecting various skin malignancies from images has attracted many researchers. Unlike many machine-learning approaches, such as artificial neural networks, genetic programming (GP) automatically evolves models with flexible representation. GP successfully provides effective solutions using its intrinsic ability to select prominent features (i.e., feature selection) and build new features (i.e., feature construction). Existing approaches have utilized GP to construct new features from the complete set of original features and the set of operators. However, the complete set of features may contain redundant or irrelevant features that do not provide useful information for classification. This study aims to develop a two-stage GP method, where the first stage selects prominent features, and the second stage constructs new features from these selected features and operators, such as multiplication in a wrapper approach to improve the classification performance. To include local, global, texture, color, and multiscale image properties of skin images, GP selects and constructs features extracted from local binary patterns and pyramid-structured wavelet decomposition. The accuracy of this GP method is assessed using two real-world skin image datasets captured from the standard camera and specialized instruments, and compared with commonly used classification algorithms, three state of the art, and an existing embedded GP method. The results reveal that this new approach of feature selection and feature construction effectively helps improve the performance of the machine-learning classification algorithms. Unlike other black-box models, the evolved models by GP are interpretable; therefore, the proposed method can assist dermatologists to identify prominent features, which has been shown by further analysis on the evolved models.},
  keywords={Feature extraction;Skin;Image color analysis;Lesions;Contracts;Wavelet analysis;Visualization;Feature construction;feature selection;genetic programming (GP);image classification;skin cancer images},
  doi={10.1109/TCYB.2022.3182474},
  ISSN={2168-2275},
  month={May},}@ARTICLE{10577183,
  author={Zhang, Qiang and Han, Zhen},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={DRSNet: Rotated-ROI Ship Segmentation for SAR Images Based on Dual-Scale Cross Attention}, 
  year={2024},
  volume={21},
  number={},
  pages={1-5},
  abstract={For ships in synthetic aperture radar (SAR) images, which have various aspect ratios and incline angles, the rotated regions of interest (ROIs) are used in instance segmentation recently as compact segmentation patches. Although the segmentation accuracy of ships has been improved with rotated ROIs, their contour details are unsatisfactory. To refine the contour details, a dual-scale-feature-fusion segmentation network, called DRSNet, is presented in this letter around rotated ROIs. To upgrade the performance of ROI detection, the Gaussian-distribution-based ATSS (Ga-ATSS) is proposed to raise positive samples according to the shape information of ships for training of the bounding-box detection module (DetHead). To enhance the segmentation of contour details, a dual-scale cross attention (DS Cross Attention) is designed to extract accurate detail features from low-scale features and add them into high-scale semantic features in the rotated ROIs. The experimental results reveal that the DRSNet can achieve average precisions (APs) of 67.5% on the SAR ship detection dataset (SSDD) and 68.1% on the instance rotated ship detection dataset (Instance-RSDD), which outperforms the comparison networks, and ablation study shows that the Ga-ATSS can improve the ship detection performance, especially Recall rises by 1.3%.},
  keywords={Feature extraction;Marine vehicles;Accuracy;Semantics;Synthetic aperture radar;Radar polarimetry;Instance segmentation;Dual-scale cross attention (DS Cross Attention);Gaussian-distribution-based ATSS (Ga-ATSS);ship instance segmentation;synthetic aperture radar (SAR) images},
  doi={10.1109/LGRS.2024.3420251},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{10677572,
  author={Jose, R. Arul and Ramesh, C. and Krishnan, R. Santhana and Gayathri, C. and Yamini, G. and Srinivasan, A.},
  booktitle={2024 8th International Conference on Inventive Systems and Control (ICISC)}, 
  title={EMANet: Revolutionizing Energy Efficiency in Smart Spaces through Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={409-415},
  abstract={In the modern smart environments, optimizing energy efficiency stands as a primary objective for attaining sustainability and resource management. Smart spaces, encompassing a variety of environments such as smart buildings, cities, and industrial settings, rely on efficient energy utilization to meet the growing demands of modern society while minimizing environmental impact This study investigates the optimization of energy efficiency within smart environments, a critical objective for sustainable resource management. Smart spaces, encompassing diverse environments like buildings, cities, and industries, require efficient energy utilization to address growing societal demands while minimizing environmental impact. To achieve this, an approach is proposed that leverages Machine Learning (ML) algorithms integrated with Adaptive Personal Area Networks (PANs) for optimized energy consumption. A novel algorithm, EMANet (EnergyManaged Attention Networks), is introduced for dynamic regulation of resource allocation and network configurations based on attention-driven insights. The performance of EMANet is evaluated through comparative simulation analysis against existing algorithms like Q-learning, Particle Swarm Optimization, and Ant Colony Optimization. Metrics including Energy Consumption Reduction, Network Lifetime Extension, and Resource Utilization Efficiency are employed for comparison. This research aims to achieve substantial improvements in energy efficiency through the combined application of ML algorithms and PANs, thereby promoting the sustainability of smart spaces. The results are expected to demonstrate the effectiveness of EMANet in optimizing energy usage and its potential to revolutionize energy management strategies in smart environments.},
  keywords={Energy consumption;Machine learning algorithms;Heuristic algorithms;Urban areas;Machine learning;Energy efficiency;Resource management;Composite Property Prediction Neural Network;Aluminum Matrix Composites;Coconut Shell Particles;Mechanical Properties;Sustainability;Compocasting},
  doi={10.1109/ICISC62624.2024.00076},
  ISSN={},
  month={July},}@INPROCEEDINGS{10721754,
  author={Wang, Hua},
  booktitle={2024 International Conference on Intelligent Algorithms for Computational Intelligence Systems (IACIS)}, 
  title={Intelligent Prediction and Training Optimization of Sports using Enhanced Whale Optimized Artificial Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Enhancing the efficiency of the sports training should be provided since many of the athletic training methods used today are ineffective at considering the unique qualities of individual athletes. The proposed research aimed at developing intelligent prediction and optimization of basketball training using data from Federation Internationale de Basketball (FIBA) website and pre-processed using min max normalization. The Capsule Network (CapsNet) of Convolutional Neural Network (CNN) is used to extract features and the classified using Attention mechanism combined Convolutional Random Forest (AttConv-RF). CapsNet makes it possible to improve the model's capabilities due to the updated loss function. The ConvRF unit recognizes spatial and temporal relationships of the training data, decreasing overfitting issues primarily while training data are limited. The performance prediction is carried out using Enhanced Whale Optimization Algorithm based Artificial Neural Network (EWOA-ANN). The results showed that proposed EWOA-ANN approach achieved better performance prediction at accuracy with 99.56%, precision of 97.42%, and recall 96.36% when compared with the existing methods Back Propagation Neural Network (BPNN) and eXtreme Gradient Boost (XGB).},
  keywords={Training;Accuracy;Training data;Feature extraction;Prediction algorithms;Whale optimization algorithms;Convolutional neural networks;Optimization;Tuning;Sports;artificial neural network;convolutional neural network;enhanced whale optimization algorithm;intelligent prediction;random forest},
  doi={10.1109/IACIS61494.2024.10721754},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10647455,
  author={Mishra, Aakansha and Agarwala, Aditya and Tiwari, Utsav and Rajendiran, Vikram N and Miriyala, Srinivas S},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={Efficient Visual Question Answering on Embedded Devices: Cross-Modality Attention With Evolutionary Quantization}, 
  year={2024},
  volume={},
  number={},
  pages={2142-2148},
  abstract={Visual Question Answering (VQA) lies at the intersection of vision and language domains necessitating learning representations from multiple modalities. While the model development for VQA has witnessed tremendous growth, the efforts for its deployment on embedded devices have been lagging limiting its true potential. In this work, the authors address this challenge by designing a novel hardware-friendly architecture for VQA based on the transformer model with cross-modality attention. The memory footprint of the VQA model is optimized for on-device deployment using a distributed framework for Post Training Quantization (PTQ) formulated as a Non-Linear Programming (NLP) problem. The NLP problem is solved using an Evolutionary algorithm to determine the low-bit representation of the VQA model with minimal accuracy drop compared to the full precision model. The quantized model for VQA with a marginal accuracy drop of less than 2%, resulted in 4 times memory improvement, and over 2 times latency improvement, enabling its successful deployment on the Samsung Galaxy S23 device. The comprehensive study explores the potential of the proposed generic end-to-end pipeline from VQA model development to its deployment.},
  keywords={Training;Visualization;Quantization (signal);Accuracy;Runtime;Pipelines;Programming;Visual Question Answering;Cross-Modality Attention;Post Training Quantization;Non-Linear Programming;Evolutionary Algorithms;Model Deployment},
  doi={10.1109/ICIP51287.2024.10647455},
  ISSN={2381-8549},
  month={Oct},}@INPROCEEDINGS{10364065,
  author={Nasrat, Sara and Khandoker, Ahsan and Jelinek, Herbert},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={Optimizing Multiscale Entropy Analysis for the Detection of Cardiac Pathology}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={The study investigates the use of the Rényi entropy algorithm with variable threshold and a signal temporal multiscaling approach for analyzing RR interval signals. The study involved 8-minute ECG recordings of 90 participants from the PhysioNet database and grouped into three groups: normal sinus rhythm, cardiac arrhythmia, and congestive heart failure. A time coarse-graining algorithm was used to obtain different temporal scales of the original signal. Rényi entropy probabilities of each scale-factored signal were calculated using a method of density based on sequences of the RR interval time series. ANOVA and post-hoc t-test were used to determine significant differences between the multiscaled Rényi entropy measures of the different groups of RR interval signals. The novel multiscaled Rényi entropy analysis provided enhanced significant discrimination between healthy and pathological (NSR vs. ARR and NSR vs. CHF) signals at post hoc t-test probability values of $p < 5\mathrm{x}10^{-6}$ and within pathological signals (ARR vs. CHF) at $p < 5\mathrm{x}10^{-} 3$. The study concludes that applying a joint approach of cardiac signal temporal multiscaling and calculating its modified Rényi entropy with variable thresholding provides an optimized approach to identifying and separating healthy and pathological cardiac signals, and further supports the complex nature of the heart dynamics.},
  keywords={Heart;Pathology;Rail to rail inputs;Time series analysis;Probability;Electrocardiography;Rhythm},
  doi={10.22489/CinC.2023.447},
  ISSN={2325-887X},
  month={Oct},}@INPROCEEDINGS{10421654,
  author={Yamsani, Nagendar and Obulesh, Kallubhavani and Ramadan, Ghazi Mohamad and Al-Jawahry, Hassan M. and Senthil Kumar, S},
  booktitle={2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={License Plate Recognition using Attention-LSTM with Dove Swarm Optimization Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, license plate prediction has advanced with machine learning, enabling accurate automated identification of vehicle plates for various applications, including law enforcement and surveillance. This study addresses the problem of effectively anticipating variations in traffic flow on metropolitan road networks, which are characterized by intermittent patterns and intense short-term volatility. DSOA-LSTM integrates Dove Swarm Optimization with Attention-based LSTM to improve traffic volume estimates using data analysis that takes into consideration spatial-temporal correlations. The attention mechanism in temporal correlation modeling demonstrates the importance of historical observations in the LSTM model. DSOA enhances license plate prediction by iteratively modifying parameters, emulating collaborative optimization, and is inspired by dove flocking behavior. The results showed that DSOA-LSTM is superior, with low Root Mean Squared Error (RMSE) of 6.55 and Mean Absolute Error of 4.65 and improved stability throughout several prediction phases, particularly in capturing intense short-term variations in traffic volume.},
  keywords={Adaptation models;Correlation;Collaboration;Predictive models;Prediction algorithms;Particle swarm optimization;License plate recognition;Attention-based Long Short-Term Memory;Dove Swarm Optimization Algorithm;License Pate Prediction;Mean Absolute Error;Root Mean Squared Error},
  doi={10.1109/ICIICS59993.2023.10421654},
  ISSN={},
  month={Nov},}@ARTICLE{10916629,
  author={Park, Jae H. and Madisetti, Vijay K.},
  journal={IEEE Access}, 
  title={CAPRI: A Context-Aware Privacy Framework for Multi-Agent Generative AI Applications}, 
  year={2025},
  volume={13},
  number={},
  pages={43168-43177},
  abstract={While the swift advancement of cloud-based Large Language Models (LLMs) has significantly increased the efficiency and automation in business processes, it has also introduced considerable privacy concerns regarding Personally Identifiable Information (PII) and other protected data in multimodal forms, such as text, video, or images, being exported, potentially insecurely, outside the corporate environments. Although traditional anonymization-based techniques can alleviate these risks in offline applications, such as summarization or classification, incorporating it into online LLM workflows poses substantial challenges, particularly when these workflows encompass real-time transactions involving multiple stakeholders, as commonly observed in multi-agent generative AI applications. This study explores these challenges and proposes novel context-aware privacy frameworks and methods to address these issues. We employ a local privacy-focused gatekeeper LLM to contextually pseudonymize PII and assign unique identifiers as part of a new mapping process, thereby facilitating re-identification in real-time operations while safeguarding privacy when interacting with cloud-based LLMs. Our proposed methodologies and frameworks adeptly integrate privacy considerations into LLM and LLM Agent workflows, preserving both privacy and data utility while maintaining operational efficiency and utility comparable to non-anonymized generative AI processes.},
  keywords={Data privacy;Synthetic data;Privacy;Identification of persons;Generative AI;Cognition;Real-time systems;Semantics;Logic gates;Large language models;Generative AI (Gen AI);large language model (LLM);pseudonymization},
  doi={10.1109/ACCESS.2025.3549312},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10545755,
  author={Zhang, Bin and Wu, Wei},
  booktitle={2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT)}, 
  title={Research on Graph Data Classification Algorithm Based on Deep Learning Technology}, 
  year={2024},
  volume={},
  number={},
  pages={1216-1220},
  abstract={With the rapid development of science and technology, the widespread application of graph data in various fields has increasingly highlighted its importance. Social networks, bioinformatics, knowledge graphs and other fields are all inseparable from the processing and analysis of graph data. The classification task of graph data is a key part of the in-depth exploration and understanding of these complex relationships. In this context, the rise of deep learning technology has brought new ideas and methods to graph data classification. Deep learning technology, with its powerful feature extraction and pattern recognition capabilities, has demonstrated excellent performance in fields such as images, speech, and natural language. Based on this cutting-edge technology, this paper conducts an in-depth study of graph data classification algorithms based on deep learning technology, focusing on two key aspects: attention network and cost sensitivity. In terms of attention network, we adopt the Graph Attention Network (GAT) as a feature extraction tool for graph data. GAT simulates the human attention mechanism and can dynamically allocate weights to highlight important information while suppressing irrelevant information, thereby better capturing the structure and attribute information of graph data. On the other hand, cost-sensitive techniques are learning methods that take into account the different costs of different classification errors. In this paper, we adopt cost-sensitive graph neural network (CS-GNN) as a classification tool for graph data. CS-GNN can dynamically adjust the loss function and gradient descent direction according to different categories and error costs to improve classification efficiency and accuracy. To sum up, this article's research on graph data classification algorithm based on deep learning technology provides important ideas and methods for the analysis and mining of graph data. These results are not only expected to promote the development of graph data classification algorithms in the academic field, but will also play an important role in practical applications and promote scientific and technological progress and innovative development in various fields.},
  keywords={Deep learning;Costs;Sensitivity;Speech recognition;Prediction algorithms;Feature extraction;Graph neural networks;Graph data;deep learning;attention network;cost sensitivity},
  doi={10.1109/ICCECT60629.2024.10545755},
  ISSN={},
  month={April},}@INPROCEEDINGS{10778769,
  author={Ezenwoye, Onyeka and Pinconschi, Eduard and Roberts, Earl},
  booktitle={2024 Cyber Awareness and Research Symposium (CARS)}, 
  title={Exploring AI for Vulnerability Detection and Repair}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={As modern applications become more complex, enhancing tools and techniques for detecting and addressing vulnerabilities is crucial. AI and ML are increasingly valuable in this domain. Large Language Models like ChatGPT, Gemini, and Phind are emerging as promising solutions for code analysis and repair. This study evaluates these models’ effectiveness in identifying and fixing vulnerabilities in small C-language code samples, focusing on various CWE categories. The evaluation reveals that while ChatGPT performs with the highest accuracy in detecting vulnerabilities, all models effectively repair known flaws, though with varying proficiency. The findings aim to provide insights for improving automated vulnerability detection and remediation tools in cybersecurity.},
  keywords={Training;Codes;Accuracy;Large language models;Focusing;Maintenance engineering;Chatbots;Data models;Automobiles;Computer security;Large Language Model;Software Vulnerability;Code Repair},
  doi={10.1109/CARS61786.2024.10778769},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11019847,
  author={Yu, Qingdi and Hu, Min and Yang, Zhen and Zhou, Xin},
  booktitle={2025 8th International Conference on Advanced Algorithms and Control Engineering (ICAACE)}, 
  title={Carbon-Efficient Data Center Scheduling under Uncertainty: A Conformal Prediction Approach}, 
  year={2025},
  volume={},
  number={},
  pages={232-236},
  abstract={The temporal and spatial mismatch between data center energy consumption and renewable energy supply, particularly solar energy, presents a significant challenge. During early morning and evening hours, computational load far exceeds the available renewable energy supply, while at midday, renewable energy generation often surpasses computational demand, leading to wasted renewable resources and increased carbon emissions. To address this issue, systemic task scheduling optimization strategies have been developed, which involve deferring nonurgent tasks from peak load periods to times of renewable energy surplus. However, the effectiveness of these strategies heavily relies on the accurate prediction of both renewable energy availability and computational load, both of which are subject to considerable uncertainty. This uncertainty can lead to suboptimal scheduling decisions. This study proposes a novel task scheduling optimization framework that integrates confidence prediction information derived from Conformal Prediction (CP) methods. By utilizing multi-step probabilistic prediction intervals for risk-aware optimization, the framework mitigates the impact of uncertainty on task scheduling strategies and enhances their reliability. In a simulated data center environment constructed with real-world load and solar energy data, the proposed frame-work achieved an 7.47% reduction in overall system carbon emissions, with a maximum reduction of 10.36%. This approach provides an interpretable uncertainty quantification paradigm for complex system optimization, effectively alleviating the impact of uncertainty due to time series data prediction on suboptimal policies generated by task scheduling optimization frameworks.},
  keywords={Renewable energy sources;Data centers;Uncertainty;Processor scheduling;Time series analysis;Carbon dioxide;Solar energy;Scheduling;Spatial databases;Optimization;uncertainty quantification;conformal prediction;data center;task scheduling optimization;carbon emission},
  doi={10.1109/ICAACE65325.2025.11019847},
  ISSN={},
  month={March},}@ARTICLE{9967762,
  author={Wei, Qinglai and Yan, Yutian and Zhang, Jie and Xiao, Jun and Wang, Cong},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Self-Attention-Based Deep Reinforcement Learning Approach for AGV Dispatching Systems}, 
  year={2024},
  volume={35},
  number={6},
  pages={7911-7922},
  abstract={The automated guided vehicle (AGV) dispatching problem is to develop a rule to assign transportation tasks to certain vehicles. This article proposes a new deep reinforcement learning approach with a self-attention mechanism to dynamically dispatch the tasks to AGV. The AGV dispatching system is modeled as a less complicated Markov decision process (MDP) using vehicle-initiated rules to dispatch a workcenter to an idle AGV. In order to deal with the highly dynamical environment, the self-attention mechanism is introduced to calculate the importance of different information. The invalid action masking technique is performed to alleviate false actions. A multimodal structure is employed to mix the features of various sources. Comparative experiments are performed to show the effectiveness of the proposed method. The properties of the learned policies are also investigated under different environment settings. It is discovered that the policies explore and learn the properties of different systems, and also smooth the traffic congestion. Under certain environment settings, the policy converges to a heuristic rule that assigns the idle AGV to the workcenter with the shortest queue length, which shows the adaptiveness of the proposed method.},
  keywords={Dispatching;Task analysis;Genetic algorithms;Deep learning;Costs;Vehicle dynamics;Heuristic algorithms;Automated guided vehicle (AGV) dispatching;deep learning;reinforcement learning (RL);self-attention},
  doi={10.1109/TNNLS.2022.3222206},
  ISSN={2162-2388},
  month={June},}@INPROCEEDINGS{10561811,
  author={Rahman, Md Shohanur and Rahman, Md. Atikur and Nipa, Tania Ahmed and Pranto, Md Asif Rahman},
  booktitle={2024 3rd International Conference on Advancement in Electrical and Electronic Engineering (ICAEEE)}, 
  title={A Machine Learning Approach to Predictive Modeling for Breast Cancer Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Breast cancer is a global problem that highlights the need for accurate and efficient diagnostic methods. The aim of this study is to improve patient outcomes by using machine learning approaches to boost early breast cancer diagnosis accuracy. This study examines the accuracy of six distinct machine learning algorithms using a sizable dataset Naive Bayes, Random Forest, Decision Trees, K-nearest neighbors (KNN), Logistic Regression, and Support Vector Machines (SVM) can all be utilized. The models provide promising results, with accuracy levels between 94% and 97%. In addition to accuracy evaluations, this study fully assesses these models using a variety of metrics and uses techniques like cross-validation to guarantee resilience and dependability. Additionally, to maximize model performance and interpretability, the study investigates the possibilities of ensemble approaches and feature selection strategies. The findings of the study offer valuable insights into the application of machine learning methods to enhance the detection of breast cancer. These results demonstrate the effectiveness of several algorithms and present prospects for more advancements in this critical field of medicine.},
  keywords={Support vector machines;Measurement;Logistic regression;Accuracy;Machine learning algorithms;Predictive models;Prediction algorithms;Breast Cancer Prediction;Breast Cancer;Machine Learning;Predictive Modeling for Breast Cancer Diagnosis},
  doi={10.1109/ICAEEE62219.2024.10561811},
  ISSN={},
  month={April},}@ARTICLE{10699471,
  author={Xu, Weihua and Zhang, Yang and Qian, Yuhua},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Novel Unsupervised Feature Selection for High-Dimensional Data Based on FCM and k-Nearest Neighbor Rough Sets}, 
  year={2025},
  volume={36},
  number={6},
  pages={10889-10898},
  abstract={Large amounts of high-dimensional unlabeled data typically contain only a small portion of truly effective information. Consequently, the issue of unsupervised feature selection methods has gained significant attention in research. However, current unsupervised feature selection approaches face limitations when dealing with datasets that exhibit uneven density, and they also require substantial computational time. To address this problem, this research article proposes a feature extraction technique that combines the Fuzzy C-Means (FCM) and k-nearest neighbor rough sets. FCM is a clustering algorithm grounded in fuzzy theory, which takes into account the inherent data structure and the correlations between different features. Consequently, FCM is particularly well-suited for datasets with uneven density. Our proposed method consists of three steps. First, the FCM algorithm is used to cluster the unlabeled data. Second, a measure that evaluates the importance of features is defined and sorted based on the clustering results. Finally, redundant features are filtered using k-nearest neighbor rough sets while retaining important features, significantly reducing the running time. In addition, we designed the feature selection algorithm (KND-UFS) and conducted experiments on 12 public datasets. We compared KND-UFS with eight existing algorithms in terms of running time, classification accuracy, and the number of selected features. The experimental results provided strong evidence supporting the superior performance of the KND-UFS algorithm.},
  keywords={Feature extraction;Clustering algorithms;Rough sets;Nearest neighbor methods;Classification algorithms;Partitioning algorithms;Approximation algorithms;Information systems;Data mining;Accuracy;Clustering;feature selection;granular computing (GrC);k-nearest neighbor rough sets},
  doi={10.1109/TNNLS.2024.3460796},
  ISSN={2162-2388},
  month={June},}@INPROCEEDINGS{10466114,
  author={Rao, Gorapalli Srinivasa and Muneeswari, G.},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={A Systematic Review for Cardiovascular Disease Detection using Machine Learning Methods}, 
  year={2023},
  volume={},
  number={},
  pages={133-138},
  abstract={The most important part of providing health care is diagnosing diseases. If a disease is diagnosed earlier than usual or anticipated, it may save a person's life. Methods based on machine learning can assist the medical field by providing accurate and immediate disease diagnoses. The difficulty of diagnosing heart disease makes it one of the most hazardous diseases in the world today. In healthcare contexts, ML is a powerful technology that can swiftly and correctly predict outcomes. After a brief explanation of machine learning, we present synopses of the very common methods for HD diagnosis. This study provides a comprehensive overview of heart disease, the risk factors associated with it, and a brief discussion of the numerous techniques employed to automatically detect heart disease. The detailed information on certain machine learning-based methodologies and investigates the methods for heart disease diagnosis that have been mentioned in the literature throughout the previous five years (2018-2023). There is also mention of a comparison chart. However, among the possibilities mentioned, the classification of cardiac disease has recently drawn increasing attention as a useful and significant alternative.},
  keywords={Heart;Systematics;Reviews;Cardiac disease;Machine learning;Information and communication technology;Medical diagnosis;Heart Disease;Machine Learning;Classification;Optimizers;XG-Boost},
  doi={10.1109/ICAICCIT60255.2023.10466114},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10799461,
  author={Inoshita, Keito},
  booktitle={2024 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)}, 
  title={Evolutionary Expert Model Merging with Task-Adaptive Iterative Self-Improvement Process for Large Language Modeling on Aspect-Based Sentiment Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={130-136},
  abstract={In recent years, natural language processing (NLP) has achieved notable advancements, particularly with large language models (LLMs) enhancing tasks such as sentiment analysis. Aspect-based sentiment analysis (ABSA), which involves identifying sentiment related to specific aspects within text, poses a more complex challenge compared to simple sentiment classification. To address this complexity, integrating multiple expert models has emerged as a promising approach. In this study, we propose the Evolutionary Expert Model merging with Task-adaptive Iterative Self-improvement Process (EEM-TISP) to improve ABSA task performance. EEM leverages evolutionary algorithms to merge expert models, optimizing task-specific outputs, while TISP iteratively refines these outputs, enhancing accuracy. Our results demonstrate that EEM significantly improves performance in simpler tasks, such as Aspect Term Sentiment Analysis (ATSA) and Aspect Category Sentiment Analysis (ACSA), surpassing individual expert models. TISP further boosts accuracy in these simpler tasks, though performance declines were observed in more complex ones. These findings indicate that while TISP is effective for simpler tasks, further optimization is required to tackle complex ABSA challenges, calling for future research into flexible prompt design and task-specific approaches.},
  keywords={Analytical models;Sentiment analysis;Adaptation models;Accuracy;Large language models;Merging;Real-time systems;Iterative methods;Internet of Things;Optimization;Evolutionary Expert Model Merging;Iterative Self-Improvement;Task Adaptation;Aspect-Based Sentiment Analysis;Large Language Model},
  doi={10.1109/IoTaIS64014.2024.10799461},
  ISSN={2832-1383},
  month={Nov},}@ARTICLE{11084978,
  author={Wang, Zunxun and Li, Junqing and Chen, Xiaolong and Duan, Peiyong and Li, Jiake},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Uncertain Interruptibility Multiobjective Flexible Job Shop via Deep Reinforcement Learning Based on Heterogeneous Graph Self-Attention}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={Although an increasing number of studies have focused on the flexible job shop problem, there has been insufficient consideration of realistic constraints, such as the working hours of employees and the noninterruptible nature of certain operations. To address this issue, here an improved deep reinforcement learning (DRL) approach is presented that utilizes end-to-end multidecision-intelligent body proximal policy optimization (m-PPO). In the proposed framework, a heterogeneous graph self-attention neural network (HGAN) model is embedded, which efficiently extracts valuable features from the original state in heterogeneous graphs to capture intricate relationships. Within this framework, agents are divided into five rule-driven job decision agents and data-driven operation-machine ( $\mathcal {O}\text {-}\mathcal {M}$ ) pair decision agents, which incorporate problem-specific knowledge. To optimize the makespan, total costs, and total lateness concurrently, the weight parameters for the objectives are generated by the network and self-updated based on the current state. Numerical experiments demonstrate the effectiveness of the proposed method.},
  keywords={Costs;Q-learning;Production;Uncertainty;Electricity;Training;Metaheuristics;Learning systems;Job shop scheduling;Heuristic algorithms;Deep reinforcement learning (DRL);flexible job shop problem;heterogeneous graph self-attention neural network (HGAN);multidecision proximal policy optimization;multiobjective optimization},
  doi={10.1109/TNNLS.2025.3578368},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10509264,
  author={Yu, Dan and Li, Xingjun and Araya, Samuel Simon and Lennart Sahlin, Simon and Liso, Vincenzo},
  booktitle={2024 IEEE Applied Power Electronics Conference and Exposition (APEC)}, 
  title={Equivalent Circuit Model Analysis for Data-Driven Oriented Diagnosis of High-Level CO in HT-PEMFC with EIS}, 
  year={2024},
  volume={},
  number={},
  pages={2972-2978},
  abstract={Different equivalent circuit models (ECMs) of Electrochemical impedance spectroscopy (EIS) were analyzed in terms of parameter identification as features for online data-driven diagnosis of CO in the high temperature proton exchanged membrane fuel cell (HT-PEMFC). Parameter identification was performed and analyzed for feature extraction in machine learning model training. The EIS data were tested under 0, 0.75 and 1.5% CO and 5-100A load current on a 10-cell short fuel cell stack. The three levels of CO can be successfully identified via artificial neural network (ANN) and support vector machine (SVM). Anode reaction(1000-100Hz) and diffusion(100-5Hz) influenced by CO were suggested as two factors for the interpretability of the selected ECM. On the other hand, the simple ECM with fewer electrical components should be selected provided it can meet the diagnosis requirement by machine learning methods. This work contributes to the selection of ECM and the interpretation of machine learning methods for online diagnosis on HT-PEMFC with EIS.},
  keywords={Support vector machines;Analytical models;Parameter estimation;Fitting;Fuel cells;Machine learning;Artificial neural networks;HT-PEMFC;EIS;Fault diagnosis;Data-driven;Equivalent circuit model},
  doi={10.1109/APEC48139.2024.10509264},
  ISSN={2470-6647},
  month={Feb},}@INPROCEEDINGS{10980781,
  author={Shen, Yunfei and Jie, Biao and Wu, Zhaoxiang and Zhang, Yang and Yang, Yang and Hu, Liangchen},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)}, 
  title={SFECNet: Fusion of Structural, Functional and Effective Connectivity Network for Epilepsy Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={For brain network analysis, multimodal fusion learning leverages multiple medical imaging modalities to gather more comprehensive information. This method could usually results more accurate diagnoses in brain diseases like epilepsy. Many multimodal approaches typically construct only structural connectivity (SC) networks and functional connectivity (FC) networks. However SC and FC are undirected connectivity, leading to lack of directed interaction between brain regions. Effective connectivity (EC) networks implying causal relationships, could further offer complementary information. So we propose a Fusion of Structural, Functional and Effective Connectivity Network for Epilepsy Classification (SFECNet). We construct SC, FC, and EC networks using DTI and fMRI data and apply graph convolutional networks (GCNs) to extract dynamic and static features. Crossattention mechanisms guide the fusion of multimodal feature information to finally make epilepsy classification. Experiments on the epilepsy dataset demonstrate the feasibility and effectiveness of our proposed method.},
  keywords={Attention mechanisms;Graph convolutional networks;Epilepsy;Network analyzers;Functional magnetic resonance imaging;Feature extraction;Brain modeling;Data mining;Diffusion tensor imaging;Biomedical imaging;Multimodal fusion;Brain connectivity network;Graph convolutional network;Epilepsy;Attention mechanism},
  doi={10.1109/ISBI60581.2025.10980781},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10796056,
  author={Mokwana, Tlhokaboyo Innocntia and Monchusi, Bessie Baakanyang},
  booktitle={2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)}, 
  title={Empowering Electrical Machine Performance: The Convergence of Artificial Intelligence and Motor Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The integration of Artificial Intelligence (AI) in electrical machine design and maintenance has opened new pathways for achieving enhanced performance, efficiency, and sustainability across various applications. This review explores the current landscape of AI-driven methodologies for motor design, predictive maintenance, and control optimization, analyzing the impact of these technologies on electrical machine capabilities. The study identifies prevalent AI approaches-including machine learning, optimization algorithms, and neural networks-detailing their application, benefits, and limitations in improving motor efficiency and reliability. Despite the advancements, challenges remain, particularly in terms of model complexity, interpretability, and economic feasibility. Moreover, the societal and environmental implications of AI-driven innovations in electrical engineering are considered, with a focus on aligning future research with sustainable development goals. This paper provides a comprehensive overview of the state of AI in electrical machine applications, emphasizing the potential of AI to transform the field while addressing the barriers that must be overcome for widespread implementation.},
  keywords={Technological innovation;Ethics;Electric potential;Reviews;Motors;Complexity theory;Artificial intelligence;Sustainable development;Optimization;Predictive maintenance;component;formatting;style;styling;insert},
  doi={10.1109/ICECCME62383.2024.10796056},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11009404,
  author={Dai, Qinghua and Yang, Xing and Gao, Haoqi and Mu, Hua},
  booktitle={2025 7th International Conference on Software Engineering and Computer Science (CSECS)}, 
  title={A Survey of Physical Adversarial Attacks Against Infrared Target Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The existence of adversarial examples revealed the underlying vulnerabilities of deep learning models. In the digital domain, meticulously designed subtle perturbations could degrade model performance or even completely cause it to lose its intended functionality. In real-world physical scenarios, adversarial examples also demonstrated potent destructive power and substantial risks. This survey explored the issue of physical adversarial attacks in the crucial field of infrared object detection. Firstly, it provided a clear and in-depth explanation of the concept of physical adversarial attacks in the field of infrared target detection, distinguishing them from traditional digital adversarial attacks, and precisely locating their unique roles and manifestations in real-world scenarios. Secondly, focusing on the diverse detection tasks and targets in infrared scenarios, this review comprehensively and thoroughly examined the emerging physical adversarial attack methods targeting infrared object detection network models, from the perspectives of different detection systems such as pedestrian, vehicle, and remote sensing data detection. Finally, based on the then-current research achievements and technological development trends, it offered a positive outlook for the future of this field.},
  keywords={Surveys;Deep learning;Pedestrians;Reviews;Perturbation methods;Focusing;Object detection;Market research;Remote sensing;Software engineering;Adversarial examples;Infrared target detection;Physical adversarial attacks},
  doi={10.1109/CSECS64665.2025.11009404},
  ISSN={},
  month={March},}@ARTICLE{10477462,
  author={Xu, Kai-Da and Tian, Jing and Cai, Yijun and Li, Daotong and Wu, Wen and Chen, Qiang},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
  title={An Optimization Method for Coupled-Line Bandpass Filters Using Transformer-Based Estimator and Multilayer Perceptron}, 
  year={2024},
  volume={71},
  number={9},
  pages={4136-4140},
  abstract={A novel method for estimation and optimizing structural parameters of coupled-line bandpass filters (BPFs) using transformer-based estimator (TBE) and multilayer perceptron (MLP) is proposed. Once trained, the TBE can quickly obtain the predicted values of the BPF structural parameters from desired S-parameters, while the trained MLP can replace the time-consuming electromagnetic (EM) simulation process, and establish the mapping from structural parameters to S-parameters. In order to obtain the optimal structural parameters, the trained MLP is combined with genetic algorithm (GA) for fast optimization. To demonstrate the effectiveness of the proposed method, a BPF using three pairs of coupled-line microstrip structure is designed and fabricated. The experimental results demonstrate that the proposed method can quickly and accurately obtain the optimal structural parameters from the desired frequency response of the coupled-line BPF.},
  keywords={Structural engineering;Scattering parameters;Band-pass filters;Artificial neural networks;Microwave filters;Transformers;Optimization;Bandpass filters;genetic algorithm;multilayer perceptron;structural parameters;transformer},
  doi={10.1109/TCSII.2024.3380412},
  ISSN={1558-3791},
  month={Sep.},}@ARTICLE{9667188,
  author={Silva, Andrew and Moorman, Nina and Silva, William and Zaidi, Zulfiqar and Gopalan, Nakul and Gombolay, Matthew},
  journal={IEEE Robotics and Automation Letters}, 
  title={LanCon-Learn: Learning With Language to Enable Generalization in Multi-Task Manipulation}, 
  year={2022},
  volume={7},
  number={2},
  pages={1635-1642},
  abstract={Robots must be capable of learning from previously solved tasks and generalizing that knowledge to quickly perform new tasks to realize the vision of ubiquitous and useful robot assistance in the real world. While multi-task learning research has produced agents capable of performing multiple tasks, these tasks are often encoded as one-hot goals. In contrast, natural language specifications offer an accessible means both for (1) users to describe a set of new tasks to the robot and (2) robots to reason about the similarities and differences among tasks through language-based task embeddings. Until now, multi-task learning with language has been limited to navigation based tasks and has not been applied to continuous manipulation tasks, requiring precision to grasp and move objects. We present LanCon-Learn, a novel attention-based approach to language-conditioned multi-task learning in manipulation domains to enable learning agents to reason about relationships between skills and task objectives through natural language and interaction. We evaluate LanCon-Learn for both reinforcement learning and imitation learning, across multiple virtual robot domains along with a demonstration on a physical robot. LanCon-Learn achieves up to a 200% improvement in zero-shot task success rate and transfers known skills to novel tasks faster than non-language-based baselines, demonstrating the utility of language for goal specification.},
  keywords={Task analysis;Multitasking;Robots;Natural languages;Reinforcement learning;Encoding;Navigation;Deep learning methods;imitation learning;reinforcement learning},
  doi={10.1109/LRA.2021.3139667},
  ISSN={2377-3766},
  month={April},}@ARTICLE{9744474,
  author={Zhu, Yuanda and Sha, Ying and Wu, Hang and Li, Mai and Hoffman, Ryan A. and Wang, May D.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Proposing Causal Sequence of Death by Neural Machine Translation in Public Health Informatics}, 
  year={2022},
  volume={26},
  number={4},
  pages={1422-1431},
  abstract={Each year there are nearly 57 million deaths worldwide, with over 2.7 million in the United States. Timely, accurate and complete death reporting is critical for public health, especially during the COVID-19 pandemic, as institutions and government agencies rely on death reports to formulate responses to communicable diseases. Unfortunately, determining the causes of death is challenging even for experienced physicians. The novel coronavirus and its variants may further complicate the task, as physicians and experts are still investigating COVID-related complications. To assist physicians in accurately reporting causes of death, an advanced Artificial Intelligence (AI) approach is presented to determine a chronically ordered sequence of conditions that lead to death (named as the causal sequence of death), based on decedent's last hospital discharge record. The key design is to learn the causal relationship among clinical codes and to identify death-related conditions. There exist three challenges: different clinical coding systems, medical domain knowledge constraint, and data interoperability. First, we apply neural machine translation models with various attention mechanisms to generate sequences of causes of death. We use the BLEU (BiLingual Evaluation Understudy) score with three accuracy metrics to evaluate the quality of generated sequences. Second, we incorporate expert-verified medical domain knowledge as constraints when generating the causal sequences of death. Lastly, we develop a Fast Healthcare Interoperability Resources (FHIR) interface that demonstrates the usability of this work in clinical practice. Our results match the state-of-art reporting and can assist physicians and experts in public health crisis such as the COVID-19 pandemic.},
  keywords={Codes;Medical services;Hospitals;Public healthcare;COVID-19;Interoperability;Deep learning;Cause of death;COVID-19 pandemic;deep learning;fast healthcare interoperability resources (FHIR);population health data analytics},
  doi={10.1109/JBHI.2022.3163013},
  ISSN={2168-2208},
  month={April},}@INPROCEEDINGS{10269859,
  author={Mishra, Priya and Chaurasia, Nisha},
  booktitle={2023 3rd Asian Conference on Innovation in Technology (ASIANCON)}, 
  title={Let's Identify the Similar and Confusing Raags of Hindustani Classical Music}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The identification of different raags in Indian classical music is a challenging task, and distinguishing between Raag Bhoopali and Raag Deshkar is no exception. The reason why this is a difficult task is both the raags share similar melodic structures, including the use of a pentatonic scale (“Audav” scale) with five notes (Sa, Re, Ga, Pa, and Dha). This makes it challenging to differentiate between the two raags, especially for those who are not familiar with the nuances of Indian classical music. The present research work addresses this issue of identification between two raags. We have purposed a method based on attention employing a Neural Network (NN) architecture, for identifying the two. To assess the proposed technique, we curated a dataset of Hindustani Classical music comprising these two distinct raags. Before proceeding with the analysis, we performed multiple pre-processing steps, audio data augmentation techniques, and feature extraction methods on the dataset, which yielded several feature values. Next, we employed the proposed architecture that utilized a classification algorithm. Additionally, to gain further insights into the proposed approach we conducted a counterfactual analysis, which involved identifying the minimum changes required in the input data to change the classification outcome. The attention-based neural network architecture plays a significant role in extracting pertinent information about the raags from the pre-processed data. The developed technique was evaluated based on key performance parameters such as accuracy, precision, recall, and F1 score, yielding impressive scores of 0.949, 0.949, 0.949, and 0.949 respectively. This indicates the clear superiority of our proposed approach over previously published methods in the literature.},
  keywords={Technological innovation;Artificial neural networks;Feature extraction;Data augmentation;Classification algorithms;Data mining;Task analysis;Attention;Neural Networks;Raag Identification;Machine Learning;Music Information Retrieval;Counterfactual},
  doi={10.1109/ASIANCON58793.2023.10269859},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10864023,
  author={Cao, Danyang and Cheng, Cheng},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Survey on Deep Learning Applications in Automated Chinese Poetry Composition}, 
  year={2024},
  volume={},
  number={},
  pages={662-666},
  abstract={Chinese poetry generation is a challenging task in natural language processing that requires meeting various criteria, including structure, phonetics, and semantics. Early research employed methods such as genetic algorithms and statistical machine translation models; however, the quality and diversity of the generated poetry were limited. With the advancement of deep learning, recurrent neural networks (RNNs) and transformer models have become mainstream approaches due to their ability to capture long-distance dependencies. Reinforcement learning has also been introduced to enhance the diversity and coherence of generated poetry. Additionally, large-scale pretrained models based on BERT and GPT have shown the ability to produce high-quality poetry after fine-tuning. Nevertheless, current technologies still face challenges regarding poetry quality, precision in format control, and consistency in theme and emotion, indicating a need for further theoretical and technical exploration in the future},
  keywords={Deep learning;Surveys;Technological innovation;Semantics;Transformers;Machine translation;Resource management;Standards;Faces;Genetic algorithms;generation of poetry;Transformer;End to end system;Reinforcement learning;LLM},
  doi={10.1109/ICAICE63571.2024.10864023},
  ISSN={},
  month={Nov},}@ARTICLE{10803076,
  author={Han, Byeolyi and Cho, Minwoo and Chen, Letian and Paleja, Rohan and Wu, Zixuan and Ye, Sean and Seraj, Esmaeil and Sidoti, David and Gombolay, Matthew},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning Multi-Agent Coordination for Replenishment At Sea}, 
  year={2025},
  volume={10},
  number={2},
  pages={1018-1025},
  abstract={Optimizing large-scale logistics is computationally challenging due to its scale and requirement to be robust to stochastic and time-varying weather disturbances. However, prior research in multi-agent reinforcement learning (MARL) does not address scenarios that capture complexity of logistics operations influenced by dynamic weather patterns. To address this gap, we suggest a new MARL environment, $\textsc {Marine}$ that has two types of agents equipped with limited resources and integrates real wave data to model the influences of weather on the replenishment at sea (RAS) operation. To this end, we propose SchedHGNN, a novel MARL algorithm that incorporates a heterogeneous graph neural network and an intrinsic reward scheme to enhance agent coordination and mitigate challenges induced by environment non-stationarity. Our results show that the combination of effective RAS scheduling and improved communication enables our model to outperform competitive baselines by up to 37.8%. This achievement marks a significant advancement in applying MARL to complex, real-world logistics scenarios.},
  keywords={Logistics;Routing;Meteorology;Vectors;Reinforcement learning;Benchmark testing;Stochastic processes;Resource management;Optimization;Marine vehicles;Multi-agent reinforcement learning (MARL);maritime logistics;replenishment-at-sea;intrinsic rewards},
  doi={10.1109/LRA.2024.3518304},
  ISSN={2377-3766},
  month={Feb},}@INPROCEEDINGS{10871994,
  author={Rao, Kota Srinivasa and Panda, Ribhu Abhusan and Bellamkonda, Pragathi},
  booktitle={2024 IEEE 4th International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC)}, 
  title={Optimization of Antenna Performance for IoT Applications Using Machine Learning Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The integration of machine learning (ML) into antenna optimization has revolutionized the design and enhancement of antenna systems. This paper provides an in-depth review of the latest advancements in antenna design optimization through ML techniques. The goal of this survey is to highlight various ML optimization methods and their effectiveness, along with the challenges they pose in terms of efficiency. A comprehensive literature review is presented, detailing the optimization algorithms and procedures employed to achieve specific antenna performance metrics, including gain, bandwidth, radiation pattern, and impedance matching. The paper begins with an overview of machine learning and its algorithms, followed by a concise explanation of the antenna optimization process. Subsequently, it introduces different printed antenna designs optimized using ML algorithms. The techniques discussed in this survey are poised to significantly impact the future development of antennas for diverse wireless applications.},
  keywords={Surveys;Wireless communication;Machine learning algorithms;Design methodology;Machine learning;Robustness;Antennas;Optimization;Antenna radiation patterns;Systematic literature review;Machine Learning;IoT;Antenna;Wireless Network},
  doi={10.1109/AESPC63931.2024.10871994},
  ISSN={},
  month={Nov},}@ARTICLE{9999227,
  author={Shafiq, Shakila and Ahmed, Sabbir and Kaiser, M. Shamim and Mahmud, Mufti and Hossain, Md. Shahadat and Andersson, Karl},
  journal={IEEE Access}, 
  title={Comprehensive Analysis of Nature-Inspired Algorithms for Parkinson’s Disease Diagnosis}, 
  year={2023},
  volume={11},
  number={},
  pages={1629-1653},
  abstract={Parkinson’s disease (PD) is a prominent neurodegenerative disease that damages the neurons of the substantia nigra, causing irreversible impairments leading to involuntary movements. As this disease disrupts patients’ daily activities in a mature stage, early detection of the disease is crucial. Several methods based on nature-inspired (NI) algorithms have been proposed for PD detection and patient management. As there are several NI algorithms for feature selection, a mapping with an individual machine learning (ML) classifier is necessary to obtain optimal performance of the detection pipeline. To fill this gap, in this work, 13 NI algorithms and 11 ML classifiers were selected, and critical comparisons were performed regarding their combined performance in detecting PD. Each NI algorithm was employed to select an optimal feature set which was then classified by the 11 ML classifiers keeping the same parameters. This generated 143 NI-ML pairs, which were carefully compared to find the best-performing pairs considering several assessment criteria such as accuracy, cross-validation mean score, precision, recall and F1-score. The results of the extensive comparative analysis allowed the ranking of the algorithms in the 50th, 75th and 95th percentile to identify the best-performing pairs. The analyses revealed that 12 NI-ML models obtained a testing accuracy of over 91%, which is above the 95th percentile value. The Flower Pollination Algorithm and Extreme Gradient Boost Algorithm pair obtained the highest testing accuracy of 93%. This study revealed the remarkable performance of the boosting algorithms promoting explainable machine learning in PD detection.},
  keywords={Classification algorithms;Feature extraction;Optimization;Genetic algorithms;Diseases;Machine learning algorithms;Costs;Parkinson’s disease;nature-inspired algorithms;machine learning classifiers;feature selection;classification},
  doi={10.1109/ACCESS.2022.3232292},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10021096,
  author={Fujimoto, Yugo and Nakagawa, Kei and Imajo, Kentaro and Minami, Kentaro},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Uncertainty Aware Trader-Company Method: Interpretable Stock Price Prediction Capturing Uncertainty}, 
  year={2022},
  volume={},
  number={},
  pages={1238-1245},
  abstract={Machine learning is an increasingly popular tool with some success in predicting stock prices. One promising method is the Trader-Company (TC) method, which takes into account the dynamism of the stock market and has both high predictive power and interpretability. Machine learning-based stock prediction methods, including the TC method, have been concentrating on point prediction. However, point prediction in the absence of uncertainty estimates lacks credibility quantification and raises concerns about safety. The challenge in this paper is to make an investment strategy that combines high predictive power and the ability to quantify uncertainty. We propose a novel approach called Uncertainty Aware Trader-Company Method (UTC) method. The core idea of this approach is to combine the strengths of both frameworks by merging the TC method with the probabilistic modeling, which provides probabilistic predictions and uncertainty estimations. We expect this to retain the predictive power and interpretability of the TC method while capturing the uncertainty. We theoretically prove that the proposed method estimates the posterior variance and does not introduce additional biases from the original TC method. We conduct a comprehensive evaluation of our approach based on the synthetic and real market datasets. We confirm with synthetic data that the UTC method can detect situations where the uncertainty increases and the prediction is difficult. We also confirmed that the UTC method could detect abrupt changes in data-generating distributions. We demonstrate with real market data that the UTC method can achieve higher returns and lower risks than baselines.},
  keywords={Uncertainty;Merging;Machine learning;Predictive models;Big Data;Probabilistic logic;Prediction algorithms;Finance;Metaheuristics;Stock Price Prediction;Uncertainty},
  doi={10.1109/BigData55660.2022.10021096},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10799909,
  author={Prasad, Rajesh and Jarin, T. and Mewada, Hiren and Jose, Jithin K and Arthi, M. and Ramu, T Bhargava},
  booktitle={2024 6th International Symposium on Advanced Electrical and Communication Technologies (ISAECT)}, 
  title={Solar Energy Forecasting using Optimized Attention-based Bidirectional Long Short-Term Memory}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Solar energy is abundantly available in the environment and is beneficial for preserving the environment, since they are regenerative and hold significant promise for the future. Forecasting accurate solar energy plays a major part in enhancing the determination of solar power plants, while also decreasing reliance on fossil fuels for economic and social progress. In the domain of deep learning (DL), the prediction of solar resources has transitioned from traditional statistical methods to the implementation of advanced DL models. This work introduces a model of "optimized attention-bidirectional long short-term memory" (OA-Bi-LSTM) for predicting solar energy. Here, the hyper-parameters of the BiLSTM are optimized by the manta ray optimization (MRO). The proposed model predicts solar energy in an efficient manner with respect to the different measures and achieves better MAE (0.15) and RMSE (0.21) values respectively.},
  keywords={Renewable energy sources;Attention mechanisms;Statistical analysis;Biological system modeling;Solar energy;Predictive models;Real-time systems;Reliability;Forecasting;Power generation;Renewable energy;solar energy;attention-bidirectional long short-term memory;optimization},
  doi={10.1109/ISAECT64333.2024.10799909},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11077474,
  author={Ramakrishnan, Akshay Bhuvaneswari and Zhu, Alex and Dasu, Shravya and Cruz, Meenalosini Vimal},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={A Unified Framework for Chest CT Image Classification: Benchmarking Pre-Trained Architectures with Lightweight and Deep Models}, 
  year={2025},
  volume={},
  number={},
  pages={312-317},
  abstract={Lung cancer is a common malignancy and a leading cause of cancer-related deaths. Accurate classification of lung cancer is essential for determining effective treatment options. Despite conventional methods for identifying lung cancer types, advancements in deep learning algorithms have enabled faster and more precise classification. While deep learning techniques have significantly advanced lung cancer classification, challenges such as explainability, computational complexity, and inconsistent model benchmarking remain in this fast-moving research area. We propose a novel approach to categorize forms of lung cancer by employing an architecture that integrates multiple deep learning models ResNet50, VGG16 and InceptionV3 into a unified framework for chest CT image classification. To reduce class imbalance and overfitting, our design makes use of class weighting and specialized data augmentation methods. To improve model transparency for clinical adoption, Grad-CAM was utilized for visual interpretability.},
  keywords={Deep learning;Analytical models;Visualization;Computed tomography;Atmospheric modeling;Computational modeling;Lung cancer;Computer architecture;Benchmark testing;Image classification;Lung Cancer Classification;Deep Learning Models;CT Image Analysis;Grad-CAM Interpretability;Ensemble Learning},
  doi={10.1109/AIRC64931.2025.11077474},
  ISSN={},
  month={May},}@INPROCEEDINGS{10131873,
  author={Nasiri, Asil Hassan and Sadath, Lipsa and Mishra, Ved Prakash},
  booktitle={2023 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Home Energy Management Using Fuzzy Logic}, 
  year={2023},
  volume={},
  number={},
  pages={499-504},
  abstract={Fuzzy logic is a new way of computing so that more content can be examined on a computer. A computer that has all its knowledge in terms of two numbers, zero and one, cannot show flexibility. Fuzzy logic, which is now part of artificial intelligence systems, can have many applications. Fuzzy logic system controls energy sources and helps to reduce energy consumption. This paper a novel study to understand the use of the fuzzy logic system in daily life. Therefore, we are propose a new framework using fuzzy logic that controls the house lighting and home temperature intelligently to make an environment with lesser amount of greenhouse gases and energy consumption.},
  keywords={Fuzzy logic;Energy consumption;Greenhouse effect;Lighting;Control systems;Temperature control;Energy management;Artificial Intelligence;Fuzzy logic;Energy},
  doi={10.1109/ICCIKE58312.2023.10131873},
  ISSN={},
  month={March},}@ARTICLE{11045723,
  author={Li, Jiacheng and Chen, Wei and Liu, Yican and Yang, Junmei and Zhou, Zhiheng and Zeng, Delu},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Integrating Ordinary Differential Equations With Sparse Attention for Power Load Forecasting}, 
  year={2025},
  volume={74},
  number={},
  pages={1-12},
  abstract={Accurate load forecasting plays an essential role in the measurement, monitoring, and control frameworks of modern power systems, particularly given the continuous influx of high-resolution data from advanced metering devices. Traditional forecasting methods often struggle due to the inherent nonstationarity and multiscale dynamics observed in these data streams. To address these challenges, this article introduces EvolvInformer, a novel long-sequence forecasting framework that integrates ordinary differential equations (ODEs) solver within a ProbSparse self-attention decoder architecture. The ODE module provides a physics-inspired, continuous-time representation of hidden state dynamics, enabling the model to capture subtle fluctuations and abrupt regime shifts commonly found in instrumented load profiles. Comprehensive experiments conducted on five large-scale power load datasets demonstrate that EvolvInformer achieves a 29.7% reduction in mean-squared error (mse) compared to state-of-the-art baseline models while preserving the logarithmic memory complexity characteristic of ProbSparse attention. Moreover, EvolvInformer consistently models both global trends and localized transient phenomena under stringent computational constraints, making it particularly suitable for embedded and edge-based metering applications. By effectively coupling continuous-time modeling via ODE with an efficient sparse attention mechanism for long-sequence forecasting, EvolvInformer provides a robust and scalable solution for measurement-centric load prediction tasks, with broad potential applications in adaptive energy management, grid load forecasting, and metering data quality assessment.},
  keywords={Forecasting;Load modeling;Predictive models;Computational modeling;Load forecasting;Accuracy;Transformers;Mathematical models;Decoding;Long short term memory;Evolutionary computation;load forecasting;ordinary differential equations (ODEs);time-series analysis;Transformer},
  doi={10.1109/TIM.2025.3581667},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{9985637,
  author={S, Manimekalai and Yamunaa, P. and Ashwini, R. and Karthick, V. and Alluri, Amarendra and Prakash, R B R and Jothi, B. Jega},
  booktitle={2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Automated Short Term Load Prediction in Power Systems using Collision Bodies Optimization with MultiHead Deep Learning Model}, 
  year={2022},
  volume={},
  number={},
  pages={693-696},
  abstract={Short-term load forecasting (STLF) of power systems is an important portion of the daily dispatch of the power industry. The preciseness of STLF straightforwardly disturbs the reliability, security, and economy of power system function. Thus, the research on STLF techniques is the main focus of researchers at abroad and home. Recently, artificial neural networks (ANN) were broadly studied as an intellectual method and implemented in the domain of short-term power load forecasting. Distinct methods like hybrid, conventional, and Artificial Intelligence (AI) methods were advanced to examine STLF. In this view, this study develops an Automated Short Term Load Prediction in Power Systems using Collision Bodies Optimization with MultiHead Deep Learning (AS TLP-CBMDL) model. The major intention of the AS TLP-CBMDL methodology is to predict the load in power systems which are adaptable to the time varying characteristics. To accomplish this, the ASTLP-CBMDL system model applies multihead attention based long short-term memory (MHALS TM) technique for performing load prediction. In addition, the colliding body's optimization (CBO) algorithm is utilized to optimally tune the hyperparameters related to the MHALSTM model to enhance the prediction efficacy. The experimental validation of the ASTLP-CBMDL model is tested using open access dataset and the outcomes are examined extensively. The comprehensive result analysis stated the enhanced performance of the ASTLP-CBMDL model over recent approaches.},
  keywords={Adaptation models;Open Access;Load forecasting;Computational modeling;Predictive models;Prediction algorithms;Power systems;Short term load prediction;Machine learning;Deep learning;Power systems;Artificial intelligence},
  doi={10.1109/ICIRCA54612.2022.9985637},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10889716,
  author={Kong, Ge and Wang, Jiao and Wang, Juan},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={GATOmics: A Novel Multi-Omics Graph Attention Network Model for Cancer Driver Gene Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Identifying cancer driver genes remains challenging due to the complexity of gene interactions in cancer genomics. Existing methods often face difficulties in integrating multidimensional biological data, which limits their ability to capture diverse gene relationships. GATOmics, a novel multi-omics framework, addresses this by integrating four networks, protein-protein interactions, tissue co-expression, pathway co-occurrence, and gene semantic similarity. Utilizing a graph attention network to enhance feature extraction. By employing self-attention mechanisms and convolutional modules, GATOmics captures long-range gene interactions, improving prediction accuracy. The use of semi-supervised learning enables the model to leverage both labeled and unlabeled data, enhancing generalization across different cancer types. Evaluations on pan-cancer datasets demonstrate that GATOmics consistently outperformed state-of-the-art methods, achieving higher AUC and AUPRC scores, highlighting its potential for broader applications in cancer genomics research. The code and data for GATOmics are available at https://github.com/ggkong/GATOmics},
  keywords={Proteins;Accuracy;Semantics;Transcriptomics;Predictive models;Data models;Bioinformatics;Biological information theory;Speech processing;Cancer;cancer driver genes;attention mechanism;graph attention network;biological signaling},
  doi={10.1109/ICASSP49660.2025.10889716},
  ISSN={2379-190X},
  month={April},}@ARTICLE{11006006,
  author={Wang, Mingcan and Wang, Zhiqiong and Qu, Luxuan and Long, Kaifu and Xin, Junchang},
  journal={IEEE Transactions on Computational Biology and Bioinformatics}, 
  title={BFMDDT: A Decision-Tree-Based Gene Regulatory Network Inference from Multi-Type Datasets}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Gene regulatory network (GRN) reconstruction remains a great challenge in computational biology and bioinformatics. However, most existing methods focus on inferring GRNs from a single type of dataset, rather than try to integrate multi-type datasets. In this work, GRN inferences based on decision tree (DT) model are improved to handle multi-type gene expression datasets and a novel inference named BFMDDT for GRN reconstruction from multi-type datasets is proposed. In BFMDDT, a specific data-integration strategy is performed on different types of datasets to extract two types of training sets, firstly. Then specific DT models are applied to learn the feature importance from these training sets in two ways. On the one hand, which gene(s) would regulate a specific gene is determined by one ensemble DT model. On the other hand, which gene(s) are regulated by the specific gene is determined by one ensemble DT model of the same type. At last, by mixing the feature importance gained via the two models, a global feature importance ranking is acquired and the GRN can be constructed according to the ranking. BFMDDT shows confidence in extracting information from multi-type datasets and the extensibility by combining with other technologies. Numerous experiments are conducted which show the effectiveness of data integration, the GRN reconstruction accuracy, efficiency and extensibility of BFMDDT, respectively. Data and codes are available at https://github.com/mcwang-neu/BFMDDT.},
  keywords={Decision trees;Training;Accuracy;Gene expression;Frequency modulation;Boosting;Bagging;Random forests;Prediction algorithms;Bioinformatics;gene regulatory network;data integration;multi-type dataset;decision tree},
  doi={10.1109/TCBBIO.2025.3570817},
  ISSN={2998-4165},
  month={},}@INPROCEEDINGS{10973577,
  author={Sugie, Naoki and Yoshizoe, Mamoru and Hattori, Hiromitsu},
  booktitle={2024 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)}, 
  title={Development of a Participatory Policy Planning Tool Based on Multi-Agent Social Simulation}, 
  year={2024},
  volume={},
  number={},
  pages={281-288},
  abstract={Cities are intricate systems where diverse social structures interact, leading to the continuous emergence of complex social phenomena. Analyzing and optimizing these interactions, as well as efficiently managing urban systems, present significant challenges. Multi-Agent Social Simulation (MASS) offers promising solutions for these challenges. However, MASS is not a user-friendly technology for stakeholders involved in urban issues, such as residents and local government officials. This paper presents the development of a participatory policy planning tool based on MASS. We developed a prototype system to explore potential traffic policies, integrating traffic simulation, data visualization, and a web-based interface. A social experiment conducted with residents in Japan demonstrated the potential of the MASS-based planning tool. Additionally, in the paper, we discuss an approach to simulate and evaluate urban traffic policies on the developed MASS-based system, focusing on optimizing the combination of traffic signal timing adjustments and policy implementations.},
  keywords={Local government;Urban areas;Merging;Data visualization;Prototypes;Traffic control;Planning;Timing;Stakeholders;Optimization;Multi-Agent Simulation;Urban Traffic Simulation;Genetic Algorithm},
  doi={10.1109/WI-IAT62293.2024.00044},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10920616,
  author={Li, Hongjun and Cai, Shixi and Long, Jianyu and Huang, Yunwei and Yang, Zhe and Li, Chuan},
  booktitle={2024 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Selective Assembly of Rolling Element Bearings Based on Pointer Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Radial clearance is an important quality indicator for deep groove ball bearings and cylindrical roller bearings. Given a batch of components, including outer rings, inner rings and rolling elements, with different sizes due to the manufacturing error, selective assembly is critical to properly combine these components to obtain qualified bearings as many as possible. This work proposes a method based on pointer network to address the precise selective assembly of bearing components. A graph embedding layer is employed to model all the components as graph nodes and their possible relationship as edges. The pointer network is trained to generate a sequence representing the assembly relationship of components, aiming to maximize the assembly rate and minimize the bias with respect to the best clearance. Compared with traditional intelligent optimization methods, such as genetic algorithm, which can also be used to approximate solutions for the selective assembly of bearing components, the proposed method outperforms with better generalization capability, it can be trained using a small-batch of data and be applied for a much large batch problem without losing accuracy and significant increasing the computational time.},
  keywords={Training;Data analysis;Accuracy;Computational modeling;Ball bearings;Rolling bearings;Optimization methods;Artificial intelligence;Assembly;Genetic algorithms;Rolling element bearings;selective assembly;clearance;pointer network},
  doi={10.1109/ICSMD64214.2024.10920616},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11043068,
  author={Sun, Yuelang and Wang, Guan and Li, Weihua and Kuo, Matthew and Bai, Quan and Jiang, Jianhua},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Multi-Level Representation of Long MIDI Sequences: Integrating Bar-Level Encoding with Music-Level Context}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Symbolic music, represented as MIDI files, encapsulates intricate performance details and complex temporal and structural dependencies. Effectively modelling ultra-long MIDI sequences is essential for understanding sophisticated compositions and advancing tasks like music generation, classification, and performance analysis. However, these long MIDI sequences pose significant challenges due to their complexity, multi-track concurrency, and extensive temporal relationships. This paper introduces a novel model named LongMIDI-Net that enhances the capability of bar-level pretrained large-scale MIDI sequence understanding models, extending their effectiveness to handle complete and long MIDI sequences. The proposed approach integrates structure-sensitive models for processing bar-level segments with temporal-sensitive models to capture global relationships across entire sequences. This hierarchical design significantly reduces sequence length while maintaining high model performance. Comprehensive experiments on classification tasks across multiple datasets demonstrate the superior effectiveness of the proposed model, achieving consistently strong results. Furthermore, ablation studies highlight the advantages of bar-level segmentation over random slicing, showcasing its ability to provide a more effective and structurally coherent representation of MIDI sequences. These findings underline the importance of combining local and global information for advancing symbolic music understanding.},
  keywords={Concurrent computing;Analytical models;Evolutionary computation;Encoding;Performance analysis;Complexity theory},
  doi={10.1109/CEC65147.2025.11043068},
  ISSN={},
  month={June},}@ARTICLE{9978641,
  author={Liu, Zhun-ga and Fu, Yi-min and Pan, Quan and Zhang, Zuo-wei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Orientational Distribution Learning With Hierarchical Spatial Attention for Open Set Recognition}, 
  year={2023},
  volume={45},
  number={7},
  pages={8757-8772},
  abstract={Open set recognition (OSR) aims to correctly recognize the known classes and reject the unknown classes for increasing the reliability of the recognition system. The distance-based loss is often employed in deep neural networks-based OSR methods to constrain the latent representation of known classes. However, the optimization is usually conducted using the nondirectional euclidean distance in a single feature space without considering the potential impact of spatial distribution. To address this problem, we propose orientational distribution learning (ODL) with hierarchical spatial attention for OSR. In ODL, the spatial distribution of feature representation is optimized orientationally to increase the discriminability of decision boundaries for open set recognition. Then, a hierarchical spatial attention mechanism is proposed to assist ODL to capture the global distribution dependencies in the feature space based on spatial relationships. Moreover, a composite feature space is constructed to integrate the features from different layers and different mapping approaches, and it can well enrich the representation information. Finally, a decision-level fusion method is developed to combine the composite feature space and the naive feature space for producing a more comprehensive classification result. The effectiveness of ODL has been demonstrated on various benchmark datasets, and ODL achieves state-of-the-art performance.},
  keywords={Training;Optimization;Graphical models;Distribution functions;Deep learning;Support vector machines;Neural networks;Composite feature space;hierarchical spatial attention;open set recognition;orientational distribution learning},
  doi={10.1109/TPAMI.2022.3227913},
  ISSN={1939-3539},
  month={July},}@ARTICLE{10505252,
  author={Cheng, Zhi and Gao, Liping and Wang, Yu and Deng, Zaohui and Tao, Yin},
  journal={IEEE Access}, 
  title={EC-YOLO: Effectual Detection Model for Steel Strip Surface Defects Based on YOLO-V5}, 
  year={2024},
  volume={12},
  number={},
  pages={62765-62778},
  abstract={Defect detection is extensively utilized within the metal industry, particularly for identifying surface imperfections on steel strips. However, the current methods still face challenges in detecting small and elongated defects on steel strips. Such defects occupy a relatively small pixel percentage within the entire image. The repeated downsampling in convolutional networks, coupled with the dynamic changes in the receptive field, can result in the potential loss of these minute defects. To mitigate the problem, our paper proposes EC-YOLO, a real-time defect detection network for steel strips of the above peculiar defects. Firstly, the 1D convolution in the efficient channel attention bottleneck (EB) module enhances the feature extraction ability of the backbone for small and elongated defects, while also facilitating the attentional mechanism for modeling channel features. Secondly, Context Transformation Networks integrate cross-stage localized blocks, referred to as CC modules, to enhance the understanding of feature semantic contextual information. Thirdly, a self-constructed dataset containing both small and elongated defects is used for understanding where such defects are more relevant in feature fusion and extraction. On the public datasets GC10-DET and NEU-DET, the improved model achieves mean Average Precision (mAP) scores of 71% and 83%, respectively, surpassing the performance of other mainstream models. The mAP of the enhanced model on the SLD-DET dataset reaches 87.5%, demonstrating its superiority in detecting both small and elongated defects.},
  keywords={Feature extraction;Steel;Defect detection;YOLO;Convolutional neural networks;Task analysis;Real-time systems;Semantics;Strips;Defect detection;small and elongated defects;attention;steel strips},
  doi={10.1109/ACCESS.2024.3391353},
  ISSN={2169-3536},
  month={},}@ARTICLE{10589307,
  author={Chen, Yuzhong and Xiao, Zhenxiang and Pan, Yi and Zhao, Lin and Dai, Haixing and Wu, Zihao and Li, Changhe and Zhang, Tuo and Li, Changying and Zhu, Dajiang and Liu, Tianming and Jiang, Xi},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Mask-Guided Vision Transformer for Few-Shot Learning}, 
  year={2025},
  volume={36},
  number={5},
  pages={9636-9647},
  abstract={Learning with little data is challenging but often inevitable in various application scenarios where the labeled data are limited and costly. Recently, few-shot learning (FSL) gained increasing attention because of its generalizability of prior knowledge to new tasks that contain only a few samples. However, for data-intensive models such as vision transformer (ViT), current fine-tuning-based FSL approaches are inefficient in knowledge generalization and, thus, degenerate the downstream task performances. In this article, we propose a novel mask-guided ViT (MG-ViT) to achieve an effective and efficient FSL on the ViT model. The key idea is to apply a mask on image patches to screen out the task-irrelevant ones and to guide the ViT focusing on task-relevant and discriminative patches during FSL. Particularly, MG-ViT only introduces an additional mask operation and a residual connection, enabling the inheritance of parameters from pretrained ViT without any other cost. To optimally select representative few-shot samples, we also include an active learning-based sample selection method to further improve the generalizability of MG-ViT-based FSL. We evaluate the proposed MG-ViT on classification, object detection, and segmentation tasks using gradient-weighted class activation mapping (Grad-CAM) to generate masks. The experimental results show that the MG-ViT model significantly improves the performance and efficiency compared with general fine-tuning-based ViT and ResNet models, providing novel insights and a concrete approach toward generalizing data-intensive and large-scale deep learning models for FSL.},
  keywords={Task analysis;Adaptation models;Transformers;Training;Few shot learning;Data models;Training data;Domain adaptation;few-shot learning (FSL);mask;vision transformer (ViT)},
  doi={10.1109/TNNLS.2024.3418527},
  ISSN={2162-2388},
  month={May},}
