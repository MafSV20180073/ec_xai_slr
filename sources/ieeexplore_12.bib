@ARTICLE{9336246,
  author={Zhu, Shixiang and Li, Shuang and Peng, Zhigang and Xie, Yao},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Imitation Learning of Neural Spatio-Temporal Point Processes}, 
  year={2022},
  volume={34},
  number={11},
  pages={5391-5402},
  abstract={We present a novel Neural Embedding Spatio-Temporal (NEST) point process model for spatio-temporal discrete event data and develop an efficient imitation learning (a type of reinforcement learning) based approach for model fitting. Despite the rapid development of one-dimensional temporal point processes for discrete event data, the study of spatial-temporal aspects of such data is relatively scarce. Our model captures complex spatio-temporal dependence between discrete events by carefully design a mixture of heterogeneous Gaussian diffusion kernels, whose parameters are parameterized by neural networks. This new kernel is the key that our model can capture intricate spatial dependence patterns and yet still lead to interpretable results as we examine maps of Gaussian diffusion kernel parameters. The imitation learning model fitting for the NEST is more robust than the maximum likelihood estimate. It directly measures the divergence between the empirical distributions between the training data and the model-generated data. Moreover, our imitation learning-based approach enjoys computational efficiency due to the explicit characterization of the reward function related to the likelihood function; furthermore, the likelihood function under our model enjoys tractable expression due to Gaussian kernel parameterization. Experiments based on real data show our method’s good performance relative to the state-of-the-art and the good interpretability of NEST’s result.},
  keywords={Kernel;Data models;Computational modeling;Earthquakes;Neural networks;Shape;Reinforcement learning;Spatio-temporal point processes;generative model;imitation learning},
  doi={10.1109/TKDE.2021.3054787},
  ISSN={1558-2191},
  month={Nov},}@ARTICLE{9928427,
  author={Zhang, Ruohan and Jiao, Licheng and Li, Lingling and Liu, Fang and Liu, Xu and Yang, Shuyuan},
  journal={IEEE Transactions on Cybernetics}, 
  title={Evolutionary Dual-Stream Transformer}, 
  year={2024},
  volume={54},
  number={4},
  pages={2166-2178},
  abstract={Vision transformers (ViTs) are rapidly evolving and are widely used in computer vision. However, high-performance ViTs require many computations, which limit their further development in the vision field. In this article, a novel evolutionary dual-stream transformer (E-DST) model is proposed to alleviate the computational resource demand problem. A hybrid attention mechanism structure is proposed for a DST model. The DST model uses a dual-branch structure to fuse convolutional and transformer features. Combining the features learned by the transformer and convolution effectively saves model computational resources. In addition, an evolutionary optimizer is proposed to optimize the parameters of the model. The excellent search ability of the evolutionary algorithm is utilized to optimize the transformer model parameters. The convergence of the evolutionary optimizer is proved in this article. In addition, the proposed E-DST model is experimentally compared with a variety of classic models and their deformations based on three datasets. And, the evolutionary optimizer proves its generality in convolutional and recurrent neural networks. The experimental results show that the E-DST model can effectively reduce computational resources and that the evolutionary optimizer can solve large-scale optimization problems. In conclusion, our proposed method is feasible and effective.},
  keywords={Transformers;Computational modeling;Optimization;Feature extraction;Adaptation models;Training;Deep learning;evolutionary optimization;image classification;transformer},
  doi={10.1109/TCYB.2022.3213537},
  ISSN={2168-2275},
  month={April},}@ARTICLE{10540330,
  author={Luo, Zihui and Jiang, Chengling and Liu, Liang and Zheng, Xiaolong and Ma, Huadong},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Flow-Shop Scheduling Problem With Batch Processing Machines via Deep Reinforcement Learning for Industrial Internet of Things}, 
  year={2024},
  volume={8},
  number={5},
  pages={3518-3533},
  abstract={The rapidly evolving Industrial Internet of Things (IIoT) is driving the transition from conventional manufacturing to intelligent manufacturing. Intelligent shop scheduling, as one of the essential components of intelligent manufacturing in IIoT, is desired to allocate jobs on different machines to achieve specific production targets. The flow-shop scheduling problem with batch processing machines (FSSP-BPM), which widely exists in real-world manufacturing, requires two distinct but interdependent decisions: batch formation and job scheduling. Existing approaches rely on fixed search paradigms that utilize expert knowledge to find satisfactory solutions. However, these methods struggle to ensure solution quality under real-time constraints due to the varying data distribution and the complexity of large-scale practical problems. To address this challenge, we propose a deep reinforcement learning (DRL) based method. First, we formulate the FSSP-BPM decision process as a Markov Decision Process (MDP) and design the corresponding state, action, and reward. Second, we propose a basic scheduling framework based on an encoder-decoder model with the attention mechanism. Finally, we design a batch formation module and a scheduling module trained on unlabeled multi-dimensional data. Extensive experiments on public benchmark datasets and actual production data demonstrate that the proposed method outperforms baseline algorithms and improves makespan performance by an average of 8.33%.},
  keywords={Job shop scheduling;Production;Industrial Internet of Things;Manufacturing processes;Batch production systems;Metaheuristics;Complexity theory;Intelligent manufacturing systems;Industrial Internet of Things (IIoT);intelligent manufacturing;flow-shop scheduling problem (FSSP);batch processing machine (BPM);deep reinforcement learning (DRL)},
  doi={10.1109/TETCI.2024.3402685},
  ISSN={2471-285X},
  month={Oct},}@INPROCEEDINGS{10969174,
  author={Alshar, Moath Mahmoud and Sao, Ameet and Sharma, Manish and Kadyan, Sunil and Rao, Vuda Sreenivasa and Anitha Vijayalakshmi, B.},
  booktitle={2025 3rd International Conference on Intelligent Systems, Advanced Computing and Communication (ISACC)}, 
  title={Leveraging AI to Personalize HR Marketing Campaigns: A Data-Driven Approach}, 
  year={2025},
  volume={},
  number={},
  pages={225-230},
  abstract={The research proposes an AI-driven personalization framework for enhancing the efficiency and engagement of HR marketing campaigns. The system integrates real-time data processing, collaborative filtering, and feedback loops to dynamically recommend job opportunities tailored to individual candidate preferences. Using an HR-related dataset from Kaggle, the framework preprocesses data by handling missing values, scaling numerical features via Min-Max Scaling, and reducing dimensionality using Principal Component Analysis (PCA). Collaborative Filtering is employed to predict candidate preferences through matrix factorization, dynamically updating recommendations based on real-time user interactions. The experimental evaluation highlights the framework's superior performance compared to traditional methods. Click-Through Rate (CTR) improved significantly, with AI-driven personalization achieving 30% compared to 18% from rule-based methods and 12% from the baseline. Accuracy analysis revealed that Collaborative Filtering outperformed random and content-based methods, achieving the highest precision (85%), recall (88%), and F1-score (86%). These results underscore the effectiveness of AI in aligning candidate preferences with recruitment goals while ensuring dynamic adaptation through feedback. The proposed system also seamlessly integrates personalized insights into HR marketing channels such as job portals, email campaigns, and social media advertisements, optimizing recruitment processes and enhancing user engagement. Future research aims to extend the dataset to include diverse candidate profiles, incorporate multi-modal data sources, and leverage deep learning for improved recommendation accuracy. Additionally, explainability techniques will be explored to ensure transparency and build trust among users. This framework demonstrates the transformative potential of AI-driven personalization in reshaping HR marketing strategies.},
  keywords={Accuracy;Social networking (online);Collaborative filtering;Soft sensors;Real-time systems;Particle swarm optimization;Intelligent systems;Portals;Recruitment;Principal component analysis;Network Anomaly detection;Cyber Security;Tuna Swarm Optimization;Multi-Layer Perceptron;Convolutional Neural Network},
  doi={10.1109/ISACC65211.2025.10969174},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10446346,
  author={Ruan, Yiwen and Jin, Rui and Liu, Zhaorui and Wang, Caishan and Zhang, Lei and Peng, Tao},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Delineation of Prostate Cancer Via Enhanced AI-Based Algorithm In Ultrasound Images}, 
  year={2024},
  volume={},
  number={},
  pages={2275-2279},
  abstract={Delineation of prostate cancer (PCa) on ultrasound images has become an essential technique for early PCa treatment, which still faces several challenges, such as low image contrast and blurred organ boundaries. Facing the aforementioned issues, a novel coarse-fine segmentation framework method is adopted in this work. First, a deep learning algorithm is used for positioning the region of interest (ROI); then, the principal curve-related technique is adopted to fine-tune initial results. Thirdly, an enhanced quantum evolutionary algorithm is used to hunt for the optimal initialization of the backpropagation neural network. Finally, an interpretable mathematical model is introduced for representing the ROI contour by using the parameters of the neural network. A comprehensive evaluation using the clinical data proves the superiority of our method, with Dice similarity coefficient (DSC) of 83.48+3.44%, Jaccard similarity coefficient (Ω) of 82.25+4.12%, and accuracy (ACC) of 83.4+3.57%, respectively.},
  keywords={Image segmentation;Ultrasonic imaging;Smoothing methods;Neural networks;Signal processing algorithms;Signal processing;Mathematical models;Prostate cancer segmentation;ultrasound image;polyline searching algorithm;quantum evolution algorithm;interpretable mathematical function},
  doi={10.1109/ICASSP48485.2024.10446346},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10394343,
  author={Chang, Wei-Chien and Liu, Alan and Wang, Hua-Ye},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Deploying a Machine Translation Model on a Mobile Device with Improved Latency Constraints}, 
  year={2023},
  volume={},
  number={},
  pages={2783-2788},
  abstract={This paper presents a method of deploying a complex machine learning model on a mobile device which has limited computing resources. With the rapid advancement of machine learning and deep learning, Natural Language Processing (NLP) has made considerable progress in recent years. The transformer approach has been widely used in NLP tasks with the ability of parallel processing in recurrent neural networks through the use of a self-attention mechanism. However, the excessive pursuit of accuracy leads to higher complexity in a model, and it becomes difficult to deploy such a model on mobile devices. To solve the problem of high computational cost, this research uses Neural Architecture Search (NAS) with Genetic Algorithm as the search strategy. It trains the supernet for performance evaluation to automatically design efficient architecture for different hardware platforms while considering network compression. We further reduce the size of the model with little impact on accuracy by applying K-means clustering. To show our method's effectiveness, we have deployed a model on a mobile device to perform machine translation. We use BLEU, FLOPs, and Latency as evaluation metrics. BLEU is used as an evaluation of sequence generative tasks while FLOPs and latency are used to observe whether the architecture found by the NAS is suitable for the hardware.},
  keywords={Performance evaluation;Computational modeling;Computer architecture;Transformers;Search problems;Mobile handsets;Hardware;Natural Language Processing;Sequence Generation;Neural Architecture Search;Network Compression;Pretrained Language Model},
  doi={10.1109/SMC53992.2023.10394343},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{10776346,
  author={Dong, Hongyu and Liu, Jingwen and Dong, Jie and Wang, Yifeng and Fu, Yaping},
  booktitle={2024 International Conference on New Trends in Computational Intelligence (NTCI)}, 
  title={Operational Behavior Computing: Task Assignment Optimization Considering Worker Behavior and Algorithmic Responsibility}, 
  year={2024},
  volume={},
  number={},
  pages={195-200},
  abstract={This study addresses a task assignment optimization problem by accounting for the heterogeneity of employee behavior and the accountability of algorithm deployment. Initially, we explore the variability within picker behavior across multiple dimensions, with experiments indicating notable differences. These behavioral variabilities are then integrated into a fairness-constrained task assignment model, aiming to minimize the maximum task completion time. The model's predictive accuracy is confirmed through some machine learning algorithms. A comparative analysis of various algorithms, including Variable Neighborhood Search (VNS), Adaptive Large Neighborhood Search (ALNS), Harmony Search (HS), Artificial Bee Colony (ABC), and Genetic Algorithm (GA), indicates that VNS and ALNS provide enhanced interpretability and timeliness, which are crucial for real-world scenarios demanding rapid response times, such as those in the second or millisecond range.},
  keywords={Adaptation models;Machine learning algorithms;Accuracy;Predictive models;Prediction algorithms;Market research;Time factors;Optimization;Genetic algorithms;operational behavior computing;predictive algorithms;task assignment;meta-heuristic algorithms},
  doi={10.1109/NTCI64025.2024.10776346},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10356483,
  author={Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas and Xu, Binbin and Bernard, Pierre Louis and Dray, Gérard},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Zero-shot Bilingual App Reviews Mining with Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={898-904},
  abstract={App reviews from app stores are crucial for improving software requirements. A large number of valuable reviews are continually being posted, describing software problems and expected features. Effectively utilizing user reviews necessitates the extraction of relevant information, as well as their subsequent summarization. Due to the substantial volume of user reviews, manual analysis is arduous. Various approaches based on natural language processing (NLP) have been proposed for automatic user review mining. However, the majority of them requires a manually crafted dataset to train their models, which limits their usage in real-world scenarios. In this work, we propose Mini-BAR, a tool that integrates large language models (LLMs) to perform zero-shot mining of user reviews in both English and French. Specifically, Mini-BAR is designed to (i) classify the user reviews, (ii) cluster similar reviews together, (iii) generate an abstractive summary for each cluster and (iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we created a dataset containing 6,000 English and 6,000 French annotated user reviews and conducted extensive experiments. Preliminary results demonstrate the effectiveness and efficiency of Mini-BAR in requirement engineering by analyzing bilingual app reviews.},
  keywords={Analytical models;Manuals;Feature extraction;Software;Natural language processing;Mobile applications;Data mining;User feedback;Requirements engineering;Large language model},
  doi={10.1109/ICTAI59109.2023.00135},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10431584,
  author={Jin, Hongpeng and Wei, Wenqi and Wang, Xuyu and Zhang, Wenbin and Wu, Yanzhao},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Rethinking Learning Rate Tuning in the Era of Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={112-121},
  abstract={Large Language Models (LLMs) represent the recent success of deep learning in achieving remarkable human-like predictive performance. It has become a mainstream strategy to leverage fine-tuning to adapt LLMs for various real-world applications due to the prohibitive expenses associated with LLM training. The learning rate is one of the most important hyper-parameters in LLM fine-tuning with direct impacts on both fine-tuning efficiency and fine-tuned LLM quality. Existing learning rate policies are primarily designed for training traditional deep neural networks (DNNs), which may not work well for LLM fine-tuning. We reassess the research challenges and opportunities of learning rate tuning in the coming era of Large Language Models. This paper makes three original contributions. First, we revisit existing learning rate policies to analyze the critical challenges of learning rate tuning in the era of LLMs. Second, we present LRBench++ to benchmark learning rate policies and facilitate learning rate tuning for both traditional DNNs and LLMs. Third, our experimental evaluation with LRBench++ demonstrates the key differences between LLM fine-tuning and traditional DNN training and validates our analysis.},
  keywords={Training;Deep learning;Artificial neural networks;Pressing;Benchmark testing;Predictive models;Tuning;Learning Rate;Hyperparameter Tuning;Deep Learning;Large Language Model},
  doi={10.1109/CogMI58952.2023.00025},
  ISSN={},
  month={Nov},}@ARTICLE{10373191,
  author={Coscia, Adam and Endert, Alex},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts}, 
  year={2024},
  volume={30},
  number={9},
  pages={6520-6532},
  abstract={Recent growth in the popularity of large language models has led to their increased usage for summarizing, predicting, and generating text, making it vital to help researchers and engineers understand how and why they work. We present KnowledgeVIS, a human-in-the-loop visual analytics system for interpreting language models using fill-in-the-blank sentences as prompts. By comparing predictions between sentences, KnowledgeVIS reveals learned associations that intuitively connect what language models learn during training to natural language tasks downstream, helping users create and test multiple prompt variations, analyze predicted words using a novel semantic clustering technique, and discover insights using interactive visualizations. Collectively, these visualizations help users identify the likelihood and uniqueness of individual predictions, compare sets of predictions between prompts, and summarize patterns and relationships between predictions across all prompts. We demonstrate the capabilities of KnowledgeVIS with feedback from six NLP experts as well as three different use cases: (1) probing biomedical knowledge in two domain-adapted models; and (2) evaluating harmful identity stereotypes and (3) discovering facts and relationships between three general-purpose models.},
  keywords={Predictive models;Task analysis;Analytical models;Transformers;Semantics;Visual analytics;Adaptation models;Visual analytics;language models;prompting;interpretability;machine learning},
  doi={10.1109/TVCG.2023.3346713},
  ISSN={1941-0506},
  month={Sep.},}@INPROCEEDINGS{9933252,
  author={Krček, Marina and Ordas, Thomas and Fronte, Daniele and Picek, Stjepan},
  booktitle={2022 Workshop on Fault Detection and Tolerance in Cryptography (FDTC)}, 
  title={The More You Know: Improving Laser Fault Injection with Prior Knowledge}, 
  year={2022},
  volume={},
  number={},
  pages={18-29},
  abstract={We consider finding as many faults as possible on the target device in the laser fault injection security evaluation. Since the search space is large, we require efficient search methods. Recently, an evolutionary approach using a memetic algorithm was proposed and shown to find more interesting parameter combinations than random search, which is commonly used. Unfortunately, once a variation on the bench or target is introduced, the process must be repeated to find suitable parameter combinations anew.To negate the effect of variation, we propose a novel method combining a memetic algorithm with a machine learning approach called a decision tree. Our approach improves the memetic algorithm by using prior knowledge of the target introduced in the initial phase of the memetic algorithm. In our experiments, the decision tree rules enhance the performance of the memetic algorithm by finding more interesting faults in different samples of the same target. Our approach shows more than two orders of magnitude better performance than random search and up to 60% better performance than previous state-of-the-art results with a memetic algorithm. Another advantage of our approach is human-readable rules, allowing the first insights into the explainability of target characterization for laser fault injection.},
  keywords={Memetics;Machine learning algorithms;Semiconductor lasers;Search methods;Fault detection;Conferences;Machine learning;Laser Fault Injection;Decision Tree;Transferability},
  doi={10.1109/FDTC57191.2022.00012},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9996691,
  author={Bouzidi, Halima and Ouarnoughi, Hamza and Niar, Smail and Talbi, El-Ghazali and El Cadi, Abdessamad Ait},
  booktitle={2022 25th Euromicro Conference on Digital System Design (DSD)}, 
  title={Co-Optimization of DNN and Hardware Configurations on Edge GPUs}, 
  year={2022},
  volume={},
  number={},
  pages={398-405},
  abstract={The ever-increasing complexity of both Deep Neural Networks (DNN) and hardware accelerators has made the co-optimization of these domains extremely complex. Previous works typically focus on optimizing DNNs given a fixed hardware configuration or optimizing a specific hardware architecture given a fixed DNN model. Recently, the importance of the joint exploration of the two spaces drew more and more attention. Our work targets the co-optimization of DNN and hardware configurations on edge GPU accelerators. We propose an evolutionary-based co-optimization strategy by considering three metrics: DNN accuracy, execution latency, and power consumption. By combining the two search spaces, a larger number of configurations can be explored in a short time interval. In addition, a better tradeoff between DNN accuracy and hardware efficiency can be obtained. Experimental results show that the co-optimization outperforms the optimization of DNN for fixed hardware configuration with up to 53% hardware efficiency gains with the same accuracy and inference time.},
  keywords={Measurement;Power demand;Neural networks;Graphics processing units;Evolutionary computation;Linear programming;Hardware;DNN;Edge GPU;Hardware-aware Neural Architecture Search;Multi-objective optimization},
  doi={10.1109/DSD57027.2022.00060},
  ISSN={2771-2508},
  month={Aug},}@INPROCEEDINGS{10095225,
  author={Huang, Tung-Sheng and Yu, Ping-Chung and Su, Li},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Note and Playing Technique Transcription of Electric Guitar Solos in Real-World Music Performance}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Transcribing electric guitar solo in real-world performance is challenging because of the interference of background accompaniments, the strong coupling between music pitch and playing technique, and the limited resource of data annotation. To address these issues, we first propose a new guitar solo dataset for this task. Then, we propose a transcription model which learns an output space jointly constructed with notes, playing techniques, and two sets of meta-class labels named note states and technique groups, such that the model can harness the layered relationship among different note-level event and playing technique classes. The proposed model outperforms the state-of-the-art guitar solo transcription and note transcription models.},
  keywords={Couplings;Annotations;Interference;Signal processing;Ontologies;Data models;Acoustics;Automatic music transcription;electric guitar;deep learning;attention;U-net},
  doi={10.1109/ICASSP49357.2023.10095225},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10254146,
  author={Nikolikj, Ana and Pluháček, Michal and Doerr, Carola and Korošec, Peter and Eftimov, Tome},
  booktitle={2023 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Sensitivity Analysis of RF+clust for Leave-One-Problem-Out Performance Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Leave-one-problem-out (LOPO) performance prediction requires machine learning (ML) models to extrapolate algorithms' performance from a set of training problems to a previously unseen problem. LOPO is a very challenging task even for state-of-the-art approaches. Models that work well in the easier leave-one-instance-out scenario often fail to generalize well to the LOPO setting. To address the LOPO problem, recent work suggested enriching standard random forest (RF) performance regression models with a weighted average of algorithms' performance on training problems that are considered similar to a test problem. More precisely, in this RF+clust approach, the weights are chosen proportionally to the distances of the problems in some feature space. Here in this work, we extend the RF+clust approach by adjusting the distance-based weights with the importance of the features for performance regression. That is, instead of considering cosine distance in the feature space, we consider a weighted distance measure, with weights depending on the relevance of the feature for the regression model. Our empirical evaluation of the modified RF+clust approach on the CEC 2014 benchmark suite confirms its advantages over the naive distance measure. However, we also observe room for improvement, in particular with respect to more expressive feature portfolios.},
  keywords={Weight measurement;Training;Radio frequency;Sensitivity analysis;Computational modeling;Predictive models;Prediction algorithms;Automated Performance Prediction;AutoML;Single-Objective Black-Box Optimization;Zero-Shot Learning},
  doi={10.1109/CEC53210.2023.10254146},
  ISSN={},
  month={July},}@INPROCEEDINGS{10230574,
  author={Kang, Zili and Lv, Yifan and He, Mengshen and Liu, Yiheng and Liu, Tianming and Ge, Bao},
  booktitle={2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Brain Surface Can Predict Fiber Connections}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={It has been of great interest to study relationship between white matter and gray matter in brain science. Previous studies have found that that the formation of gray matter is closely related to white matter. This paper attempts explore the relationship between cerebral cortex and white matter from the perspective of brain image, which tries to predict fiber connection information by using brain cortical information alone. The extensive experiments on HCP dataset demonstrate that brain cortical surface can be used to predict the presence or absence of fibers between any two cortical regions with about 80% accuracy, furtherly, it can be used to predict the fractional anisotropy (FA) value for each fiber, the experiments show that the FA value can be also predicted with a percentage error of about 20%. These results demonstrate that the brain surface can be used to predict fiber connection information, and there is a close relationship between the gray matter and white matter fiber. This work provides a new perspective for further study of the relationship between cerebral cortex and axonal fiber.},
  keywords={Cerebral cortex;Anisotropic magnetoresistance;Error analysis;Magnetic resonance imaging;Grey matter;Streaming media;White matter;Brain surface;fiber streamline;diffusion MRI},
  doi={10.1109/ISBI53787.2023.10230574},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10899657,
  author={Ren, Shiqi and Zhang, Yu},
  booktitle={2024 7th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI)}, 
  title={Terrain Image Classification Based on Vision Transformer Deep Learning Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Terrain image classification is an important research direction in the field of remote sensing and computer vision, aiming to realize automatic recognition and classification of different landform features through the analysis and processing of terrain images. In this paper, a deep learning algorithm based on Vision Transformer (ViT) is used to classify terrain images, and the performance of the algorithm in this task is systematically evaluated. In the process of model construction, we first imported the Vision Transformer model and made corresponding parameter Settings to ensure its adaptability and effectiveness. After training, it is observed that the loss function of the training set decreases from the initial value of 2.84 to 0.35, a decrease of 2.49, indicating that the model tends to converge in continuous optimization. At the same time, the accuracy is also significantly improved, from 55.9% to 86.8%, an increase of 30.9%, showing the enhancement of the model's learning ability. For the validation set, loss also decreased from 0.78 to 0.47, a decrease of 0.31, while accuracy increased from 60.1% to 83.5%, an increase of 23.4%. These results further prove the good performance of the model on different data sets and its convergence trend. In addition, through the evaluation of the test set, we get more specific performance indicators: The accuracy of the terrain image classification model based on Vision Transformer on the test set reaches 89.9%, the Precision is 0.9615, the Recall is 0.9494, and the F1-score is 0.9554. These indicators show that the model not only has high classification accuracy, but also performs well in generalization ability. To sum up, this research demonstrates the effectiveness of Vision Transformer deep learning algorithm in terrain image classification, and provides a new solution idea and method for related fields. Through continuous optimization and adjustment, the algorithm is expected to achieve more extensive promotion in practical applications, and bring positive impact on geographic information system, environmental monitoring and other fields..},
  keywords={Training;Deep learning;Computer vision;Adaptation models;Accuracy;Transformers;Classification algorithms;Numerical models;Optimization;Image classification;Terrain image classification;Vision Transformer;Deep learning},
  doi={10.1109/ACAI63924.2024.10899657},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11035921,
  author={Jena, Suvendu Kumar and Alrwbaye, Taki and Pareek, Piyush Kumar and M, Nikitha and Kaliappan, S.},
  booktitle={2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Comprehensive Analysis on Feature Selection and Dimensionality Reduction in Big Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={From the past few years, massive volumes of structured, semi-structured and unstructured data are generated across various domains like healthcare, Internet of Things (IoT), finance and multimedia. Removing or ignoring irrelevant attributes from the data reduces the burden on Machine Learning (ML) algorithms. Traditional approaches faced challenges like handling high-dimensional data, scalability issues, limited interpretability, noise, outliers and curse of dimensionality. The need for effective feature selection and dimensionality reduction method improves the model performance by reducing computational costs and enhancing interpretability. In this survey, recent technological approaches based on ML and Deep Learning (DL) are explored for feature selection and dimensionality reduction in big data analytics. The approaches like Principal Component Analysis (PCA), t-distributed Stochastic Neighbour Embedding (t-SNE) and autoencoders efficiently reduce the dimensionality of high-dimensional data from the ImageNet dataset when compared with traditional approaches. The outcome illustrates that ML and DL techniques in this survey are well suited for feature selection and dimensionality reduction in big data analysis, especially in large-scale datasets like ImageNet.},
  keywords={Dimensionality reduction;Surveys;Accuracy;High dimensional data;Computational modeling;Big Data;Feature extraction;Internet of Things;Integrated circuit modeling;Principal component analysis;big data;dimensionality reduction;feature selection;internet of things;machine learning},
  doi={10.1109/ICDCECE65353.2025.11035921},
  ISSN={},
  month={April},}@INPROCEEDINGS{9979962,
  author={Ngambenjavichaikul, Nisawan and Chen, Sovann and Aramvith, Supavadee},
  booktitle={2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Optimal Deep Multi-Route Self-Attention for Single Image Super-Resolution}, 
  year={2022},
  volume={},
  number={},
  pages={1181-1186},
  abstract={Image restoration, such as single image super-resolution (SISR), is a long-established low-level vision issue that intends to regenerate high-resolution (HR) images from low-resolution (LR) input counterparts. While state-of-the-art image super-resolution models are based on the well-known convolutional neural network (CNN), many self-attention-based or transformer-based experiment attempts have been conducted and have shown promising performance on vision problems. A powerful baseline model based on the swin transformer adopts the shifted window approach. It enhances the capability by restricting the model to compute the self-attention function only on non-superimpose local windows while enabling cross-window relations. However, the architecture design is manually fixed. Therefore, the results are not achieving optimal performance. This paper presents an optimal deep multi-route self-attention network for single image super-resolution (ODMR-SASR). The genetic algorithm (GA) is introduced to discover the optimal number of filters and layers. Experimental results demonstrate that the proposed optimization technique can produce a progressive SR image quality.},
  keywords={Training;Computational modeling;Superresolution;Optimization methods;Information processing;Network architecture;Transformers},
  doi={10.23919/APSIPAASC55919.2022.9979962},
  ISSN={2640-0103},
  month={Nov},}@ARTICLE{11072388,
  author={Yang, Duo and Yan, Fuhui and Wang, Siyu and Yan, Yu},
  journal={IEEE Transactions on Transportation Electrification}, 
  title={Genetic Programming-Based Energy Management Strategy for Fuel Cell Vehicles Considering Temperature and Aging Factors}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Combining fuel cells and lithium-ion batteries (LiBs) in a hybrid vehicle presents a promising automotive energy supply technology. The durability of power components, fuel consumption, and safety all depend on effective energy management strategies (EMSs). This paper is the first to use the context-aware typed multi-population genetic programming (CAT-MPGP) algorithm to extract interpretable rules for the offline near-optimal solution of Pontryagin’s minimum principle (PMP), which are applied to the real-time EMS considering system aging factors. Firstly, the paper integrates the thermal model of LiBs into the system model to balance system lifespan and energy consumption. The PMP is employed to find the offline near-optimal power allocation results. Secondly, Bagging method is used to construct the driving condition recognizer, and the interpretable data relationship between driving information and power distribution is mined by MPGP algorithm, and embedded in real-time EMS. Finally, simulations using a real driving route and two standard periodic datasets are conducted as the test sets to compare the results of different EMSs. Hardware-in-the-loop test is adopted to verify the feasibility of the controller in practical application. The proposed method achieves a well-performing real-time EMS, which reaches 94.6% of the offline reference results.},
  keywords={Fuel cells;Energy management;Real-time systems;Aging;State of charge;Integrated circuit modeling;Optimization;Hydrogen;Adaptation models;Accuracy;Fuel cell;Transportation;Energy management strategy;Pontryagin’s minimum principle},
  doi={10.1109/TTE.2025.3586696},
  ISSN={2332-7782},
  month={},}@INPROCEEDINGS{10822499,
  author={Shi, Qinglei and Duan, Wenhan and Chen, Wanyi and Yang, Haotian and Lu, Haochen and Wu, Kecan and Zhu, Junxi and Yuan, Juefei and Ke, Qiyan and Zhang, Andu and Wan, Xiang and Wang, Changmiao and Ruan, Li and Wang, Renzhi},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={PGP: Prior-Guided Pretraining for Small-sample Esophageal Cancer Segmentation}, 
  year={2024},
  volume={},
  number={},
  pages={3701-3704},
  abstract={Transformer-based models have demonstrated substantial potential in medical image segmentation tasks due to their exceptional ability to capture long-range dependencies. To further enhance segmentation performance, various effective methods have been proposed, including pretraining methods (weakly supervised or self-supervised pretraining schemes), contrastive learning schemes, and knowledge distillation methods. However, segmenting esophageal cancer (EC) from CT images remains a significant challenge, partly due to the complex anatomy of EC, such as variable shapes, extensive extents, and often blurred boundaries with adjacent anatomical structures. In this study, we propose a prior-guided pretraining (PGP) regimen based on bounding boxes, which enhances the model’s ability to discern textural differences between EC and the surrounding tissues. Using Swin UNITR as the backbone, our proposed pretraining scheme demonstrates superior performance in EC segmentation compared to other schemes. To further improve the segmentation accuracy of EC, we also addressed the class imbalance and long-tail problems inherent in EC segmentation, thereby further enhancing segmentation performance.},
  keywords={Image segmentation;Heavily-tailed distribution;Shape;Computed tomography;Contrastive learning;Streaming media;Transformers;Cancer;Biomedical imaging;Tumors;Weakly Supervised Learning;Esophageal Cancer;Medical Image Segmentation},
  doi={10.1109/BIBM62325.2024.10822499},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10531625,
  author={Kaur, Tanvir and Kamboj, Shivani and Singh, Lovedeep and Tamanna},
  booktitle={2024 2nd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Advanced YOLO-NAS-Based Detection and Screening of Brain Tumors Using Medical Diagnostic}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent years have witnessed tremendous advancements within the medical imaging domain, with brain tumor detection arising as an integral area necessitating further research and development. Sophisticated imaging modalities including magnetic resonance imaging (MRI), computed tomography (CT), and positron emission tomography (PET) have enabled detailed cerebral visualization. Notwithstanding their accomplishments, persisting impediments exist including inconsistent datasets and requisite enhanced interpretability. Additionally, investigation continues into methods to augment generalization and interpretability capacities, this work investigates potential synergies between state-of-the-art algorithms and medical imaging modalities to enhance brain tumor identification. The research looks at how well-known algorithms YOLO NAS (You Only Look Once Neural Architecture Search) and model perform, with both showing impressive accuracy levels above 95%. Prospectively, amalgamating these algorithms within a multi-modal framework holds promise for improved overall brain tumor detection accuracy. Within the dynamic neuroimaging domain, these modalities harbor immense potential to profoundly impact early diagnosis and augment patient outcomes, contingent on persistent research efforts addressing existing obstacles and refining methodological approaches.},
  keywords={YOLO;Visualization;Magnetic resonance imaging;Heuristic algorithms;Computed tomography;Refining;Positron emission tomography;Detection;Neurological;Diagnosis;Tumor Stroma;Brain Tissues},
  doi={10.1109/AIMLA59606.2024.10531625},
  ISSN={},
  month={March},}@INPROCEEDINGS{10429926,
  author={Das, Ayushman and Chen, Shu-Ching and Shyu, Mei-Ling and Sadiq, Saad},
  booktitle={2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Enabling Synergistic Knowledge Sharing and Reasoning in Large Language Models with Collaborative Multi-Agents}, 
  year={2023},
  volume={},
  number={},
  pages={92-98},
  abstract={Despite the significant advancements in the field of Natural Language Processing (NLP), Large Language Models (LLMs) have shown limitations in performing complex tasks that require arithmetic, commonsense, and symbolic reasoning. Reasoning frameworks like ReAct, Chain-of-thought (CoT), Tree-of-thoughts (ToT), etc. have shown success but with limitations in solving long-form complex tasks. To address this, we pro-pose a knowledge-sharing and collaborative multi-agent assisted framework on LLMs that leverages the capabilities of existing reasoning frameworks and the collaborative skills of multi-agent systems (MASs). The objectives of the proposed framework are to overcome the limitations of LLMs, enhance their reasoning capabilities, and improve their performance in complex tasks. It involves generating natural language rationales and in-context few-shot learning via prompting, and integrates the reasoning techniques with efficient knowledge-sharing and communication-driven agent networks. The potential benefits of the proposed framework include saving time and money, improved efficiency for computationally intensive reasoning, and the ability to incor-porate multiple collaboration strategies for dynamically changing environments.},
  keywords={Collaboration;Cognition;Natural language processing;Internet;Reliability;Task analysis;Multi-agent systems;large language model (LLM);multi-agent system (MAS);knowledge sharing;reasoning},
  doi={10.1109/CIC58953.2023.00021},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10725945,
  author={Roy, Sourabarna and Debbarma, Tina and Pal, Tannistha and Duraisamy, Prakash},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Investigating the Efficacy of Diverse Machine Learning Classifiers for Parkinson’s Disease Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={To detect Parkinson’s disease, we compare the effectiveness of K-Nearest Neighbors (KNN), Logistic Regression (LR), Support Vector Machines (SVM), and Random Forest (RF) algorithms. Utilizing a dataset with clinical and biomedical features, we preprocess the data to handle missing values and standardize the features. Subsequently, we train each algorithm with the preprocessed data and evaluate their performance using metrics like accuracy, precision, recall, and F1-score. Our results indicate that all four algorithms achieve excellent accuracy in diagnosing Parkinson’s disease, with KNN slightly outperforming the others. However, the selection of the algorithm may depend on specific needs such as interpretability and computational efficiency. Additionally, we conduct a feature importance analysis to identify the most relevant features for Parkinson’s disease identification, offering insights that can aid in early diagnosis and disease management.},
  keywords={Support vector machines;Radio frequency;Accuracy;Sensitivity;Machine learning algorithms;Nearest neighbor methods;Sensitivity and specificity;Vectors;Random forests;Diseases;k-nearest neighbors;random forest;support vector machine;logistic regression;parkinson’s disease},
  doi={10.1109/ICCCNT61001.2024.10725945},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10916769,
  author={Zhang, Yongqing and Zhou, Zhigan and Wang, Maocheng and Mao, Xinyu and Wang, Zixuan and Zou, Quan},
  journal={IEEE Transactions on Computational Biology and Bioinformatics}, 
  title={A Multi-Omics Data Integration Framework for Gene Regulatory Network Inference Based on Contrastive Learning}, 
  year={2025},
  volume={22},
  number={3},
  pages={1095-1106},
  abstract={The Gene Regulatory Networks (GRNs) ensure the stability of cellular states, preserving specific phenotypes and functions throughout the differentiation process. However, current tools still need improvement to effectively integrate multi-omics data and infer GRNs for particular cell types. We introduce CLMOGRI, a multi-omics TF-gene regulatory network inference framework based on heterogeneous networks and contrastive learning, designed to integrate multi-omics data for GRN inference. Through random walk techniques, CLMOGRI embeds multi-omics data into a unified feature space and extracts similar features between nodes. It then measures node similarity and predicts node relationships by contrastive learning. Finally, it includes a regulatory network interpreter to identify critical nodes and modules in GRNs, offering an analytical method for understanding complex interactions within biological systems. CLMOGRI surpasses existing baseline methods in terms of Area Under the Precision-Recall Curve (AUPR) and F-Score metrics, indicating its efficacy in capturing multi-omics information for GRN inference. It also reveals vital nodes and modules within the gene regulatory network, improving the interpretability of CLMOGRI and the utility of GRNs.},
  keywords={Contrastive learning;Gene expression;Feature extraction;Data mining;Data integration;Bioinformatics;Accuracy;Vectors;Heterogeneous networks;Data models;Gene regulatory networks;multi-omics data;contrastive learning;deep learning},
  doi={10.1109/TCBBIO.2025.3548953},
  ISSN={2998-4165},
  month={May},}@ARTICLE{10265042,
  author={Abimannan, Satheesh and El-Alfy, El-Sayed M. and Chang, Yue-Shan and Hussain, Shahid and Shukla, Saurabh and Satheesh, Dhivyadharsini},
  journal={IEEE Access}, 
  title={Ensemble Multifeatured Deep Learning Models and Applications: A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={107194-107217},
  abstract={Ensemble multifeatured deep learning methodology has emerged as a powerful approach to overcome the limitations of single deep learning models in terms of generalization, robustness, and performance. This survey provides an extended review of ensemble multifeatured deep learning models, and their applications, challenges, and future directions. We explore potential applications of these models across various domains, including computer vision, medical imaging, natural language processing, and speech recognition. By combining the strengths of multiple models and features, ensemble multifeatured deep learning models have demonstrated improved performance and adaptability in diverse problem settings. We also discuss the challenges associated with these models, such as model interpretability, computational complexity, ensemble model selection, adversarial robustness, and personalized and federated learning. This survey highlights recent advancements in addressing these challenges and emphasizes the importance of continued research in tackling these issues to enable widespread adoption of ensemble multifeatured deep learning models. It provides an outlook on future research directions, focusing on the development of new algorithms, frameworks, and hardware architectures that can efficiently handle the large-scale computations required by these models. Moreover, it underlines the need for a better understanding of the trade-offs between model complexity, accuracy, and computational resources to optimize the design and deployment of ensemble multifeatured deep learning models.},
  keywords={Computational modeling;Deep learning;Ensemble learning;Computer vision;Adaptation models;Surveys;Robustness;Computational complexity;Adversarial machine learning;Federated learning;Ensemble multifeatured deep learning models;model interpretability;computational complexity;ensemble model selection;adversarial robustness;personalized and federated learning},
  doi={10.1109/ACCESS.2023.3320042},
  ISSN={2169-3536},
  month={},}@ARTICLE{9064920,
  author={Varghese, Elizabeth B. and Thampi, Sabu M. and Berretti, Stefano},
  journal={IEEE Transactions on Affective Computing}, 
  title={A Psychologically Inspired Fuzzy Cognitive Deep Learning Framework to Predict Crowd Behavior}, 
  year={2022},
  volume={13},
  number={2},
  pages={1005-1022},
  abstract={In an intelligent surveillance system, detecting and predicting diverse collective crowd behaviors has emerged as a challenging problem for efficient crowd management. In real-world scenarios, potential disasters and hazards can be averted by considering crowd psychology for predicting crowd behaviors. This article proposes an approach that exploits the psychological and cognitive aspects of human behavior in determining nine diverse crowd behaviors. The proposed approach is a combination of two cognitive deep learning frameworks and a psychological fuzzy computational model that utilizes OCC theory of emotions, OCEAN five-factor model of personality and visual attention for detecting crowd behaviors. Experiments are performed on different datasets and the results prove that our approach is successful in detecting and predicting crowd behavior in confronting situations and also outperforms the state-of-the-art methods. In particular, considering psychological aspects and cognition in determining crowd behavior is beneficial for rectifying the semantic ambiguity in identifying crowd behaviors.},
  keywords={Computational modeling;Psychology;Predictive models;Feature extraction;Machine learning;Visualization;Videos;Crowd behavior;crowd emotions;OCC theory of emotions;OCEAN five-factor model;cognitive visual attention;fuzzy logic;convolutional LSTM (Conv LSTM)},
  doi={10.1109/TAFFC.2020.2987021},
  ISSN={1949-3045},
  month={April},}@INPROCEEDINGS{9835394,
  author={Ding, Daizong and Zhang, Mi and Huang, Yuanmin and Pan, Xudong and Feng, Fuli and Jiang, Erling and Yang, Min},
  booktitle={2022 IEEE 38th International Conference on Data Engineering (ICDE)}, 
  title={Towards Backdoor Attack on Deep Learning based Time Series Classification}, 
  year={2022},
  volume={},
  number={},
  pages={1274-1287},
  abstract={As a fundamental task in modern data mining, time series classification is powering mission-critical tasks including stock price prediction and network traffic analysis. Due to the non-linear structure of deep neural networks (DNN), deep learning has established as a promising solution to time series classification. However, the excessive learning capacity of DNNs may make them prone to threats of backdoor attacks, where an attacker embeds hidden functionalities (i.e., backdoor) to DNNs and activates the backdoor by specially-designed inputs (i.e., triggers). Despite extensive studies concerning backdoor attacks on image and text domains, there is little known about the vulnerability of DNN based time series classifiers against backdoor attacks. Due to the unique characteristics of time series data, most existing backdoor attack techniques fail to threaten time series classifiers. In this paper, through analyzing the key factors which influence the effectiveness of a backdoor, we systematize a list of practical principles for designing triggers on time series data. In this light, we propose a novel framework called TimeTrojan, which aims to learn to form the trigger pattern through a constrained multi-objective optimization. To solve the hereafter challenging optimization issue, we further design an iterative learning algorithm. Remarkably, the proposed framework is agnostic to a wide range of DNN classifiers. Extensive empirical results on 6 representative DNN classifiers and 6 real-world datasets validate the effectiveness of the proposed attack framework. In most cases, TimeTrojan successfully injects backdoors with 100% attack success rate without affecting the model accuracy on clean samples, which implies the complete control of the behavior of the DNN classifiers by the adversary.},
  keywords={Deep learning;Time series analysis;Neural networks;Mission critical systems;Telecommunication traffic;Data engineering;Iterative algorithms;Time Series;Deep Learning;Backdoor Attack},
  doi={10.1109/ICDE53745.2022.00100},
  ISSN={2375-026X},
  month={May},}@INPROCEEDINGS{10693207,
  author={Chen, Xi and Ji, Ning and Qin, Xue and Zhang, Mengmeng and Chen, Xueming and Jiang, Chenlu and Tao, Kai},
  booktitle={2024 3rd International Conference on Energy and Electrical Power Systems (ICEEPS)}, 
  title={Transformer Fault Diagnosis Based on the Improved Sparrow Search Algorithm and Random Forest Feature Selection}, 
  year={2024},
  volume={},
  number={},
  pages={1086-1091},
  abstract={To improve the problems such as low relevance, redundant features and the low accuracy of traditional fault diagnosis methods, a transformer fault diagnosis method based on the random forest (RF) feature optimization and improved sparrow search algorithm (ISSA)- support vector machine (SVM) was proposed. First, the transformer fault features were optimized through the RF-based average accuracy reduction method. Then, the traditional sparrow search algorithm (SSA) was improved using the Tent chaos mapping and Levy flight strategy, so that the support vector machine (SVM) parameters could be optimized. The proposed method was compared with the SVM, particle swarm algorithm-support vector machine (PSO-SVM), and sparrow search algorithm-support vector machine (SSA-SVM). The results show that the fault diagnosis rate of ISSA-SVM is 91.67%, which is 11.11%, 8.34% and 2.78% higher than that of SVM, PSO-SVM and SSA-SVM respectively. This result verified the effectiveness of the proposed method in the fault diagnosis of transformer.},
  keywords={Fault diagnosis;Support vector machines;Radio frequency;Chaos;Accuracy;Transformers;Feature extraction;Search problems;Vectors;Signal analysis;Transformer;Fault diagnosis;Sparrow search algorithm;Support vector machine},
  doi={10.1109/ICEEPS62542.2024.10693207},
  ISSN={},
  month={July},}@INPROCEEDINGS{10500208,
  author={Liu, Maohua and Ahmad, Faraz and Hao, Jianwei and Mehmood, Muhammad and Ahmed, Ishfaque and Beyette, Fred R.},
  booktitle={SoutheastCon 2024}, 
  title={Enhancing P300 Feature Extraction through Multi-Scale Separable Convolution}, 
  year={2024},
  volume={},
  number={},
  pages={1420-1425},
  abstract={P300, one kind of Event-Related Potentials (ERP), plays a crucial role in Brain-Computer Interfaces (BCIs). P300 detection is a key step in P300-based BCIs. Convolutional Neural Networks (CNNs) have emerged as popular solutions in P300 detection due to their automatic feature extraction capabilities. From 2010 to 2021, various CNN architectures with different layers and convolutional methods have been developed for P300 feature extraction. Among them, SepConv1D, utilizing a single separable convolution layer with only 4 kernels (or 225 parameters), has achieved state-of-the-art performance. This study builds upon SepConv1D's success by proposing a novel approach: multi-scale separable convolution for P300 feature extraction. Unlike SepConv1D, which employs the same size for each convolutional kernel, our approach utilizes different sizes for each kernel. Experimental results demonstrate superior performance, showing improved feature saliency maps and higher AUC values in P300 detection.},
  keywords={Convolution;Feature extraction;Brain-computer interfaces;Convolutional neural networks;Kernel;P300;ERP;BCls;feature extraction;multi-scale;separable convolution},
  doi={10.1109/SoutheastCon52093.2024.10500208},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10579013,
  author={Wang, Alvin and Zhai, Lujun},
  booktitle={2024 IEEE World AI IoT Congress (AIIoT)}, 
  title={GA-Net: Global-aware Attention-guided CNN for Food Image Classification}, 
  year={2024},
  volume={},
  number={},
  pages={0408-0413},
  abstract={Overweight and obesity have become pressing societal concerns, particularly among African American women, directly impacting their life expectancy and quality of life. This paper aims to address the dietary health of African American women by introducing a method to assess food calorie content through image analysis. Firstly, we develop food vision neural network as a powerful tool for food analysis and prediction. Secondly, we explore the utilization of text-to-image generative models to construct the food vision training dataset, thereby significantly reducing labor and cost. Finally, extensive experiments demonstrate the effectiveness of our food vision prediction system. This approach provides a pathway for improving awareness of unhealthy dietary habits and offers resources to enhance health outcomes for African American women.},
  keywords={Training;Obesity;Costs;Machine vision;Neural networks;Text to image;Pressing;Food Vision;Image Classification;CNN;Generative Model},
  doi={10.1109/AIIoT61789.2024.10579013},
  ISSN={},
  month={May},}@ARTICLE{10932830,
  author={Lu, Guangquan and Ling, Fuqing and Li, Jiechen and Zhu, Longtao and Qin, Xiaohua and Nong, Sebing},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Graph Attention-Based Dual Enhancement for Multiview Clustering}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={In deep contrastive graph clustering, many methods tend to adopt a singular enhancement strategy, focusing either on structural or attribute augmentation. This limited approach constrains the model’s ability to integrate multidimensional information, resulting in an imbalance in information utilization. Furthermore, the randomness involved in the selection of negative samples may lead to blurred distinctions between positive and negative samples. Therefore, we introduce a graph attention-based dual enhancement multiview clustering (GA-DE-MVC). The GA-DE-MVC first encodes structure and attributes through attention mechanisms and fully connected layers to achieve dual enhancement of structure and attributes. Then, it selects the farthest sample as the negative sample based on the Euclidean distance between cluster centers, to alleviate the randomness in negative sample selection, thereby enhancing the distinctiveness between positive and negative samples.The experimental results on six datasets surpass existing algorithms, verifying the effectiveness of the GA-DE-MVC algorithm.},
  keywords={Contrastive learning;Laplace equations;Data augmentation;Symmetric matrices;Technological innovation;Representation learning;Electronic mail;Computational complexity;Training;Smoothing methods;Attention mechanism;contrastive learning;graph clustering;multiview},
  doi={10.1109/TCSS.2025.3525696},
  ISSN={2329-924X},
  month={},}@ARTICLE{10663218,
  author={Jiao, Ruwang and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Sparse Learning-Based Feature Selection in Classification: A Multi-Objective Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Sparse learning-based feature selection is an emerging topic, acclaimed for its potential in delivering promising performance and interpretability. Nevertheless, the task of determining a suitable regularization parameter to strike a balance between the loss function and regularization is a challenging endeavor, where existing methods encounter great difficulties. Moreover, the ranking mechanism in most sparse learning-based feature selection methods requires a predefined number of selected features, which is usually dataset-dependent and not known in advance. It is of great importance to automatically balance the loss function and sparse regularization and determine the appropriate number of selected features. To this end, this paper proposes formulating the sparse learning-based feature selection problem as a bi-objective optimization problem, which takes the loss term and the $\ell _{2,0}$-norm regularization as two objectives, to automatically identify the optimal number of selected features and obtain a set of trade-off solutions between the loss term and the number of selected features. To solve such a non-convex problem, a novel solution representation, an initialization strategy, and an environmental selection operator are proposed. Compared with seven feature selection methods, extensive experiments on 16 practical classification datasets demonstrate that the proposed method attains highly competitive classification accuracy with a small number of selected features, and the features selected by the proposed method have low redundancy.},
  keywords={Feature extraction;Sparse matrices;Optimization;Contracts;Task analysis;Computational modeling;Vectors;Evolutionary computation;feature selection;multi-objective learning;classification;sparse learning},
  doi={10.1109/TETCI.2024.3449850},
  ISSN={2471-285X},
  month={},}@ARTICLE{9695209,
  author={Ye, Lin and Dai, Binhua and Pei, Ming and Lu, Peng and Zhao, Jinlong and Chen, Mei and Wang, Bo},
  journal={IEEE Transactions on Industry Applications}, 
  title={Combined Approach for Short-Term Wind Power Forecasting Based on Wave Division and Seq2Seq Model Using Deep Learning}, 
  year={2022},
  volume={58},
  number={2},
  pages={2586-2596},
  abstract={The accuracy of short-term wind power forecasting (WPF) can be improved by effective mining of numerical weather prediction data. In this article, a novel short-term WPF approach is proposed by combining wave division (WD), improved grey wolf optimizer based on fuzzy C-means clusters (IGFCM), and Seq2Seq model with attention mechanism based on long short-term memory model (LSTMS), named the WD-IGFCM-LSTMS model. Based on the fluctuation trend, the wind speed sequences of NWP are divided into a series of waves. Six fluctuation features that reflect the shape characteristics are extracted to quantify the partitioned waves. A new strategy is proposed to improve the global searching ability of the GWO to select the initial clustering center of FCM more effectively. The Seq2Seq deep learning model based on LSTM, named LSTMS, is applied for wave-oriented forecasting. The proposed approach outperforms the traditional point-to-point forecasting and realizes continuous sequence forecasting. The simulation results demonstrate that the WD-IGFCM-LSTMS model can perform better than other benchmark forecasting models.},
  keywords={Wind speed;Forecasting;Wind power generation;Feature extraction;Fluctuations;Predictive models;Mathematical models;Combined approach;feature extraction;numerical weather prediction (NWP);Seq2Seq model;short-term wind power forecasting (WPF);wave division (WD)},
  doi={10.1109/TIA.2022.3146224},
  ISSN={1939-9367},
  month={March},}@ARTICLE{9585428,
  author={Zhou, Anni and Beyah, Raheem and Kamaleswaran, Rishikesan},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={OnAI-Comp: An Online AI Experts Competing Framework for Early Sepsis Detection}, 
  year={2022},
  volume={19},
  number={6},
  pages={3595-3603},
  abstract={Sepsis is a major public concern due to its high mortality, morbidity, and financial cost. There are many existing works of early sepsis prediction using different machine learning models to mitigate the outcomes brought by sepsis. In the practical scenario, the dataset grows dynamically as new patients visit the hospital. Most existing models, being “offline” models and having used retrospective observational data, cannot be updated and improved dynamically using the new observational data. Incorporating the new data to improve the offline models requires retraining the model, which is very computationally expensive. To solve the challenge mentioned above, we propose an Online Artificial Intelligence Experts Competing Framework (OnAI-Comp) for early sepsis detection using an online learning algorithm called Multi-armed Bandit. We selected several machine learning models as the artificial intelligence experts and used average regret to evaluate the performance of our model. The experimental analysis demonstrated that our model would converge to the optimal strategy in the long run. Meanwhile, our model can provide clinically interpretable predictions using existing local interpretable model-agnostic explanation technologies, which can aid clinicians in making decisions and might improve the probability of survival.},
  keywords={Computational modeling;Predictive models;Data models;Machine learning;Stochastic processes;Hospitals;Training;Early sepsis detection;multi-armed bandit;online learning},
  doi={10.1109/TCBB.2021.3122405},
  ISSN={1557-9964},
  month={Nov},}@ARTICLE{10056154,
  author={Takagi, Tomoaki and Takadama, Keiki and Sato, Hiroyuki},
  journal={IEEE Access}, 
  title={Directional Pareto Front and Its Estimation to Encourage Multi-Objective Decision-Making}, 
  year={2023},
  volume={11},
  number={},
  pages={20619-20634},
  abstract={This work introduces the following concepts of directional and estimated directional Pareto front to encourage multi-objective decision making, especially when the Pareto front exists in limited regions in the objective space. The general output of multi-objective optimization is a set of non-dominated solutions to approximate the Pareto front. When the Pareto front exists in limited regions, few solutions are obtained and presented to the decision maker. The limited output representing the objective value trade-off is a barrier to multi-objective decision making. The directional Pareto front introduced in this study is a superset of the Pareto front and supplements the objective value trade-off between the Pareto fronts. The estimated directional Pareto front is a response surface that represents the directional Pareto front using a limited number of points, which are objective vectors of the obtained solutions. The experimental results show that the directional Pareto front and the estimated front provide an objective value trade-off even in areas where the Pareto front does not exist and enhances the explanation of the objective space of the target problem.},
  keywords={Estimation;Optimization;Pareto optimization;Decision making;Response surface methodology;Linear programming;Decision making;Multi-objective optimization;multi-objective decision-making;evolutionary algorithm;response surface methodology},
  doi={10.1109/ACCESS.2023.3250238},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10230749,
  author={Liu, Yiheng and Ge, Enjie and Qiang, Ning and Liu, Tianming and Ge, Bao},
  booktitle={2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Spatial-Temporal Convolutional Attention for Mapping Functional Brain Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Using functional magnetic resonance imaging (fMRI) and deep learning to explore functional brain networks (FBNs) has attracted many researchers. However, most of these studies still rely on temporal correlation between sources and voxel signals, lacking exploration of the dynamics of brain function. Due to the prevalent local correlations in volumes, FBNs can be directly generated in the spatial domain using spatial-wise attention (SA) in a self-supervised manner, resulting in higher spatial similarity with templates compared to classical methods. Therefore, we propose a novel Spatial-Temporal Convolutional Attention (STCA) model to dynamically discover FBNs using sliding windows. We validate the performance of our proposed method on the HCP-rest dataset, showing that STCA can be used to dynamically discover FBNs, offering a novel approach to better understand the human brain.},
  keywords={Deep learning;Correlation;Convolution;Biological system modeling;Functional magnetic resonance imaging;Brain modeling;Task analysis;fMRI;Attention Mechanism;Functional Brain Network;Brain Function Dynamic},
  doi={10.1109/ISBI53787.2023.10230749},
  ISSN={1945-8452},
  month={April},}@ARTICLE{10713420,
  author={Tong, Yunfei and Liu, Jing and Fu, Zhiling and Wang, Zhe and Yang, Hai and Niu, Saisai and Tan, Qinyan},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Guided Attention and Joint Loss for Infrared Dim Small Target Detection}, 
  year={2024},
  volume={62},
  number={},
  pages={1-14},
  abstract={Infrared dim small target (IDST) detection is of great significance in security surveillance and disaster relief. However, the complex background interference and tiny targets in infrared images keep it still a long-term challenge. Existing deep learning models stack network layers to expand the model fitting capability, but this operation also increases redundant features which reduce model speed and accuracy. Meanwhile, small targets are more susceptible to positional bias, with this dramatically reducing the model’s localization accuracy. In this article, we propose a guided attention and joint loss (GA-JL) network for infrared small target detection. More specifically, the method visualizes the feature maps at each resolution through a two-branch detection head (TDH) module, filters out the features that are strongly related to the task, and cuts out the redundant features. On this basis, the guided attention (GA) module guides the prediction layer features using the features that are associated closely with the task and combines spatial and channel bidirectional attention to make the prediction layer feature maps embedded with effective messages. Finally, through the joint loss (JL) module, the target position regression is performed with multiangle metrics for enhancing the target detection accuracy. Experimental results of our method on the SIATD, SIRST, and IRSTD_1k datasets reveal that it is capable of accurately identifying IDSTs, remarkably reduces the false alarm rate, and outperforms other methods.},
  keywords={Feature extraction;Object detection;Accuracy;Attention mechanisms;Sensitivity;Geoscience and remote sensing;Fitting;Detection algorithms;Deep learning;Windows;Guided-attention (GA) mechanism;infrared dim small target (IDST) detection;joint loss (JL);positional bias;YOLO series},
  doi={10.1109/TGRS.2024.3477575},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{9995284,
  author={Lu, Yilin and Liu, Jinduo and Ji, Junzhong and Lv, Han and Huai, Mengdi},
  booktitle={2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Brain Effective Connectivity Learning with Deep Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1664-1667},
  abstract={In recent years, using functional magnetic resonance imaging (fMRI) data to infer brain effective connectivity (EC) between different brain regions is an important advanced study in neuroinformatics. However, current methods always perform not well due to the high noise of neuroimaging data. In this paper, we propose an effective connectivity learning method with deep reinforcement learning, called EC-DRL, aiming to more accurately identify the brain effective connectivity from fMRI data. The proposed method is based on the actor-critic algorithm framework, using the encoder-decoder model as the actor network. More specifically, the encoder adopts the Transformer model structure, and the decoder uses a bidirectional long-short-term memory network with an attention mechanism. A large number of experimental results on simulated fMRI data and real-world fMRI data show that EC-DRL can better infer effective connectivity compared to the state-of-the-art methods.},
  keywords={Deep learning;Neuroimaging;Biological system modeling;Time series analysis;Reinforcement learning;Neuroinformatics;Functional magnetic resonance imaging;Brain effective connectivity;deep reinforcement learning;encoder-decoder model;bidirectional long-short-term memory network;fMRI time series},
  doi={10.1109/BIBM55620.2022.9995284},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10962795,
  author={Hasan, Irtiza and Islam, Mainul and Hoque, Mohammad Ehsanul and Jim, Salman Jubair},
  booktitle={2024 IEEE International Conference on Biomedical Engineering, Computer and Information Technology for Health (BECITHCON)}, 
  title={A Framework for Early Diabetes Prediction and Interpretation: Sex-specific Factor Analysis Approach Using Ensemble Classifiers}, 
  year={2024},
  volume={},
  number={},
  pages={143-148},
  abstract={Diabetes mellitus is a prevalent metabolic disorder, underscoring the need for predictive strategies to enable early detection and timely intervention. This study presents a novel approach that utilizes Exploratory Factor Analysis (EFA) to enhance both interpretability and predictive accuracy, with an emphasis on sex-specific analysis. By leveraging EFA for dimensionality reduction, the model achieves significant improvements in both prediction performance and interpretability. Tailoring the analysis to sex-specific factors, this approach provides distinct insights for male and female populations, optimizing early detection strategies. Ensemble classifiers were employed, achieving optimal F1 scores and Area Under the Curve of the Receiver Operating Characteristic (AUC-ROC) scores of 97.62% and 0.9992 for males, and 98.15% and 0.9811 for females, respectively. These results underscore the efficacy of EFA-driven dimensionality reduction in clinical decision-making, marking a substantial contribution to diabetes prediction and personalized healthcare. Keywords: Diabetes Prediction, Exploratory Factor Analysis, Sex-specific Analysis, Ensemble Classifiers, Early Detection},
  keywords={Dimensionality reduction;Accuracy;Decision making;Receivers;Medical services;Predictive models;Diabetes;Information technology;Biomedical engineering},
  doi={10.1109/BECITHCON64160.2024.10962795},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10644365,
  author={Yang, Yejiang and Mo, Zihao and Tran, Hoang-Dung and Xiang, Weiming},
  booktitle={2024 American Control Conference (ACC)}, 
  title={A Transition System Abstraction Framework for Neural Network Dynamical System Models}, 
  year={2024},
  volume={},
  number={},
  pages={388-393},
  abstract={This paper proposes a transition system abstraction framework for neural network dynamical system models to enhance the model interpretability, with applications to complex dynamical systems such as human behavior learning and verification. To begin with, the localized working zone will be segmented into multiple localized partitions under the data-driven Maximum Entropy (ME) partitioning method. Then, the transition matrix will be obtained based on the set-valued reachability analysis of neural networks. Finally, applications to human handwriting dynamics learning and verification are given to validate our proposed abstraction framework, which demonstrates the advantages of enhancing the interpretability of the black-box model, i.e., our proposed framework is able to abstract a data-driven neural network model into a transition system, making the neural network model interpretable through verifying specifications described in Computational Tree Logic (CTL) languages.},
  keywords={Shape;Computational modeling;Neural networks;Closed box;Entropy;Behavioral sciences;Logic},
  doi={10.23919/ACC60939.2024.10644365},
  ISSN={2378-5861},
  month={July},}@INPROCEEDINGS{10881498,
  author={Abhisheka, Barsha and Biswas, Saroj Kumar and Purkayastha, Biswajit},
  booktitle={2024 6th International Conference on Computational Intelligence and Networks (CINE)}, 
  title={A Weighted Average Ensemble Approach for Breast Cancer detection using Deep Learning with Genetic Optimization:GeneOptBM-Net}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Breast cancer poses a significant global health challenge, especially due to its asymptomatic early stages, which complicates detection. While Machine Learning (ML) and Deep Learning (DL) techniques are commonly employed, achieving a comprehensive diagnosis remains difficult. Medical experts stress early treatment as crucial for improving patients’ chances of recovery and mitigating associated risks. Many ComputerAided Diagnosis (CAD) systems have been proposed, often integrating various imaging modalities. However, most rely on either attention-based deep features or handcrafted features with a single classifier based models, lacking the ability to provide vital local information for precise tumor detection and robustness. Furthermore, existing breast cancer datasets suffer from class imbalance problem. Hence, this study introduces a novel Genetic Optimized Breast Mass Network (GeneOptBMNet) for early-stage breast cancer detection, leveraging ensemble techniques for improved robustness and accuracy over singleclassifier models. The proposed model integrates decisions from base learners and employs weighted averaging for final decisionmaking. The optimal combination of weights is determined using the Genetic Algorithm (GA). Furthermore, it enhances overall system performance by combining attention-based deep features and handcrafted features extracted using HOG, thus offering precise local information. To tackle class imbalance, the model incorporates the Borderline Synthetic Minority Over-sampling Technique (BSMOTE). Evaluation on BUSI and UDIAT datasets shows promising results, with average accuracies of 99.08% and $\mathbf{9 7. 0 2 \%}$, respectively.},
  keywords={Deep learning;Solid modeling;Accuracy;Feature extraction;Genetics;Breast cancer;Robustness;Ensemble learning;Genetic algorithms;Tumors;weighted average Ensemble;Breast Cancer;Attention techniques;Handcrafted features},
  doi={10.1109/CINE63708.2024.10881498},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10883404,
  author={Venkateswaran, N. and J, Ramprabu and Marimuthu, Ramaprabha and Ramana, Nagella Venkata and Kotha, Mahesh and Mallala, Balasubbareddy},
  booktitle={2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI)}, 
  title={Enhanced Demand-Side Management for Electric Vehicle Charging Stations Using Pyramidal Dilation Attention Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={572-577},
  abstract={With the improvement in EV's popularity, controlling the load demand of EVCS's has become an essential task to keep the grid balanced and efficient. Conventional DSM techniques tend to rely on historic patterns to predict charging trends, hence cannot serve as viable solutions to peak load problems. In order to improve charging demand forecasting, this research presents a Pyramidal Dilation Attention Convolutional Neural Network (PDACNN) for the DSM of EV charging stations. By using precise forecasting and ideal charging schedule, this study aims to increase the effectiveness of DSM in EV charging stations. The PDACNN is used to predict the charging load for EV stations, allowing for optimized scheduling of charging sessions that align with grid capacity and energy availability. By then, the proposed method is implemented on MATLAB platform and evaluated with other existing methods such as Artificial Neural Network (ANN), Deep Reinforcement Learning (DRL), and Genetic Algorithm (GA). The proposed PDACNN method achieves an RMSE of 0.0753 and an accuracy of 98.9%, demonstrating its effectiveness in EV charging load forecasting and demand-side management.},
  keywords={Training;Accuracy;Demand side management;Scalability;Transportation;Electric vehicle charging;Mathematical models;Convolutional neural networks;Vehicle dynamics;Genetic algorithms;Charging Station;Demand-Side Management;Electric Vehicles;Pyramidal Dilation Attention Convolutional Neural Network},
  doi={10.1109/ICMCSI64620.2025.10883404},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10903581,
  author={Khaloujini, Amirmasood and Talaeizadeh, Amin and Taheri, Alireza and Alastya, Aria},
  booktitle={2024 12th RSI International Conference on Robotics and Mechatronics (ICRoM)}, 
  title={Coverage Path Planning of Agricultural Spraying Drones with Graph Convolutional Network}, 
  year={2024},
  volume={},
  number={},
  pages={543-548},
  abstract={Optimal route planning for autonomous robots is a crucial element of contemporary agriculture, especially for activities like spraying and pollination. This paper presents a Graph Convolutional Network (GCN) model especially developed to address the Coverage Path Planning (CPP). The aim of this paper is to convert the CPP problem into a Traveling Salesman Problem (TSP), so that by solving the TSP using the proposed neural network, an optimal route can be extracted for each agricultural field in the shortest possible time and with sufficient accuracy, ensuring full coverage of the field's area. The proposed model is a GCN, augmented with a transformer layer and a Multi-Layer Perceptron (MLP), was trained using datasets produced by a Genetic Algorithm (GA) Method. The model obtained a network error of 0.12 while solving TSP cases with 20 points. It showed robust generalization skills, as evidenced by validation and test errors of 0.1261 and 0.1264, respectively. Significantly, the GCN model reduces the solution time to approximately one-tenth compared to conventional approaches, a benefit that increases as the number of points increases. The effectiveness of the model in producing ideal coverage routes highlights its potential for wider use in optimization and coverage path planning, especially in dynamic and extensive agricultural environments.},
  keywords={Training;Accuracy;Graph convolutional networks;Neural networks;Spraying;Traveling salesman problems;Transformers;Path planning;Vehicle dynamics;Genetic algorithms;Multi Rotor;Agricultural Robotic;Graph Convolution},
  doi={10.1109/ICRoM64545.2024.10903581},
  ISSN={2572-6889},
  month={Dec},}@INPROCEEDINGS{10356472,
  author={Zhang, Wenxi and Yang, Peilin and Zheng, Wenguang and Xiao, Yingyuan},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Deep Interaction Behavioral Feature Network for Click-Through Rate Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={636-640},
  abstract={Click-through rate prediction(CTR) is a critical task in recommendation system. Most previous work on modelling the interaction features between user history behavior and target item focused only on mining the single interaction feature between user’s single historical behavior and the target item, or only modeling the user behavior sequence to capture user interest, which may lead to lower prediction accuracy. To solve the above problem, we propose the Deep Interaction Behavioral Feature Network(DIBFN), which is a dual-module approach that focuses on both the interaction features of user interest and the target item and on the interaction features of user’s single historical behavior and the target item. First, the Evolving Interaction Module (EIM), which processes user behavior sequence to explore the user interest over time, captures the interaction features of the user interest with the target item. Then, the Behavioral Feature Module (BFM) is proposed to learn behavior representations from multi-space through multi-head self-attention and use a two-layer attention mechanism to mine the interaction features between user’s single historical behavior and the target item. Experimental results on real datasets show that the proposed DIBFN model outperforms previous main-stream approaches.},
  keywords={Predictive models;Data models;Behavioral sciences;History;Task analysis;Artificial intelligence;Recommender systems;CTR Prediction;Recommender systems;Neural Networks},
  doi={10.1109/ICTAI59109.2023.00099},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{10056257,
  author={Wan, Bin and Zhou, Xiaofei and Zheng, Bolun and Yin, Haibing and Zhu, Zunjie and Wang, Hongkui and Sun, Yaoqi and Zhang, Jiyong and Yan, Chenggang},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={LFRNet: Localizing, Focus, and Refinement Network for Salient Object Detection of Surface Defects}, 
  year={2023},
  volume={72},
  number={},
  pages={1-12},
  abstract={Salient object detection of surface defects is one of the surface defect detection tasks, which aims at highlighting the defect regions from the surface of strip steel, magnetic tale, road, and so on. However, the performance of existing methods degrades dramatically when dealing with complex scenarios, such as low contrast of defect regions and various defect shapes. Therefore, in this article, we propose a novel saliency model, namely, localizing, focus, and refinement network (LFRNet), which consists of the semantic-guided localizing module, the context-driven focus module, and the edge-aware refinement (ER) module. First, the semantic-guided localizing module deploys the graph reasoning (GR) unit and the global attention (GA) unit to localize the potential defect regions from a global view. Second, the context-driven focus module employs the split context (SC) unit and the mutual attention (MA) unit to perform the identification process via the introduction of spatial detail features. Finally, to further improve the accuracy of the detection results, we deploy the ER module, which introduces the boundary cues via the edge generation (EG) unit and aggregates the localizing result, the focus results, and the edge information into the high-quality detection map. Extensive experiments on four public defect datasets clearly show the effectiveness and superiority of the proposed LFRNet, where the LFRNet obtains an improvement of 4.1%, 5.7%, 1.0%, and 0.8% on F-measure (FM), weighted FM (WF), E-measure (EM), and structure-measure (SM), respectively, compared with the top-level method: AEP.},
  keywords={Feature extraction;Image edge detection;Semantics;Task analysis;Object detection;Inspection;Cognition;Context information;edge cues;saliency detection;semantic features;surface defect detection},
  doi={10.1109/TIM.2023.3250302},
  ISSN={1557-9662},
  month={},}@ARTICLE{9439895,
  author={Fister, Iztok and Fister, Iztok},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Information Cartography in Association Rule Mining}, 
  year={2022},
  volume={6},
  number={3},
  pages={660-676},
  abstract={Association Rule Mining is a machine learning method for discovering the interesting relations between the attributes in a huge transaction database. Typically, algorithms for Association Rule Mining generate a huge number of association rules, from which it is hard to extract structured knowledge and present this automatically in a form that would be suitable for the user. Recently, an information cartography has been proposed for creating structured summaries of information and visualizing with methodology called “metro maps”. This was applied to several problem domains, where pattern mining was necessary. The aim of this study is to develop a method for automatic creation of metro maps of information obtained by Association Rule Mining and, thus, spread its applicability to the other machine learning methods. Although the proposed method consists of multiple steps, its core presents metro map construction that is defined in the study as an optimization problem, which is solved using an evolutionary algorithm. Finally, this was applied to four well-known UCI Machine Learning datasets and one sport dataset. Visualizing the resulted metro maps not only justifies that this is a suitable tool for presenting structured knowledge hidden in data, but also that they can tell stories to users.},
  keywords={Data visualization;Machine learning;Visualization;Transaction databases;Machine learning algorithms;Clustering algorithms;Transportation;Information cartography;metro map;evolutionary algorithms;machine learning;explainable artificial intelligence},
  doi={10.1109/TETCI.2021.3074919},
  ISSN={2471-285X},
  month={June},}@INPROCEEDINGS{9761432,
  author={Logan, Yash-Yee and Kokilepersaud, Kiran and Kwon, Gukyeong and AlRegib, Ghassan and Wykoff, Charles and Yu, Hannah},
  booktitle={2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Multi-Modal Learning Using Physicians Diagnostics for Optical Coherence Tomography Classification}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we propose a framework that incorporates experts diagnostics and insights into the analysis of Optical Coherence Tomography (OCT) using multi-modal learning. To demonstrate the effectiveness of this approach, we create a medical diagnostic attribute dataset to improve disease classification using OCT. Although there have been successful attempts to deploy machine learning for disease classification in OCT, such methodologies lack the experts insights. We argue that injecting ophthalmological assessments as another supervision in a learning framework is of great importance for the machine learning process to perform accurate and interpretable classification. We demonstrate the proposed framework through comprehensive experiments that compare the effectiveness of combining diagnostic attribute features with latent visual representations and show that they surpass the state-of-the-art approach. Finally, we analyze the proposed dual-stream architecture and provide an insight that determine the components that contribute most to classification performance.},
  keywords={Learning systems;Visualization;Pathology;Optical coherence tomography;Machine learning;Medical diagnosis;Medical diagnostic imaging;Multi-modal Learning;Diagnostic Attributes;Latent Representation;Autoencoder;OCT},
  doi={10.1109/ISBI52829.2022.9761432},
  ISSN={1945-8452},
  month={March},}@INPROCEEDINGS{9897248,
  author={Logan, Yash-yee and Benkert, Ryan and Mustafa, Ahmad and AlRegib, Ghassan},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={Patient Aware Active Learning for Fine-Grained OCT Classification}, 
  year={2022},
  volume={},
  number={},
  pages={3908-3912},
  abstract={This paper considers making active learning more sensible from a medical perspective. In practice, a disease manifests itself in different forms across patient cohorts. Existing frameworks have primarily used mathematical constructs to engineer uncertainty or diversity-based methods for selecting the most informative samples. However, such algorithms do not present themselves naturally as usable by the medical community and healthcare providers. Thus, their deployment in clinical settings is very limited, if any. For this purpose, we propose a framework that incorporates clinical insights into the sample selection process of active learning that can be incorporated with existing algorithms. Our medically interpretable active learning framework captures diverse disease manifestations from patients to improve generalization performance of OCT classification. After comprehensive experiments, we report that incorporating patient insights within the active learning framework yields performance that matches or surpasses five commonly used paradigms on two architectures with a dataset having imbalanced patient distributions. Also, the framework integrates within existing medical practices and thus can be used by healthcare providers.},
  keywords={Learning systems;Uncertainty;Image processing;Medical services;Robustness;Classification algorithms;Medical diagnostic imaging;Active learning;Deep learning;OCT;Patient awareness;Personalized diagnosis},
  doi={10.1109/ICIP46576.2022.9897248},
  ISSN={2381-8549},
  month={Oct},}@INPROCEEDINGS{10218024,
  author={Rguez, Amine and Hadjadj-Aoul, Yassine and Slim, Farah and Rubino, Gerardo and Selmi, Asma},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={A GRASP-Based Algorithm for Virtual Network Embedding}, 
  year={2023},
  volume={},
  number={},
  pages={470-473},
  abstract={With the rise of network virtualization, network slicing is becoming a hot research topic. Indeed, network operators must deal with capacity-limited resources while insuring an extreme availability of services. Several approaches exist in the literature to tackle such a problem, some of them converge quickly to a local minimum, while others are not explainable and therefore do not provide the necessary guarantees for their deployment in a real network. In this context, we propose a new approach for Virtual Network Embedding (VNE) based on the Greedy Adaptive Search Procedure (GRASP). Using the GRASP meta-heuristic ensures the robustness of the solution to changing constraints and environments. Moreover, the proposed realistic approach allows a more efficient and directed exploration of the solution space, in opposition to existing techniques. The simulation results show the potential of the proposed method for solving services' placement problems and its superiority over existing approaches.},
  keywords={Deep learning;Computers;Filtering;Network slicing;Heuristic algorithms;Simulation;Metaheuristics;Virtual Network Embedding;GRASP algorithm;Cloud Resource Allocation;Network Slicing},
  doi={10.1109/ISCC58397.2023.10218024},
  ISSN={2642-7389},
  month={July},}@ARTICLE{10806835,
  author={Mao, Lingchao and Wang, Hairong and Hu, Leland S. and Tran, Nhan L. and Canoll, Peter D. and Swanson, Kristin R. and Li, Jing},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis: A Review}, 
  year={2025},
  volume={22},
  number={},
  pages={10008-10028},
  abstract={Cancer remains one of the most challenging diseases to treat in the medical field. Machine learning (ML) has enabled in-depth analysis of complex patterns from large, diverse datasets, greatly facilitating “healthcare automation” in cancer diagnosis and prognosis. Despite these advancements, ML models face challenges stemming from limited labeled sample sizes, the intricate interplay of high-dimensionality data types, the inherent heterogeneity observed among patients and within tumors, and concerns about interpretability and consistency with existing biomedical knowledge. One approach to address these challenges is to integrate biomedical knowledge into data-driven models, which has proven potential to improve the accuracy, robustness, and interpretability of model results. Here, we review the state-of-the-art ML studies that leverage the fusion of biomedical knowledge and data, termed knowledge-informed machine learning (KIML), to advance cancer diagnosis and prognosis. We provide an overview of diverse forms of knowledge representation and current strategies of knowledge integration into machine learning pipelines with concrete examples. We conclude the review article by discussing future directions aimed at leveraging KIML to advance cancer research and healthcare automation. A live summary of the review is hosted at https://lingchm.github.io/kinformed-machine-learning-cancer/ offering an evolving resource to support research in this field.Note to Practitioners—Recognizing the challenges posed by inter-patient and intratumoral heterogeneity, constrained sample size, and interpretability requirements in cancer applications, practitioners should consider integration of existing biomedical knowledge into their modeling frameworks. This strategy holds promise for enhancing model performance, robustness, and interpretability. We review classic machine learning and deep learning models that incorporated domain knowledge in their cancer diagnosis and prognosis models spanning models that use clinical, imaging, molecular, and treatment data. Pros and cons of each integration approach are discussed. Key design questions such as which knowledge to leverage, how to represent it effectively, and how to seamlessly integrate it into their models need be examined for each case. Collaboration between modeling scientists and medical experts is essential in this endeavor.},
  keywords={Cancer;Tumors;Reviews;Biological system modeling;Medical diagnostic imaging;Prognostics and health management;Machine learning;Imaging;Automation;Medical services;Machine learning;deep learning;healthcare automation;cancer diagnosis;prognosis},
  doi={10.1109/TASE.2024.3515839},
  ISSN={1558-3783},
  month={},}@ARTICLE{9839334,
  author={Wang, Junliang and Zhao, Shuxuan and Xu, Chuqiao and Zhang, Jie and Zhong, Ray},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Brain-Inspired Interpretable Network Pruning for Smart Vision-Based Defect Detection Equipment}, 
  year={2023},
  volume={19},
  number={2},
  pages={1666-1673},
  abstract={Detection algorithms play an important role in the life-cycle management of smart vision-based defect detection equipment. This article proposes a brain-inspired interpretable network pruning method for smart detection equipment for online defect detection scenarios. A brain-inspired neuronal circuit decomposition model is constructed from the view of the structure physics of artificial neural networks. To meet the real-time requirements, an interpretable network pruning is proposed in three steps: First, a full-size basic convolutional neural network is constructed. Second, the convolutional neural circuit's extraction method based on a genetic algorithm is designed to evaluate the function of different neural units. Third, a pruning method is proposed to eliminate the redundant convolutional neural circuits and retain key units to balance the accuracy and time efficiency. The experimental results demonstrated the proposed pruning method can improve the frame-pre-second by 116% on the premise of maintaining the detection accuracy of 92%.},
  keywords={Integrated circuit modeling;Convolution;Neural circuits;Brain modeling;Neurons;Feature extraction;Kernel;Brain-inspired;convolutional neural network (CNN);network pruning;online detection},
  doi={10.1109/TII.2022.3188349},
  ISSN={1941-0050},
  month={Feb},}@INPROCEEDINGS{9882615,
  author={Hein, Alice and Meier, Lukas J. and Buyx, Alena M. and Diepold, Klaus},
  booktitle={2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={A Fuzzy-Cognitive-Maps Approach to Decision-Making in Medical Ethics}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Although machine intelligence is increasingly employed in healthcare, the realm of decision-making in medical ethics remains largely unexplored from a technical perspective. We propose an approach based on fuzzy cognitive maps (FCMs), which builds on Beauchamp and Childress’ prima-facie principles. The FCM’s weights are optimized using a genetic algorithm to provide recommendations regarding the initiation, continuation, or withdrawal of medical treatment. The resulting model approximates the answers provided by our team of medical ethicists fairly well and offers a high degree of interpretability. Possible applications of such a system include informal guidance on medical ethics dilemmas as well as educational purposes.},
  keywords={Ethics;Pediatrics;Decision making;Fuzzy cognitive maps;Medical treatment;Machine intelligence;Genetic algorithms;fuzzy cognitive map;medical ethics;genetic algorithm;decision support systems},
  doi={10.1109/FUZZ-IEEE55066.2022.9882615},
  ISSN={1558-4739},
  month={July},}@ARTICLE{9800909,
  author={Jia, Jingyuan and Wang, Bo and Ma, Rubing and Deng, Zhihong and Fu, Mengyin},
  journal={IEEE Internet of Things Journal}, 
  title={State Monitoring of Gas Regulator Station Based on Feature Selection of Improved Grey Relational Analysis}, 
  year={2022},
  volume={9},
  number={22},
  pages={22765-22773},
  abstract={The in-depth application of the IoT technology in the gas industry has improved the intelligence of the gas system. As an important part of the gas system, the optimization of state monitoring of regulator stations is of great significance. The efficiency of monitoring can be improved by feature selection, but the reduction of important features will reduce the accuracy of identification. Therefore, a feature selection method based on gray relational analysis is proposed. First, the distance between the comparison matrix and the reference matrix is transformed using the geometric probability distribution, which solves the problem of data initial transformation. Then, an adaptive value method of resolution coefficient based on the cuckoo algorithm is proposed. Finally, a weight coefficient is constructed by combining the redundancy and the correlation to improve the gray relational degree applied to nonsequential systems. The maximum classification accuracy and the number of selected features are used to compare the performance of feature selection methods for several different types of data sets. Simulation analysis shows that the proposed method has higher maximum classification accuracy and smaller selected feature set. Finally, the proposed method is applied to the state monitoring of gas regulator stations. Seven feature selection methods, including the proposed method, the classical methods, and the advanced methods are combined with a support vector machine,  $k$ -nearest neighbor, and decision tree, respectively. The experimental results indicate that the comprehensive performance of the proposed method combined with the three classifiers is good. It enables the subset containing the most identifiable features to be obtained quickly, which is beneficial to improve the efficiency of state monitoring.},
  keywords={Correlation;Feature extraction;Monitoring;Regulators;Internet of Things;Redundancy;Genetic algorithms;Adaptive resolution coefficient;feature selection;gray relational analysis (GRA);state monitoring},
  doi={10.1109/JIOT.2022.3184333},
  ISSN={2327-4662},
  month={Nov},}@INPROCEEDINGS{10500291,
  author={Parsa, Faraz Frank and Amiri Moghadam, Amir Ali and Ashuri, Turaj},
  booktitle={SoutheastCon 2024}, 
  title={From Learning Agents to Agile Software: Reinforcement Learning's Transformative Role in Requirements Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1627-1631},
  abstract={This paper studies the trans formative role of Reinforcement Learning for Requirements Engineering in the context of software development. The integration of Reinforcement Learning, with its adaptive decision-making capabilities, and Requirements Engineering, focused on systematic requirement analysis, offers a promising interaction to address challenges in dynamic project environments. The paper discusses the potential benefits, including adaptive decision-making, optimization in uncertainty, and intelligent requirement prioritization. However, challenges such as complexity, interpretability, data availability, resource intensiveness, and ethical concerns are identified. The conclusion highlights the trans formative potential of this integration while emphasizing the importance of addressing challenges through interdisciplinary collaboration and responsible adoption in different environments. The paper serves as a broad study of the intersection of Reinforcement Learning and Requirements Engineering, providing insights for practitioners, researchers, and stakeholders in the field of software development.},
  keywords={Ethics;Uncertainty;Systematics;Decision making;Reinforcement learning;Software;Complexity theory;Reinforcement Learning;Requirements Engineering;Agile Software Development;Adaptive Decision-Making},
  doi={10.1109/SoutheastCon52093.2024.10500291},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10820102,
  author={Jiang, Ruiyuan and Wang, Shangbo and Jia, Dongyao and Mao, Guoqiang and Lim, Eng Gee},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={An Adaptive Prediction Model for Randomly Distributed Traffic Data in Urban Road Networks}, 
  year={2025},
  volume={74},
  number={5},
  pages={7188-7200},
  abstract={Effective and efficient traffic prediction can provide a reliable data basis for traffic management in Intelligent Transportation Systems (ITS). While various machine learning methods have been proposed to enhance prediction accuracy in recent decades, there remain potential issues to be further addressed. Firstly, the inherent randomness of traffic dynamics usually leads to some outliers in historical observations, which may deviate the model parameter estimation when utilizing deep learning-based models to learn data distribution. Secondly, the spatial correlation among the road sections may dynamically change over time, posing challenges for modeling. In addition, due to the complexity of urban traffic networks, capturing such non-linear spatial dependencies based on the global road structure may consume huge computational resources. To address these issues, this paper proposes an adaptive temporal graph attention network (ATGAN), which is implemented in two steps: 1) An outlier time series filter (OTSF) technique is introduced to mitigate the adverse impact of outlier points and to adaptively learn the distribution of fluctuations of traffic data; 2) We design a group attention temporal graph convolutional network (GA-TGCN) to model the spatiotemporal features among neighboring road sections, which is achieved by adjusting the spatial correlation matrix dynamically in each training epoch with attention mechanism. We evaluate the prediction performance of ATGAN on two real-world datasets and the results show that our model can achieve higher prediction accuracy in less computational time compared with baseline methods.},
  keywords={Data models;Roads;Spatiotemporal phenomena;Correlation;Predictive models;Feature extraction;Adaptation models;Time series analysis;Attention mechanisms;Vehicle dynamics;Attention mechanism;Intelligent Transportation Systems (ITS);randomly distributed data;spatiotemporal correlations;traffic prediction},
  doi={10.1109/TVT.2024.3525023},
  ISSN={1939-9359},
  month={May},}@INPROCEEDINGS{10356590,
  author={Pang, Tianfu and Mao, Yingchi and Ding, Silong and Wang, Biao and Qi, Rongzhi},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Script Event Prediction Based on Causal Generalization Learning}, 
  year={2023},
  volume={},
  number={},
  pages={865-872},
  abstract={Causal relationships between events can reflect the historical evolution of events and provide an important reference for predicting future trends. Script prediction methods based on event graphs often struggle to adequately consider the complex interdependencies among events, leading to prediction biases. The Script Event Prediction Based on Causal Generalization Learning (SEPCG) method has been proposed to enhance the accuracy of script event prediction. SEPCG uses the graph attention network to learn the direct causal relationship similarity between known events and candidate events, the direct result event similarity between known events and candidate events, and utilizes double similarity generalization to learn the predicate type between known events and candidate events. SEPCG uses a Neural Tensor Network to learn parameter-level event embeddings and improve the model’s sensitivity to parameter-level changes. Finally, based on the generalized event embeddings, the BiLSTM network is used to simultaneously learn the forward contextual information from the known event to the candidate event direction, i.e., the cause to the result information, and the reverse contextual information from the candidate event to the known event direction, i.e., the result to the cause information. The BiLSTM is used to capture the temporal information of event chains at different levels. The effectiveness of the model is verified on the NYT dataset, with a 1.84% improvement in accuracy compared to the best baseline.},
  keywords={Knowledge engineering;Degradation;Sensitivity;Tensors;Neural networks;Prediction methods;Reinforcement learning;Event Prediction;Event Graph;Graph Attention Network;Causal Generalization Learning},
  doi={10.1109/ICTAI59109.2023.00131},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10814888,
  author={Aguiar, Marcelo and Vellasco, Marley and Tanscheit, Ricardo and Kohler, Manoela and Pacheco, Marco},
  booktitle={2024 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={Remaining Useful Life Prediction of Turbofan Engines with Fuzzy Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Since the beginning of the 21st century, predictive maintenance (PdM) has gained increasing prominence in the industry, providing the capability to predict the Remaining Useful Life (RUL) of equipment and mitigate accidents and financial losses. In this context, Machine Learning (ML) models are widely employed. This study proposes the prediction of Turbofan engine RUL through a machine learning model trained with historical data from this equipment. Two distinct models were evaluated: the Fuzzy System and the Neuro-Fuzzy System. To enable training, it was necessary to select the best features using a genetic algorithm, aiming to reduce complexity and enhance the performance of the Fuzzy System. The model with the best performance was the Fuzzy System with 5 selected features and 11 Fuzzy sets. Despite not yielding the lowest RMSE metric compared to related works, this interpretable model demonstrated reasonable performance in comparison to the model by Babu et al. [8]. This suggests that, for the dataset in question, the Fuzzy system is recommended to ensure better interpretability, while neural networks used in previous studies are better suited for precise predictions.},
  keywords={Training;Neural networks;Machine learning;Predictive models;Libraries;Maintenance;Safety;Engines;Tuning;Fuzzy systems;Fuzzy System;Genetic Algorithm;Machine Learning;Turbofan;Predictive Maintenance},
  doi={10.1109/LA-CCI62337.2024.10814888},
  ISSN={2769-7622},
  month={Nov},}@INPROCEEDINGS{10990952,
  author={R, Rajesh Sharma and Sungheetha, Akey and M, Prem Kumar and V, Ellappan. and K, Rajiv Gandhi and C, Priyatharsini},
  booktitle={2024 2nd International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES)}, 
  title={Examine of Algorithmic Approaches to Software Security}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The complexity of threats in the virtual world is growing, so new solutions are required for software protection. Artificial Intelligence has become a leading factor in strengthening software security against constantly changing threats. This extensive review synthesizes the current progress and trends for algorithmic AI methodologies in context of software protection. Specifically, we discuss requesting machine learning techniques and neural networks used for threat detection, vulnerability assessment, and adaptive defense mechanisms as well as using evolutionary algorithms. From this, we can deduce that security systems that AI enhances are much more flexible and efficient than traditional security. Zero-day vulnerabilities can be detected by deep learning models with high accuracy and reinforcement learning algorithms are effective in real-time threat handling. AI opens up opportunities in the software security domain as a predictor of vulnerability, yet there are shortcomings related to model interpretability and adversarial robustness. More detailed studies are needed to work on the more transparent models of artificial intelligence and to incorporate those into existing security systems.},
  keywords={Machine learning algorithms;Software protection;Software algorithms;Signal processing algorithms;Reinforcement learning;Prediction algorithms;Threat assessment;Robustness;Real-time systems;Security;-Artificial Intelligence;Software Security;Machine Learning;Cyber Resilience;Algorithmic Defense},
  doi={10.1109/SCOPES64467.2024.10990952},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10906131,
  author={Zheng, Lin and An, Wen and Huang, Yonggui and Li, Qingli and Zhang, Qing},
  booktitle={2024 17th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={YOLO Based Intelligent Recognition of Planktonic Algae in Whole Slide Microscopic Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Planktonic algae are widely existed biological resources in nature, and realizing real-time accurate and intelligent detection of planktonic algae is of great significance in many fields. Whole-slide scanning technology is a fundamental method to acquire and digitize microscopic images of planktonic algae, making constituting a dataset for deep learning possible. Currently, deep learning-based intelligent identification of planktonic algae is limited by the scarcity of large-scale multi-class planktonic algae dataset and the difficulty of extracting features among its various classes, which makes it hard to the detection accuracy and identification types at the same time. To solve the above problems, we propose a YOLO based method for planktonic algae recognition and analysis. In order to solve the problem of very limited samples in the dataset, we combine the mosaic and traditional data augmentation to expand the size of the dataset to ten times of the original one. To mitigate the impact of scale variations among different algal species on the proposed method, we combine the Gather-and-Distribute mechanism with the Attention Scale Sequence Fusion module, named as YOLOv8-GA, to comprehensively learning multi-scale features. We conduct experiments on our established planktonic algae dataset with 8 types, and the results show that the proposed method can get higher recognition accuracy. The accuracy rate of YOLOv8-GA for the recognition of eight types of planktonic algae is 90.1%, and the mAP@50 can be up to 92%, Compared to the unenhanced model without data augmentation, the accuracy has increased by 13.3%, while the mAP@50 has improved by 4.3%.},
  keywords={YOLO;Accuracy;Image recognition;Microscopy;Face recognition;Biological system modeling;Algae;Data augmentation;Feature extraction;Data models;Planktonic algae;intelligent recognition;multi-scale feature fusion},
  doi={10.1109/CISP-BMEI64163.2024.10906131},
  ISSN={},
  month={Oct},}@ARTICLE{9684988,
  author={Gao, Yuyang and Chowdhury, Tanmoy and Wu, Lingfei and Zhao, Liang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Modeling Health Stage Development of Patients With Dynamic Attributed Graphs in Online Health Communities}, 
  year={2023},
  volume={35},
  number={2},
  pages={1831-1843},
  abstract={In this paper, we propose a novel DynAttGraph2Seq framework to model complex dynamic transitions of an individual user's activities and the textual information of the posts over time in online health forums and learning how these correspond to his/her health stage. To achieve this, we first formulate the transition of user activities as a dynamic attributed graph with multi-attributed nodes that evolves over time, then formalize the health stage inference task as a dynamic attributed graph to sequence learning problem. Our proposed model consists of a novel dynamic graph encoder along with a two-level sequential encoder to capture the semantic features from user posts and an interpretable sequence decoder that learn the mapping between a sequence of time-evolving user activity graphs as well as user posts to a sequence of target health stages. We go on to propose new dynamic graph regularization and dynamic graph hierarchical attention mechanisms to facilitate the necessary multi-level interpretability. A comprehensive experimental analysis of its use for a health stage prediction task demonstrates both the effectiveness and the interpretability of the proposed models.},
  keywords={Data models;Task analysis;History;Semantics;Breast cancer;Representation learning;Predictive models;Deep learning;dynamic graph;sequence prediction;health stage development},
  doi={10.1109/TKDE.2022.3144083},
  ISSN={1558-2191},
  month={Feb},}@INPROCEEDINGS{10488304,
  author={Narsis, Ouassila Labbani and Dujardin, Erik and Nicolle, Christophe},
  booktitle={2023 15th International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter)}, 
  title={Objective-Driven Modular and Hybrid Approach Combining Machine Learning and Ontology}, 
  year={2023},
  volume={},
  number={},
  pages={300-305},
  abstract={Hybrid artificial intelligence is rapidly advancing, particularly in the domain of combining ontology and machine learning models. However, existing approaches in this field still encounter several limitations. Most current works tend to com-bine a single ontology model with a specific learning algorithm and often have a strong focus on specific application domains, which can complicate system adaptation and generalization. To address these limitations, we introduce in this paper an objective-driven, hybrid, and modular approach that promotes the integration of multiple machine learning and ontology models. The approach consists of decomposing the studied application into several tasks, each of them using the most appropriate ontological and machine learning models applied to a subset of knowledge and data. Our approach enhances adaptability and flexibility by tailoring artificial intelligence models to specific goals and reasoning requirements, thereby promoting a more effective hybrid artificial intelligence system and enabling the abstraction and reuse of developed solutions in various application domains. The proposed approach is applied in the design of a hybrid artificial intelligence model for the development of a compact all-optical Arithmetic and Logic Unit.},
  keywords={Adaptation models;Machine learning algorithms;Cognitive processes;Pipelines;Machine learning;Ontologies;Data models;Hybrid artificial intelligence;machine learning;ontology;modular approach},
  doi={10.1109/IIAI-AAI-Winter61682.2023.00062},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10793226,
  author={Zhang, Enzhi and Lyngaas, Isaac and Chen, Peng and Wang, Xiao and Igarashi, Jun and Huo, Yuankai and Munetomo, Masaharu and Wahib, Mohamed},
  booktitle={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Adaptive Patching for High-resolution Image Segmentation with Transformers}, 
  year={2024},
  volume={},
  number={},
  pages={1-16},
  abstract={Attention-based models are proliferating in the space of image analytics, including segmentation. The standard method of feeding images to transformer encoders is to divide the images into patches and then feed the patches to the model as a linear sequence of tokens. For high-resolution images, e.g. microscopic pathology images, the quadratic compute and memory cost prohibits the use of an attention-based model, if we are to use smaller patch sizes that are favorable in segmentation. The solution is to either use custom complex multi-resolution models or approximate attention schemes. We take inspiration from Adapative Mesh Refinement (AMR) methods in HPC by adaptively patching the images, as a pre-processing step, based on the image details to reduce the number of patches being fed to the model, by orders of magnitude. This method has a negligible overhead, and works seamlessly with any attention-based model, i.e. it is a pre-processing step that can be adopted by any attention-based model without friction. We demonstrate superior segmentation quality over SoTA segmentation models for real-world pathology datasets while gaining a geomean speedup of $6.9 \times$ for resolutions up to $64 K^{2}$, on up to 2,048 GPUs.},
  keywords={Training;Adaptation models;Image segmentation;Pathology;Image resolution;Computational modeling;Microscopy;High performance computing;Transformers;Standards},
  doi={10.1109/SC41406.2024.00082},
  ISSN={},
  month={Nov},}@ARTICLE{9810192,
  author={Guan, Tianrui and Kothandaraman, Divya and Chandra, Rohan and Sathyamoorthy, Adarsh Jagan and Weerakoon, Kasun and Manocha, Dinesh},
  journal={IEEE Robotics and Automation Letters}, 
  title={GA-Nav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments}, 
  year={2022},
  volume={7},
  number={3},
  pages={8138-8145},
  abstract={We propose GA-Nav, a novel group-wise attention mechanism to identify safe and navigable regions in unstructured environments from RGB images. Our group-wise attention method extracts multi-scale features from each type of terrain independently and classifies terrains based on their navigability levels using coarse-grained semantic segmentation. Our novel loss can be embedded within any backbone network to explicitly focus on the different groups’ features, at a low spatial resolution. Our design leads to efficient inference while maintaining a high level of accuracy compared to existing SOTA methods. Our extensive evaluations on the RUGD and RELLIS-3D datasets shows that GA-Nav achieves the state-of-the-art performance on RUGD and RELLIS-3D datasets. We interface GA-Nav with a deep reinforcement learning-based navigation algorithm and highlight its benefits in terms of navigation in real-world unstructured terrains. We integrate our GA-Nav-based navigation algorithm with ClearPath Jackal and Husky robots, and observe an improvement in terms of navigation success rate and better trajectory selections.},
  keywords={Navigation;Feature extraction;Image segmentation;Robots;Transformers;Semantics;Computer architecture;Vision-based navigation;AI-enabled robotics;deep learning for visual perception;AI-based methods;deep learn- ing methods},
  doi={10.1109/LRA.2022.3187278},
  ISSN={2377-3766},
  month={July},}@ARTICLE{9399811,
  author={Ye, Yang and Ji, Shihao},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Sparse Graph Attention Networks}, 
  year={2023},
  volume={35},
  number={1},
  pages={905-916},
  abstract={Graph Neural Networks (GNNs) have proved to be an effective representation learning framework for graph-structured data, and have achieved state-of-the-art performance on many practical predictive tasks, such as node classification, link prediction and graph classification. Among the variants of GNNs, Graph Attention Networks (GATs) learn to assign dense attention coefficients over all neighbors of a node for feature aggregation, and improve the performance of many graph learning tasks. However, real-world graphs are often very large and noisy, and GATs are prone to overfitting if not regularized properly. Even worse, the local aggregation mechanism of GATs may fail on disassortative graphs, where nodes within local neighborhood provide more noise than useful information for feature aggregation. In this paper, we propose Sparse Graph Attention Networks (SGATs) that learn sparse attention coefficients under an $L_0$L0-norm regularization, and the learned sparse attentions are then used for all GNN layers, resulting in an edge-sparsified graph. By doing so, we can identify noisy/task-irrelevant edges, and thus perform feature aggregation on most informative neighbors. Extensive experiments on synthetic and real-world (assortative and disassortative) graph learning benchmarks demonstrate the superior performance of SGATs. In particular, SGATs can remove about 50-80 percent edges from large assortative graphs, such as PPI and Reddit, while retaining similar classification accuracies. On disassortative graphs, SGATs prune majority of noisy edges and outperform GATs in classification accuracies by significant margins. Furthermore, the removed edges can be interpreted intuitively and quantitatively. To the best of our knowledge, this is the first graph learning algorithm that shows significant redundancies in graphs and edge-sparsified graphs can achieve similar (on assortative graphs) or sometimes higher (on disassortative graphs) predictive performances than original graphs. Our code is available at https://github.com/Yangyeeee/SGAT.},
  keywords={Task analysis;Noise measurement;Training;Redundancy;Convolution;Aggregates;Social networking (online);Graph neural networks;attention networks;sparsity learning},
  doi={10.1109/TKDE.2021.3072345},
  ISSN={1558-2191},
  month={Jan},}@ARTICLE{9325929,
  author={Li, Yin and Liu, Miao and Rehg, James M.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={In the Eye of the Beholder: Gaze and Actions in First Person Video}, 
  year={2023},
  volume={45},
  number={6},
  pages={6731-6747},
  abstract={We address the task of jointly determining what a person is doing and where they are looking based on the analysis of video captured by a headworn camera. To facilitate our research, we first introduce the EGTEA Gaze+ dataset. Our dataset comes with videos, gaze tracking data, hand masks and action annotations, thereby providing the most comprehensive benchmark for First Person Vision (FPV). Moving beyond the dataset, we propose a novel deep model for joint gaze estimation and action recognition in FPV. Our method describes the participant's gaze as a probabilistic variable and models its distribution using stochastic units in a deep network. We further sample from these stochastic units, generating an attention map to guide the aggregation of visual features for action recognition. Our method is evaluated on our EGTEA Gaze+ dataset and achieves a performance level that exceeds the state-of-the-art by a significant margin. More importantly, we demonstrate that our model can be applied to larger scale FPV dataset—EPIC-Kitchens even without using gaze, offering new state-of-the-art results on FPV action recognition.},
  keywords={Three-dimensional displays;Convolution;Visualization;Cameras;Benchmark testing;Stochastic processes;Gaze tracking;Action recognition;deep probabilistic models;first person vision;gaze estimation;video analysis},
  doi={10.1109/TPAMI.2021.3051319},
  ISSN={1939-3539},
  month={June},}@ARTICLE{10583875,
  author={Shahbazian, Reza and Pugliese, Luigi Di Puglia and Guerriero, Francesca and Macrina, Giusy},
  journal={IEEE Access}, 
  title={Integrating Machine Learning Into Vehicle Routing Problem: Methods and Applications}, 
  year={2024},
  volume={12},
  number={},
  pages={93087-93115},
  abstract={The vehicle routing problem (VRP) and its variants have been intensively studied by the operational research community. The existing surveys and the majority of the published articles tackle traditional solutions, including exact methods, heuristics, and meta-heuristics. Recently, machine learning (ML)-based methods have been applied to a variety of combinatorial optimization problems, specifically VRPs. The strong trend of using ML in VRPs and the gap in the literature motivated us to review the state-of-the-art. To provide a clear understanding of the ML-VRP landscape, we categorize the related studies based on their applications/constraints and technical details. We mainly focus on reinforcement learning (RL)-based approaches because of their importance in the literature, while we also address non RL-based methods. We cover both theoretical and practical aspects by clearly addressing the existing trends, research gap, and limitations and advantages of ML-based methods. We also discuss some of the potential future research directions.},
  keywords={Surveys;Reviews;Vehicle routing;Vehicle dynamics;Metaheuristics;Heuristic algorithms;Benchmark testing;Machine learning;Reinforcement learning;Deep learning;Combinatorial mathematics;Vehicle routing problem (VRP);machine learning;reinforcement learning;deep learning;combinatorial optimization},
  doi={10.1109/ACCESS.2024.3422479},
  ISSN={2169-3536},
  month={},}@ARTICLE{10590717,
  author={An, Jianpeng and Wang, Yong and Cai, Qing and Zhao, Gang and Dooper, Stephan and Litjens, Geert and Gao, Zhongke},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Transformer-Based Weakly Supervised Learning for Whole Slide Lung Cancer Image Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Image analysis can play an important role in supporting histopathological diagnoses of lung cancer, with deep learning methods already achieving remarkable results. However, due to the large scale of whole-slide images (WSIs), creating manual pixel-wise annotations from expert pathologists is expensive and time-consuming. In addition, the heterogeneity of tumors and similarities in the morphological phenotype of tumor subtypes have caused inter-observer variability in annotations, which limits optimal performance. Effective use of weak labels could potentially alleviate these issues. In this paper, we propose a two-stage transformer-based weakly supervised learning framework called Simple Shuffle-Remix Vision Transformer (SSRViT). Firstly, we introduce a Shuffle-Remix Vision Transformer (SRViT) to retrieve discriminative local tokens and extract effective representative features. Then, the token features are selected and aggregated to generate sparse representations of WSIs, which are fed into a simple transformer-based classifier (SViT) for slide-level prediction. Experimental results demonstrate that the performance of our proposed SSRViT is significantly improved compared with other state-of-the-art methods in discriminating between adenocarcinoma, pulmonary sclerosing pneumocytoma and normal lung tissue (accuracy of 96.9% and AUC of 99.6%).},
  keywords={Annotations;Transformers;Lung cancer;Supervised learning;Tumors;Feature extraction;Lung;Lung cancer;vision transformer;whole-slide image analysis;weakly supervised learning},
  doi={10.1109/JBHI.2024.3425434},
  ISSN={2168-2208},
  month={},}@ARTICLE{10173539,
  author={Ozmen, Goktug C. and Mabrouk, Samer and Nichols, Christopher and Berkebile, John and Goossens, Quentin and Gazi, Asim H. and Inan, Omer T.},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Mid-Activity and At-Home Wearable Bioimpedance Elucidates an Interpretable Digital Biomarker of Muscle Fatigue}, 
  year={2023},
  volume={70},
  number={12},
  pages={3513-3524},
  abstract={Objective: Muscle health and decreased muscle performance (fatigue) quantification has proven to be an invaluable tool for both athletic performance assessment and injury prevention. However, existing methods estimating muscle fatigue are infeasible for everyday use. Wearable technologies are feasible for everyday use and can enable discovery of digital biomarkers of muscle fatigue. Unfortunately, the current state-of-the-art wearable systems for muscle fatigue tracking suffer from either low specificity or poor usability. Methods: We propose using dual-frequency bioimpedance analysis (DFBIA) to non-invasively assess intramuscular fluid dynamics and thereby muscle fatigue. A wearable DFBIA system was developed to measure leg muscle fatigue of 11 individuals during a 13-day protocol consisting of exercise and unsupervised at-home portions. Results: We derived a digital biomarker of muscle fatigue, fatigue score, from the DFBIA signals that was able to estimate the percent reduction in muscle force during exercise with repeated-measures Pearson's r = 0.90 and mean absolute error (MAE) of 3.6%. This fatigue score also estimated delayed onset muscle soreness with repeated-measures Pearson's r = 0.83 and MAE = 0.83. Using at-home data, DFBIA was strongly associated with absolute muscle force of participants (n = 198, p < 0.001). Conclusion: These results demonstrate the utility of wearable DFBIA for non-invasively estimating muscle force and pain through the changes in intramuscular fluid dynamics. Significance: The presented approach may inform development of future wearable systems for quantifying muscle health and provide a novel framework for athletic performance optimization and injury prevention.},
  keywords={Muscles;Fatigue;Biomedical measurement;Legged locomotion;Force;Protocols;Biomedical monitoring;Bioimpedance;Wearable computers;Performance evaluation;At-home;electrical bioimpedance;mid-activity;muscle performance;wearable technologies},
  doi={10.1109/TBME.2023.3290530},
  ISSN={1558-2531},
  month={Dec},}@ARTICLE{10909411,
  author={Karwowska, Kinga and Wierzbicki, Damian and Kedzierski, Michal},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Image Inpainting and Digital Camouflage: Methods, Applications, and Perspectives for Remote Sensing}, 
  year={2025},
  volume={18},
  number={},
  pages={8215-8247},
  abstract={Image inpainting refers to the process of restoring missing or damaged areas in an image. This research field has been very active in recent years, driven by various applications such as reconstructing lost fragments, concealing data loss in corrupted image transmissions, removing objects in image editing, and interpolating image content for reconstruction in image-based rendering from various fields of view. This article presents existing methods of image inpainting, covering classical approaches, CNN-based methods, and GAN-based methods. In addition, it explores techniques related to steganography, adversarial image synthesis, and false image generation. Examples of applications are provided for each category of image modification methods. Although image inpainting and digital camouflage are not yet widely studied in the remote sensing community, there has been a growing interest in these topics in recent years. To broaden the understanding of these methods, this study also reviews techniques developed in the field of computer science, which have the potential to be adapted for remote sensing applications. The main contribution of this article is the presentation of various forms of digital masking, extending beyond traditional inpainting. We also provide a curated list of publicly available datasets that can support the development of new solutions, along with a selection of qualitative metrics for the robust evaluation of image inpainting algorithms.},
  keywords={Reviews;Digital images;Classification algorithms;Databases;Steganography;Satellite images;Image reconstruction;Satellites;Remote sensing;Visualization;Computer vision (CV);convolutional neural network (CNN);deep learning (DL);image fusion;image inpainting;image processing},
  doi={10.1109/JSTARS.2025.3547917},
  ISSN={2151-1535},
  month={},}@ARTICLE{10878483,
  author={Kim, Sekeun and Jin, Pengfei and Chen, Cheng and Kim, Kyungsang and Lyu, Zhiliang and Ren, Hui and Kim, Sunghwan and Liu, Zhengliang and Zhong, Aoxiao and Liu, Tianming and Li, Xiang and Li, Quanzheng},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={MediViSTA: Medical Video Segmentation via Temporal Fusion SAM Adaptation for Echocardiography}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Despite achieving impressive results in general-purpose semantic segmentation with strong generalization on natural images, the Segment Anything Model (SAM) has shown less precision and stability in medical image segmentation. In particular, the SAM architecture is designed for 2D natural images and is therefore not support to handle three-dimensional information, which is particularly important for medical imaging modalities that are often volumetric or video data. In this paper, we introduce MediViSTA, a parameter-efficient fine-tuning method designed to adapt the vision foundation model for medical video, with a specific focus on echocardiography segmentation. To achieve spatial adaptation, we propose a frequency feature fusion technique that injects spatial frequency information from a CNN branch. For temporal adaptation, we integrate temporal adapters within the transformer blocks of the image encoder. Using a fine-tuning strategy, only a small subset of pre-trained parameters is updated, allowing efficient adaptation to echocardiography data. The effectiveness of our method has been comprehensively evaluated on three datasets, comprising two public datasets and one multi-center in-house dataset. Our method consistently outperforms various state-of-the-art approaches without using any prompts. Furthermore, our model exhibits strong generalization capabilities on unseen datasets, surpassing the second-best approach by 2.15% in Dice and 0.09 in temporal consistency. The results demonstrate the potential of MediViSTA to significantly advance echocardiography video segmentation, offering improved accuracy and robustness in cardiac assessment applications.},
  keywords={Biomedical imaging;Image segmentation;Echocardiography;Decoding;Accuracy;Foundation models;Three-dimensional displays;Training;Adaptation models;Visualization;Vision Foundation model;Segment Anything Model;Parameter-efficient fine-tuning;Echocardiography;Segmentation},
  doi={10.1109/JBHI.2025.3540306},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10629670,
  author={Sharif, Dyari Mohammed},
  booktitle={2023 International Conference on Engineering Applied and Nano Sciences (ICEANS)}, 
  title={High-Accurate Application-Layer DDoS Attack Detection Using Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={72-76},
  abstract={Distributed Denial-of-Service (DDoS) attacks continue to escalate in frequency and severity, disrupting system access and network functionality. This paper addresses the evolving landscape of DDoS attacks, particularly the shift towards sophisticated application layer DDoS attacks, which challenge traditional detection methods. A novel machine learning approach is proposed using a combination of random forest, decision tree, and genetic algorithm, along with a multilayer perceptron classifier, to detect five distinct categories of network traffic, including four variants of DDoS attacks and benign traffic. The methodology involves meticulous data preprocessing, optimal feature selection through RF and GADT, min-max scaling, and multi-layer Perceptron classifier classification. The effectiveness of the proposed approach, which is demonstrated using the CICIDS2017 dataset, achieves exceptional results, with accuracy reaching 99.1%, precision of up to 92.2%, F1 score of up to 95%, and recall of up to 98.4%. The obtained findings highlight the potential for accurate AppDDoS attack detection using a streamlined feature subset, contributing to enhanced network security.},
  keywords={Accuracy;Heuristic algorithms;Telecommunication traffic;Network security;Denial-of-service attack;Feature extraction;Pattern recognition;DDoS;Machine Learning;Deep Learning;Ge- netic Algorithms},
  doi={10.1109/ICEANS58413.2023.10629670},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10831472,
  author={Xiao, Pei and Zhang, Zizhen and Chen, Jinbiao and Wang, Jiahai},
  booktitle={2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Neural Model Embedded Heuristics for Robust Traveling Salesman Problem with Interval Uncertainty}, 
  year={2024},
  volume={},
  number={},
  pages={4193-4198},
  abstract={We explore the robust traveling salesman problem (RTSP) with interval uncertainty under the min-max regret criterion, which enhances the classic traveling salesman problem (TSP) by focusing on robustness. Our aim is to develop a conservative solution that minimizes the maximum deviation from the optimal routing time in the worst-case scenario. To achieve this, we integrate neural models into heuristic approaches, capitalizing on recent advancements in neural techniques. Specifically, we incorporate a pre-trained neural model into the tabu search framework, using it to refine the evaluation function. This novel integration streamlines the solution improvement process. Our experimental results underscore the effectiveness of this approach, showing that it handles various scales of the robust traveling salesman problem more efficiently and in less time compared to traditional heuristic methods.},
  keywords={Uncertainty;Heuristic algorithms;Neural networks;Metaheuristics;Focusing;Traveling salesman problems;Parallel processing;Routing;Robustness;Inference algorithms},
  doi={10.1109/SMC54092.2024.10831472},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10540699,
  author={Alshaer, Samer and Piridi, Murali and Obermaisser, Roman},
  booktitle={2024 IEEE International Conference on Industrial Technology (ICIT)}, 
  title={Model Comparative Analysis of Neighborhood Aggregation Levels in Graph Neural Networks for Metaschedulers}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={In Time-Triggered Systems (TTS), meta-scheduling algorithms are crucial for adjusting to situations that necessitate rescheduling, including hardware malfunctions and changes in operational modes. However, the state-space explosion problem in Cyber-Physical Systems (CPS) causes immense storage demands. This paper extends previous research from [1] [2], studying the impact of neibourhood aggregations of Graph Neural Networks (GNN) in meta-scheduling. The focus is on multi-neighbourhood aggregations and their impact on makespan results in task scheduling. The paper presents a comparative analysis between Genetic Algorithms (GA), a GNN-based approach, and traditional Artificial Neural Networks (ANNs). The results highlight the significance of second neighbourhood aggregation as a compromise for event-driven Multi-Schedule Graphs (MSG). Out of the considered machine learning solutions, GNNs are the most feasible one for meta-scheduling in terms of makespan to model parameter cost (number of adjustable weights).},
  keywords={Job shop scheduling;Costs;Machine learning;Artificial neural networks;Cyber-physical systems;Graph neural networks;Hardware;Metascheduling;Task Scheduling;Graph Neural Networks;Graph Attention Networks;Multi-Neighborhood Aggregation;State-space explosion;Genetic Algorithm},
  doi={10.1109/ICIT58233.2024.10540699},
  ISSN={2643-2978},
  month={March},}@INPROCEEDINGS{10662023,
  author={Zhang, Jierui and Si, Chaoming and Ma, Changbo and Chen, Ting and Xia, Hongwei and Ma, Guangcheng},
  booktitle={2024 43rd Chinese Control Conference (CCC)}, 
  title={DRL-based Optimal Scheduling for On-orbit Service with the Encoder-decoder network}, 
  year={2024},
  volume={},
  number={},
  pages={8786-8791},
  abstract={In this paper, we present a deep reinforcement learning (DRL) based strategy for optimizing the scheduling of satellite on-orbit services. The orbital maneuvers necessitate the servicing satellite to consecutively rendezvous with multiple targets to execute its on-orbit missions. The principal aim of our optimization approach is to ascertain the most advantageous sequence for servicing satellites, thereby minimizing the overall cost, contingent upon the expenditure of propulsion maneuvers. To surmount this formidable challenge, we introduce an attention-based encoder-decoder neural network and train its parameters utilizing the REINFORCE algorithm with a greedy rollout baseline. Ultimately, experimental results across diverse scenarios validate the efficacy and supremacy of our proposed algorithm. The chief contribution of this work lies in its conceptualization of the satellite on-orbit service scheduling optimization quandary as an extended traveling salesman problem, culminating in the introduction of an innovative DRL-based methodology.},
  keywords={Satellites;Costs;Processor scheduling;Neural networks;Metaheuristics;Optimal scheduling;Traveling salesman problems;Satellite on-orbit service;Optimal scheduling;Deep reinforcement learning;Encoder-decoder neural network},
  doi={10.23919/CCC63176.2024.10662023},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{10960963,
  author={Chidambaranathan, Senthilnathan and Sundaramoorthy, Pandian and Puli, Balaram and Daruvuri, Rajesh and VamsiLala, Purushothapatnapu Naga Venkata and Sathya, R.},
  booktitle={2025 International Conference on Visual Analytics and Data Visualization (ICVADV)}, 
  title={Enhanced Transformers with Dilated Convolutional Attention for Predicting Lung Cancer Outcomes}, 
  year={2025},
  volume={},
  number={},
  pages={1392-1398},
  abstract={The study in investigation of the usage of dilated convolutional attention functions with transformers to improve the accuracy of the prognosis of lung cancer. The suggested model exploits the benefits of the dilated convolutions to seize multi-scale spatial features in medical related data while it is integrating the human attention of the transformers that are focused on the most important information. The predicted model needs to cover collected clinical data patterns from which the best results for lung cancer will be achieved. These patterns are including early detection and tracking of tumor progression. this alternative the most effective way to improve feature extraction, but it also ensures presenting the most important trends in medical data to achieve an exact prognosis. The proposed methodology is an structured methodology that health experts use to diagnose tumor at variable stages of patient's testing while also giving hints of the possibility of Lyme Infections.},
  keywords={Heart;Analytical models;Visual analytics;Lung cancer;Transformers;Feature extraction;Data models;Prognostics and health management;Medical diagnostic imaging;Tumors;Dilated convolution network;attention methodology;transformer model;lung cancer prognosis procedure;medical data base collection;feature extraction;tumor progression analysis;clinical decision-making process;personalized treatment plans;deep learning model},
  doi={10.1109/ICVADV63329.2025.10960963},
  ISSN={},
  month={March},}@ARTICLE{9669023,
  author={Zheng, Wendong and Hu, Jun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Multivariate Time Series Prediction Based on Temporal Change Information Learning Method}, 
  year={2023},
  volume={34},
  number={10},
  pages={7034-7048},
  abstract={In the multivariate time series prediction tasks, the impact information of all nonpredictive time series on the predictive target series is difficult to be extracted at different time stages. Through the emphasis on optimal-related sequences in the target series, the deep learning model with the attention mechanism achieves a good predictive performance. However, temporal change information in the objective function and optimization algorithm is completely ignored in these models. To this end, a temporal change information learning (CIL) method is proposed in this article. First, mean absolute error (MAE) and mean squared error (MSE) losses are contained in the objective function to evaluate different amplitude errors. Meanwhile, the second-order difference technology is used in the correlation terms of the objective function to adaptively capture the impact of the abrupt and slow change information in each series on the target series. Second, the long short-term memory (LSTM) network with the transformation mechanism is used in the method so that temporal dependence information can be fully extracted (i.e., avoiding the supersaturation region). Third, to effectively obtain the optimal model parameters, the current and historical moment estimation information is adaptively memorized without the introduction of additional hyperparameters, and therefore, the acquisition ability of temporal change information in the error gradient flow is greatly enhanced by the proposed optimization algorithm. Finally, three datasets with different scales are used to verify the advantages of the CIL method in computational overhead and prediction effect.},
  keywords={Time series analysis;Linear programming;Prediction algorithms;Task analysis;Predictive models;Optimization;Estimation;Abrupt and slow change information;adaptive stochastic optimization algorithm;long short-term memory (LSTM);multivariate time series prediction},
  doi={10.1109/TNNLS.2021.3137178},
  ISSN={2162-2388},
  month={Oct},}@ARTICLE{9495944,
  author={Mou, Shancong and Wang, Andi and Zhang, Chuck and Shi, Jianjun},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Additive Tensor Decomposition Considering Structural Data Information}, 
  year={2022},
  volume={19},
  number={4},
  pages={2904-2917},
  abstract={Tensor data with rich structural information become increasingly important in process modeling, monitoring, and diagnosis in manufacturing medical and other applications. Here structural information is referred to the information of tensor components such as sparsity, smoothness, low-rank, and piecewise constancy. To reveal useful information from tensor data, we propose to decompose the tensor into the summation of multiple components based on their different structural information. In this article, we provide a new definition of structural information in tensor data. We then propose an additive tensor decomposition (ATD) framework to extract useful information from tensor data. This framework specifies a high dimensional optimization problem to obtain the components with distinct structural information. An alternating direction method of multipliers (ADMM) algorithm is proposed to solve it, which is highly parallelable and thus suitable for the proposed optimization problem. Two simulation examples and a real case study in medical image analysis illustrate the versatility and effectiveness of the ATD framework. Note to Practitioners—This article was motivated by a real case in medical imaging: extracting aortic valve calcification (AVC) regions from the tensor data obtained from computed tomography (CT) image series of the aortic region. The main objective is to decompose image series into multiple components corresponding to tissues, calcium deposition, and error. Similar needs are pervasive in other medical image analysis applications as well as the image-based modeling, monitoring, and diagnosis of industrial processes and systems. Existing methods fail to incorporate a detailed description of the properties of image series that reflect the physical understanding of the system in both the spatial and temporal domains. In this article, we provide a systematic description of the properties of image series and use them to develop a decomposition framework. It is applicable to various applications and can generate more accurate and interpretable results.},
  keywords={Tensors;Matrix decomposition;Computed tomography;Optimization;Image edge detection;Medical diagnostic imaging;Image analysis;Alternating direction method of multipliers (ADMM) algorithm;structural information;tensor decomposition},
  doi={10.1109/TASE.2021.3096964},
  ISSN={1558-3783},
  month={Oct},}@INPROCEEDINGS{9981513,
  author={Guan, Huifeng and Gao, Yuan and Zhao, Min and Yang, Yong and Deng, Fuqin and Lam, Tin Lun},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={AB-Mapper: Attention and BicNet based Multi-agent Path Planning for Dynamic Environment}, 
  year={2022},
  volume={},
  number={},
  pages={13799-13806},
  abstract={Multi-agent path finding in dynamic environments is of great academic and practical value for multi-robot systems in the real world. To improve the effectiveness and efficiency of the learning process during path planning in dynamic environments, we introduce an algorithm called Attention and BicNet based Multi-agent path planning with effective reinforcement (AB-Mapper) under the actor-critic reinforcement learning framework. In this framework, on one hand, we design an actor-network that can utilize the BicNet with communication function to achieve the intra-team coordination. On the other hand, we propose a critic network that can selectively allocate attention weights to surrounding agents. This attention mechanism allows an individual agent to automatically learn a better evaluation of actions by considering the behaviours of its surrounding agents. Compared with the SOTA method Mapper in crowded environments with dynamic obstacles, our AB-Mapper is more effective (90.27±0.06% vs. 61.65±13.90% in terms of mean success rate) in solving the general multi-agent path finding problem.},
  keywords={Scalability;Heuristic algorithms;Reinforcement learning;Path planning;Multi-robot systems;Intelligent robots},
  doi={10.1109/IROS47612.2022.9981513},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{10443355,
  author={Yu, Chuer and Zhang, Xuhong and Duan, Yuxuan and Yan, Senbo and Wang, Zonghui and Xiang, Yang and Ji, Shouling and Chen, Wenzhi},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Diff-ID: An Explainable Identity Difference Quantification Framework for DeepFake Detection}, 
  year={2024},
  volume={21},
  number={5},
  pages={5029-5045},
  abstract={In recent years, DeepFake technologies have seen widespread adoption in various domains, including entertainment and film production. However, they have also been maliciously employed for disseminating false information and engaging in video fraud. Existing detection methods often experience significant performance degradation when confronted with unknown forgeries or exhibit limitations when dealing with low-quality images. To address this challenge, we introduce Diff-ID, a novel approach designed to elucidate and quantify the identity loss induced by facial manipulations. When assessing the authenticity of an image, Diff-ID leverages a genuine image of the same individual as a reference and processes two images jointly. It aligns the reference image and the test image into the same identity-insensitive attribute feature space using a face-swapping generator. This alignment allows us to observe the identity disparities between the two images through the differences in the aligned generation pairs. Subsequently, we have developed a custom metric designed to quantify the identity loss relative to the reference image in the test image. This metric effectively distinguishes forgery images from the real ones. Extensive experiments have demonstrated the exceptional performance of our approach. It achieves a high level of detection accuracy on DeepFake images and showcases state-of-the-art generalization capabilities when confronted with previously unknown forgery methods. Moreover, it exhibits robustness even in the presence of image distortions.},
  keywords={Faces;Forgery;Deepfakes;Feature extraction;Visualization;Shape;Robustness;Face forgery detection;generalization ability;identity difference},
  doi={10.1109/TDSC.2024.3364679},
  ISSN={1941-0018},
  month={Sep.},}@INPROCEEDINGS{9951037,
  author={Wang, Yingjie and Chandrasekaran, Jaganmohan and Haberkorn, Flora and Dong, Yan and Gopinath, Munisamy and Batarseh, Feras A.},
  booktitle={2022 IEEE 29th Annual Software Technology Conference (STC)}, 
  title={DeepFarm: AI-Driven Management of Farm Production using Explainable Causality}, 
  year={2022},
  volume={},
  number={},
  pages={27-36},
  abstract={American agriculture has been afflicted by numerous outlier events in the past decade, such as several natural disasters, cyber-attacks, trade wars, and a global pandemic. Such unprecedented black-swans have created outcome uncertainties throughout the food supply chain, starting at the farm level for agricultural producers and aggregating at the consumption level for households and international trade flows. The primary drivers behind the shocks in agricultural productivity include strong weather-related events, transitory transportation disruptions, shipping delays, and policy shifts. This paper presents DeepFarm, an Artificial Intelligence (AI)-enabled framework to measure and manage uncertainties while evaluating multiple cause-effect scenarios in agricultural farm production. We deploy Deep Learning (DL) models to predict the impact of crop yield during outlier events such as extreme weather events and cyber-attacks. Additionally, we use a causal inference-based approach to quantity the impact of such events affecting the critical phases of farm production. Models are developed; experiments are performed; the results are recorded, evaluated, and discussed. Our results suggest that DeepFarm can effectively forecast and quantity the impact of outlier events on crop yield across different regions in the US.},
  keywords={Productivity;Uncertainty;Supply chains;Crops;Weather forecasting;Transportation;Predictive models;AI for Agriculture;Farm Production;GAN;Synthetic Data;DeepAR;Causality},
  doi={10.1109/STC55697.2022.00013},
  ISSN={},
  month={Oct},}@ARTICLE{10568211,
  author={Wang, Yanni and Jia, Hecheng and Fu, Shilei and Lin, Huiping and Xu, Feng},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Reinforcement Learning for SAR Target Orientation Inference With the Differentiable SAR Renderer}, 
  year={2024},
  volume={62},
  number={},
  pages={1-13},
  abstract={This article attempts to infer the orientation angle of the target in synthetic aperture radar (SAR) images using reinforcement learning (RL). It is intended to address the challenges like limited interpretability, the scarcity of SAR data, and complex imaging mechanisms restrict the broader application of learning-based approaches. We propose an interactive deep RL (DRL) framework, where an electromagnetic simulator named differentiable SAR renderer (DSR) is embedded to facilitate the interaction between the agent and the environment. Specifically, DSR generates SAR images at arbitrary orientation angles in real time, helping to simulate a human-like process of angle estimation. The differences in sequential and semantic aspects between images of different orientation angles are leveraged to construct the state space in DRL, which effectively suppress the complex background interference, and enhance the sensitivity to temporal variations. Moreover, to maintain the stability and convergence of our approach, reward mechanisms such as memory difference, smoothing and boundary penalty are incorporated to contribute to the formulation of the comprehensive reward function. Extensive experiments performed on both simulated and real datasets demonstrate the effectiveness and robustness of our proposed method. In addition, when utilized in the cross-domain area, the proposed method mitigates inconsistency between simulated and real domains, outperforming reference methods significantly.},
  keywords={Radar polarimetry;Radar imaging;Synthetic aperture radar;Imaging;Inverse problems;Electromagnetics;Decision making;Deep reinforcement learning (DRL);differentiable SAR renderer (DSR);synthetic aperture radar (SAR);target orientation angles},
  doi={10.1109/TGRS.2024.3417383},
  ISSN={1558-0644},
  month={},}@ARTICLE{10945821,
  author={Kwak, Min Gu and Mao, Lingchao and Zheng, Zhiyang and Su, Yi and Lure, Fleming and Li, Jing},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={A Cross-Modal Mutual Knowledge Distillation Framework for Alzheimer’s Disease Diagnosis: Addressing Incomplete Modalities}, 
  year={2025},
  volume={22},
  number={},
  pages={14218-14233},
  abstract={Early detection of Alzheimer’s Disease (AD) is crucial for timely interventions and optimizing treatment outcomes. Integrating multimodal neuroimaging datasets can enhance the early detection of AD. However, models must address the challenge of incomplete modalities, a common issue in real-world scenarios, as not all patients have access to all modalities due to practical constraints such as cost and availability. We propose a deep learning framework employing Incomplete Cross-modal Mutual Knowledge Distillation (IC-MKD) to model different sub-cohorts of patients based on their available modalities. In IC-MKD, the multimodal model (e.g., MRI and PET) serves as a teacher, while the single-modality model (e.g., MRI only) is the student. Our IC-MKD framework features three components: a Modality-Disentangling Teacher (MDT) model designed through information disentanglement, a student model that learns from classification errors and MDT’s knowledge, and the teacher model enhanced via distilling the student’s single-modal feature extraction capabilities. Moreover, we show the effectiveness of the proposed method through theoretical analysis and validate its performance with simulation studies. In addition, our method is demonstrated through a case study with Alzheimer’s Disease Neuroimaging Initiative (ADNI) datasets, underscoring the potential of artificial intelligence in addressing incomplete multimodal neuroimaging datasets and advancing early AD detection. Note to Practitioners—This paper was motivated by the challenge of early AD diagnosis, particularly in scenarios when clinicians encounter varied availability of patient imaging data, such as MRI and PET scans, often constrained by cost or accessibility issues. We propose an incomplete multimodal learning framework that produces tailored models for patients with only MRI and patients with both MRI and PET. This approach improves the accuracy and effectiveness of early AD diagnosis, especially when imaging resources are limited, via bi-directional knowledge transfer. We introduced a teacher model that prioritizes extracting common information between different modalities, significantly enhancing the student model’s learning process. This paper includes theoretical analysis, simulation study, and real-world case study to illustrate the method’s promising potential in early AD detection. However, practitioners should be mindful of the complexities involved in model tuning. Future work will focus on improving model interpretability and expanding its application. This includes developing methods to discover the key brain regions for predictions, enhancing clinical trust, and extending the framework to incorporate a broader range of imaging modalities, demographic information, and clinical data. These advancements aim to provide a more comprehensive view of patient health and improve diagnostic accuracy across various neurodegenerative diseases.},
  keywords={Magnetic resonance imaging;Neuroimaging;Feature extraction;Modeling;Imaging;Alzheimer's disease;Accuracy;Artificial intelligence;Adaptation models;Predictive models;Alzheimer’s disease;incomplete multimodal datasets;knowledge distillation;mild cognitive impairment;representation disentanglement},
  doi={10.1109/TASE.2025.3556290},
  ISSN={1558-3783},
  month={},}@INPROCEEDINGS{10326291,
  author={Jahandoost, Alireza and Houshmand, Mahboobeh and Hosseini, Seyyed Abed},
  booktitle={2023 13th International Conference on Computer and Knowledge Engineering (ICCKE)}, 
  title={Prediction of West Texas Intermediate Crude-oil Price Using Hybrid Attention-based Deep Neural Networks: A Comparative Study}, 
  year={2023},
  volume={},
  number={},
  pages={240-245},
  abstract={Crude oil, as a prerequisite for many industries, is vital in today’s world. In this regard, predicting its future price is crucial for many purposes. Even though plenty of research has been done in this field with many methods, such as evolutionary algorithms, neural networks (NN), and other machine learning techniques, because of the extremely unpredictable nature of crude oil prices, the outcomes are not satisfactory. This study employs 39 features for oil price prediction and proposes a hybrid architecture for deep NNs (DNN) to take advantage of features in different periods. Attention-based DNNs are utilized in the proposed architecture, and the comparisons are based on the mean absolute error. The results show that (1) attention-based DNNs are useful for forecasting the crude oil price with many features, and (2) the proposed architecture can enhance the accuracy of previous models.},
  keywords={Biological system modeling;Oils;Computational modeling;Artificial neural networks;Computer architecture;Machine learning;Predictive models;Deep Learning;Recurrent Neural Networks;Crude-oil Price Prediction;West Texas Intermediate;Attention Mechanism;Skip Connection},
  doi={10.1109/ICCKE60553.2023.10326291},
  ISSN={2643-279X},
  month={Nov},}@INPROCEEDINGS{10447625,
  author={Yousfi, Nacer and Abed-Meraim, Karim and Marnissi, Yosra and Leiber, Maxime and El-Badaoui, Mohammed},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Neural Network-Based Symbolic Regression for Empirical Modeling of the Behavior of a Planetary Gearbox}, 
  year={2024},
  volume={},
  number={},
  pages={9866-9870},
  abstract={Gearbox condition monitoring and quality surveillance are crucial techniques to ensure safe and cost-efficient machine operations. In condition monitoring, the interpretation of the different vibration spectrum elements is still an open question, many works show that some predefined vibration models are improper to explain the spectrum contents. In this paper, we investigate a method to identify the mixture model that describes a single-stage planetary gearbox vibration to properly interpret the vibration spectrum. Our method is based on neural network-based symbolic regression, a so-called equation learner that describes the vibration model based on prior knowledge about the planetary gearbox rotation frequencies. The method employs an end-to-end differentiable feed-forward network trained with sparsity regularization that promotes an interpretable and concise expression for the vibration measurement. With this, the obtained model contributes to increasing the effectiveness of vibration-based condition monitoring in the planetary gearbox with proper separation of the elementary vibration sources. Our proposed approach yields promising results in modeling and sources estimation based on simulated data, even at low SNRs.},
  keywords={Vibrations;Condition monitoring;Source separation;Surveillance;Simulation;Estimation;Mixture models;Vibration analysis;planetary gear transmission;symbolic regression;neural network},
  doi={10.1109/ICASSP48485.2024.10447625},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10366499,
  author={Wei, Song and Xie, Yao and Josef, Christopher S. and Kamaleswaran, Rishikesan},
  journal={IEEE Journal on Selected Areas in Information Theory}, 
  title={Causal Graph Discovery From Self and Mutually Exciting Time Series}, 
  year={2023},
  volume={4},
  number={},
  pages={747-761},
  abstract={We present a generalized linear structural causal model, coupled with a novel data-adaptive linear regularization, to recover causal directed acyclic graphs (DAGs) from time series. By leveraging a recently developed stochastic monotone Variational Inequality (VI) formulation, we cast the causal discovery problem as a general convex optimization. Furthermore, we develop a non-asymptotic recovery guarantee and quantifiable uncertainty by solving a linear program to establish confidence intervals for a wide range of non-linear monotone link functions. We validate our theoretical results and show the competitive performance of our method via extensive numerical experiments. Most importantly, we demonstrate the effectiveness of our approach in recovering highly interpretable causal DAGs over Sepsis Associated Derangements (SADs) while achieving comparable prediction performance to powerful “black-box” models such as XGBoost.},
  keywords={Time series analysis;Predictive models;Information theory;Graph theory;Adaptive systems;Linear programming;Optimization;Causal structural learning;directed acyclic graph;data-adaptive approach;generalized linear model},
  doi={10.1109/JSAIT.2023.3342569},
  ISSN={2641-8770},
  month={},}@INPROCEEDINGS{10544081,
  author={Gill, Kanwarpartap Singh and Gupta, Rupesh and Kumar, Mukesh and Rawat, Ruchira and Chanti, Yerrolla},
  booktitle={2024 IEEE 9th International Conference for Convergence in Technology (I2CT)}, 
  title={Healthcare Insurance Cost Classification Using Machine Learning's Linear Regression Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Advanced analytical approaches are required for effective prediction and categorization of healthcare expenses because of the increasing complexity of these costs and the dynamic nature of the costs themselves. Within the scope of this research project, the classification of healthcare insurance costs is investigated via the use of machine learning, more especially linear regression. In order to identify correlations between these characteristics and to forecast insurance costs, the linear regression model makes use of a dataset that contains a wide variety of demographic, medical, and financial information. The ultimate goal of this study is to provide assistance to policymakers, insurers, and healthcare providers in optimising resource allocation and increasing cost-effectiveness within the healthcare sector. The increasing intricacies and ever-changing nature of healthcare expenses need sophisticated analytical techniques to provide precise forecasting and categorization. This work investigates the use of machine learning, particularly linear regression, for categorising healthcare insurance expenses. The linear regression model utilises a dataset that includes a wide range of demographic, medical, and financial characteristics. Its objective is to identify connections between these elements and make predictions about insurance costs. The study is centred on feature selection, model training, and performance assessment in order to improve the accuracy and interpretability of the predictive model. This research aims to use linear regression to give valuable insights into the determinants of healthcare insurance costs. The findings will be beneficial for policymakers, insurers, and healthcare providers as they can use this information to allocate resources more efficiently and enhance cost-effectiveness in the healthcare industry.},
  keywords={Training;Costs;Correlation;Linear regression;Insurance;Medical services;Machine learning;Artificial Intelligence;Deep Learning;Healthcare Insurance Cost Classification Analysis;Model Training;Linear Regression},
  doi={10.1109/I2CT61223.2024.10544081},
  ISSN={},
  month={April},}@ARTICLE{10137421,
  author={Fu, Jinbang and Jorgensen, Erik J. and Juyal, Prateek and Zajić, Alenka},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={Deep-Learning-Based THz Wireless Channel Property Prediction in Motherboard Desktop Environment}, 
  year={2023},
  volume={71},
  number={7},
  pages={6084-6097},
  abstract={This article proposes a residual network (ResNet)-based feature concatenated neural network model to predict the type of scenario the channel is under and the attribute of the predicted scenario with power delay profile (PDP) as the inputs. The generalized model structure consists of three blocks for feature extraction, scenario prediction, and attribute prediction, respectively. The PDP data is collected from a motherboard desktop environment under five different physical arrangement scenarios. Within each scenario, data is collected several times while varying a different physical attributes for each scenario. Two steps of data augmentation are applied to expand the size and to improve the resolution (difference between the neighboring attributes) of the measured dataset for the robust training and thorough evaluation of the proposed model. The proposed model is evaluated and compared with a multilayer perceptron (MLP)-based model on an expanded measured and averaged interpolated dataset. It is shown that both models perform very well on the expanded measured dataset with nearly 100% prediction accuracy on both scenarios and attributes. The MLP-based model suffers performance degradation on the averaged interpolated dataset with up to a 9% drop of classification accuracy on attribute prediction tasks, while our ResNet-based feature concatenated model performs equally in both scenarios. Feature activation mapping (FAM) and grad-class activation mapping (Grad-CAM) approaches are applied to provide visual explanations highlighting characteristics of the input PDP used for model decisions. FAM shows that the MLP-based model focuses on the multipath generated peaks of the PDP where some interpolated neighboring data points cannot be distinguished. The Grad-CAM shows that the proposed ResNet-based feature concatenated model performs better because it has strong attention not only on the multipath peaks but also on the valleys between those peaks which hold distinguishing information.},
  keywords={Wireless communication;Predictive models;Antenna measurements;Data models;Computational modeling;Semiconductor device measurement;Frequency measurement;Channel characterization;channel prediction;channel sounding;chip-to-chip wireless channels;THz communications},
  doi={10.1109/TAP.2023.3278831},
  ISSN={1558-2221},
  month={July},}@INPROCEEDINGS{9865837,
  author={Sharma, Kavita and Nagappan, Partheeban},
  booktitle={2022 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={Machine Learning/Deep Learning Algorithms & Variability in Grading Improves Early Detection of DR}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Health condition which mainly influence human retina i.e. cognate by Diabetic Mellitus (DM) is a main thread of Diabetic Retinopathy (DR). As a result of the damage of the retina, it causes vision loss. In accordance with census diabetic individuals who had suffered from diabetics in a long time also have DR issues. As a result, DR has become a critical issue that needs a primary stage screening and assessment in order to prevent vision loss and blindness. Physical diagnosis of the condition is time-consuming and prone to inaccuracy. Furthermore, it is not possible to find an ophthalmologist regardless of location or time. As a result, the need for a highly advanced and computerized intelligent system arises, which can be used to diagnose DR in its early stages. Researchers have proposed a number of Machine Learning (ML) algorithms for the diagnosis of DR for decapods. For determining retinal lesion significantly and for initial stage DR diagnosis various feature extraction and analyzing approaches are recommended. Traditional Machine Learning models, on the other hand, suffer from poor generalization during feature extraction due to limited datasets. Using Deep Learning models, more datasets and high computer processing unit weak generalization problem can be reduced. This study intends to provide a DR overview as well as a brief explanation of previous efforts and current automated methods and improvements, in order to the staring exposure of DR. This paper also discusses the most up-to-date DR lesions as well as the causes and symptoms of DR and focus on how AI/ML approaches helpful in early diagnosis of DR and we have to study more on variability in grading to evaluate the best possible result for screening and improving eye disease mainly caused by diabetics.},
  keywords={Deep learning;Machine learning algorithms;Retinopathy;Computational modeling;Retina;Feature extraction;Approximation algorithms;Machine Learning;Deep Learning;Diabetic Retinopathy;Non-proliferative DR and proliferative DR},
  doi={10.1109/CONECCT55679.2022.9865837},
  ISSN={2766-2101},
  month={July},}@INPROCEEDINGS{10014835,
  author={Ganeshamoorthy, S. and Roden, L. and Klepl, D. and He, F.},
  booktitle={2022 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)}, 
  title={Gene Regulatory Network Inference through Link Prediction using Graph Neural Network}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Gene Regulatory Networks (GRNs) depict the causal regulatory interactions between transcription factors (TFs) and their target genes [2], where TFs are proteins that regulate gene transcription. GRN plays a vital role in explaining gene function, which helps to identify and prioritize the candidate genes for functional analysis [3]. Currently, high-dimensional transcriptome datasets are produced from high-throughput sequencing techniques, such as microarray and RNA-Seq. These techniques can capture the differences in the expression of thousands of genes at once. Through these wet-lab experiments, studying the interconnections among a large number of genes or TFs at a network level is challenging [4]. Therefore, one of the important topics in computational biology is the inference of GRNs from high-dimensional gene expression data through statistical and machine learning approaches [2].},
  keywords={Proteins;Sequential analysis;Machine learning;Signal processing;Graph neural networks;Functional analysis;Biology},
  doi={10.1109/SPMB55497.2022.10014835},
  ISSN={2473-716X},
  month={Dec},}@INPROCEEDINGS{10944722,
  author={Ruz, Gonzalo A.},
  booktitle={2025 59th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Training threshold Boolean networks: applications to gene regulatory network modeling}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores a Boolean model of the Arabidopsis thaliana flower organ specification gene regulatory network (FOS-GRN), consisting of thirteen genes with logical rules to update their states. We focus on the threshold Boolean network (TBN) variant, which simplifies gene network modeling by inferring weights and thresholds for each gene. This linear approach provides a more interpretable model compared to traditional Boolean networks with complex logical rules. To train the TBN for the FOS-GRN, we apply a machine learning method, using perceptrons to learn the linear relationships between genes. Our results indicate that three genes exhibit non-linear interactions, which cannot be captured by a TBN. Despite this, the inferred model closely approximates the original network. Additionally, the network’s asymptotic behavior correctly identifies biologically meaningful fixed points with the largest basins of attraction. When the goal of fully replicating the FOS-GRN state transition table was relaxed, and instead the focus shifted to identifying at least ten important fixed points, the inferred network succeeded in this objective. However, it also introduced spurious fixed points. Nevertheless, the perceptron-based training approach proves valuable for gene regulatory network inference within the TBN framework.},
  keywords={Training;Codes;Biological system modeling;Machine learning;Biological systems;Flowering plants;Vectors;Regulation;Object recognition;Biological information theory;Boolean networks;threshold Boolean networks;gene regulatory networks;the perceptron},
  doi={10.1109/CISS64860.2025.10944722},
  ISSN={2837-178X},
  month={March},}@INPROCEEDINGS{10934651,
  author={Kanth, Tatiraju.V.Rajani and Singh, Balveer and Singh, Yaspal and Bhutada, Sunil and Yamaganti, Rohita},
  booktitle={2025 International Conference on Intelligent Systems and Computational Networks (ICISCN)}, 
  title={Adaptive Kernel Optimization for Probabilistic Learning: Integrating Support Vector Machines with Gaussian Process Frameworks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={With its robust capabilities for non-linear regression and classification, kernel-based learning has emerged as a fundamental component of state-of-the-art machine learning approaches. In order to improve probabilistic learning, this study investigates Adaptive Kernel Optimization (AKO), a new method that combines the best features of the Support Vector Machine (SVM) and the Gaussian Process (GP) frameworks. Achieving better flexibility in modeling complicated data distributions while keeping computational efficiency is achieved by employing adaptive kernel functions in the suggested strategy. Quantifying uncertainty in addition to deterministic SVM classifications is made possible with the incorporation of GP kernels, which offer probabilistic insights. The suggested approach guarantees resilience across varied and high-dimensional datasets by dynamically adjusting kernel parameters according to data properties. Extensive testing on benchmark datasets shows that, in comparison to conventional SVM and GP approaches, our model generalizability, classification accuracy, and interpretability are much improved. Autonomous systems, healthcare diagnostics, and financial sectors can all benefit from the scalable, adaptive, and probabilistic learning models that this study establishes.},
  keywords={Support vector machines;Adaptation models;Uncertainty;High dimensional data;Gaussian processes;Medical services;Probabilistic logic;Real-time systems;Kernel;Optimization;adaptive kernel optimization;probabilistic learning;support vector machines (SVM);gaussian process kernels;uncertainty quantification;non-linear classification;high-dimensional data;machine learning;model generalization;robustness},
  doi={10.1109/ICISCN64258.2025.10934651},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11069611,
  author={Chen, Yifan and Guo, Yicun and Chan, Weng Howe and Diao, Qi and Wu, YiTong},
  booktitle={2025 2nd International Conference on Smart City and Information System (ICSCIS)}, 
  title={Multi-Objective Optimization of Traveling Salesman Problems for Smart Urban Systems: A Comprehensive Review and Future Research Perspectives}, 
  year={2025},
  volume={},
  number={},
  pages={55-59},
  abstract={The Traveling Salesman Problem (TSP) and its multi-objective extensions have become essential frameworks for optimizing complex routing and scheduling in smart urban systems. This paper comprehensively reviews TSP-based models across key domains, including autonomous logistics, public transportation, emergency response, infrastructure maintenance, waste management, and energy-constrained mobility. It emphasizes multi-objective optimization (MOO) techniques balancing efficiency, cost, energy consumption, and sustainability. Key research challenges─scalability, dynamic adaptation, heterogeneous data integration, and ethical considerations─are outlined, alongside future directions involving hybrid frame-works, interpretable models, and cross-paradigm synergies. This review consolidates current knowledge and provides a structured roadmap bridging MO-TSP theory with practical smart city applications.},
  keywords={Waste management;Adaptation models;Reviews;Smart cities;Scalability;Traveling salesman problems;Emergency services;Sustainable development;Optimization;Logistics;Traveling Salesman Problem;Smart Urban Systems;Multi-Objective Optimization;Urban Mobility;Intelligent Infrastructure},
  doi={10.1109/ICSCIS65391.2025.11069611},
  ISSN={},
  month={May},}@INPROCEEDINGS{10821193,
  author={Ouedrhiri, Oumayma and Faghihi, Usef and Toure, Fadel and Banouar, Oumayma},
  booktitle={2024 IEEE International Conference on Quantum Computing and Engineering (QCE)}, 
  title={Quantum Fidelity Based Fuzzy C-Means Clustering Algorithm}, 
  year={2024},
  volume={02},
  number={},
  pages={138-143},
  abstract={Among clustering algorithms, fuzzy clustering stands out for its ability to offer a nuanced representation of the data by assigning degrees of membership to clusters, providing a more flexible and adaptive approach than the rigid partitioning of hard clustering algorithms. This has proved highly advantageous, particularly for image segmentation problems. Numerous approaches have been proposed to improve the Fuzzy C-means (FCM) algorithm using quantum computing, some are quantum-inspired and others can be run on quantum simulators. In this paper, a study was conducted on Quantum Fuzzy Means (QFCM) approaches. Then, a novel QFCM algorithm is introduced to address the challenges associated with these current algorithms, particularly in handling large datasets and incorporating genuine fuzzy system principles. Using concepts from quantum computing, our approach aims to improve distance calculations between data points by using a quantum distance measure. This method enables significant acceleration of the clustering process especially when dealing with extensive datasets. Moreover, our proposed algorithm integrates a structured fuzzy system framework into the membership matrix calculation, enhancing the precision and interpretability of the clustering results. Furthermore, unlike other FCM algorithms, which often lack explicit representation of fuzzy logic principles, our approach incorporates a well-defined fuzzy system to capture the inherent uncertainty and ambiguity in real-world data.},
  keywords={Fuzzy logic;Image segmentation;Quantum computing;Uncertainty;Clustering algorithms;Classification algorithms;Partitioning algorithms;Time complexity;Recommender systems;Fuzzy systems;Quantum clustering;Quantum fuzzy clustering;Quantum machine learning;Quantum computing;Quantum optimization;Fuzzy logic},
  doi={10.1109/QCE60285.2024.10267},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10944997,
  author={Han, Jiaqi and Wang, Dan and Luo, Hong and Zhou, Ye and Song, Bin},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={Hardware Latency-Aware Differential Architecture Search: Search for Latency-Friendly Architectures on Different Hardware}, 
  year={2024},
  volume={},
  number={},
  pages={2635-2643},
  abstract={As a result of its low search cost, Differentiable Architecture Search (DARTS) has recently received a lot of interest. Nowadays, most methods based on DARTS only focus on improving a single indicator (e.g., accuracy), making the search process more inclined to complex networks with more robust representational capabilities. Hence, the architectures searched by these methods tend to own high latency, leading to DARTS in some low-latency scenarios or edges with limited computing power, and on-device deployment becomes difficult. To deal with this challenge, we propose a Hardware Latency-Aware Differentiable Search (HL-DARTS) algorithm. This algorithm designs a multi-layer regression network that uses the soft attention mechanism to predict the latency on the corresponding hardware devices, thus adding a differentiable latency loss term based on the DARTS algorithm. We further propose an adaptive constraint amplitude—a mechanism for balancing accuracy and latency while searching for a latency-friendly architecture for a given hardware device. We conduct ablation experiments on different datasets and different hardware devices. The experimental results show that HL-DARTS can find the ideal architecture for different hardware devices and that this architecture is also broadly applicable to various datasets.},
  keywords={Privacy;Costs;Attention mechanisms;Accuracy;Computer architecture;Prediction algorithms;Hardware;Neural architecture search;Security;Optimization;Neural Architecture Search;Hardware Latency-Aware Algorithm;latency-friendly Neural Architecture},
  doi={10.1109/TrustCom63139.2024.00367},
  ISSN={2324-9013},
  month={Dec},}@INPROCEEDINGS{10435397,
  author={Zheng, Yi},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={Diabetes Prediction and Analysis based on Ensemble Learning Method}, 
  year={2023},
  volume={},
  number={},
  pages={1353-1358},
  abstract={Diabetes is a chronic lifelong disease that can cause multiple complications. Since the beginning of the 21st century, it has rapidly developed into one of the top ten causes of death in the world. However, its early symptoms are not obvious and difficult to detect. Therefore, the main goal of this article is to identify key indicators of diabetes and use an ensemble learning method to more accurately predict whether a patient has diabetes. This article selects the classic Pima-Indians diabetes data set, balances its data through three methods, and determines an effective balancing strategy. Secondly, six machine learning methods are used to rank feature importance, and more important features are obtained based on weighted ranking. Finally, a new BP-XGBoost-RF integrated learning model was proposed. The initial weights of each base model were calculated through gray correlation analysis, and the genetic algorithm was used to optimize the weights to obtain the final comprehensive model. This model is better than single models and other integrated methods in the accuracy and comprehensive score, and can more accurately and comprehensively determine whether a patient has diabetes. Similarly, the model can be extended to the prediction of other diseases and related research in other fields.},
  keywords={Analytical models;Predictive models;Data models;Diabetes;Ensemble learning;Diseases;Genetic algorithms;diabetes;machine learning;ensemble learning method},
  doi={10.1109/EIECS59936.2023.10435397},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10941322,
  author={Babiker, Safia and Jadalhaq, Jouri and Jadalhaq, Jana and Barkat, Enfel},
  booktitle={2025 22nd International Learning and Technology Conference (L&T)}, 
  title={Development of an Intelligent GUI with ChatGPT for Efficient and Accurate Transformer Fault Diagnosis Using DGA, Duval Triangle Method, and Machine Learning Automation}, 
  year={2025},
  volume={22},
  number={},
  pages={263-268},
  abstract={This study presents an intelligent graphical user interface (GUI) for transformer fault diagnosis, utilizing Dissolved Gas Analysis (DGA), the Duval Triangle method, and automated machine learning model selection. Key gases—Methane (CH4), Ethylene (C2 H4), and Acetylene (C2 H2)—are analyzed to classify fault types, including partial discharges and thermal/electrical faults, through gas concentration ratios. The system leverages TPOT's model selection capabilities, with the Multi-Layer Perceptron (MLP) emerging as the optimal classifier, achieving over 95% accuracy. The GUI, developed using Gradio, enables CSV uploads for batch processing and real-time fault classification, complemented by ChatGPT-generated explanations and maintenance suggestions. A case study on mineral oil-based transformers demonstrates the tool's high diagnostic accuracy, user-friendly design, and potential for expanded applications in predictive maintenance.},
  keywords={Gases;Accuracy;Oil insulation;Predictive models;Transformers;Chatbots;Minerals;Maintenance;Graphical user interfaces;Predictive maintenance;Transformer fault diagnosis;Dissolved Gas Analysis;Duval Triangle;Machine Learning;TPOTClassifier;Gradio;Artificial Intelligence;GUI;ChatGPT Integration},
  doi={10.1109/LT64002.2025.10941322},
  ISSN={2996-2331},
  month={Jan},}@INPROCEEDINGS{10327629,
  author={Yan, Duojin and Yang, Chunjie and Yang, Bo and Chen, Yu and Kong, Liyuan and Chen, Jian},
  booktitle={2023 35th Chinese Control and Decision Conference (CCDC)}, 
  title={Multi-objective optimization method of blast furnace operation performance indicators based on data and knowledge}, 
  year={2023},
  volume={},
  number={},
  pages={3933-3939},
  abstract={During blast furnace (BF) ironmaking, hot metal quality and energy consumption directly affect industrial economic benefits. Field engineers usually adjust the production state based on their experience, which makes control optimization uncertain. A data and knowledge-based optimization framework for BF operation performance indicators is proposed in this paper. Firstly, design the Attention Long Short Term Memory (Attention-LSTM) neural network to predict the Silicon content and coke ratio, which is used as fitness value function of the multi-objective optimization model. To initialize the population, knowledge based non-dominated sorting genetic algorithm (KB-NSGA) uses a knowledge base of historical optimal solutions. Finally, an optimization solution set that meets the actual production requirements is obtained using the TOPSIS evaluation method. The KB-NSGA successfully achieves the goal compared with other genetic algorithms. The effectiveness of the proposed method is verified by long-term running experiments.},
  keywords={Soft sensors;Knowledge based systems;Sociology;Optimization methods;Production;Blast furnaces;Silicon;Blast furnace ironmaking;multi-objective optimization;Attention Long Short Term Memory;Non-dominated Sorting Genetic Algorithm},
  doi={10.1109/CCDC58219.2023.10327629},
  ISSN={1948-9447},
  month={May},}@ARTICLE{10699367,
  author={Singh, Hemraj and Verma, Mridula and Cheruku, Ramalingaswamy},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={DSFNet: Video Salient Object Detection Using a Novel Lightweight Deformable Separable Fusion Network}, 
  year={2024},
  volume={73},
  number={},
  pages={1-12},
  abstract={Geometric variations of spatial and temporal features of objects in video streams cause great difficulty in video salient object detection (VSOD) tasks. Most existing deep-learning methods utilize fixed-sized kernels, which limits the receptive field (RF) to extract the local and global features and fails to understand the visual semantics of the deformed objects’ foreground and background. Moreover, due to their complex architectures, these methods need more computational resources, which limits their deployment in real-world scenarios. To address the aforementioned challenges and to make a balance between performance and computational complexity, a deformable separable fusion network (DSFNet) is proposed, which extracts the geometric spatiotemporal variations at multiscale features dynamically without compromising the network’s complexity. A Swarm-Enhanced Adam (SEAdam) optimizer has been proposed to adaptively balance the exploration and exploitation of gradients locally and globally and improve the convergence speed. This is the first work that extracts the multiscale geometric local and global context-based visual information. With the help of extensive experimentation on six benchmark highly challenging datasets, we show that the proposed model outperforms state-of-the-art models in terms of the number of parameters, floating-point operations (FLOPs), and latency.},
  keywords={Feature extraction;Data mining;Convolution;Deformable models;Visualization;Computational modeling;Spatiotemporal phenomena;Adaptation models;Streaming media;Object detection;Deformable attention fusion;deformable global attention (GA);deformable region context;deformable separable fusion network (DSFNet);spatial and temporal features;video salient object detection (VSOD)},
  doi={10.1109/TIM.2024.3470045},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{9892069,
  author={He, Rongguang and Xiao, Xiao and Kang, Yufan and Zhao, Hongyu and Shao, Wei},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Heterogeneous Pointer Network for Travelling Officer Problem}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Traveling Salesman Problem (TSP) is a classic NP-hard problem in Combinatorial Optimization (CO), which has been widely studied. Traveling Officer Problem (TOP) derived from illegal parking in urban areas is a variant of TSP. Its solution aims to capture as many illegally parked vehicles as possible in a limited time. However, traditional methods of solving TSP cannot be applied to TOP because the illegally parked vehicle may leave before the officer arrives. Existing methods to solve TOP include heuristic search and deep learning algorithms such as ant colony optimization and feed-forward neural network. However, the performance based on capture rate and traveling distance of these algorithms is still comparably low. Hence, in this paper, we propose the heterogeneous pointer network to address this problem by modifying the encoder of the traditional pointer network to suit the spatial-temporal features of TOP. We conduct experiments using real-world datasets from Melbourne open data platform to show that our method achieves significant improvement and outperforms the existing algorithms based on capture rate and traveling distance.},
  keywords={Measurement;Training;Adaptation models;Gradient methods;Heuristic algorithms;Neural networks;Urban areas;Traveling Salesman Problem;NP-hard;Traveling Officer Problem},
  doi={10.1109/IJCNN55064.2022.9892069},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10032449,
  author={Xiang, Mingrong and Luo, Wei and Hou, Jingyu and Tao, Wenjing},
  booktitle={2022 IEEE 9th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Attention-based Feature Fusion for Reconstructing Gene-Regulatory Interactions}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Reconstructing gene regulatory networks (GRNs) from expression data is vital for understanding gene transcrip- tion. Although increasingly advanced algorithms, particularly deep learning models, are proposed to mine potential gene regulatory interactions, insufficient effort has been invested in improving the reliability of features in the presence of biological variability between expression samples. In this research, we propose a robust feature fusion method inspired by emerging attention-based techniques in computer vision. Our method can capture the functional asymmetry between transcription factors (TF) and target genes with an important adaptation using differentiated attention heads. Based on three different gene expression datasets: in silico, E.coli, and S.cerevisiae, we demonstrate that our method is superior to other state-of-the- art competitors. The overall GRN reconstruction performance of our method yields a gain of 3%-14% in the AUC score over the competing models.},
  keywords={Computer vision;Adaptation models;Computational modeling;Biological system modeling;Reconstruction algorithms;Size measurement;Graph neural networks;Gene regulatory network reconstruction;Feature fusion;Attention;Gene expression},
  doi={10.1109/DSAA54385.2022.10032449},
  ISSN={},
  month={Oct},}
