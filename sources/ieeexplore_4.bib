@ARTICLE{10153769,
  author={Li, Qing and Yuan, Xin and Liu, Sannyuya and Gao, Lu and Wei, Tianyu and Shen, Xiaoxuan and Sun, Jianwen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={A Genetic Causal Explainer for Deep Knowledge Tracing}, 
  year={2024},
  volume={28},
  number={4},
  pages={861-875},
  abstract={Knowledge tracing (KT) has become an increasingly relevant problem in intelligent education services. Deep learning-based KT (DLKT) achieves superb performance in terms of prediction accuracy, but it lacks of explainability, which makes us hard to trust or understand models. The previous work on explaining DLKT was mainly based on gradients or attention scores, which is susceptible to spurious correlations, reducing the credibility of the explanation. To address this limitation, in this article, we propose a causal explanation method based on the genetic algorithm (GA), named genetic causal explainer (GCE), which constructs a causal framework to estimate the attribution of subsequence to the predictions of DLKT models, and a genetic coding system is designed. Further, A multistrategy initialization method inspired by domain prior knowledge is proposed, and a global empirical matrix is introduced to capture the causal correlation knowledge during the search process across instances, and guiding the mutation operators. The GCE as a post hoc explanation method can generate explanation results without affecting model training, and can be applied to analyze different DLKT models. Experimental results demonstrate the GCE perform better than other explanation methods in terms of accuracy and readability in quantitative assessments. Meanwhile, the GCE also shows good application prospects in mining educational laws and comparing KT models.},
  keywords={Predictive models;Neural networks;Analytical models;Deep learning;Correlation;Data models;Knowledge engineering;Cause-effect;explanation method;genetic algorithm (GA);knowledge tracing (KT)},
  doi={10.1109/TEVC.2023.3286666},
  ISSN={1941-0026},
  month={Aug},}@INPROCEEDINGS{10708602,
  author={Manai, Elyes and Mejri, Mohamed and Fattahi, Jaouhar},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Intrusion Detection Explainability by Ensemble Learning with a Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={1542-1547},
  abstract={This paper introduces a novel ensemble learning methodology that leverages the confusion matrix and statistical metrics, particularly the mean, to intelligently select the most suitable model from a pool of candidates for predictive tasks on test inputs. The approach has been tested on a well-known Network Intrusion Detection Dataset (UNSW-NB15) and compared against its underlying models and other ensembling methods where it yielded superior results in three performance metrics (accuracy, recall, and F1). Out approach is model-agnostic, easily adaptable, and scalable to accommodate any number of models. Additionnally, the use of interpretable metrics such as the confusion matrix and mean enhances explainability, providing a comprehensive understanding of the model’s decision-making processes and improvement directions.},
  keywords={Measurement;Adaptation models;Refining;Decision making;Network intrusion detection;Predictive models;Ensemble learning;Information technology;Standards;Genetic algorithms},
  doi={10.1109/CoDIT62066.2024.10708602},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{10762551,
  author={Jiang, Ya and Si, Chaoming and Yang, Liu},
  booktitle={2024 3rd International Conference on Electronics and Information Technology (EIT)}, 
  title={Improvement Strategies for Mask R-CNN in Satellite Image Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={739-744},
  abstract={With the development of mega-constellations and space technology, the frequency and number of satellite anomalies in orbit are increasing in tandem, and the demand for autonomous in-orbit repair operations is becoming increasingly urgent. Autonomous repair technology is limited by the efficiency and accuracy of identifying and operating on repair targets (such as malfunctioning parts and capture components) in orbit, and it is not yet capable of supporting in-orbit application implementation. To address this issue, this paper proposes a satellite component recognition method based on an improved MASK R-CNN model, which introduces a new network structure, CB-Resnet, and integrates the Particle Swarm Optimization (PSO) algorithm to achieve precise fault part recognition and localization. The CB-Resnet module enhances the model's ability to express key component features in images, while the PSO algorithm optimizes network parameters, improving the model's global search capability and generalization performance. With this method, repair spacecraft can quickly identify operational components, thereby supporting the formulation of rapid fault handling plans, improving repair efficiency, and reducing operational difficulty. Experimental results show that the improved model performs excellently in component recognition tasks, providing an effective technical support for the development of autonomous in-orbit satellite repair operations.},
  keywords={Space vehicles;Satellites;Accuracy;Space technology;Maintenance engineering;Orbits;Maintenance;Satellite images;Particle swarm optimization;Optimization;Mask R-CNN;Particle Swarm Optimization;Convolutional Attention Network;Component Recognition},
  doi={10.1109/EIT63098.2024.10762551},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10776743,
  author={Gharbi, Safa El and Landolsi, Kamel and Echouchene, Fraj},
  booktitle={2024 IEEE International Conference on Artificial Intelligence & Green Energy (ICAIGE)}, 
  title={Optimizing Hydrogen Production from NaBH4 Hydrolysis Using BBD, ANN, and Genetic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study investigates the optimization of hydrogen generation rate (HGR) by NaBH4 hydrolysis using a comprehensive approach integrating experimental design, response surface methodology (RSM), artificial neural networks (ANN), and genetic algorithms (GA). Catalyst synthesis and Box-Behnken design were used to investigate the effects of temperature, stirring rate, NaBH4 and catalyst masses, and NaOH concentration on HGR. The RSM-built quadratic regression model highlighted significant effects of temperature, NaBH4 mass, and catalyst mass on HGR. ANN modeling demonstrated strong predictive performance, explaining 98% of the variance with a mean absolute percentage error (MAPE) of 0.065, root mean square error (RMSE) of 304.06, and R2 of 0.98. GA optimization indicated that the maximum HGR of 6912 mL/min.gcata can be achieved at 55°C, 150 mg NaBH4, 10 mg catalyst, and 0.7 mol/L NaOH concentration. In addition, the activation energy for NaBH4 hydrolysis was determined to be 49.72 kJ/mol, which is in agreement with literature values.},
  keywords={Hydrolysis;Temperature;Catalysts;Hydrogen;Artificial neural networks;Production;Predictive models;Response surface methodology;Optimization;Genetic algorithms;Optimization;Box-Behnken design;Genetic algorithms;hydrogen generation},
  doi={10.1109/ICAIGE62696.2024.10776743},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10691712,
  author={Shi, Hao and Ni, Yongliang and Wei, Zhongbao and Tong, Yuqi and Wang, Tianze},
  booktitle={2024 IEEE 25th China Conference on System Simulation Technology and its Application (CCSSTA)}, 
  title={Water Fault Diagnosis for PEMFC based on an Improved Equivalent Circuit Model}, 
  year={2024},
  volume={},
  number={},
  pages={543-547},
  abstract={The water faults significantly impact the durability and performance of the proton exchange membrane fuel cell (PEMFC). As a non-invasive detection method, the equivalent circuit model (ECM) based water fault diagnostic method offers great interpretability for internal states of the PEMFC. However, the conventional ECM of the PEMFC has poor fitting accuracy in the high-frequency region. To address this, an improved ECM is proposed by introducing constant phase element (CPE) and short Warburg impedance elements, which can reflect the effects of plate unevenness and dielectric heterogeneity. Compared to the second-order RC and R(RC)(RC) models, the proposed ECM increases the fitting accuracy by 96.5% and 97.9%, respectively. The features derived from the ECM are used to develop the water fault classification model based on the particle swarm optimization clustering. To validate the proposed method, a PEMFC water fault dataset are generated from experiments, and all 35 sets of data are accurately classified. Compared to the K-means clustering, the classification precision of the proposed method analysis increased by 23.86%.},
  keywords={Protons;Accuracy;Fitting;Fuel cells;Systems simulation;Circuit faults;Impedance;Integrated circuit modeling;Particle swarm optimization;Equivalent circuits;pemfc;water fault diagnosis;eis;equivalent circuit model},
  doi={10.1109/CCSSTA62096.2024.10691712},
  ISSN={},
  month={July},}@INPROCEEDINGS{9776030,
  author={Hu, Chuhang and Liu, Guikai and Li, Ming},
  booktitle={2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={A Network Security Situation Prediction Method Based On Attention-CNN-BiGRU}, 
  year={2022},
  volume={},
  number={},
  pages={257-262},
  abstract={To improve the accuracy and efficiency of network security situation prediction, a network security situation prediction method based on Attention-CNN-BiGRU is proposed. It combined Convolutional Neural Network(CNN) and bidirectional Gated Recurrent Unit(BiGRU), The structure of the proposed model is more accurate for extraction and understanding of situation time series; besides, to improve the performance of proposed model, the Attention mechanism is utilized to optimize the model; particle swarm optimization(PSO) is applied to optimize varieties of hyperparameters of the model. The optimal combination of hyperparameters selected by PSO is used for training of the model. Finally, the method proposed in this paper was verified in experiment and compared with other models. The results shows that the method can acomplish the task of situation prediction with better capability.},
  keywords={Training;Analytical models;Computational modeling;Time series analysis;Predictive models;Network security;Logic gates;Network security;Situation prediction;Neural network;PSO},
  doi={10.1109/CSCWD54268.2022.9776030},
  ISSN={},
  month={May},}@INPROCEEDINGS{10371868,
  author={Ŝkvorc, Urban and Eftimov, Tome and Koro]ec, Peter},
  booktitle={2023 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Analyzing the Generalizability of Automated Algorithm Selection: A Case Study for Numerical Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={335-340},
  abstract={In numerical single-objective optimization, auto-mated algorithm selection that uses exploratory landscape analy-sis to describe problem features has achieved great results when the machine learning models used for prediction are trained and tested on the same problem set. However, recent work has shown that the performance of such models decreases when the training and testing sets contain different problems. In this paper, we examine a recently developed algorithm selection model trained on a set of artificial problems and tested on a well-known set of hand-made benchmark problems. This model performed poorly when it was originally presented. Here, we provide an explanation for its poor performance by analyzing the feature importance of the model using Shapley Additive Explanations. We then compare these results to an alternative algorithm selection model that was both trained and tested on the same set of hand-made benchmark problems and achieved much higher performance. This allows us to determine which features each model considers as most significant for their predictions, and where they differ. We show that the original and the alternative model use different landscape features for their predictions, which explains the difference in their performance. Further, by plotting the SHAP values on a 2D plane, we show that the original model is unable to distinguish between certain types of problems. Finally, we show that regardless of their differences in utilizing the features both the original and the alternative models perform poorly on a specific group of problems.},
  keywords={Training;Analytical models;Machine learning algorithms;Computational modeling;Machine learning;Predictive models;Benchmark testing;algorithm selection;exploratory landscape anal-ysis;numerical optimization},
  doi={10.1109/SSCI52147.2023.10371868},
  ISSN={2472-8322},
  month={Dec},}@INPROCEEDINGS{10911521,
  author={M, Shalini and Bhushan, Bharat and S, Mithun Kumar and Chavhan, Gajanan H and Thangamani, A. and Rampal, Sourav},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={Artificial Intelligence and its Algorithmic Foundations Reshaping the Future}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Because AI is built on formulas, numerous industries are evolving. This study examines three types of networks: genetic algorithms, convolutional neural net-works (CNNs), and long short-term memory networks (LSTMs). It investigates how advanced AI approaches influence these networks. This method combines many algorithms to create a versatile artificial intelligence system capable of solving issues. CNNs, on the other hand, acquire hierarchical features quickly and function well with images, while LSTMs excel at sequential data and other tasks. GAs employs genetic optimization to strengthen and improve response capabilities. By combining these technologies in novel ways, you may improve their optimization, natural language processing, and image identification. Even though artificial intelligence is still in its early stages, this study demonstrates the importance of algorithmic roots in predicting when smart systems may begin to challenge technology again.},
  keywords={Transforms;Reinforcement learning;Prediction algorithms;Smart systems;Natural language processing;Artificial intelligence;Optimization;Long short term memory;Genetic algorithms;Testing;Algorithmic Foundations;Artificial Intelligence;Convolutional Neural Networks;Deep Learning;Genetic Algorithms;Long Short-Term Memory Networks;Ma-chine Learning;Natural Language Processing;Reinforcement Learning},
  doi={10.1109/ICTBIG64922.2024.10911521},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11043025,
  author={Xie, Zhuoliang and Liu, Fei and Wang, Zhenkun and Zhang, Qingfu},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={LLM-Driven Neighborhood Search for Efficient Heuristic Design}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Handcrafting heuristics often demands extensive domain knowledge and significant development effort. Recently, heuristic search powered by large language models (LLMs) has emerged as a new approach, offering enhanced automation and promising performance. Existing methods rely on an evolutionary computation (EC) framework with carefully designed prompt strategies. However, the large heuristic search space poses significant challenges for these EC-based methods. This paper proposes a simple yet effective LLM-driven Heuristic Neighborhood Search (LHNS) paradigm to iteratively search in the heuristic neighborhood in a principled way for efficient heuristic design. Three distinct methods are designed under this neighborhood search paradigm and demonstrated on three widely studied problems. Results indicate that LHNS exhibits very competitive performance and surpasses existing EC-based methods in efficiency. It also demonstrates sufficient robustness in the absence of problem-specific knowledge regarding the target problem. The efficiency and robust adaptability make it a practical new solution for efficient heuristic design.},
  keywords={Automation;Large language models;Evolutionary computation;Search problems;Robustness;heuristic design;neighborhood search;large language model},
  doi={10.1109/CEC65147.2025.11043025},
  ISSN={},
  month={June},}@ARTICLE{10963732,
  author={Zhang, Xiaolu and Chen, Yazhou and Zhao, Min and Li, Yansong},
  journal={IEEE Transactions on Electromagnetic Compatibility}, 
  title={Assessment of EMI Effects on UAV Data Links}, 
  year={2025},
  volume={67},
  number={3},
  pages={786-799},
  abstract={To assess the survivability of an unmanned aerial vehicle (UAV) in a complex electromagnetic environment, a novel method for assessing electromagnetic interference (EMI) threats to a UAV is introduced. A dataset of loss-of-lock thresholds for the UAV data link was generated through EMI injection tests. A genetic algorithm (GA)-optimized extreme gradient boosting (XGBoost) was then applied to efficiently predict these loss-of-lock thresholds. And Shapley additive explanations (SHAP) were used to measure the importance of features. Compared with K-nearest neighbor, support vector machine, decision tree, and XGBoost, GA-XGBoost shows better prediction accuracy and overall performance. Based on this, a GA-XGBoost-based assessment method was proposed to classify EMI effects into four levels using a three-level effect index. Finally, the EMI effect levels and SHAP results were used to formulate targeted anti-interference strategies. The proposed method can help to improve the anti-interference performance of UAVs.},
  keywords={Electromagnetic interference;Autonomous aerial vehicles;Noise;Spread spectrum communication;Attenuators;Signal generators;Power generation;Monitoring;Mathematical models;Predictive models;Data link;electromagnetic interference (EMI) effect;genetic algorithm (GA);extreme gradient boosting algorithm (XGBoost);Shapley additive explanations (SHAP);unmanned aerial vehicle (UAV)},
  doi={10.1109/TEMC.2025.3550620},
  ISSN={1558-187X},
  month={June},}@INPROCEEDINGS{10424874,
  author={Guo, Shixin and Yang, Xuezhi and He, Xiang and Zhou, Ruoyv},
  booktitle={2023 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)}, 
  title={Deep Learning-Based Classification of Tobacco Leaf Alcoholization Levels Resistant to Lighting Interference}, 
  year={2023},
  volume={},
  number={},
  pages={833-840},
  abstract={The alcoholization level of tobacco leaves is a critical parameter in the tobacco processing industry. Currently, the grading of tobacco alcoholization levels relies primarily on manual assessment, which is time-consuming, labor-intensive, and often lacks accuracy. This paper introduces a tobacco leaf alcoholization grading method based on computer vision and deep learning, aiming to achieve automatic alcoholization level determination while being resilient to lighting interference. By combining an attention mechanism with an enhanced FC4 (Fully Convolutional Color Constancy with Confidence-weighted Pooling) model, the consistency of tobacco leaf color is maintained under varying lighting conditions. Additionally, the performance of the Back Progagation Neural Network is optimized using the particle swarm optimization to accurately map the color and texture features of the images to the classification results. Using tobacco leaves of known grades from the repository as experimental subjects, the test results indicate that the method proposed exhibits a higher classification accuracy compared to existing approaches.},
  keywords={Resistance;Computer vision;Image color analysis;Computational modeling;Lighting;Interference;Particle swarm optimization;image classification;lighting interference;attention mechanism;FC4;BPNN;PSO},
  doi={10.1109/ICICML60161.2023.10424874},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11022249,
  author={Chang, Teng and Li, Bohui and Zhang, Zhixia and Cai, Xingjuan},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Explainable Recommendation Merging Sentiment Analysis and Multi-Scale Collaborative Filtering}, 
  year={2024},
  volume={},
  number={},
  pages={803-811},
  abstract={Recommender systems (RSs) based on collaborative filtering (CF) are often perceived as black-box models incapable of offering plausible explanations for recommended items. CF that combines methods such as deep learning mitigates this problem but explains only in terms of feature similarity, which neglects the user-item correlation and users’ real sentiment. In order to improve the explainability of CF models and the rationality of explanation, an explainable recommendation model merging sentiment analysis and multi-scale collaborative filtering (ERSA-MCF) is proposed in this paper. Specifically, we extend the scale of CF to implement filtering in three aspects: user acceptance, user preference, and item similarity, to increase the association between users and items. Simultaneously, the sentiment score of conformity ratings is introduced to mirror the user’s genuine receptiveness. In order to balance the recommended lists generated by the three filtering scales with accuracy, diversity, and explainability, a multi-objective particle swarm optimization algorithm based on a global optimal quality centroid (MPSO-GOC) is proposed for optimizing the candidate lists and improving the overall efficiency of the model. Experimental results show that the model improves diversity and explainability while ensuring accuracy.},
  keywords={Sentiment analysis;Analytical models;Accuracy;Filtering;Social networking (online);Reviews;Collaborative filtering;Merging;Cultural differences;User preference;explainable recommendation;multi-scale collaborative filtering;sentiment analysis;multi-objective optimization},
  doi={10.1109/ACAIT63902.2024.11022249},
  ISSN={},
  month={Nov},}@ARTICLE{9527391,
  author={Shao, Yinan and Lin, Jerry Chun-Wei and Srivastava, Gautam and Guo, Dongdong and Zhang, Hongchun and Yi, Hu and Jolfaei, Alireza},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Multi-Objective Neural Evolutionary Algorithm for Combinatorial Optimization Problems}, 
  year={2023},
  volume={34},
  number={4},
  pages={2133-2143},
  abstract={There has been a recent surge of success in optimizing deep reinforcement learning (DRL) models with neural evolutionary algorithms. This type of method is inspired by biological evolution and uses different genetic operations to evolve neural networks. Previous neural evolutionary algorithms mainly focused on single-objective optimization problems (SOPs). In this article, we present an end-to-end multi-objective neural evolutionary algorithm based on decomposition and dominance (MONEADD) for combinatorial optimization problems. The proposed MONEADD is an end-to-end algorithm that utilizes genetic operations and rewards signals to evolve neural networks for different combinatorial optimization problems without further engineering. To accelerate convergence, a set of nondominated neural networks is maintained based on the notion of dominance and decomposition in each generation. In inference time, the trained model can be directly utilized to solve similar problems efficiently, while the conventional heuristic methods need to learn from scratch for every given test problem. To further enhance the model performance in inference time, three multi-objective search strategies are introduced in this work. Our experimental results clearly show that the proposed MONEADD has a competitive and robust performance on a bi-objective of the classic travel salesman problem (TSP), as well as Knapsack problem up to 200 instances. We also empirically show that the designed MONEADD has good scalability when distributed on multiple graphics processing units (GPUs).},
  keywords={Optimization;Evolutionary computation;Heuristic algorithms;Search problems;Neural networks;Genetics;Urban areas;Attention mechanism;deep reinforcement learning (DRL);multi-objective learning;neural combinatorial optimization;neural evolutionary algorithm},
  doi={10.1109/TNNLS.2021.3105937},
  ISSN={2162-2388},
  month={April},}@ARTICLE{10720058,
  author={Saiyed, Makhduma F and Al-Anbagi, Irfan and Hossain, M. Shamim},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Interactive and Explainable Optimized Learning for DDoS Detection in Consumer IoT Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={The integration of Internet of Things (IoT) in consumer environments enhances convenience and security while increasing Human-Computer Interaction (HCI). However, this increased interactivity has also increased the vulnerability of Consumer IoT (CIoT) networks to cyber threats, mainly Distributed Denial of Service (DDoS) attacks. The DDoS attacks, which vary in volume, present substantial challenges to these networks’ operational integrity and customer trust. This paper introduces the Artificial Intelligence (AI)-driven (ADEPT) system that utilizes explainable and optimized deep-ensemble learning with pruning for DDoS detection. The system uses attention-based ensemble DL for DDoS detection, combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks. To address the resource constraints of edge devices in CIoT networks, the system uses Differential Evolution (DE)-based pruning and quantization techniques, optimizing the model for efficient deployment on edge nodes while preserving high performance. An HCI interface is designed to allow network administrators and researchers to engage with the system through dynamic visualizations, facilitating complex data interpretation and empowering administrators to refine detection strategies. The interface, integrating SHapley Additive exPlanations (SHAP) and risk assessment, enhances model transparency and interpretability, highlighting the synergy of HCI and AI. The ADEPT system is evaluated using an experimental testbed and CIoT datasets and has demonstrated over 90% accuracy in detecting high-and low-volume DDoS attacks.},
  keywords={Denial-of-service attack;Computational modeling;Quantization (signal);Accuracy;Internet of Things;Adaptation models;Convolutional neural networks;Optimization;Intrusion detection;Image edge detection;DDoS;CNN;Ensemble Learning;Differential Evolution;CIoT;LSTM;Pruning;Quantization;Security;SHAP},
  doi={10.1109/TCE.2024.3482092},
  ISSN={1558-4127},
  month={},}@ARTICLE{9760177,
  author={Tian, Ye and Pan, Jingwen and Yang, Shangshang and Zhang, Xingyi and He, Shuping and Jin, Yaochu},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Imperceptible and Sparse Adversarial Attacks via a Dual-Population-Based Constrained Evolutionary Algorithm}, 
  year={2023},
  volume={4},
  number={2},
  pages={268-281},
  abstract={The sparse adversarial attack has attracted increasing attention due to the merit of a low attack cost via changing a small number of pixels. However, the generated adversarial examples are easily detected in vision since the perturbation to each pixel is relatively large. To achieve imperceptible and sparse adversarial attacks, this article formulates a bi-objective constrained optimization problem, simultaneously minimizing the $\ell _{0}$ and $\ell _{2}$ distances to the original image, and proposes a dual-population-based constrained evolutionary algorithm to solve it. The proposed method solves the optimization problem by evolving two populations, where one population is responsible for finding feasible solutions (i.e., successful attacks) and the other one is to minimize both the $\ell _{0}$ and $\ell _{2}$ distances. Moreover, a population initialization strategy and two genetic operators are customized to accelerate the convergence speed. Experimental results indicate that the proposed method can achieve high success rates with low attack costs, and strikes a better balance between the $\ell _{0}$ and $\ell _{2}$ distances than state-of-the-art methods.},
  keywords={Perturbation methods;Optimization;Evolutionary computation;Statistics;Sociology;Costs;Task analysis;Constrained multiobjective optimization;evolutionary computation;imperceptible adversarial examples;sparse adversarial attacks},
  doi={10.1109/TAI.2022.3168038},
  ISSN={2691-4581},
  month={April},}@INPROCEEDINGS{10988134,
  author={Kumar, Neeraj and Murugan, A. S. S. and Muthurajan, S. and Chidambararaj, N. and Kumar, D Praveen Sangeeth and Pandian, Alagu Sundara},
  booktitle={2025 5th International Conference on Trends in Material Science and Inventive Materials (ICTMIM)}, 
  title={An IoT-Enabled Battery Capacity Monitoring System for Solar Panels in Electric Vehicles with Self-Attention and Bidirectional LSTM Models}, 
  year={2025},
  volume={},
  number={},
  pages={1342-1347},
  abstract={The expansion of automobiles significantly contributes to deteriorating air quality by augmenting the demand for non-renewable fossil fuels. Solar panels incorporated within EV provide a viable energy solution that may address this issue. Nonetheless, there are challenges to address during this transition, particularly with energy efficiency and battery management. This study concentrates on efficient energy usage, analyzing the components of electric vehicles' battery management systems and their interrelations. A significant issue in charging electric vehicle batteries is the inefficiency that arises when cells with a high SOC charge more rapidly than those with a low SOC. Particle swarm optimization was employed to minimize features, while z-score normalization was utilized to preprocess data for optimal performance. To enhance analytical efficiency, the proposed SA-BiLSTM model integrates a self-attention mechanism with multi-channel features, enabling it to replicate the capabilities of solar panels in electric vehicles without necessitating manual panel arrangement. Achieving a classification accuracy of 97.37%, SA-BiLSTM existing methodologies, as per performance assessment. The results indicate that solar panels in electric vehicles can address battery optimization issues and enhance sustainability. Future research should focus on enhancing these strategies for improved integration with RES in real-world applications.},
  keywords={Renewable energy sources;Accuracy;Battery management systems;Electric vehicles;Fossil fuels;Batteries;Solar panels;State of charge;Particle swarm optimization;Optimization;Renewable Energy Resources (RES);State of Charge (SoC);Particle Swarm Optimization (PSO);Electric Vehicle (EV);Long-Short Term Memory (LSTM)},
  doi={10.1109/ICTMIM65579.2025.10988134},
  ISSN={},
  month={April},}@INPROCEEDINGS{10796285,
  author={Nahid, Mehzabul Hoque and Rabbani, Golam Mustafa Md. Nurullah and Mona, Lagina and Anwar, Md. Aftab and Baijed, Mohammad},
  booktitle={2024 IEEE International Conference on Computing, Applications and Systems (COMPAS)}, 
  title={Exploring factors affecting tertiary students’ stickiness with Edu-Tech GPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Students from Generation Z receive individualized help through brainstorming and suggestions, as well as access to quality knowledge through Edu-Tech GPT. This study investigates the factors that contribute to the engagement and adherence of tertiary students with these tools, particularly focusing on the use of explainable AI in academic research among digitally divided nations. A conceptual framework with four reflective dimensions derived from literature on adapted Diffusion of Innovation theories and verified through focus group discussions. Initially, this research conducted a focus group interview of 141 Generation Z students from 10 different universities from Bangladesh who regularly use web-based Edu-Tech GPT services for their research projects. The process was able to extract four study dimensions after that conduct a survey with 26 items using purposing sampling technique. The data has been processed using Smart-PLS 4 for hypothesis testing. The results demonstrated that hedonic motivation, perceived utility, and usability have the most impact on students’ engagement with Edu-Tech GPT services. This unique research empirically examines the impact of AI-powered technologies on Edu-Tech innovation and also proposed a value proposition framework for academician and practitioners.},
  keywords={Surveys;Technological innovation;Explainable AI;Heuristic algorithms;Focusing;Usability;Particle swarm optimization;Interviews;Testing;Edu-Tech;GPT;Explainable AI;Diffusion of Innovation theory;Usability;Perceived usefulness},
  doi={10.1109/COMPAS60761.2024.10796285},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10756478,
  author={Goula, Evgenia-Maria K. and Sotiropoulos, Dimitris G.},
  booktitle={2024 Sixth International Conference on Intelligent Computing in Data Sciences (ICDS)}, 
  title={HRA: A Multi-Criteria Framework for Ranking Metaheuristic Optimization Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Metaheuristic algorithms are essential for solving complex optimization problems in different fields. However, the difficulty in comparing and rating these algorithms remains due to the wide range of performance metrics and problem dimensions usually involved. On the other hand, nonparametric statistical methods and post hoc tests are time-consuming, especially when we only need to identify the top performers among many algorithms. The Hierarchical Rank Aggregation (HRA) algorithm aims to efficiently rank metaheuristic algorithms based on their performance across many criteria and dimensions. The HRA employs a hierarchical framework that begins with collecting performance metrics on various benchmark functions and dimensions. Rank-based normalization is employed for each performance measure to ensure comparability and the robust TOPSIS aggregation is applied to combine these rankings at several hierarchical levels, resulting in a comprehensive ranking of the algorithms. Our study uses data from the CEC 2017 competition to demonstrate the robustness and efficacy of the HRA framework. It examines 30 benchmark functions and evaluates the performance of 13 metaheuristic algorithms across five performance indicators in four distinct dimensions. This presentation highlights the potential of the HRA to enhance the interpretation of the comparative advantages and disadvantages of various algorithms by simplifying practitioners' choices of the most appropriate algorithm for certain optimization problems.},
  keywords={Statistical analysis;Atmospheric measurements;Metaheuristics;Benchmark testing;Particle measurements;Robustness;Classification algorithms;MCDM;Time complexity;Multi-Criteria Decision Making (MCDM);Metaheuristic algorithms;Hierarchical Rank Aggregation;Rank-Based Normalization;Robust TOPSIS;CEC2017},
  doi={10.1109/ICDS62089.2024.10756478},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10647891,
  author={Yarici, Yavuz and Kokilepersaud, Kiran and Prabhushankar, Mohit and AlRegib, Ghassan},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={Explaining Representation Learning With Perceptual Components}, 
  year={2024},
  volume={},
  number={},
  pages={228-234},
  abstract={Self-supervised models create representation spaces that lack clear semantic meaning. This interpretability problem of representations makes traditional explainability methods ineffective in this context. In this paper, we introduce a novel method to analyze representation spaces using three key perceptual components: color, shape, and texture. We employ selective masking of these components to observe changes in representations, resulting in distinct importance maps for each. In scenarios, where labels are absent, these importance maps provide more intuitive explanations as they are integral to the human visual system. Our approach enhances the interpretability of the representation space, offering explanations that resonate with human visual perception. We analyze how different training objectives create distinct representation spaces using perceptual components. Additionally, we examine the representation of images across diverse image domains, providing insights into the role of these components in different contexts.},
  keywords={Training;Representation learning;Analytical models;Shape;Image color analysis;Semantics;Visual perception;Explainability;Representation Learning;Color;Shape;Texture},
  doi={10.1109/ICIP51287.2024.10647891},
  ISSN={2381-8549},
  month={Oct},}@INPROCEEDINGS{10838034,
  author={Rathore, Himmat and Ratnawat, Renu},
  booktitle={2024 4th Asian Conference on Innovation in Technology (ASIANCON)}, 
  title={An Explanatory Machine Learning Method for the Identification of DDoS Attacks in SDN Architectures}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Online services are the backbone of the digital world. A distributed denial of service (DDoS) attack is a persistent risk to the accessibility of internet facilities. Detecting DDoS attacks as they occur is only one of the problems; tracking down attack streams is another major obstacle to mitigation. However, DDoS attacks are difficult, if not impossible, to detect using current attack detection systems. In this paper, an innovative methodology is proposed to classify the traffic flow as DDoS attacks in software-defined networking. The proposed system is comprised of three steps. The initial stage involves pre-AI modeling explanations, where the data is presented visually to extract valuable insights. In addition, the data undergoes pre-processing to detect and eliminate any null values. One hot encoding approach is utilized to transform String features into numerical ones. The next step involves using machine learning modeling techniques, where a range of ML algorithms are applied to the pre-processed data. Out of all the ML models available, the decision tree and random forest models stand out as the top performers with an accuracy of 100%. The last step involves explaining the predictions made by the ML models. In order to clarify the predictions, Explainable Artificial Intelligence is utilized. Implementing the proposed approach in real-time will enhance the ability to precisely distinguish DDoS attacks and provide clear explanations for the predictions made.},
  keywords={Machine learning algorithms;Accuracy;Transforms;Denial-of-service attack;Prediction algorithms;Data models;Numerical models;Decision trees;Random forests;Anomaly detection;XAI;CNN;Decision tree;Random Forest;LIME},
  doi={10.1109/ASIANCON62057.2024.10838034},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10113972,
  author={Arya, Monika and Dewangan, Bhupesh Kumar and Verma, Monika and Rohini, M. and Motwani, Anand and Sar, Sumit Kumar},
  booktitle={2022 OPJU International Technology Conference on Emerging Technologies for Sustainable Development (OTCON)}, 
  title={Hybrid Nature-Inspired Based Oversampling and Feature Selection Approach for Imbalance Data Streams Classification}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={A big data stream is described using 5 $\mathrm{V}prime$s (Volume, Variety, Velocity, Variability, and Veracity). These characteristics impose various challenges. In many cases, data streams are unbalanced, making traditional data mining approaches impossible to employ. The standard data mining approaches are not suitable for imbalanced data streams for achieving analytical efficiency because they require periodic analyses, but big data requires real-time analytics. Additionally, the induction model must be re-run and rebuilt each time to add up the most recent data. Mining these unique streams, on the other hand, is one of the most intriguing research areas. Deep learning (DL) algorithms were developed to increase classification performance for issues requiring large data sets with varying types and characteristics. Feature selection (F.S.) is a critical stage in any classification application. F.S. entails eliminating superfluous and redundant characteristics, resulting in a prediction model that is more efficient, interpretable, and fast. While complete solutions are available for F.S., managing massive data streams that need instantaneous processing is challenging by its own nature. This work provides a hybrid metaheuristic strategy with FFSMOTE for oversampling imbalanced data stream and Honey Bee algorithm for feature selection. Hybridization aims to improve feature selection processes by combing the advantage of both the algorithms. Furthermore, the Ensemble Deep classifiers are used for data stream classification.},
  keywords={Metaheuristics;Big Data;Predictive models;Feature extraction;Prediction algorithms;Real-time systems;Classification algorithms;Big Data;Data Stream;Data Mining;Deep Learning;Feature Selection;SMOTE Algorithm;Honey-Bee Algorithm;Ensemble;Classification.},
  doi={10.1109/OTCON56053.2023.10113972},
  ISSN={},
  month={Feb},}@ARTICLE{10085957,
  author={Sun, Tong and Wang, Chuang and Dong, Hongli and Zhou, Yina and Guan, Chuang},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={A Novel Parameter-Optimized Recurrent Attention Network for Pipeline Leakage Detection}, 
  year={2023},
  volume={10},
  number={4},
  pages={1064-1076},
  abstract={Accurate detection of pipeline leakage is essential to maintain the safety of pipeline transportation. Recently, deep learning (DL) has emerged as a promising tool for pipeline leakage detection (PLD). However, most existing DL methods have difficulty in achieving good performance in identifying leakage types due to the complex time dynamics of pipeline data. On the other hand, the initial parameter selection in the detection model is generally random, which may lead to unstable recognition performance. For this reason, a hybrid DL framework referred to as parameter-optimized recurrent attention network (PRAN) is presented in this paper to improve the accuracy of PLD. First, a parameter-optimized long short-term memory (LSTM) network is introduced to extract effective and robust features, which exploits a particle swarm optimization (PSO) algorithm with cross-entropy fitness function to search for globally optimal parameters. With this framework, the learning representation capability of the model is improved and the convergence rate is accelerated. Moreover, an anomaly-attention mechanism (AM) is proposed to discover class discriminative information by weighting the hidden states, which contributes to amplifying the normal-abnormal distinguishable discrepancy, further improving the accuracy of PLD. After that, the proposed PRAN not only implements the adaptive optimization of network parameters, but also enlarges the contribution of normal-abnormal discrepancy, thereby overcoming the drawbacks of instability and poor generalization. Finally, the experimental results demonstrate the effectiveness and superiority of the proposed PRAN for PLD.},
  keywords={Adaptation models;Adaptive systems;Pipelines;Signal processing algorithms;Transportation;Feature extraction;Classification algorithms;Anomaly-attention mechanism (AM);long short-term memory (LSTM);parameter-optimized recurrent attention network (PRAN);particle swarm optimization (PSO);pipeline leakage detection (PLD)},
  doi={10.1109/JAS.2023.123180},
  ISSN={2329-9274},
  month={April},}@INPROCEEDINGS{10261049,
  author={Bai, Xue and Zhang, Zhe},
  booktitle={2023 12th International Conference of Information and Communication Technology (ICTech)}, 
  title={Regional Air Quality Prediction Model Based on Deep Belief Network}, 
  year={2023},
  volume={},
  number={},
  pages={626-632},
  abstract={Air quality prediction is of great significance for the daily travel of the public, the government to control air pollution and promote green development. In view of the problem that most current researches in the field is the daily prediction of air quality index, there are few studies on the prediction of a variety of specific pollutant concentrations. In this paper, a Deep Belief Network-Extreme Learning Machine (DBN-ELM) air quality prediction model combined with attention mechanism is proposed. Firstly, DBN is used to extract the features of air quality data, and the robustness of network is enhanced by using the improved particle swarm optimization algorithm to optimize initial weights. To address the spatial correlation of air quality in the region, the attention mechanism is used to fuse the features of data from different monitoring sites, and the fused feature data are input into ELM for prediction, then the hourly concentrations of six air pollutants are obtained. The experimental results show that the prediction results of the proposed model are better than other comparison models, and it has good prediction performance, which provides a new idea for the field of air quality prediction.},
  keywords={Fuses;Atmospheric modeling;Predictive models;Air quality;Prediction algorithms;Feature extraction;Air pollution;Air quality prediction;deep belief network;particle swarm optimization;attention mechanism;extreme learning machine},
  doi={10.1109/ICTech58362.2023.00120},
  ISSN={},
  month={April},}@INPROCEEDINGS{10635105,
  author={Dolci, Giorgio and Cruciani, Federica and Brusini, Lorenza and Pini, Lorenzo and Galazzo, Ilaria Boscolo and Calhoun, Vince D. and Menegaz, Gloria},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)}, 
  title={Diffusion MRI Allows Capturing the Amyloid-β and τ Proteins Status in Alzheimer’s Disease Continuum}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Alzheimer’s Disease (AD) is a neurodegenerative process characterized by the accumulation of amyloid-β (Aβ) and tau (τ) proteins leading to neurodegeneration. It has been hypothesizes that the aggregation of these proteins could spread through specific white matter (WM) pathways. To investigate such hypothesis, convolutional neural networks were employed to analyze microstructural alterations induced by the accumulation of Aβ and τ proteins via two classification tasks, relying on mean diffusivity (MD) and fractional anisotropy (FA), achieving competitive performance. A post-hoc analysis via integrated gradients revealed that the splenium of the corpus callosum played a prominent role for both indices, while index-specific were the ventricles and subcortical regions for MD and the corticospinal tract for FA. This supports the assumption that WM pathways might play a key role in misfolded protein distribution and highlights the potential of diffusion imaging for the identification of Aβ and τ proteins spread and accumulation.},
  keywords={Proteins;Protein engineering;Pathology;Microstructure;Convolutional neural networks;Alzheimer's disease;White matter;Amyloid-beta;Tau protein;Diffusion MRI;Deep learning;Explainable AI},
  doi={10.1109/ISBI56570.2024.10635105},
  ISSN={1945-8452},
  month={May},}@INPROCEEDINGS{9995667,
  author={Zhong, Yuting and Yan, Bowei and Liu, KunHong and Xu, Yong and He, Song and Bo, Xiaochen},
  booktitle={2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={A Multi-View Learning-Based Rule Extraction Algorithm For Accurate Hepatotoxicity Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={1423-1428},
  abstract={Hepatotoxicity prediction is key to diseases with the high mortality rate. However, most of the algorithms used by now are black box in nature and lack of clear interpretability. This paper proposes a genetic algorithm-based interpretable algorithm based on rules extracted from a random forest. To take advantages from different types of omics data and molecular representations gathered from various datasets, our algorithm utilizes multiple distinct features to form a multi-view learning strategy. In detail, the genetic algorithm is designed to select optimal rules from each view, which are then used to form the ensemble of multi-view rule sets. The experiments are carried out to verify the performance of our algorithm on the hepatotoxicity data. The results confirm that our algorithm can gain high accuracy in most cases with more compact and shorter rules, compared with the original random forest or other rule-based algorithms. Our python source code and the related Supplementary Materials are available at: github.com/MLDMXM2017/MVR-GA.},
  keywords={Drugs;Machine learning algorithms;Source coding;Predictive models;Prediction algorithms;Feature extraction;Excavation;Hepatotoxicity Prediction;Interpretable Machine Learning;Genetic Algorithm;Rules;Multi-view Learning},
  doi={10.1109/BIBM55620.2022.9995667},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10431571,
  author={Rai, Swati and Bhatt, Jignesh S. and Patra, Sarat Kumar and Ambadkar, Tanmay},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={A Cognitive Behavioral AI: Novel Conversational Memory Elements for Technical Understanding of Medical Deep Denoisers}, 
  year={2023},
  volume={},
  number={},
  pages={41-48},
  abstract={Conversation is a powerful cognitive behavioral mechanism for revealing what is understood. In this paper, we propose conversational memory elements (CMEs) to (technically) comprehend the learning functional by state-of-the-art medical deep denoisers. The gradients of neurons' weights, varying over the epochs, are utilized to build the novel CMEs. These are defined in terms of Jacobian matrices and integrated in between layers of the medical deep denoisers without affecting their neural architectures. A covariance map is then defined using values of CME at the convergence of training a denoiser; while an autocorrelation function is derived considering values of CMEs over the epochs. In turn, these statistical indicators are used to infer gross characterizations of the unknown denoising functional in terms of joint probability function expressed by the hidden weights. The ability of learning is quantified via patterns in the covariance maps, while the autocorrelation function help understanding the stability and convergence of deep denoisers. It is further cross-validated against denoising performance analysis on benchmark synthetic and real medical datasets and found consistent. Besides, the proposed approach assists suggesting optimal convergence as well as a deployment strategy among available medical deep denoisers.},
  keywords={Training;Noise reduction;Probability;Stability analysis;Behavioral sciences;Autocorrelation;Convergence;Cognitive machine learning;Conversational memory element;Deep learning;Denoising},
  doi={10.1109/CogMI58952.2023.00016},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9892433,
  author={Shu, Hai and Shi, Ronghua and Jia, Qiran and Zhu, Hongtu and Chen, Ziqi},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={mFI-PSO: A Flexible and Effective Method in Adversarial Image Generation for Deep Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={01-08},
  abstract={Deep neural networks (DNNs) have achieved great success in image classification, but can be very vulnerable to adversarial attacks with small perturbations to images. To improve adversarial image generation for DNNs, we develop a novel method, called mFI-PSO, which utilizes a Manifold-based First-order Influence measure for vulnerable image and pixel selection and the Particle Swarm Optimization for various objective functions. Our mFI-PSO can thus effectively design adversarial images with flexible, customized options on the number of perturbed pixels, the misclassification probability, and the targeted incorrect class. Experiments demonstrate the flexibility and effectiveness of our mFI-PSO in adversarial attacks and its appealing advantages over some popular methods.},
  keywords={Manifolds;Deep learning;Image synthesis;Atmospheric measurements;Perturbation methods;Neural networks;Particle measurements;adversarial attack;influence measure;particle swarm optimization;perturbation manifold},
  doi={10.1109/IJCNN55064.2022.9892433},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10612105,
  author={Ain, Qurrat UI and Al-Sahaf, Harith and Xue, Bing and Zhang, Mengjie},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Exploring Genetic Programming Models in Computer-Aided Diagnosis of Skin Cancer Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Extracting important information from complex skin lesion images is vital to effectively distinguish between different types of skin cancer images. In addition to providing high classification performance, such computer-aided diagnostic methods are needed where the models are interpretable and can provide knowledge about the discriminative features in skin lesion images. This underlying information can significantly assist dermatologists in identifying a particular stage or type of cancer. With its flexible representation and global search abilities, Genetic Programming (GP) is an ideal learning al-gorithm to evolve interpretable models and identify important features with significant information to discriminate between skin cancer classes. This paper provides an in-depth analysis of a recent GP-based feature learning method where different well-developed feature descriptors are integrated into the learning algorithms to extract high-level features for skin cancer image classification. The study explores the effectiveness of utilizing feature learning for this complex task and designing program structure to suit the problem domain as it has shown promising results compared to commonly used feature descriptors and an existing GP-based feature learning method developed for general image classification. This study analyzes the GP-evolved models to identify the prominent features and most effective feature descriptors important for the classification of these skin cancer images. The evolved models are interpretable, they provide knowledge that can assist dermatologists in making diagnoses in real-time clinical situations by identifying prominent skin cancer characteristics captured by the feature descriptors and learned during the evolutionary process.},
  keywords={Representation learning;Visualization;Computational modeling;Genetic programming;Feature extraction;Skin;Lesions;Image Classification;Skin Cancer Detection;Genetic Programming;Feature Extraction},
  doi={10.1109/CEC60901.2024.10612105},
  ISSN={},
  month={June},}@ARTICLE{10464337,
  author={Efe, Mehmet Önder and Kürkçü, Burak and Kasnakoǧlu, Coşku and Mohamed, Zaharuddin and Liu, Zhijie},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Switched Neural Networks for Simultaneous Learning of Multiple Functions}, 
  year={2024},
  volume={8},
  number={4},
  pages={3095-3104},
  abstract={This paper introduces the notion of switched neural networks for learning multiple functions under different switching configurations. The neural network structure has adjustable parameters and for each function the state of the parameter vector is determined by a mask vector, 1/0 for active/inactive or +1/-1 for plain/inverted. The optimization problem is to schedule the switching strategy (mask vector) required for each function together with the best parameter vector (weights/biases) minimizing the loss function. This requires a procedure that optimizes a vector containing real and binary values simultaneously to discover commonalities among various functions. Our studies show that a small sized neural network structure with an appropriate switching regime is able to learn multiple functions successfully. During the tests focusing on classification, we considered 2-variable binary functions and all 16 combinations have been chosen as the functions. The regression tests consider four functions of two variables. Our studies showed that simple NN structures are capable of storing multiple information via appropriate switching.},
  keywords={Artificial neural networks;Optimization;Genetic algorithms;Switches;Task analysis;Training;Neural networks;Genetic algorithms;Neural networks;parameter switching;learning multiple functions;genetic algorithms},
  doi={10.1109/TETCI.2024.3369981},
  ISSN={2471-285X},
  month={Aug},}@ARTICLE{10266760,
  author={Zheng, Weijie and Doerr, Benjamin},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Runtime Analysis for the NSGA-II: Proving, Quantifying, and Explaining the Inefficiency for Many Objectives}, 
  year={2024},
  volume={28},
  number={5},
  pages={1442-1454},
  abstract={The nondominated sorting genetic algorithm II (NSGA-II) is one of the most prominent algorithms to solve multiobjective optimization problems. Despite numerous successful applications, several studies have shown that the NSGA-II is less effective for larger numbers of objectives. In this work, we use mathematical runtime analyses to rigorously demonstrate and quantify this phenomenon. We show that even on the simple  $m$ -objective generalization of the discrete OneMinMax benchmark, where every solution is Pareto optimal, the NSGA-II also with large population sizes cannot compute the full Pareto front (objective vectors of all Pareto optima) in subexponential time when the number of objectives is at least three. The reason for this unexpected behavior lies in the fact that in the computation of the crowding distance, the different objectives are regarded independently. This is not a problem for two objectives, where any sorting of a pairwise incomparable set of solutions according to one objective is also such a sorting according to the other objective (in the inverse order).},
  keywords={Runtime;Statistics;Sociology;Benchmark testing;Optimization;Sorting;Evolutionary computation;Many-objective optimization;nondominated sorting genetic algorithm II (NSGA-II);runtime analysis;theory of computing},
  doi={10.1109/TEVC.2023.3320278},
  ISSN={1941-0026},
  month={Oct},}@ARTICLE{9919314,
  author={Bi, Ying and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Genetic Programming-Based Evolutionary Deep Learning for Data-Efficient Image Classification}, 
  year={2024},
  volume={28},
  number={2},
  pages={307-322},
  abstract={Data-efficient image classification is a challenging task that aims to solve image classification using small training data. Neural network-based deep learning methods are effective for image classification, but they typically require large-scale training data and have major limitations, such as requiring expertise to design network architectures and having poor interpretability. Evolutionary deep learning (EDL) is a recent hot topic that combines evolutionary computation with deep learning. However, most EDL methods focus on evolving architectures of neural networks, which still suffers from limitations such as poor interpretability. To address this, this article proposes a new genetic programming-based EDL approach to data-efficient image classification. The new approach can automatically evolve variable-length models using many important operators from both image and classification domains. It can learn different types of image features from color or grayscale images, and construct effective and diverse ensembles for image classification. A flexible multilayer representation enables the new approach to automatically construct shallow or deep models/trees for different tasks and perform effective transformations on the input data via multiple internal nodes. The new approach is applied to solve five image classification tasks with different training set sizes. The results show that it achieves a better performance in most cases than deep learning methods for data-efficient image classification. A deep analysis shows that the new approach has good convergence and evolves models with high interpretability, different lengths/sizes/shapes, and good transferability.},
  keywords={Image classification;Deep learning;Artificial neural networks;Task analysis;Training;Computer architecture;Computational modeling;Deep learning;evolutionary computation (EC);evolutionary deep learning (EDL);genetic programming (GP);image classification;small data},
  doi={10.1109/TEVC.2022.3214503},
  ISSN={1941-0026},
  month={April},}@ARTICLE{11052213,
  author={El-Khalek, Aya A. Abd and Balaha, Hossam Magdy and Azam, Mohamed T. and Sewelam, Ashraf and Ghazal, Mohammed and Khalil, Abeer T. and Abo-Elsoud, Mohy Eldin A. and El-Baz, Ayman},
  journal={IEEE Access}, 
  title={XV-AMD: An Explainable Vision Transformer Detection Framework for Age-Related Macular Degeneration Using Fundus Imaging}, 
  year={2025},
  volume={13},
  number={},
  pages={113967-113983},
  abstract={Age-related macular degeneration (AMD) is a leading cause of visual impairment in adults over 50 years of age and is characterized by progressive damage to the macula, leading to challenges in daily activities such as reading and driving. This study introduces the XV-AMD (An Explainable Vision Transformer Detection for Age-Related Macular Degeneration) framework, which uses Vision Transformers (ViTs) and SHapley Additive exPlanations (SHAPs) for the diagnosis and explainability of AMD. Through a systematic preprocessing pipeline, including average cumulative distribution function (CDF) calculation and contrast limited adaptive histogram equalization (CLAHE), our approach enhances image quality and prepares data for analysis. We classify color fundus images into four distinct AMD categories, namely, normal, geographic atrophy (GA), intermediate AMD, and wet AMD, demonstrating the framework’s effectiveness in a clinical context. The experimental results reveal that our ViT-based model not only improves diagnostic accuracy but also facilitates the understanding of decision-making processes, thus supporting early detection and intervention strategies in AMD management. In addition, a 99.54% classification accuracy was attained, with a sensitivity of 99.54%, specificity of 99.85%, precision of 99.54%, and F1 of 99.54%. This research shows the promise of AI and deep learning in improving AMD diagnoses and identifies future paths for boosting model performance and interpretability in medical imaging applications.},
  keywords={Retina;Transformers;Accuracy;Solid modeling;Diseases;Macular degeneration;Data models;Computer vision;Analytical models;Image color analysis;Deep learning (DL);computer aided diagnosis (CAD);eXplainable artificial intelligence (XAI);age-related macular degeneration (AMD)},
  doi={10.1109/ACCESS.2025.3583555},
  ISSN={2169-3536},
  month={},}@ARTICLE{10759644,
  author={Ye, Hengzhou and Tang, Peikang and Wen, Haoxiang and Li, Shiying},
  journal={IEEE Access}, 
  title={PSO-VMD-Informer: A New Edge Load Prediction Method}, 
  year={2024},
  volume={12},
  number={},
  pages={174983-174995},
  abstract={In edge computing systems, efficient load prediction plays an important role in optimizing resource allocation and efficient utilization of edge service providers, as well as maintaining stable service quality. Due to the high dynamics of edge computing environments, the load data characteristics of different edge servers are significantly different, which seriously affects the accuracy and generalization ability of load prediction. This paper proposes a new edge load prediction method, called PSO-VMD-Informer. This method first uses Variational Mode Decomposition (VMD) to decompose the edge load data sequence into stable intrinsic mode functions to effectively extract nonlinear features; then the Particle Swarm Optimization (PSO) algorithm is used to optimize the intrinsic mode function and penalty factor of VMD to improve the subsequence extraction quality and enhance the generalization ability of the model; finally, the Informer model is used to predict the edge load using the encoder-decoder architecture and self-attention mechanism. A large number of experimental results based on real edge load datasets show that compared with other mainstream methods, the PSO-VMD-Informer model shows the best performance on different edge server data and different prediction lengths, especially significantly outperforming other models in the MAE indicator. Compared with the other three mainstream methods, the proposed method reduces MAE, RMSE, and MAPE by 41.61%, 27.43%, and 11.21% respectively.},
  keywords={Load modeling;Predictive models;Computational modeling;Feature extraction;Data models;Accuracy;Servers;Cloud computing;Resource management;Deep learning;Edge computing;load forecasting;variational mode decomposition;particle swarm optimization},
  doi={10.1109/ACCESS.2024.3503584},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10594151,
  author={Qin, Huiping},
  booktitle={2024 Second International Conference on Data Science and Information System (ICDSIS)}, 
  title={A Facial Feature Recognition-based System for Evaluation of Teaching Quality in College English Classrooms}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The quick advancement of big data technology has contributed to a greater importance of online learning, thus particularly in the way of online courses. A face feature recognition-based approach is proposed for evaluating the quality of teaching in English classrooms. An Improved Cat Swarm Optimization (ICSO) approach is proposed to tuning the hyperparameter to adjust DenseNet 121 for accurately determining whether the mouth and eyes are open or closed. For increasing recognition accuracy, Attention Mechanism (AM) is used with DenseNet121 to avoid over-fitting issue. Due to its compact size and efficient architecture, the over fitting issue in the channel attention network also avoided. Lastly, the learning focus of the learners is assessed using the fuzzy comprehensive assessment approach. The findings of the simulation studies demonstrate that the DenseNet121-AM-ICSO outperforms the conventional approaches such as Multitask Convolutional Neural Network (MT-CNN) and Spatial AM with Residual Network (Sd_ResNeSt) a higher recognition accuracy of 99.79%.},
  keywords={Accuracy;Face recognition;Education;Fitting;Mouth;Particle swarm optimization;Tuning;Attention Mechanism;DenseNet121;Face Feature Recognition;Hyperparameter Tuning;Online Learning},
  doi={10.1109/ICDSIS61070.2024.10594151},
  ISSN={},
  month={May},}@ARTICLE{10720678,
  author={Rong, Yibiao and Lin, Tian and Chen, Haoyu and Fan, Zhun and Chen, Xinjian},
  journal={IEEE Transactions on Image Processing}, 
  title={Searching Discriminative Regions for Convolutional Neural Networks in Fundus Image Classification With Genetic Algorithms}, 
  year={2024},
  volume={33},
  number={},
  pages={5949-5958},
  abstract={Deep convolutional neural networks (CNNs) have been widely used for fundus image classification and have achieved very impressive performance. However, the explainability of CNNs is poor because of their black-box nature, which limits their application in clinical practice. In this paper, we propose a novel method to search for discriminative regions to increase the confidence of CNNs in the classification of features in specific category, thereby helping users understand which regions in an image are important for a CNN to make a particular prediction. In the proposed method, a set of superpixels is selected in an evolutionary process, such that discriminative regions can be found automatically. Many experiments are conducted to verify the effectiveness of the proposed method. The average drop and average increase obtained with the proposed method are 0 and 77.8%, respectively, in fundus image classification, indicating that the proposed method is very effective in identifying discriminative regions. Additionally, several interesting findings are reported: 1) Some superpixels, which contain the evidence used by humans to make a certain decision in practice, can be identified as discriminative regions via the proposed method; 2) The superpixels identified as discriminative regions are distributed in different locations in an image rather than focusing on regions with a specific instance; and 3) The number of discriminative superpixels obtained via the proposed method is relatively small. In other words, a CNN model can employ a small portion of the pixels in an image to increase the confidence for a specific category.},
  keywords={Image classification;Visualization;Glaucoma;Genetic algorithms;Deep learning;Convolutional neural networks;Search problems;Optical imaging;Fans;Data models;Discriminative regions;genetic algorithms;convolutional neural networks;fundus image classification},
  doi={10.1109/TIP.2024.3477932},
  ISSN={1941-0042},
  month={},}@ARTICLE{10375812,
  author={Singh, Pratima and Jain, Amita},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Context-Aware Civil Unrest Event Prediction Using Neutrosophic-Aspect-Based Sentiment Analysis, PSO, and Hierarchical LSTM}, 
  year={2024},
  volume={11},
  number={3},
  pages={3667-3677},
  abstract={Civil unrest is among the important hurdles in the countries’ progress as it deteriorates gross domestic product (GDP), international relations, foreign direct investment (FDI), globalization, public opinion, tourism, and businesses. Due to civil unrest a variety of serious problems, viz. loss of life/injury, resources, political stability, and human rights occur. Recently, few researchers have given insights on the prediction of occurrences of civil unrest events by using hypothesis testing and some basic machine/deep learning models. Important factors such as people’s emotions/sentiments, contextual information, and civil unrest events feature’ importance are ignored presently. For the first time, the proposed work overcomes all these research gaps by hybridizing the neutrosophic set, aspect-based sentiment analysis, particle swarm optimization (PSO), and hierarchical long short-term memory (hierarchical LSTM). Neutrosophic set along with aspect-based sentiment analysis has been used to get the sentiment and features’ importance. The resulting features’ weights have been optimized using PSO. For a more comprehensive understanding of the input sequence and feature weights, hierarchical LSTM has been used. Doing so obtained results that are more accurately improved for civil unrest events prediction. The performance of the proposed model has been evaluated and compared with state of art methods. Experimentation and evaluation show the proposed model outperforms the baseline methods by 3% to 15% on the standard datasets in terms of accuracy.},
  keywords={Data mining;Feature extraction;Predictive models;Hidden Markov models;Sentiment analysis;Analytical models;Social networking (online);Aspect-based sentiment analysis;civil unrest;event prediction;long short-term memory (LSTM);neutrosophic set;particle swarm optimization (PSO)},
  doi={10.1109/TCSS.2023.3338509},
  ISSN={2329-924X},
  month={June},}@INPROCEEDINGS{11043053,
  author={Cenikj, Gjorgjina and Petelin, Gašper and Eftimov, Tome},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={ClustOpt: A Clustering-Based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Understanding the behavior of numerical metaheuristic optimization algorithms is critical for advancing their development and application. Traditional visualization techniques, such as convergence plots, trajectory mapping, and fitness landscape analysis, often fall short in illustrating the structural dynamics of the search process, especially in high-dimensional or complex solution spaces. To address this, we propose a novel representation and visualization methodology that clusters solution candidates explored by the algorithm and tracks the evolution of cluster memberships across iterations, offering a dynamic and interpretable view of the search process. Additionally, we introduce two metrics – algorithm stability and algorithm similarity – to quantify the consistency of search trajectories across runs of an individual algorithm and the similarity between different algorithms, respectively. We apply this methodology on a set of ten numerical metaheuristic algorithms, revealing insights into their stability and comparative behaviors, thereby providing a deeper understanding of their search dynamics.},
  keywords={Visualization;Sensitivity;Heuristic algorithms;Metaheuristics;Clustering algorithms;Stability analysis;Libraries;Trajectory;Planning;Numerical stability;algorithm trajectory representations;optimization algorithm analysis},
  doi={10.1109/CEC65147.2025.11043053},
  ISSN={},
  month={June},}@INPROCEEDINGS{10859451,
  author={Sree, Jamalpur Navya and Charan, Gade and Kanishka, Sriramoju and Ramana, Kadiyala},
  booktitle={2024 9th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={Advancements in Handwritten Character Recognition: A Comprehensive Review}, 
  year={2024},
  volume={},
  number={},
  pages={1817-1823},
  abstract={Handwritten English character recognition is based on deep learning techniques, including CNNs, hybrid models, and optimization methods. This review focuses on advancements in handwritten English character recognition techniques. From feature-based techniques, this HCR system evolved into the new deep learning approach, where the use of CNNs was proven superior to the existing techniques in both character and digit recognition accuracies. However, there are challenges as well, especially in dealing with complex handwriting styles that pose the challenge of understanding the sequential nature of characters. To overcome such limitations, several hybrid and enhanced models have been proposed. Recent studies have introduced methods like CNNs combined with extended local binary patterns (ELBPs), through which better features can be extracted but difficult with cursive handwriting. Other works focused on control mechanisms, Gated-CNN-BGRU architecture design, in order to relieve the complexity and noise of handwriting images, simultaneously solving the scale issue. And the optimization methods with particle swarm optimization and CNN showed accuracy improvement but were sensitive to image quality. In this review, results from some papers have been integrated together with evaluation of the strengths and weaknesses in present methods. The aim is to provide a comprehensive understanding of current challenges and propose future directions for developing more robust and accurate HCR systems.},
  keywords={Deep learning;Adaptation models;Accuracy;Reviews;Computational modeling;Optimization methods;Logic gates;Feature extraction;Character recognition;Particle swarm optimization;Handwritten English character recognition (HCR);Convolutional Neural Networks (CNNs);Extended Local Binary Patterns (ELBPs);Gated-CNN-BGRU architecture;Particle Swarm Optimization},
  doi={10.1109/ICCES63552.2024.10859451},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9776145,
  author={Yang, Lu and He, Fazhi and Dai, Li and Zhang, Lin},
  booktitle={2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={An Automatical And Efficient Image Classification Based On Improved Genetic Programming}, 
  year={2022},
  volume={},
  number={},
  pages={477-483},
  abstract={Image classification is a basic task in machine intelligence, but challenging due to high variations across images. Traditional methods use hand-crafted features to solve it, which require much domain knowledge. Genetic Programming (GP) can automatically solve problems without much knowledge about the structure and form of the solution. And GP is interpretable and needs less time to adjust the parameters compared with deep image classification methods. However, the existing GP-based image classification methods have some disadvantages, such as poor classification performance and long training time. This paper proposed a new image classification algorithm based on multilayer genetic programming with cache (MCGP). MCGP designs a new hierarchical individual program structure with a classification layer and uses a subtree cache strategy to reduce training time. The experiments show that MCGP can get better or competitive results compared with traditional methods, other GP methods, and convolutional neural network methods. In addition, the training speed of MCGP is much faster than other GP methods.},
  keywords={Training;Conferences;Genetic programming;Nonhomogeneous media;Collaborative work;Computational efficiency;Convolutional neural networks;Genetic programming;Image classification;Evolutionary computation;Machine learning;Machine Intelligence},
  doi={10.1109/CSCWD54268.2022.9776145},
  ISSN={},
  month={May},}@INPROCEEDINGS{10704419,
  author={Zhong, Rui and Cao, Yang and Yu, Jun and Munetomo, Masaharu},
  booktitle={2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS)}, 
  title={Large Language Model Assisted Adversarial Robustness Neural Architecture Search}, 
  year={2024},
  volume={},
  number={},
  pages={433-437},
  abstract={Large Language Models (LLMs) have shown signif-icant promise as evolutionary optimizers. This paper introduces a novel LLM-based Optimizer (LLMO) to address Neural Archi-tecture Search Considering Adversarial Robustness (ARNAS), a classic combinatorial optimization problem. Using the standard CRISPE framework, we design the prompt and employ Gemini to iteratively refine solutions based on its responses. In our numerical experiments, we investigate the performance of LLMO on NAS-Bench-201-based ARNAS tasks with CIFAR-IO and CIFAR-IOO datasets. The results, compared with six well-known metaheuristic algorithms (MHAs), highlight the superiority and competitiveness of using LLMs as combinatorial optimizers. The source code is available at https://github.com/RuiZhong961230/LLMO.},
  keywords={Large language models;Source coding;Metaheuristics;Search problems;Robustness;Complex systems;Optimization;Standards;Large Language Models (LLMs);Adversarial Attack;Neural Architecture Search (NAS);Combinatorial Optimizer},
  doi={10.1109/DOCS63458.2024.10704419},
  ISSN={},
  month={Aug},}@ARTICLE{9779792,
  author={Lai, Gorm and Leymarie, Frederic Fol and Latham, William},
  journal={IEEE Transactions on Games}, 
  title={On Mixed-Initiative Content Creation for Video Games}, 
  year={2022},
  volume={14},
  number={4},
  pages={543-557},
  abstract={In this article, we present a survey of mixed-initiative methods for the creation of content for video games. We also propose a definition of what mixed initiative implies, as the term lacks a clear specification. The survey includes works not directly aimed at video games but which create content that can potentially be used in games, such as art programs utilizing mixed initiative. Furthermore, we highlight research areas that overlap wholly or partly with mixed initiative, such as casual creators, explainable artificial intelligence, or interactive evolutionary computation. We examine these and several other topics in the context of mixed initiative. Finally, we provide a catalogue of typical techniques and challenges connected with mixed initiative before considering future directions.},
  keywords={Games;Visualization;Phonocardiography;Creativity;Task analysis;Machine learning;Production;Co-creativity;experience-driven procedural content generation (EDPCG);interactive evolutionary computation (IEC);mixed initiative;mutant shopping;procedural content generation (PCG);procedural content generation via machine learning (PCGML);user fatigue;video games},
  doi={10.1109/TG.2022.3176215},
  ISSN={2475-1510},
  month={Dec},}@ARTICLE{10854879,
  author={Hancer, Emrah and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={A Many-Objective Diversity-Guided Differential Evolution Algorithm for Multi-Label Feature Selection in High-Dimensional Datasets}, 
  year={2025},
  volume={9},
  number={2},
  pages={1226-1237},
  abstract={Multi-label classification (MLC) is crucial as it allows for a more nuanced and realistic representation of complex real-world scenarios, where instances may belong to multiple categories simultaneously, providing a comprehensive understanding of the data. Effective feature selection in MLC is paramount as it cannot only enhance model efficiency and interpretability but also mitigate the curse of dimensionality, ensuring more accurate and streamlined predictions for complex, multi-label data. Despite the proven efficacy of evolutionary computation (EC) techniques in enhancing feature selection for multi-label datasets, research on feature selection in MLC remains sparse in the domain of multi- and many-objective optimization. This paper proposes a many-objective differential evolution algorithm called MODivDE for feature selection in high-dimensional MLC tasks. The MODivDE algorithm involves multiple improvements and innovations in quality indicator-based selection, logic-based search strategy, and diversity-based archive update. The results demonstrate the exceptional performance of the MODivDE algorithm across a diverse range of high-dimensional datasets, surpassing recently introduced many-objective and conventional multi-label feature selection algorithms. The advancements in MODivDE collectively contribute to significantly improved accuracy, efficiency, and interpretability compared to state-of-the-art methods in the realm of multi-label feature selection.},
  keywords={Feature extraction;Measurement;Optimization;Vectors;Convergence;Computational modeling;Search problems;Linear programming;Evolutionary computation;Accuracy;Multi-label feature selection;differential evolution;multi-label classification},
  doi={10.1109/TETCI.2025.3529840},
  ISSN={2471-285X},
  month={April},}@ARTICLE{11075776,
  author={Jin Kim, Kyeong and Hoon Park, Ji and Hoo Min, Dong and Guy Min, Seun},
  journal={IEEE Access}, 
  title={Data-Driven Optimization of Aspect Ratio in Permanent Magnet Machines Using Deep Learning and SHAP Analysis}, 
  year={2025},
  volume={13},
  number={},
  pages={122164-122174},
  abstract={The aspect ratio, defined as the ratio of the outer diameter to the stack length, is a critical parameter in permanent magnet (PM) machine design, with a profound impact on motor performance. This study presents a novel framework integrating deep learning and Shapley additive explanations (SHAP) to analyze the influence of design variables on the optimal aspect ratio. To achieve this, extensive datasets are generated using a metaheuristic optimization algorithm, covering diverse scenarios and objectives to ensure robust generalization and accuracy. A deep learning model is then trained on these datasets to capture the complex, nonlinear relationships between design variables and the aspect ratio. To enhance the interpretability of the “opaque model”, SHAP is employed, providing a detailed attribution analysis of each design variable contribution to the aspect ratio. This dual approach successfully uncovers the complex relationships between the aspect ratio and design variables across diverse design scenarios, thereby enabling actionable guidelines for sizing the outer diameter and height of the motor in the early design phase. Furthermore, the proposed methodology offers a scalable framework for analyzing other key ratios in motor design, establishing itself as a foundational tool for future advancements in this field.},
  keywords={Optimization;Deep learning;Analytical models;Motors;Artificial neural networks;Linear programming;Accuracy;Training;Torque;Symbols;Aspect ratio;deep learning;explainable artificial intelligence;optimization;permanent magnet synchronous machine;Shapley additive explanation (SHAP) values},
  doi={10.1109/ACCESS.2025.3586216},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10152841,
  author={Liu, Jiahui and Yang, Lvqing and Chen, Sien and Dong, Wensheng and Yu, Bo and Wang, Qingkai},
  booktitle={2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={An Improved MOEA Based on Adaptive Adjustment Strategy for Optimizing Deep Model of RFID Indoor Positioning}, 
  year={2023},
  volume={},
  number={},
  pages={357-362},
  abstract={Nowadays, IoT technology is developing rapidly and RFID (Radio Frequency Identification) based indoor positioning problems can be performed using deep learning and intelligent optimization algorithms. Deep models can analyze and predict the localization problem as a regression problem to achieve high accuracy positioning. Meanwhile, to ensure the accuracy of the model, we need to find excellent hyperparameters, which requires the support of optimization algorithms, but existing optimization algorithms do not allow flexible adaptation according to the optimization phase and there is room for improvement. In this paper, we propose a deep model, called CTT, and a multi-objective evolutionary algorithm (MOEA) based on a neighborhood adaptive adjustment strategy, called MOEA-NAAS. The experimental results show that CTT optimized by the NAAS algorithm is significantly more accurate and stable in the localization problem, with significant improvements in the three main metrics, proving the usability of the optimization algorithm. At the same time, the localization effect of the CTT also shows obvious advantages. In the future, the optimized algorithm can be combined with other deep models and widely used in various high-precision indoor positioning.},
  keywords={Location awareness;Measurement;Deep learning;Adaptation models;Heuristic algorithms;Prediction algorithms;Feature extraction;Indoor positioning;RFID;Deep learning;MOEA},
  doi={10.1109/CSCWD57460.2023.10152841},
  ISSN={2768-1904},
  month={May},}@INPROCEEDINGS{10908297,
  author={Yaicharoen, Auapong and Mai, Nghia Thi and Hashikura, Kotaro and Kamal, Md Abdus Samad and Murakami, Iwanori and Yamada, Kou},
  booktitle={2024 International Conference on Advanced Technologies for Communications (ATC)}, 
  title={Improving Classifier Training Efficiency with Genetic Algorithm Feature Selection}, 
  year={2024},
  volume={},
  number={},
  pages={540-543},
  abstract={A genetic algorithm feature selection technique is used to improve efficiency of a classifier training process while maintaining its output quality. To achieve this goal, values of some hyper-parameters in the genetic algorithm for feature selection are varied and investigated. Also, different focuses of fitness functions are explored. A set of experiments is conducted on two types of data, unknown and known feature importance. Training time and average accuracy score of the result classifier from each experiment are collected and compared. The results show that there can be an improvement in classifying time and quality of the classifier when appropriate hyper-parameters and fitness function are combined.},
  keywords={Training;Accuracy;Costs;Machine learning;Feature extraction;Genetic algorithms;Principal component analysis;genetic algorithm;hyper-parameter;fitness function;feature selection},
  doi={10.1109/ATC63255.2024.10908297},
  ISSN={2162-1039},
  month={Oct},}@INPROCEEDINGS{10934236,
  author={Xia, Yao},
  booktitle={2025 International Conference on Intelligent Systems and Computational Networks (ICISCN)}, 
  title={Financial Management Early Warning System based on Improved Bi-Directional Gated Recurrent Unit}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, predicting financial risk warnings is significant for protecting economic stability, and enabling realistic actions over market crises, systemic risks and credit defaults. Previous researchers suggested various traditional models but still, because of the complexity of and high-dimensional financial data there are challenges such as; noise, macroeconomic factors and thus facilitates model interpretability for stakeholders, and computing uncertainty to improve confidence in predictions. In this research, Improved Bi-Directional Gated Recurrent Unit (Bi-GRU) method is proposed for effective and early financial risk prediction. Initially, Factor Analysis (FA) is used for acquiring common factors among the non-financial and financial indicators. Further, Improved Bi-GRU is employed for predicting the financial risks by capturing complex relationships and focuses on relevant information within the financial data can lead to effective predictions of market trends, stock prices and other financial indicators. Then, the Particle Swarm Optimization (PSO) is used to optimizes learning rates of Improved Bi-GRU. From the results, the Improved Bi-GRU model attains effective results including MSE (0.0029), MAPE (2.1987) and MAE (0.0489) respectively compared to the FA, Particle Swarm Optimizer and Long Short-Term Memory namely FA-PSO-LSTM.},
  keywords={Uncertainty;Computational modeling;Biological system modeling;Bidirectional control;Predictive models;Financial management;Alarm systems;Data models;Stakeholders;Particle swarm optimization;early warning system;financial management;factor analysis;improved bi-directional gated recurrent unit;particle swarm optimization},
  doi={10.1109/ICISCN64258.2025.10934236},
  ISSN={},
  month={Jan},}@ARTICLE{10955196,
  author={Masood, Atiya and Ebrahim, Mansoor and Najeeb, Fahad and Muhammad Daniyal, Syed},
  journal={IEEE Access}, 
  title={Evolving Many-Objective Job Shop Scheduling Dispatching Rules via Genetic Programming With Adaptive Search Based on the Frequency of Features}, 
  year={2025},
  volume={13},
  number={},
  pages={75020-75036},
  abstract={Job Shop Scheduling (JSS) is a critical application in diverse fields, such as cloud computing and manufacturing. Genetic Programming (GP) is acknowledged for its wide use in evolving dispatching rules for JSS, offering an automated approach to heuristic generation. A dispatching rule can use many machine-related, job-related, and system-related features to create scheduling heuristics in JSS. Proper feature selection is a critical factor for the success of heuristics. Moreover, there can be many features in JSS whose importance varies from one scenario to another. It has been shown that irrelevant and redundant features can adversely affect performance. Feature selection is a promising task to select relevant features and reduce genetic programming hyper-heuristics (GPHH) search space. However, more research is needed to quantify the contribution of features in the GPHH to many-objective JSS. The proposed algorithm introduces an adaptive search strategy that is implemented through re-initialization during the evolutionary process. In addition, relevant features are selected based on their frequency of occurrence in diverse sets of best individuals. The proposed algorithm, Adaptive Feature Selection-GP-NSGA-III (AFS-GP-NSGA-III), is compared with the FS-GP-NSGA-III and standard GP-NSGA-III on a four-objective JSS problem. The experimental results indicate that feature selection using GP and adaptive search can improve the performance of the algorithm. Furthermore, the findings suggest the practical applicability of the proposed algorithm for generating improved dispatching rules for training and unseen test instances using only the selected relevant feature subset.},
  keywords={Dispatching;Schedules;Job shop scheduling;Optimization;Feature extraction;Search problems;Genetic programming;Heuristic algorithms;Processor scheduling;Delays;Adaptive search;feature selection;genetic programming;hyper-heuristic;job shop scheduling;many-objective optimization},
  doi={10.1109/ACCESS.2025.3558521},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10650046,
  author={Morales, Giorgio and Sheppard, John},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Counterfactual Analysis of Neural Networks Used to Create Fertilizer Management Zones}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In Precision Agriculture, the utilization of management zones (MZs) that take into account within-field variability facilitates effective fertilizer management. This approach enables the optimization of nitrogen (N) rates to maximize crop yield production and enhance agronomic use efficiency. However, existing works often neglect the consideration of responsivity to fertilizer as a factor influencing MZ determination. In response to this gap, we present a MZ clustering method based on fertilizer responsivity. We build upon the statement that the responsivity of a given site to the fertilizer rate is described by the shape of its corresponding N fertilizer-yield response (N-response) curve. Thus, we generate N-response curves for all sites within the field using a convolutional neural network (CNN). The shape of the approximated N-response curves is then characterized using functional principal component analysis. Subsequently, a counter-factual explanation (CFE) method is applied to discern the impact of various variables on MZ membership. The genetic algorithm-based CFE solves a multi-objective optimization problem and aims to identify the minimum combination of features needed to alter a site’s cluster assignment. Results from two yield prediction datasets indicate that the features with the greatest influence on MZ membership are associated with terrain characteristics that either facilitate or impede fertilizer runoff, such as terrain slope or topographic aspect.},
  keywords={Precision agriculture;Shape;Clustering methods;Neural networks;Production;Convolutional neural networks;Optimization;Neural network response curves;management zones;counterfactual explanations;explainable machine learning},
  doi={10.1109/IJCNN60899.2024.10650046},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10980849,
  author={Mazumder, Badhan and Wu, Lei and Calhoun, Vince D. and Ye, Dong Hye},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)}, 
  title={Genetics Encoded Joint Embedding of Multimodal Connectomes with Explainable Graph Neural Network for Schizophrenia Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Investigating structural and functional brain connectivity is crucial for understanding neuropsychiatric disorders like schizophrenia (SZ), where genetic markers such as SNPs (single nucleotide polymorphisms) also play a significant role. Graph Neural Networks (GNNs) offer powerful tools for learning complex patterns from connectome data, yet their use across multimodal connectomes remains under-explored. In this study, we developed an explainable multiview GNN framework for SZ classification, integrating genetic markers with connectome features by leveraging message-passing scheme of GNN with Deep Canonical Correlation Analysis (DCCA) for multimodal fusion. Experiments on clinical dataset confirmed the robustness of the framework, highlighting potential clinical biomarkers.},
  keywords={Correlation;Transfer learning;Genomics;Schizophrenia;Biomarkers;Graph neural networks;Robustness;Bioinformatics;Biomedical imaging;Graph Neural Network;Explanation;Brain Networks;Genomics;Schizophrenia},
  doi={10.1109/ISBI60581.2025.10980849},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10979061,
  author={Verdaguer-Gonzalez, Aaron and Dalmau-Moreno, Magí and Merino, Luis and García, Néstor},
  booktitle={2025 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)}, 
  title={Boosting Behavior Tree Generation for Robots with Large Language Models and Genetic Programming}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Mobile robots are becoming increasingly ubiquitous in modern society, requiring more human-like interaction capabilities, such as following operator instructions and collaborating with humans. Conventional robot programming methods often fall short in achieving these complex behaviors. Behavior Trees (BTs) offer a promising alternative due to their modularity, scalability and reactivity. We propose utilizing general purpose, system-prompted Large Language Model (LLM) assistants to decompose task descriptions into executable BTs, which are subsequently refined using Genetic Programming (GP) and a state machine like low-resource BT execution simulator, where they will be tested for task completion. This approach eliminates the need for fine-tuning LLMs, thereby reducing computational costs and saving time and energy. Our method successfully solves all proposed scenarios, enhances applicability across diverse environments, and democratizes behavior generation for non-experts, outperforming baseline methods in efficiency.},
  keywords={Uncertainty;Service robots;Scalability;Large language models;Pipelines;Genetic programming;Robot sensing systems;Behavioral sciences;Usability;Robots;Behavior Trees;Large Language Models;Genetic Programming;Human-Robot Interaction;Simulation},
  doi={10.1109/SIMPAR62925.2025.10979061},
  ISSN={},
  month={April},}@INPROCEEDINGS{10831171,
  author={Dehnad, Parastoo and Bidgoli, Azam Asilian and Rahnamayan, Shahryar},
  booktitle={2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={A Multi-objective Binary Differential Evolution Operator for Feature Selection}, 
  year={2024},
  volume={},
  number={},
  pages={2158-2164},
  abstract={Feature selection is a pivotal component of machine learning and data analysis, to optimize model performance by eliminating irrelevant and redundant features, to address the challenges associated with the “curse of dimensionality” and interpretability. In this context, we present feature selection as a multi-objective binary optimization task with the dual aim of maximizing classification accuracy while minimizing the number of selected features. In order to address this optimization challenge, we introduce the Multi-objective Binary Differential Evolution algorithm (MOBDE). It's worth noting that DE originally is an extremely powerful real-value coded algorithm, and to make it binary, set-based operators must replace vector-based operations. Optimization in binary space is deemed more suitable than real-value optimization because a many-to-one mapping can waste the efforts of the optimizer when solving a binary problem like feature selection. The algorithm leverages a partial opposition-based binary operator to generate diverse solutions to enhance its exploration within the search space. Additionally, it incorporates a majority voting mechanism as a local search strategy to bolster the algorithm's exploitation capabilities. Results from experimentation on eleven datasets underscore the efficiency of MOBDE, outperforming the widely recognized NSGA-II method in terms of the hypervolume (HV) performance metric and minimizing the number of selected features. The proposed algorithm and its experimental outcomes are comprehensively detailed and analyzed, offering valuable insights into its efficacy for feature selection tasks.},
  keywords={Measurement;Analytical models;Data analysis;Machine learning;Feature extraction;Search problems;Data models;Classification algorithms;Optimization;Cybernetics;Feature Selection;Multi-objective Optimization;Binary Differential Evolution;Partial Opposition-based Computation;NSGA-II;Majority Voting},
  doi={10.1109/SMC54092.2024.10831171},
  ISSN={},
  month={Oct},}@ARTICLE{10492982,
  author={Lin, Ping-Ju and Li, Wei and Zhai, Xiaoxue and Li, Zhibin and Sun, Jingyao and Xu, Quan and Pan, Yu and Ji, Linhong and Li, Chong},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Explainable Deep-Learning Prediction for Brain–Computer Interfaces Supported Lower Extremity Motor Gains Based on Multistate Fusion}, 
  year={2024},
  volume={32},
  number={},
  pages={1546-1555},
  abstract={Predicting the potential for recovery of motor function in stroke patients who undergo specific rehabilitation treatments is an important and major challenge. Recently, electroencephalography (EEG) has shown potential in helping to determine the relationship between cortical neural activity and motor recovery. EEG recorded in different states could more accurately predict motor recovery than single-state recordings. Here, we design a multi-state (combining eyes closed, EC, and eyes open, EO) fusion neural network for predicting the motor recovery of patients with stroke after EEG-brain-computer-interface (BCI) rehabilitation training and use an explainable deep learning method to identify the most important features of EEG power spectral density and functional connectivity contributing to prediction. The prediction accuracy of the multi-states fusion network was 82%, significantly improved compared with a single-state model. The neural network explanation result demonstrated the important region and frequency oscillation bands. Specifically, in those two states, power spectral density and functional connectivity were shown as the regions and bands related to motor recovery in frontal, central, and occipital. Moreover, the motor recovery relation in bands, the power spectrum density shows the bands at delta and alpha bands. The functional connectivity shows the delta, theta, and alpha bands in the EC state; delta, theta, and beta mid at the EO state are related to motor recovery. Multi-state fusion neural networks, which combine multiple states of EEG signals into a single network, can increase the accuracy of predicting motor recovery after BCI training, and reveal the underlying mechanisms of motor recovery in brain activity.},
  keywords={Electroencephalography;Motors;Training;Brain modeling;Stroke (medical condition);Robots;Particle measurements;Deep learning;multi-model fusion;explainable AI;electroencephalography;prognosis},
  doi={10.1109/TNSRE.2024.3384498},
  ISSN={1558-0210},
  month={},}@INPROCEEDINGS{10683847,
  author={Efe, Berat and Çerkez, Elif and Kılıç, Hürevren},
  booktitle={2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, 
  title={Cooperation Formation and Progression Among Culturally Adaptive Rational Agents in Prisoner’s Dilemma Game Environment}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={We investigate whether a persistent and stable cooperative behavior can be observed among particle swarm inspired culturally adaptive and rational players in the context of Prisoner’s Dilemma game environment. Our obtained results and discussions point out to the initial value sensitivity of the game set up for cooperation progression as well as soundness of the Prisoner’s Dilemma game in the explanation player’s behavior.},
  keywords={Technological innovation;Sensitivity;Adaptive systems;Lattices;Games;Particle swarm optimization;Intelligent systems;Evolutionary game theory;prisoner’s dilemma game;culturally adaptive agents;promotion of cooperation;honest strategy},
  doi={10.1109/INISTA62901.2024.10683847},
  ISSN={2768-7295},
  month={Sep.},}@INPROCEEDINGS{10770949,
  author={Koyama, So and Fukuyama, Yoshikazu and Watanabe, Takuya and Iizaka, Tatsuya},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={Improved Discrete Spider Monkey Optimization for Vending Machine Column Optimization Considering Sales and a Replenishment Cycle}, 
  year={2024},
  volume={},
  number={},
  pages={212-213},
  abstract={There are approximately 2.24 million beverage vending machines (VM) in Japan. They have space to contain products called columns. The time until the entire product is sold out can be extended by containing high demand products in the columns with higher capacity. Namely, it can reduce the number of product deliveries to VMs. Fewer number of deliveries contribute to lower carbon dioxide emissions, lower fuel costs, and fewer hours of work by delivery personnel. For example, reducing carbon dioxide emissions is important to mitigate global warming.},
  keywords={Supply chain management;Costs;Carbon dioxide;Evolutionary computation;Product delivery;Global warming;Fuels;Optimization;Business;Climate change;Carbon emissions;Product delivery;Improved discrete spider monkey optimization;dynamic multi-population;Combinatorial optimization;Vending machine column optimization},
  doi={10.1109/AIxSET62544.2024.00040},
  ISSN={},
  month={Sep.},}@ARTICLE{10079141,
  author={Xu, Jian and Jiang, Xinxiong and Liao, Siyang and Ke, Deping and Sun, Yuanzhang and Yao, Liangzhong},
  journal={IEEE Transactions on Power Systems}, 
  title={High-Dimensional Feature Selection for Power System Congestion Event Prognosis With Enhanced Evolutionary Computation}, 
  year={2024},
  volume={39},
  number={1},
  pages={1752-1770},
  abstract={Power system congestion event prognosis (CEP) based on multivariate time series (MTS) learning is an effective way to improve the warning abilities against risky situations. However, it is still challenging to decide which measurement sequences of system variables should be selected to train MTS learning-based CEPs models, especially when facing high-dimensional candidate features from power systems. Focusing on this issue, this paper proposes a novel high-dimensional feature selection (FS) method to identify and select variables that contain beneficial data patterns for the prognosis of network congestion events. A wrapper framework embedded with multiple MTS learning models is first built to treat FS as a combinatorial optimization task and receive MTS as inputs directly without sequence compressions. Then, to improve the combinatorial optimization efficiency and FS results in the high-dimensional case, a hybrid structure called enhanced evolutionary computation (EEC) is developed by combining with information theory-based feature priority scores, which play the role of semi-guidance in the iterative search. Test results on both the real-world and synthetic datasets validate the effectiveness of the developed EEC structure and show that the selected features by the proposed FS method are more beneficial in identifying the early patterns of network congestion events, thus contributing to efficient and accurate CEP for power systems.},
  keywords={Computational modeling;Feature extraction;Prognostics and health management;Time series analysis;Power systems;Optimization;Data models;Congestion event prognosis;early warning;evolutionary computation;feature selection;multivariate time series},
  doi={10.1109/TPWRS.2023.3260871},
  ISSN={1558-0679},
  month={Jan},}@INPROCEEDINGS{10883232,
  author={Jiang, Yuchen and Wang, Jia and Peng, Yiming},
  booktitle={2024 Boao New Power System International Forum - Power System and New Energy Technology Innovation Forum (NPSIF)}, 
  title={Probabilistic Photovoltaic Power Prediction based on QR-BiLSTM-SA}, 
  year={2024},
  volume={},
  number={},
  pages={90-94},
  abstract={In this paper, we propose a method for the ultra- short-term probabilistic prediction of photovoltaic (PV) power to mitigate the impact of PV uncertainty on the power system. Feature correlation analysis and K-means++ weather clustering are performed on the raw data to select the quantile points; a bidirectional long- and short-term memory (BiLSTM) neural network with self-attention mechanism (SA) is constructed to capture the temporal features and pay attention to the key information in the sequences, and the parameters of the neural network are optimised using a particle swarm algorithm; an error analysis is performed based on the point prediction results, and quantile regression is introduced (QR), a QR-BiLSTM-SA model is constructed for probabilistic prediction. The performance of the model is evaluated using various metrics, and the probabilistic prediction results show higher accuracy than the QR-LSTM, QR-BiLSTM, and QR-BiLSTM-AM methods, with an overall accuracy of more than 95%.},
  keywords={Photovoltaic systems;Adaptation models;Accuracy;Neural networks;Bidirectional long short term memory;Predictive models;Probabilistic logic;Data models;Power systems;Forecasting;photovoltaic power prediction;probability interval prediction;deep learning;quantile regression;bidirectional long short-term memory network;self-attention mechanism},
  doi={10.1109/NPSIF64134.2024.10883232},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10645928,
  author={Wen, Bo and Norel, Raquel and Liu, Julia and Stappenbeck, Thaddeus and Zulkernine, Farhana and Chen, Huamin},
  booktitle={2024 IEEE International Conference on Digital Health (ICDH)}, 
  title={Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health}, 
  year={2024},
  volume={},
  number={},
  pages={104-113},
  abstract={The rapid advancements in large language models (LLMs) have opened up new opportunities for transforming patient engagement in healthcare through conversational AI. This paper presents an overview of the current landscape of LLMs in healthcare, specifically focusing on their applications in analyzing and generating conversations for improved patient engagement. We showcase the power of LLMs in handling unstructured conversational data through four case studies: (1) analyzing mental health discussions on Reddit, (2) developing a personalized chatbot for cognitive engagement in seniors, (3) summarizing medical conversation datasets, and (4) designing an AI-powered patient engagement system. These case studies demonstrate how LLMs can effectively extract insights and summarizations from unstructured dialogues and engage patients in guided, goal-oriented conversations. Leveraging LLMs for conversational analysis and generation opens new doors for many patient-centered outcomes research opportunities. However, integrating LLMs into healthcare raises important ethical considerations regarding data privacy, bias, transparency, and regulatory compliance. We discuss best practices and guidelines for the responsible development and deployment of LLMs in healthcare settings. Realizing the full potential of LLMs in digital health will require close collaboration between the AI and healthcare professionals communities to address technical challenges and ensure these powerful tools’ safety, efficacy, and equity.},
  keywords={Ethics;Large language models;Oral communication;Transforms;Mental health;Electronic healthcare;Safety;Large Language Model;Digital Health;Patient Engagements},
  doi={10.1109/ICDH62654.2024.00027},
  ISSN={},
  month={July},}@INPROCEEDINGS{10222871,
  author={Meynen, Toon and Behzadi-Khormouji, Hamed and Oramas, José},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)}, 
  title={Interpreting Convolutional Neural Networks by Explaining Their Predictions}, 
  year={2023},
  volume={},
  number={},
  pages={1685-1689},
  abstract={We propose a method that exploits the feedback provided by visual explanation methods combined with pattern mining techniques to identify the relevant class-specific and class-shared internal units. In addition, we put forward a patch extraction approach to find faithfully class-specific and class-shared visual patterns. Contrary to the common practice in literature, our approach does not require pushing augmented visual patches through the model. Experiments on two CNN architectures show the effectiveness of the proposed method.},
  keywords={Visualization;Image processing;Neural networks;Metaheuristics;Convolutional neural networks;Task analysis;Neural Network Interpretation;Data Mining},
  doi={10.1109/ICIP49359.2023.10222871},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10405708,
  author={Dolci, Giorgio and Cruciani, Federica and Galazzo, Ilaria Boscolo and Calhoun, Vince D. and Menegaz, Gloria},
  booktitle={2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Objective Assessment of the Bias Introduced by Baseline Signals in XAI Attribution Methods}, 
  year={2023},
  volume={},
  number={},
  pages={266-271},
  abstract={This work represents a first step towards a systematic analysis of the impact of the choice of the baseline signals to be used in explainable baseline-dependent methods for multi-modal and multi-dimensional data relying on single-input deep networks, in view of the generalization to multi -channel architectures. This point is critical for ensuring the soundness of the attribution values and enabling their subsequent validation through association studies. In this work, two different CNNs were implemented to predict Alzheimer's disease patients from control subjects using structural Magnetic Resonance Imaging volumes and genetics data. The Integrated Gradients method was applied to both models for post-hoc attribution visualization relying on different baselines. Differences in the attribution maps were found with respect to the attributions of the reference baseline in both modalities highlighting the importance of finding and using the “optimal” baseline. We believe this work is highly relevant for the community in the framework of the validation of XAI post-hoc methods, as it provides evidence of the impact of the choice of the baselines for deriving feature attribution values with the Integrated Gradients method which determines the reliability of the outcomes, improving both the awareness of the users and their trust in the methods.},
  keywords={Gradient methods;Solid modeling;Three-dimensional displays;Systematics;Neural engineering;Reliability;Task analysis;XAI;Baseline;Integrated Gradients},
  doi={10.1109/MetroXRAINE58569.2023.10405708},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11042959,
  author={Zhang, Yuye and Zhang, Fangfang and Xue, Bing and Zhang, Mengjie},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Multimodal Image Classification Using Genetic Programming for Alzheimer’s Disease Diagnosis}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Alzheimer’s disease (AD) is a progressive neurological disorder and a major contributor to dementia cases across the world. Timely and accurate diagnosis is crucial for effective clinical management and therapeutic intervention. This paper presents a genetic programming (GP) method with a multi-tree representation designed to effectively integrate multimodal neuroimaging data while preserving spatial information for AD classification. Unlike existing GP approaches that focus on single-modality data, our GP approach directly uses the images from multiple imaging sources as inputs into the evolutionary process. A new GP representation is designed to handle multimodal data effectively, enabling feature extraction and classification. Experiments on the commonly used public database of Alzheimer’s disease neuroimaging initiative (ADNI) show that the proposed method performs effectively in diagnosing AD. These findings suggest that multi-tree GP has the potential to serve as a powerful and interpretable tool for neuroimaging-based AD diagnosis, offering a promising approach to improve AD detection and clinical decision-making.},
  keywords={Neuroimaging;Training;Accuracy;Magnetic resonance imaging;Redundancy;Genetic programming;Feature extraction;Medical diagnosis;Alzheimer's disease;Image classification;Genetic programming;image classification;neuroimaging;multimodal classification;medical diagnosis},
  doi={10.1109/CEC65147.2025.11042959},
  ISSN={},
  month={June},}@ARTICLE{10681550,
  author={Qiu, Kehai and Bakirtzis, Stefanos and Wassell, Ian and Song, Hui and Zhang, Jie and Wang, Kezhi},
  journal={IEEE Wireless Communications Letters}, 
  title={Large Language Model-Based Wireless Network Design}, 
  year={2024},
  volume={13},
  number={12},
  pages={3340-3344},
  abstract={In this letter, we present the Large Language Model-based combinatorial optimizer (LMCO) for wireless network optimization and planning tasks, focusing on optimizing the number and the placement of wireless access point placement. The performance and efficiency of LMCO are evaluated and compared with the well-established Ant Colony Optimization (ACO) algorithm. The results indicate that LMCO exhibits superior performance, particularly as the complexity of the problem increases. These findings also underscore the significant potential of LLM-based algorithms in revolutionizing combinatorial optimization across a wide range of applications.},
  keywords={Optimization;Planning;Solid modeling;Wireless communication;Wireless networks;Ray tracing;Floors;Large language model;network optimization;combinatorial optimization;access point placement},
  doi={10.1109/LWC.2024.3462556},
  ISSN={2162-2345},
  month={Dec},}@INPROCEEDINGS{10637650,
  author={Li, Jinning and Han, Ruipeng and Sun, Chenkai and Sun, Dachun and Wang, Ruijie and Zeng, Jingying and Yan, Yuchen and Tong, Hanghang and Abdelzaher, Tarek},
  booktitle={2024 33rd International Conference on Computer Communications and Networks (ICCCN)}, 
  title={Large Language Model-Guided Disentangled Belief Representation Learning on Polarized Social Graphs}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The paper advances belief representation learning in polarized networks – the mapping of social beliefs espoused by users and posts in a polarized network into a disentangled latent space that separates (the members and beliefs of) each side. Our prior work embeds social interaction data, using non-negative variational graph auto-encoders, into a disentangled latent space. However, the interaction graphs alone may not adequately reflect similarity and/or disparity in beliefs, especially for those graphs with sparsity and outlier issues. In this paper, we investigate the impact of limited guidance from Large Language Models (LLMs) on the accuracy of belief separation. Specifically, we integrate social graphs with LLM-based soft labels as a novel weakly-supervised interpretable graph representation learning framework. This framework combines the strengths of graph-and text-based information, and is shown to maintain the interpretability of learned representations, where different axes in the latent space denote association with different sides of the divide. An evaluation on six real-world Twitter datasets illustrates the effectiveness of the proposed model at solving stance detection problems, demonstrating 5.9%-6.5% improvements in the accuracy, F1 score, and purity metrics, without introducing a significant computational overhead. An ablation study is also discussed to study the impact of different components of the proposed architecture.},
  keywords={Representation learning;Measurement;Analytical models;Accuracy;Social networking (online);Computational modeling;Large language models;Large Language Models;Weak Supervision;Graph Auto-Encoders;Interpretability;Social Networks},
  doi={10.1109/ICCCN61486.2024.10637650},
  ISSN={2637-9430},
  month={July},}@ARTICLE{10072401,
  author={Pugalendhi, Ganeshkumar and Rathore, M. Mazhar and Shukla, Dhirendra and Paul, Anand},
  journal={IEEE Access}, 
  title={Handling Big Microarray Data: A Novel Approach to Design Accurate Fuzzy-Based Medical Expert System}, 
  year={2023},
  volume={11},
  number={},
  pages={35182-35196},
  abstract={The genes data produced by microarray experiments is complex in terms of dimensions and samples. It consumes a lot of computation power and time when it is processed for a disease analysis while working with an expert system. At the same time, data can help doctors identify a patient’s health condition if it is presented in a meaningful way and processed on time. Several methods have been proposed to reduce the dimensions of medical microarray data and optimize its search space with minimal accuracy loss. However, the discretization of continuous gene-values in the process of dimension reduction is failed to preserve the inherent meaning of genes. Also, ensuring high accuracy and interpretability in the reduction process may result in extra processing time, which is unfavorable for time-critical applications. To overcome these issues, in this paper, we propose a dimension reduction method in conjunction with a fuzzy expert system (FES) optimization approach, while keeping an accuracy-interpretability-speedy tradeoff in mind. To accomplish this, we use a fuzzy rough set on  ${f}$ -information to identify meaningful genes without changing their original values. We propose a conditionally guided particle swarm optimization for faster knowledge acquisition, where the velocity is adjusted based on a predefined update probability, resulting in a faster search. A big data processing architecture is designed using the Hadoop ecosystem along with a  $MapReduce$ -equivalent algorithm of the proposed method for speedy processing, enabling parallel processing on microarray data to reduce dimensions and perform classification through knowledge extraction. The proposed method is thoroughly tested on eleven microarray datasets by considering accuracy-interpretability-speed tradeoff. The results show that the proposed method is effective in identifying disease-causing genes while also understanding the patient’s genetic profile with only a few operations and a small amount of CPU time. Statistical tests are also run to validate the proposed method’s efficacy in comparison to other methods.},
  keywords={Iron;Medical services;Expert systems;Dimensionality reduction;Diseases;Rough sets;Particle swarm optimization;f-information;fuzzy expert system;microarray data;particle swarm optimization},
  doi={10.1109/ACCESS.2023.3257875},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10702107,
  author={Tangherloni, Andrea and Cazzaniga, Paolo and Stranieri, Nicolò and Buffa, Francesca M. and Nobile, Marco S.},
  booktitle={2024 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)}, 
  title={A Fast Feature Selection for Interpretable Modeling Based on Fuzzy Inference Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Large datasets are often beneficial for the generation of predictive models using machine learning approaches. However, it is often the case that not all variables in the dataset contain useful information. In fact, some variables might be useless, redundant, misleading, or even harmful to performance, both in terms of accuracy and computational effort. Because of that, Feature Selection (FS) is one of the most delicate and important steps in machine learning. This is even more relevant in the case of interpretable models based on Fuzzy Inference Systems (FIS). The reasons are two-fold: on the one hand, FIS are generally built on top of a data partitioning based on clustering, which can suffer from high dimensionality; on the other hand, the knowledge base of the FIS, to be concretely understandable, should not contain rules involving too many variables. FS can be performed using multiple approaches, most notably filter and wrapper methods. The latter are often based on evolutionary algorithms, where a population of candidate solutions (each representing a possible set of selected variables) evolves towards the optimal selection. Although wrapper methods can be effective, they are, in general, computationally expensive. In this work, we propose a completely different – and more computationally effective – algorithm based on Random Forest (RF) models. Specifically, we exploit RFs to rank variables according to their importance. Then, we use that information to perform a statistical analysis and determine the minimal set of features necessary to build an accurate FIS. We show the effectiveness of our approach by using two (semi)synthetic datasets built on real-world datasets, and we validate our approach by applying the FS method to a medical dataset.},
  keywords={Radio frequency;Fuzzy logic;Accuracy;Statistical analysis;Computational modeling;Predictive models;Feature extraction;Inference algorithms;Noise measurement;Random forests;Feature Selection;Feature Importance;Fuzzy Inference Systems;Interpretable Models;Interpretable AI},
  doi={10.1109/CIBCB58642.2024.10702107},
  ISSN={2994-9408},
  month={Aug},}@INPROCEEDINGS{10629263,
  author={Cui, Hangrui},
  booktitle={2024 5th International Conference on Mechatronics Technology and Intelligent Manufacturing (ICMTIM)}, 
  title={Construction of an Intelligent Fault Identification System for Power Grid under Adaptive Genetic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={697-701},
  abstract={The increasingly complex structure of the power grid, as well as the integration of new energy and distributed generation resources, have led to a more diverse variety of types and modes of power grid faults. This study proposes an intelligent identification method for power grid faults based on the principle of Adaptive Genetic Algorithm (AGA). Firstly, it collects fault data through power grid monitoring equipment. Then, through an encoding scheme, these parameters are transformed into chromosomes that can be processed by genetic algorithms. In the design of the fitness function, the accuracy and real-time performance of fault detection are considered to ensure that the algorithm can effectively evaluate the quality of chromosomes. The control parameters of the genetic algorithm based on the performance of the process to enhance the convergence and robustness of the algorithm can be dynamically adjusted. Through comparative testing on multiple power grid fault data, the results show that the AGA based intelligent identification system for power grid faults is superior to traditional genetic algorithms (GA) and artificial neural networks (ANN) in terms of fitness function, convergence accuracy, and interpretability. Its fitness value can reach 96%, with a minimum relative error of 0.8% and an interpretability of 88%. This system can effectively process power grid fault data and provide a new intelligent tool for power grid operation and maintenance. Future work can focus on further optimizing the performance of AGA and achieving its widespread application.},
  keywords={Fault diagnosis;Adaptive systems;Heuristic algorithms;Fault detection;Artificial neural networks;Power grids;Monitoring;Adaptive Genetic Algorithm;Traditional Genetic Algorithm;Artificial Neural Networks;Intelligent Identification of Power Grid Faults},
  doi={10.1109/ICMTIM62047.2024.10629263},
  ISSN={},
  month={April},}@ARTICLE{10416342,
  author={Vyshnya, Sofiya and Epperson, Rachel and Giuste, Felipe and Shi, Wenqi and Hornback, Andrew and Wang, May D.},
  journal={IEEE Open Journal of Engineering in Medicine and Biology}, 
  title={Optimized Clinical Feature Analysis for Improved Cardiovascular Disease Risk Screening}, 
  year={2024},
  volume={5},
  number={},
  pages={816-827},
  abstract={Objective: To develop a clinical decision support tool that can predict cardiovascular disease (CVD) risk with high accuracy while requiring minimal clinical feature input, thus reducing the time and effort required by clinicians to manually enter data prior to obtaining patient risk assessment. Results: In this study, we propose a robust feature selection approach that identifies five key features strongly associated with CVD risk, which have been found to be consistent across various models. The machine learning model developed using this optimized feature set achieved state-of-the-art results, with an AUROC of 91.30%, sensitivity of 89.01%, and specificity of 85.39%. Furthermore, the insights obtained from explainable artificial intelligence techniques enable medical practitioners to offer personalized interventions by prioritizing patient-specific high-risk factors. Conclusion: Our work illustrates a robust approach to patient risk prediction which minimizes clinical feature requirements while also generating patient-specific insights to facilitate shared decision-making between clinicians and patients.},
  keywords={Feature extraction;Predictive models;Pain;Electrocardiography;Classification algorithms;Machine learning;Biomedical engineering;Cardiovascular disease;feature interpretation;machine learning;personalized medicine;risk prediction},
  doi={10.1109/OJEMB.2023.3347479},
  ISSN={2644-1276},
  month={},}@INPROCEEDINGS{10696341,
  author={Wang, Yan and Huang, Wei and Zeng, Zhiqiang and Long, Wenqing and Duan, Yumei and Yang, Fan and Xie, Yinghong},
  booktitle={2024 6th International Conference on Electronic Engineering and Informatics (EEI)}, 
  title={Research on the Prediction Model of PCB Etch Factor Based on DE-BP Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={455-459},
  abstract={As a core component of various electronic products, the production quality of printed circuit board (PCB) directly affects the performance and reliability of electronic devices. The etch factor serves as a key indicator for assessing the quality of PCB traces, and its rapid and precise detection is vital for enhancing the production efficiency and quality of PCB. In this paper, a differential evolution (DE) algorithm optimized backpropagation (BP) neural network (DE-BP) prediction model is proposed to achieve the prediction of the PCB etch factor. After employing feature selection to reduce the input features, the DE algorithm is utilized to optimize the initial parameters of the BP neural network. Subsequently, the trained model is applied to predict the etch factor of PCB. The results show that the DE-BP model constructed in this paper can effectively predict the etch factor of PCB. Compared with the traditional BP model, the DE-BP model exhibits enhanced prediction performance.},
  keywords={Performance evaluation;Printed circuits;Neural networks;Production;Predictive models;Prediction algorithms;Search problems;Product design;Quality assessment;Testing;etch factor;differential evolution algorithm;BP neural network;prediction model},
  doi={10.1109/EEI63073.2024.10696341},
  ISSN={},
  month={June},}@INPROCEEDINGS{10612020,
  author={Li, Chen and Han, Zidong and Jiang, Jinrong and Zhao, Lian and Bai, Yidi and Lu, Zhonghua and Chi, Xuebin},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Generative Evolution Attacks Portfolio Selection}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={It is agreed that portfolio selection is of great importance for the financial market. Numerous outstanding exact and heuristic algorithms have been proposed in the past decades. However, their development always demands meticulous human ideas and could be time-consuming. Moreover, most of them tend to suffer from performance degradation when exposed to new portfolio selection models and different investment environments. Learning-enabled approaches have recently yielded impressive results, but these methods still grapple with challenges in model design and training. In this paper, we explore the mutual facilitation of large language models (LLMs) and huristic approaches in portfolio selection, and propose a novel LLM-based multi-objective evolutionary algorithm (MOEA) named IlmPC-NSGA-II. In this algorithm, the LLM with carefully-designed well-structured prompts serves as a straightforward yet effective engine for generating new solutions, non-dominated sorting and crowding distance calculation are adopted to enable the LLM and the evolutionary process to mutually guide toward the optimal region of the solution space. Experimental results on various scales of constrained multi-objective portfolio selection models and four benchmark problems demonstrate that our proposed approach can achieve a more competitive performance compared to widely-used MOEAs and the LLM-only method.},
  keywords={Training;Degradation;Computational modeling;Large language models;Heuristic algorithms;Evolutionary computation;Portfolios;multi-objective evolutionary algorithm;portfolio selection;large language model;in-context learning;few-shot prompting},
  doi={10.1109/CEC60901.2024.10612020},
  ISSN={},
  month={June},}@INPROCEEDINGS{10929576,
  author={Liu, Tianju and Liu, Yuan and Li, Ningyi and Shi, Hui},
  booktitle={2024 4th International Conference on Electronic Information Engineering and Computer Communication (EIECC)}, 
  title={Multi-domain Multi-scale DeepFake Detection for Generalization}, 
  year={2024},
  volume={},
  number={},
  pages={1485-1492},
  abstract={As deepfake detection technology progresses and application scenarios broaden, it becomes challenging for detection models within a single domain or single scale to handle the complex application environments, leading to limited accuracy and generalization capabilities of the detection models. To address the above problems, we propose a Multi-domain Multi-scale DeepFake Detection model. First, we employ the RetinaFace framework to preprocess and augment the image data, which directs the model’s attention to the relevant regions of the image. Next, we utilize the EfficientNet-B0 network for rapid coarse-grained feature extraction. Building on these coarse-grained features, we design two modules to capture forgery traces at multiple levels: a spatial-domain fine-grained feature extraction module based on multi-scale analysis and a frequency-domain fine-grained feature extraction module leveraging the Fast Fourier Transform. Finally, the dual-domain features are fused using a multi-channel attention mechanism, enabling the model to comprehensively analyze images from various perspectives. Additionally, we implement a Particle Swarm Optimization (PSO) strategy to optimize the hyper-parameters of the network model. The proposed model demonstrates significant advantages over other algorithms, particularly in cross-dataset detection, exhibiting strong generalization, robustness, and adaptability. When trained on the FF++ dataset and tested on the Celeb-DF dataset, it achieves an AUC of 91.7%. This represents a 14.8% improvement in cross-dataset performance compared to the best existing model.},
  keywords={Training;Deepfakes;Adaptation models;Accuracy;Attention mechanisms;Frequency-domain analysis;Feature extraction;Robustness;Data models;Particle swarm optimization;DeepFake Detection;Multi-domain Multi-scale;P article Swarm Optimization;Data Preprocessing and Augmentation;Generalization},
  doi={10.1109/EIECC64539.2024.10929576},
  ISSN={},
  month={Dec},}@ARTICLE{10872805,
  author={Hu, Lijie and Wang, Xinhai and Liu, Yixin and Liu, Ninghao and Huai, Mengdi and Sun, Lichao and Wang, Di},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Towards Stable and Explainable Attention Mechanisms}, 
  year={2025},
  volume={37},
  number={5},
  pages={3047-3061},
  abstract={Currently, attention mechanism has become a standard fixture in most state-of-the-art natural language processing (NLP) models, not only due to the outstanding performance it could gain but also due to plausible innate explanations for the behaviors of neural architectures it provides, which is notoriously difficult to analyze. However, recent studies show that attention is unstable against randomness and perturbations during training or testing, such as random seeds and slight perturbation of embedding vectors, which impedes it from becoming a faithful explanation tool. Thus, a natural question is whether we can find some substitute for the current attention that is more stable and could keep the most important characteristics of explanation and prediction of attention. In this paper, to resolve the problem, we provide a rigorous definition of such alternate namely SEAT (Stable and Explainable Attention). Specifically, a SEAT should have the following three properties: (1) Its prediction distribution is enforced to be close to the distribution based on the vanilla attention; (2) Its top-$k$k indices have large overlaps with those of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any slight perturbation on SEAT will not change the prediction distribution too much, which implicitly indicates that it is stable to randomness and perturbations. To further improve the interpretability stability against perturbations, based on SEAT we provide another definition called SEAT++. Then we propose a method to get a SEAT++, which could be considered an ad hoc modification for canonical attention. Finally, through intensive experiments on various datasets, we compare our SEAT and SEAT++ with other baseline methods using RNN, BiLSTM, and BERT architectures via six different evaluation metrics for model interpretation, stability, and accuracy. Results show that SEAT and SEAT++ are more stable against different perturbations and randomness while also keeping the explainability of attention, which indicates they provide more faithful explanations. Moreover, compared with vanilla attention, there is almost no utility (accuracy) degradation for SEAT and SEAT++.},
  keywords={Perturbation methods;Training;Stability criteria;Vectors;Attention mechanisms;Robustness;Natural language processing;Predictive models;Motion pictures;Measurement;Explainable AI;interpretation;faithfulness;stability},
  doi={10.1109/TKDE.2025.3538583},
  ISSN={1558-2191},
  month={May},}@INPROCEEDINGS{10776426,
  author={Pula, Rolando A. and Angeline M., Dalit and Ilagan, Lorena},
  booktitle={2024 11th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)}, 
  title={Oryza Sativa Disease Diagnosis Through Particle Swarm Optimized Shifted Windows Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={463-469},
  abstract={One of the primary problems farmers encounters is the frequent occurrence of diseases that specifically target the leaves of rice plants. This makes it extremely difficult for farmers to supply the rising demand for food needed to support an expanding population. The agricultural sector suffers substantial losses due to rice diseases, which greatly affect food production. Traditional methods of identifying diseases in rice leave have limitations in accuracy and computational efficiency. To tackle these challenges, this study introduces a novel approach: a rice leaf disease detection system employing the Shifted Windows Transformer (SWIN). This system represents a significant advancement in rice disease classification. Unlike conventional methods such as Convolutional Neural Networks (CNNs), which may struggle to capture the full context efficiently, Shifted Windows leverages hierarchical transformer blocks to better understand the complexities of images. By utilizing this architecture, the proposed system offers improved precision and computational efficiency in identifying rice leaf diseases from captured images from rice leaves giving high accuracy.},
  keywords={Training;Technological innovation;Accuracy;Computational modeling;Production;Transformers;Computational efficiency;Particle swarm optimization;Tuning;Diseases;Shifted Windows Transformer;Rice leaf;Rice Diseases;Machine Learning;Particle Swarm Optimization},
  doi={10.1109/EECSI63442.2024.10776426},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10652098,
  author={Li, Yunlong and Shao, Yong and Guan, Xin},
  booktitle={2024 6th International Conference on Energy Systems and Electrical Power (ICESEP)}, 
  title={Combining TPE-PSO and BiGRU for High-Precision Short-Term Wind Power Forecasting}, 
  year={2024},
  volume={},
  number={},
  pages={81-84},
  abstract={Given the significant volatility and unpredictability of wind power generation, accurately forecasting its future power output has become a key element in ensuring the stability and reliability of energy systems. This paper proposes a network model based on TPE-PSO hyperparameter optimization, aimed at maximizing the search for optimal parameters globally and locally to achieve the highest precision. The predictive performance of the model was evaluated using two sets of wind power data with a resolution of 1 hour, employing four commonly used evaluation metrics in the field. The results show that all power forecasting results within 24 hours have R2 decision values consistently above 0.973. Under the same environmental conditions, our model significantly outperforms other models in predicting wind power generation, as evidenced by its superior MAE, RMSE, and NMAE. This significant research outcome provides strong support and precise guidance for the safe and stable operation of power grids in practical applications.},
  keywords={Accuracy;Uncertainty;Weather forecasting;Wind power generation;Predictive models;Power system stability;Stability analysis;deep learning;short-term forecasting;wind power;optimization algorithm;time series},
  doi={10.1109/ICESEP62218.2024.10652098},
  ISSN={},
  month={June},}@ARTICLE{10129205,
  author={Brunello, Andrea and Monica, Dario Della and Montanari, Angelo and Saccomanno, Nicola and Urgolo, Andrea},
  journal={IEEE Access}, 
  title={Monitors That Learn From Failures: Pairing STL and Genetic Programming}, 
  year={2023},
  volume={11},
  number={},
  pages={57349-57364},
  abstract={In several domains, systems generate continuous streams of data during their execution, including meaningful telemetry information, that can be used to perform tasks like preemptive failure detection. Deep learning models have been exploited for these tasks with increasing success, but they hardly provide guarantees over their execution, a problem which is exacerbated by their lack of interpretability. In many critical contexts, formal methods, which ensure the correct behavior of a system, are thus necessary. However, specifying in advance all the relevant properties and building a complete model of the system against which to check them is often out of reach in real-world scenarios. To overcome these limitations, we design a framework that resorts to monitoring, a lightweight runtime verification technique that does not require an explicit model specification, and pairs it with machine learning. Its goal is to automatically derive relevant properties, related to a bad behavior of the considered system, encoded by means of formulas of Signal Temporal Logic ( $\mathsf {STL}$ ). Results based on experiments performed on well-known benchmark datasets show that the proposed framework is able to effectively anticipate critical system behaviors in an online setting, providing human-interpretable results.},
  keywords={Monitoring;Machine learning;Task analysis;Feature extraction;Runtime;Data mining;Telemetry;Failure analysis;Machine learning;formal methods;runtime verification;monitoring;failure detection;explainable AI},
  doi={10.1109/ACCESS.2023.3277620},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10612052,
  author={Zhou, Youhua and Yan, Xueming and Huang, Han and Yan, Haowen and Chen, Minghao},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Legal Text Retrieval with Contrastive Representation Learning and Evolutionary Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Legal text retrieval holds significant importance in the audit field, posing a challenge as a semantic matching problem. Despite the success of text semantic matching methods, particularly with the advent of large language models, these approaches face challenges when applied to domain-specific tasks, like legal text retrieval. Specifically, issues arise due to the concentrated distribution of data within the specific domain and the insufficient number of training samples. To address these challenges, this paper introduces a text semantic matching model tailored for the task of legal text retrieval, leveraging contrastive learning and evolutionary algorithms. A contrastive learning-based embedding model, which learns semantic representations in a feature space, is used to minimize the distance between matched text pairs and maximize the distance between unmatched text pairs. Additionally, an evolutionary algorithm-based sample augmentation model is introduced to augment the sample set and enhance the representational capabilities of the samples. The efficacy of the proposed method is evaluated in the context of legal text retrieval in the auditing field, and the experimental results reveal promising outcomes, with the proposed method achieving a Hits@l accuracy of 53.09%, a 2.99% improvement over the best baseline model. The Hits@20 accuracy reaches 75.15%, representing a 2.69% enhancement compared to the state-of-the-art methods.},
  keywords={Training;Adaptation models;Accuracy;Law;Computational modeling;Semantics;Evolutionary computation;legal text retrieval;evolutionary algorithm;sam-ple augment;contrastive learning;text semantic matching;large language model},
  doi={10.1109/CEC60901.2024.10612052},
  ISSN={},
  month={June},}@ARTICLE{10816406,
  author={Tian, Hu and Ji, Anping},
  journal={IEEE Access}, 
  title={Real-Time Adaptive Tractor Ride Comfort Adjustment System Based on Machine Learning Method}, 
  year={2025},
  volume={13},
  number={},
  pages={3274-3283},
  abstract={Tractors are among the most widely used machinery in agriculture. However, low-frequency vibrations during tractor operations pose significant health risks to drivers, such as musculoskeletal disorders, and negatively impact ride comfort. Current approaches rely on offline comfort prediction models, which lack real-time feedback, making them unsuitable for practical field applications. To address this gap, we propose a real-time recommendation system based on Internet of Things (IoT) and Machine Learning (ML) to enhance the driving comfort of agricultural tractors. Our low-cost IoT-enabled solution is compatible with existing tractors, requiring no expensive intelligent upgrades. Using the XGBoost model for ride comfort prediction, we achieved superior performance (R $^{2} =0.96$ , RMSE =0.015) compared to other ML models. Additionally, the Particle Swarm Optimization (PSO) algorithm is employed to recommend optimal operational parameters, reducing the ride comfort value (OVV) by 6.67% in real-time experiments. This study highlights a scalable, data-driven approach for improving tractor comfort and offers a reference for intelligent control strategies in Agriculture 4.0.},
  keywords={Agricultural machinery;Real-time systems;Vibrations;Predictive models;Internet of Things;Agriculture;Prediction algorithms;Machine learning;Soil;Software;Tractor;machine learning;particle swarm optimization;internet of things;driving comfort;real-time control},
  doi={10.1109/ACCESS.2024.3522959},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9800086,
  author={Jabor, Fadhel K. and Omran, Ghufran A. and Mhana, Ammar and Gheni, Hassan Muwafaq},
  booktitle={2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)}, 
  title={Optimization of Particle Swarms for Travelling Salesman Problem}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The Traveling Salesman Problem is a story application of Atom Swarm Optimizations in this research. We have developed several novel techniques intended for solving TSP with PSO. Additionally, we introduced the notions to Swap Operative and Swap Chronological sequence and redefining the remaining operatives their foundation; that way, the study created unique PSO. Research prove it can produce satisfactory outcomes. The aim of this paper be there to assess the functioning of particle swarm optimization, for the going salesman issue TSP. The solution to this trouble is common to be NP-hard, it has N! permutations. The study's goal is to examine the capacity of both algorithms to solve intercontinental and other benchmark problems. Overall, the results suggest that used algorithms know how to understand good quality explanations than PSO algorithm, but they are not good enough in terms of normal generation.},
  keywords={Human computer interaction;Costs;Traveling salesman problems;Benchmark testing;Space exploration;Particle swarm optimization;Junctions;Particle Swam Optimization;Salesman;Element swarm optimization;Traveling salesman},
  doi={10.1109/HORA55278.2022.9800086},
  ISSN={},
  month={June},}@INPROCEEDINGS{11043014,
  author={Li, Yunjie and Liu, Pengfei and Zhao, Haitao and Tang, Haifeng and Shen, Minxian and Wang, Lingyao},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={LW-MSTCNN: An Optimization Study on Integrating Multiscale Attention Mechanism with Deep Separable Convolutional Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Multivariate time series (MTS) forecasting is crucial in the finance, energy and transportation sectors. Although current models deliver high prediction accuracy, their complexity and extensive computational demands hinder practical deployment. To address these limitations, this paper introduces a lightweight multiscale spatio-temporal convolutional network (LW-MSTCNN) that leverages deep separable convolution (DSCNN) to build an efficient multiscale pyramid model to decrease model complexity and computational costs. Additionally, a multiscale attention (MA) mechanism is incorporated to selectively emphasize important features across different spatial and temporal scales, improving feature extraction and overall performance. This combined approach enhances the model’s ability to process high-dimensional data efficiently while capturing critical multiscale patterns, addressing key challenges in spatio-temporal data processing. Experimental results on four datasets demonstrate that the proposed model significantly reduces the usage of computational resources, with the parameter count reduced by 4 to 5 times, while maintaining comparable prediction accuracy. Additionally, extensive generalization experiments show that the model exhibits strong robustness. This highlights the effectiveness and practicality of the model in multivariate time series (MTS) forecasting.},
  keywords={Accuracy;Convolution;Computational modeling;Time series analysis;Predictive models;Feature extraction;Robustness;Complexity theory;Convolutional neural networks;Forecasting;multivariate time series;lightweight;multi- scale spatio-temporal convolution;multiscale attention mechanism;deep separable convolution},
  doi={10.1109/CEC65147.2025.11043014},
  ISSN={},
  month={June},}@INPROCEEDINGS{10161792,
  author={Beaulieu, Maxime and Candocia, Adrian and Taboh, Henry and Chen, Liangliang and Zhang, Ying},
  booktitle={2023 IEEE International Opportunity Research Scholars Symposium (ORSS)}, 
  title={Feature Importance Analysis For A Personalized Thermal Comfort Model Using Meta-learning}, 
  year={2023},
  volume={},
  number={},
  pages={24-28},
  abstract={The continual demand for energy-efficient devices has a far-reaching impact, and the HVAC system is no exception. To account for this energy demand, the HVAC system could potentially focus exclusively on energy efficiency while sacrificing user satisfaction. However, the thermal comfort of occupants is also a vital factor when designing HVAC control systems. In this paper, we present a personalized thermal preference model using meta-learning and feature importance analysis (FIA) in order to predict the thermal sensation of an individual with a minimum number of individual surveys and sensor measurements. The use of meta-learning reduces the number of required personalized thermal sensation votes. The FIA algorithm attempts to identify the most important features of the thermal preference model under the framework of meta-learning. With the ASHRAE database II, we find that the use of the FIA algorithm with meta-learning provides a clear distinction between the most important features in the model as compared to when only supervised learning is used.},
  keywords={Metalearning;Surveys;Analytical models;HVAC;Thermal factors;Supervised learning;Thermal sensors},
  doi={10.1109/ORSS58323.2023.10161792},
  ISSN={},
  month={April},}@INPROCEEDINGS{10971061,
  author={Magomedov, Vali O.},
  booktitle={2025 7th International Youth Conference on Radio Electronics, Electrical and Power Engineering (REEPE)}, 
  title={Fast and Lightweight Multiagent Image Generation Based on the Evolution Methods}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The paper presents a novel approach to the multiagent image generation leveraging the evolutionary methods to enhance both speed and efficiency. The developed method utilizes latent noise as an input to generate the facial images achieving a 10-fold increase in the learning speed while maintaining the high-quality output. Our approach integrates the lightweight multiagent methods with facilitating rapid adaptation in the complex environments. Experimental results demonstrate significant improvements in the learning time and image quality and demonstrate the evolution-driven techniques evolution in the efficient distributed generative tasks.},
  keywords={Image quality;Power engineering;Image synthesis;Noise;Evolutionary computation;multiagent learning;image generation;evolutionary algorithms;generative models;learning acceleration},
  doi={10.1109/REEPE63962.2025.10971061},
  ISSN={2831-7262},
  month={April},}@ARTICLE{9844142,
  author={Gorzałczany, Marian B. and Rudziński, Filip},
  journal={IEEE Internet of Things Journal}, 
  title={Intrusion Detection in Internet of Things With MQTT Protocol—An Accurate and Interpretable Genetic-Fuzzy Rule-Based Solution}, 
  year={2022},
  volume={9},
  number={24},
  pages={24843-24855},
  abstract={This article addresses the problem of an accurate and interpretable intrusion detection in Internet of Things (IoT) systems using the knowledge-discovery data-mining/machine-learning approach proposed by us. This approach—implemented as a fuzzy rule-based classifier—employs our generalization of the well-known multiobjective evolutionary optimization algorithm to optimize the accuracy-interpretability tradeoff of the IoT intrusion detection systems (IoT IDSs). The main contribution of this work is the design of accurate and interpretable IoT IDSs from the most recently published data—referred to as MQTT-IOT-IDS2020 data sets—describing the behavior of an MQTT-protocol-based IoT system. A comparison with seven available alternative approaches was also performed demonstrating that the approach proposed by us significantly outperforms alternative methods in terms of interpretability of intrusion-detection decisions made while remaining competitive or superior in terms of the accuracy of those decisions.},
  keywords={Intrusion detection;Internet of Things;Optimization;Protocols;Cyberattack;Genetic algorithms;Data mining;Machine learning;Data mining (DM);fuzzy rule-based classifiers (FRBCs);Internet of Things (IoT);interpretable intrusion detection;intrusion detection systems;machine learning (ML);MQTT protocol;multiobjective evolutionary optimization},
  doi={10.1109/JIOT.2022.3194837},
  ISSN={2327-4662},
  month={Dec},}@INPROCEEDINGS{10402252,
  author={Jiang, Zhenghong and Zhou, Chunrong},
  booktitle={2023 IEEE 15th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Application of Biomimetic Optimization Algorithm in Computer Vision Object Detection System}, 
  year={2023},
  volume={},
  number={},
  pages={507-512},
  abstract={Currently, computer vision object detection technology is rapidly developing in multiple fields. However, under limited memory conditions, computer vision object detection technology still faces problems such as difficulty in deploying a large number of models, long training cycles, poor real-time detection, difficulty in accurately locating prominent objects, and blurred boundaries. The biomimetic intelligent optimization algorithm is a goal optimal algorithm that simulates the survival and development patterns of organisms in nature, and can efficiently solve complex optimization problems. Using biomimetic intelligent optimization algorithms to solve complex object detection problems is a promising method. This article focused on the theory and methods of applying ABC optimization algorithms to image processing, and proposed a new approach to object detection in computer vision. The experimental results showed that the ABC optimization algorithm had high convergence accuracy and short calculation time. Moreover, in motion shadow detection, the shadow detection rate and shadow resolution reached 96.9% and 97.3%, respectively. It can be seen that bionic optimization algorithm has fast convergence speed and high search performance in computer vision target detection system, and the algorithm in this paper shows stable and good effect in moving shadow detection. These results and findings provide useful reference and guidance for object detection research in the field of computer vision.},
  keywords={Computer vision;Image segmentation;Biomimetics;Motion segmentation;Object detection;Optimization;Convergence;computer vision;target detection;biomimetic optimization algorithm;artificial bee colony optimization algorithm},
  doi={10.1109/CICN59264.2023.10402252},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{10456654,
  author={Chen, Kuiyu and Lei, Zhongkui and Huang, Daqing and Su, Nan and Ling, Zhicheng},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer Communication (EIECC)}, 
  title={A PSO-BP Target Localization Accuracy Enhancement Method for Airborne Optoelectronic Platforms}, 
  year={2023},
  volume={},
  number={},
  pages={198-203},
  abstract={This study aims to address the issue of target positioning accuracy in airborne optoelectronic platforms. Firstly, the paper refines and summarizes the typical workflow for target positioning based on UAV airborne optoelectronic platforms. To enhance the target positioning accuracy of airborne optoelectronic platforms, an improved method based on the particle swarm optimization algorithm (PSO) and the backpropagation neural network (BP) is proposed. The paper begins by explaining the research background and identifying the problems. It then proposes a target localization model based on the optoelectronic platform. Subsequently, the PSO-BP method is introduced, highlighting its advantages, principles, and implementation process. Experimental results demonstrate that the PSO-BP method can effectively enhance the target localization accuracy of airborne optoelectronic platforms. The research findings of this paper hold significant theoretical importance and practical value in improving the target localization accuracy of airborne optoelectronic platforms. Additionally, they offer a new research direction for further advancements in UAV target localization. In conclusion, this comprehensive literature review provides insights into the research gap and research motivation in the field of target positioning accuracy in airborne optoelectronic platforms. The proposed PSO-BP method demonstrates its effectiveness in enhancing target localization accuracy. The findings contribute to the theoretical understanding and practical application of improving target localization in airborne optoelectronic platforms, and they also suggest avenues for future research in UAV target localization.},
  keywords={Location awareness;Analytical models;Monte Carlo methods;Atmospheric modeling;Neural networks;Error compensation;Optical variables measurement;Airborne optoelectronic platform;Target positioning accuracy;Particle swarm optimisation algorithm;BP neural network},
  doi={10.1109/EIECC60864.2023.10456654},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10295024,
  author={Teng, Yuanxin and Wang, Guan and Su, Xiaomeng and Wu, Meiying},
  booktitle={2023 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)}, 
  title={Time Series Prediction of Transformer Oil Chromatography Based on Attention-PSO-GRU Model}, 
  year={2023},
  volume={},
  number={},
  pages={1019-1026},
  abstract={The content of dissolved gas in transformer oil is an important characteristic to reflect the operating condition of transformers. To overcome the problems that the traditional transformer oil chromatography gas prediction model cannot effectively use the older transformer oil chromatography data and it is difficult to track the transformer oil chromatography data under abnormal conditions and it can only rely on experience to adjust the model parameters, we introduce Gated Recurrent Unit (GRU), Attention Mechanism (APM) and Particle Swarm Optimization (PSO) to construct the Attention-PSO-GRU prediction model. Firstly, the transformer oil chromatography monitoring data are pre-processed, and the attention mechanism is introduced into the time channel to realize the redistribution of the input data weights. Then, the hyperparameters in the GRU model are optimality-seeking iterated by PSO to realize the adaptive tuning of the model. Finally, the optimized GRU neural network is used to extract spatiotemporal features from transformer oil chromatography monitoring data and construct the Attention-PSO-GRU transformer oil chromatography gas prediction model. The experimental results show that the Attention-PSO-GRU model can reach 97.9% accuracy in predicting the normal transformer oil chromatography data and has a better tracking ability for the abnormal transformer oil chromatography data. Therefore, the Attention-PSO-GRU model proposed in this paper can effectively improve the accuracy of transformer oil chromatography gas prediction, which has practical significance for preventing transformer faults and ensuring the safe and stable operation of power systems.},
  keywords={Adaptation models;Oils;Oil insulation;Predictive models;Transformers;Prediction algorithms;Data models;oil chromatography gas content prediction;attention mechanism;particle swarm optimization algorithm;Gated recurrent neural network},
  doi={10.1109/ICPSAsia58343.2023.10295024},
  ISSN={},
  month={July},}@ARTICLE{9499117,
  author={Bi, Ying and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Dual-Tree Genetic Programming for Few-Shot Image Classification}, 
  year={2022},
  volume={26},
  number={3},
  pages={555-569},
  abstract={Few-shot image classification (FSIC) is an important but challenging task due to high variations across images and a small number of training instances. A learning system often has poor generalization performance due to the lack of sufficient training data. Genetic programming (GP) has been successfully applied to image classification and achieved promising performance. This article proposes a GP-based approach with a dual-tree representation and a new fitness function to automatically learn image features for FSIC. The dual-tree representation allows the proposed approach to have better searchability and learn richer features than a single-tree representation when the number of training instances is very small. The fitness function based on the classification accuracy and the distances of the training instances to the class centroids aims to improve the generalization performance. The proposed approach can deal with different types of FSIC tasks with various numbers of classes and different image sizes. The results show that the proposed approach achieves significantly better performance than a large number of state-of-the-art methods on nine 3-shot and 5-shot image classification datasets. Further analysis shows the effectiveness of the new components of the proposed approach, its good searchability, and the high interpretability of the evolved solutions.},
  keywords={Training;Task analysis;Feature extraction;Genetic programming;Transfer learning;Genetic algorithms;Knowledge transfer;Few-shot learning (FSL);fitness evaluation;genetic programming (GP);image classification;representation},
  doi={10.1109/TEVC.2021.3100576},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{10431570,
  author={Luo, Feng and Liu, Ling and Wang, G. Geoff and Kumar, Vijay and Ashton, Mark S. and Abernethy, Jacob and Afghah, Fatemeh and Browning, Matthew H. E. M and Coyle, David and Dames, Philip and O'Halloran, Tom and Hays, James and Heisl, Patrick and Jiang, Chenfanfu and Khanal, Puskar and Krovi, Venkat Narayan and Kuebbing, Sara and Li, Nianyi and Liang, JingJing and Liu, Ninghao and McNulty, Steve and Oswalt, Christopher M. and Pederson, Neil and Terzopoulos, Demetri and Woodall, Christopher W. and Wu, Yongkai and Yang, Jian and Yang, Yin and Zhao, Liang},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Artificial Intelligence for Climate Smart Forestry: A Forward Looking Vision}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={Forests and forest ecosystems are vital to our social, economic, and environmental well-being. However, climate change and climate-driven disturbances (CDDs) are undermining the health and resilience of forests worldwide and pose significant uncertainty to sustainable forest management. Climate-smart forestry (CSF) remains a grand challenge in practice due to our limited knowledge of how forests respond to climate change and our abilities to collect related information to empower decision making. Rapid advances in artificial intelligence (AI) can offer a timely opportunity to address the challenges in CSF. We argue that the AI-enabled, next-generation CSF can be achievable through synergistically coordinated and transdisciplinary efforts that develop and advance foundational and use-inspired AI technologies that can lead to building next-generation forest decision support systems.},
  keywords={Climate change;Forestry;Artificial intelligence;Ecosystems;Environmental monitoring;Environmental management;Decision making;Smart agriculture;Global warming;Globalization;Sustainable development;artificial intelligence;climate-smart forestry},
  doi={10.1109/CogMI58952.2023.00011},
  ISSN={},
  month={Nov},}@ARTICLE{10745990,
  author={Zhou, Qian and Wu, Jiayang and Dai, Hua and Yang, Geng and Zhang, Yanchun},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={An Intelligent Ride-Sharing Recommendation Method Based on Graph Neural Network and Evolutionary Computation}, 
  year={2025},
  volume={26},
  number={1},
  pages={569-578},
  abstract={This research is dedicated to addressing user recommendation matching and multi-objective optimization problems in ride-sharing services. For addressing the challenge of node classification in social networks, the Graph Attention Network with Opinion Dynamics (OD-GAT) is proposed. This model combines opinion dynamics and attention mechanism, which can make full use of multi-dimensional information for social relationship reasoning, and at the same time simulate the influence of individuals by other objects in the group, realize more accurate prediction and reasoning of social relationships, improved service quality and ride-sharing safety. To address the intricate task of balancing multiple objectives, including average detour cost, average response rate, and average user similarity rate, we introduce a novel evolutionary computation method for optimizing ride-sharing scenarios. This approach tackles the dynamic ride-sharing matching problem by emphasizing human factors in the optimization goals, successfully overcoming challenges related to local optima and convergence. Experimental validation confirms the effectiveness of OD-GAT in feature extraction and classification, showcasing the method’s fastest convergence speed and global optimum achievement across three key metrics.},
  keywords={Optimization;Social networking (online);Costs;Vehicle dynamics;Evolutionary computation;Safety;Heuristic algorithms;Feature extraction;Convergence;Mathematical models;Graph attention network;opinion dynamics;social network analysis;evolutionary computation},
  doi={10.1109/TITS.2024.3485985},
  ISSN={1558-0016},
  month={Jan},}@INPROCEEDINGS{9870293,
  author={Junior, João Roberto Bertini and Cano, Alberto},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={An Explainable Classifier based on Genetically Evolved Graph Structures}, 
  year={2022},
  volume={},
  number={},
  pages={01-08},
  abstract={Trusting an algorithmic decision is much easier if it is understood how it was achieved. Therefore, data mining algorithms with explainable abilities are preferred over complex models for critical applications. Rule-based algorithms are among the easiest data classification models to understand. However, as most interpretable models, rule-based algorithms do not provide the highest accuracy. The Attribute-based Decision Graph (AbDG) is a model to represent a labeled data set as a weighted graph over the attributes. When associated with a proper algorithm, AbDGs can be used for supervised data mining tasks. An important aspect of AbDGs is that the graph encompasses the original attribute values and their relationships, which makes it easily interpretable by extracting rules. The AbDG drawback is defining a suitable graph structure for a given data set. In previous works, the authors proposed GA-AbDG, a genetic algorithm to search for an AbDG by evolving its edge set, keeping the vertex set fixed. In this paper, we propose an evolutionary algorithm and genetic operators to evolve both, vertex and edge sets, enhancing the search space of possible AbDG structures. Moreover, we associate a rule-based classifier with the AbDG to achieve explainable results. Experimental results show the proposed method outperforms GA-AbDG and five other classical interpretable classification algorithms.},
  keywords={Knowledge based systems;Evolutionary computation;Genetics;Data models;Classification algorithms;Topology;Data mining;Attribute-based Decision Graphs;Explainable Classification;Genetically Evolving Classifiers},
  doi={10.1109/CEC55065.2022.9870293},
  ISSN={},
  month={July},}@INPROCEEDINGS{10662749,
  author={Ma, Huaibo and Ma, Jun and Li, Xiang},
  booktitle={2024 43rd Chinese Control Conference (CCC)}, 
  title={Interpretable prediction method of Matte grade based on GA-BiLSTM and SHAP}, 
  year={2024},
  volume={},
  number={},
  pages={3565-3570},
  abstract={Aiming at the problem that the ice-copper grade prediction process is difficult to effectively capture the long-term dependency relationship between data, which leads to low prediction accuracy, it is proposed to construct a model using the powerful long-term memory capability and bidirectional information prediction ability of bidirectional long and short-term memory network (BiLSTM) model, and further optimize the model by using the genetic algorithm (GA) to achieve accurate prediction of ice-copper grades. First, the genetic algorithm was used to find the optimal hyperparameter combination of the model. Second, the predicted values of the BiLSTM model optimized by the genetic algorithm are compared with the predicted values of the existing methods and the unoptimized BiLSTM model using different evaluation indexes. Finally, the SHAP method is used to give the overall and local interpretation of the prediction results of the BiLSTM model. The experimental results show that the RMSE of the BiLSTM model optimized by the genetic algorithm is reduced by at least $3.05 \%$, the MAE is reduced by at least $2.75 \%$, the MAPE is reduced by at least $3.29 \%$, and the $\mathrm{R}^{2}$ is increased by at least 1.51%, which verifies the effectiveness of the proposed method in solving the problem of ice-copper grade prediction, and the SHAP method is able to explain the output of the BiLSTM model efficiently and increase the transparency of the model. The SHAP method can effectively explain the output of the BiLSTM model and increase the transparency of the model.},
  keywords={Recurrent neural networks;Accuracy;Production;Predictive models;Prediction algorithms;Data models;Reliability;Matte grade prediction;Genetic algorithm;BiLSTM model;SHAP model interpretation},
  doi={10.23919/CCC63176.2024.10662749},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{9851027,
  author={Wang, Zhengqin},
  booktitle={2022 4th International Conference on Communications, Information System and Computer Engineering (CISCE)}, 
  title={Research on industrial Internet Platform Technology based on machine learning algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={390-396},
  abstract={Industrial Internet, is a new generation of information technology and industrial system full range of deep integration of the product, mainly for the transformation and upgrading of the manufacturing industry, can greatly boost the development of productivity, to pull the real economy has an important role. However, as the industrial Internet is an emerging industry, its development and construction experience and capacity are still in the initial stage. The report to the 19th National Congress of the Communist Party of China made it clear that we will promote the deep integration of the Internet, big data, artificial intelligence and the real economy. After the financial crisis, the manufacturing industry once again became the focus of global attention. With the digital transformation of the manufacturing industry, the industrial Internet platform based on cloud computing, big data, Internet of Things, artificial intelligence and other new generation of information technology emerged. With the development of machine learning and deep learning, machine learning models such as genetic algorithm and gradient optimization have achieved good results in data classification, regression and fitting. Internet project evaluation based on industry characteristics, puts forward the improved analytic hierarchy process (ahp) based on machine learning methods, and machine learning algorithms and hierarchical analysis method, puts forward a new solution to the problem of the expert scoring to determine judgment matrix and in order to achieve the consistency and accuracy of the algorithm and introduce the weight of the particle swarm algorithm to adjust and sorting, Reduce the inaccuracy and complexity of ahp algorithm in the face of complex problems. To achieve the expert scoring more comprehensive consideration method, as well as more intelligent consistency adjustment and final weight calculation, the index of the industrial Internet design scheme weight calculation, finally according to the scoring scheme and the final hair there are final evaluation scores and further analysis and explanation of the results.},
  keywords={Manufacturing industries;Machine learning algorithms;Analytic hierarchy process;Big Data;Internet;Complexity theory;Indexes;Industrial Internet;machine learning;analytic hierarchy Process;particle swarm optimization},
  doi={10.1109/CISCE55963.2022.9851027},
  ISSN={},
  month={May},}@INPROCEEDINGS{11025880,
  author={Valenzuela-Toledo, Pablo and Wu, Chuyue and Hernández, Sandro and Boll, Alexander and Machacek, Roman and Panichella, Sebastiano and Kehrer, Timo},
  booktitle={2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC)}, 
  title={Explaining GitHub Actions Failures with Large Language Models: Challenges, Insights, and Limitations}, 
  year={2025},
  volume={},
  number={},
  pages={286-297},
  abstract={GitHub Actions (GA) has become the de facto tool that developers use to automate software workflows, seamlessly building, testing, and deploying code. Yet when GA fails, it disrupts development, causing delays and driving up costs. Diagnosing failures becomes especially challenging because error logs are often long, complex and unstructured. Given these difficulties, this study explores the potential of large language models (LLMs) to generate correct, clear, concise, and actionable contextual descriptions (or summaries) for GA failures, focusing on developers' perceptions of their feasibility and usefulness. Our results show that over 80 % of developers rated LLM explanations positively in terms of correctness for simpler/small logs. Overall, our findings suggest that LLMs can feasibly assist developers in understanding common GA errors, thus, potentially reducing manual analysis. However, we also found that improved reasoning abilities are needed to support more complex CI/CD scenarios. For instance, less experienced developers tend to be more positive on the described context, while seasoned developers prefer concise summaries. Overall, our work offers key insights for researchers enhancing LLM reasoning, particularly in adapting explanations to user expertise.},
  keywords={Productivity;Large language models;Focusing;Manuals;Cognition;Stability analysis;Software;Usability;Software development management;Testing;CI/CD;GitHub Actions;Large Language Models;GitHub Action Run Failure Explanation},
  doi={10.1109/ICPC66645.2025.00037},
  ISSN={2643-7171},
  month={April},}@INPROCEEDINGS{10291988,
  author={Ferren, Felicia and Kurniadi, Felix Indra},
  booktitle={2023 10th International Conference on ICT for Smart Society (ICISS)}, 
  title={Enhancing Bankruptcy Prediction with Feature Selection in AdaBoost Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Since the 1960s, bankruptcy prediction research has been intensively examined, with the importance of accurate forecasting representing a nation's economic development. The high costs related to business failures have prompted efforts to enhance prediction techniques, which have been highlighted further as the effects of globalization have increased. There are two primary types of bankruptcy prediction models: statistical and artificial intelligence (AI) methods. The study found that several AI algorithms, namely C5.0, CART, and Support Vector Machines with evolutionary computation, demonstrated efficacy in forecasting impending bankruptcies, as well as short- and long-term predictions. Prior studies have proposed the utilization of Multilayer Perceptron (MLP), ensemble learning methodologies, and AdaBoost as potential approaches for the purpose of bankruptcy prediction. The significance of feature importance is frequently disregarded in such models, resulting in prejudiced outcomes. This study presents a proposed approach for feature selection in AdaBoost algorithm that incorporates the consideration of feature importance, with the aim of enhancing the aforementioned findings. The proposed methodology is validated through a comparative analysis with several other machine learning algorithms. The result showed that ADABoost with feature selection using feature importance generated better value with increased around 5-7% in accuracy score.},
  keywords={Support vector machines;Machine learning algorithms;Biological system modeling;Globalization;Predictive models;Prediction algorithms;Feature extraction;bankrupt;Adaboost;feature importance;feature selection},
  doi={10.1109/ICISS59129.2023.10291988},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11007626,
  author={Wang, Bingcheng and Hiwa, Satoru and Hiroyasu, Tomoyuki},
  booktitle={2025 IEEE Symposium on Computational Intelligence on Engineering/Cyber Physical Systems (CIES)}, 
  title={A Structural Topology Optimization Method Integrating Genetic Algorithm and Bidirectional Evolutionary Structural Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This study introduces a novel framework for topology optimization in structural design by integrating global and local search algorithms. Specifically, a genetic algorithm (GA) is employed as the global search method, leveraging its strengths in handling diverse objective functions while preserving interpretability throughout the optimization process. As a specific example of the framework, a system integrating GA as the global search algorithm and Bidirectional Evolutionary Structural Optimization (BESO) as the local search algorithm is introduced. GA is employed for its global exploration capability, enabling exploration on a diverse set of solutions for a wide range of optimization problems. BESO is applied as a local search method to refine solutions, enhancing the optimization results by precisely adjusting the structural design during the searching process. The effectiveness of this approach is demonstrated through two numerical examples focusing on their own primary objectives: one maximizing the structural stiffness, and the other maximizing the displacement. The results show that the combination of GA and BESO effectively meets the set design goals, highlighting the potential for significant structural design improvements through their synergistic effect, confirming the benefits of combining GA's ability to conduct global exploration with BESO's capacity to fine-tune solutions through local search. This study demonstrates the effectiveness of integrating GA and BESO in structural topology optimization, providing a powerful tool for advancing generative structural design.},
  keywords={Refining;Linear programming;Three-dimensional printing;Search problems;Topology;Optimization;Stress;Standards;Genetic algorithms;Pragmatics;Structural Topology Optimization;GA with Local Search;BESO;Generative Design;Finite Element Method},
  doi={10.1109/CIES64955.2025.11007626},
  ISSN={},
  month={March},}@INPROCEEDINGS{10612005,
  author={Zhang, Hanyu and Tang, Lixin and Song, Xiangman and Xu, Te},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={NSMD-NAS: Retinal Image Segmentation with Neural Architecture Search and Non-Subsampled Multiscale Decomposition}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Accurate segmentation of the microvascular component of the retinal fundus image is of great significance for the clinical diagnosis. Currently, deep learning-based methods are often employed for retinal fundus image segmentation. However, most deep learning models manually designed by experts are not suitable for task-specific applications. Therefore, we propose a novel retinal image segmentation method that integrates a neural architecture search framework with a non-subsampled multiscale decomposition (NSMD-NAS) technique. Specifically, the feature extraction layer includes the convolutional layer and the transformer layer. In addition, the non-subsampling filter bank is embedded into the convolutional and the transformer modules respectively to generate a new network module for exploring multiscale, multi-frequency, and multi-directional information. Unlike previous wavelet-based network modules, non-subsampling network modules have translation invariance. Subsequently, the components of the network are specified by the elaborated encoding strategy, and then the network with the highest adaptation is searched by a genetic evolutionary algorithm (GA) to finally obtain the best network structure. Experimental results demonstrate the effectiveness of each component in the proposed model on the public benchmark datasets.},
  keywords={Convolutional codes;Wavelet transforms;Image segmentation;Filter banks;Computer architecture;Evolutionary computation;Retina;Retinal vessel image segmentation;Neural architecture search;Non-subsampled multiscale decomposition;Transformer Unet;Evolutionary algorithm},
  doi={10.1109/CEC60901.2024.10612005},
  ISSN={},
  month={June},}@ARTICLE{10696966,
  author={Liu, Xiaofeng and Ma, Yinglong and Chen, Degang and Liu, Ling},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Toward Embedding Ambiguity-Sensitive Graph Neural Network Explainability}, 
  year={2024},
  volume={32},
  number={12},
  pages={6951-6964},
  abstract={Recently, many post hoc graph neural network (GNN) explanation methods have been explored to uncover GNNs' predictive behaviors by analyzing the embeddings produced by the GNN models. However, these methods suffer from explanation ambiguity inherent in learned graph embeddings because aggregation-based embeddings can lead to the loss of unique identifiers for individual graph components and, thus, allow noncausal nodes that are adjacent to true causal patterns to unintentionally embody causal information in their embeddings, hindering the explanations from faithfully representing the true insights of GNNs' predictive reasoning. In this article, we present an embedding ambiguity-sensitive GNN explanation framework (EAGX). EAGX can effectively mitigate the impact of embedding-induced explanation ambiguity by creating edges' ambiguity feature extractor, exploring edges' predictive relevance, and integrating them into the explanation process, thereby capturing each graph component's contribution to the predictions. Specifically, we first propose a centroid-constrained fuzzy c-means algorithm to construct an ambiguity feature extractor. Then, we leverage the ambiguity features for edges to develop the ambiguity-based edge attribution module for assigning a prediction relevance score to each edge. Finally, instead of focusing only on the edges with high influence to the GNN prediction, we introduce a joint optimization strategy to refine the learning process of our edge attribution module, empowering EAGX to capture the subtle interplay of both causal and noncausal subgraphs on model predictions, which further improve the explainability of GNN predictions. Experimental results demonstrate that EAGX outperforms the leading explainers on most evaluation metrics, underscoring its effectiveness in generating reliable and precise explanations for GNNs.},
  keywords={Predictive models;Graph neural networks;Feature extraction;Optimization;Fuzzy systems;Reliability;Prototypes;Analytical models;Probability distribution;Power systems;Embedding ambiguity;explainability;fuzzy C-means (FCM);graph neural networks (GNNs);joint optimization},
  doi={10.1109/TFUZZ.2024.3457914},
  ISSN={1941-0034},
  month={Dec},}@ARTICLE{10829859,
  author={Xue, Xingsi and Li, Xingwang},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Explicit and Implicit Consumer Electronics Information Integration via Automatic Large Language Model Construction}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Integrating diverse Consumer Electronics (CE) information is essential to enhance and optimize user experiences, but CE Information Integration (CEII) faces challenges arising from differences in entity descriptions. In recent years, Large Language Models (LLMs) have emerged as valuable tools for analyzing heterogeneous CE data due to their deep contextual embeddings. However, different LLMs capture various nuances and complexity levels within the CE data, and none of them can ensure their effectiveness in all heterogeneous scenarios. To address this issue, this paper proposes an automatic LLM Construction for CEII, which can determine both explicit and implicit CE entity mappings. First, a hybrid Genetic Programming is developed to determine explicit entity mappings using a new individual representation, an innovative fitness function, and a Probability-based Incremental Learning algorithm. Then, a novel Rough Set based matching method is presented to efficiently induce implicit CE entity mappings, which uses the entity feature relevance metric and the dominance-based matching approach. The experiment tests the performance of our approach with the OAEI’s KG and common KG datasets, and the practical CE datasets in the smart home context. The experimental results show the effectiveness of the developed approach, which significantly outperforms the state-of-the-art entity matching methods.},
  keywords={Consumer electronics;Accuracy;Complexity theory;Optimization;Interoperability;Uncertainty;Training;Terminology;Smart homes;Simple object access protocol;Consumer Electronics;Information Integration;Large Language Model;Genetic Programming;Rough Set},
  doi={10.1109/TCE.2025.3526772},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{10721056,
  author={Feng, Chao and Zhu, Jianjun and Zhao, Zhongyang and Shi, Qinfeng and Zhuge, Jingtao and Yang, Haoming},
  booktitle={2024 4th Power System and Green Energy Conference (PSGEC)}, 
  title={Outlet Dust Concentration Prediction of Electrostatic Precipitator Based on Deep Learning Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={7-12},
  abstract={Electrostatic precipitator is the main equipment for removing dust in coal-fired power plants, it removes dust by consuming electrical energy. Establishing an accurate prediction model for electrostatic precipitator can provide important scientific basis for reducing pollution and carbon emissions in coal-fired power plants, which is of great significance for achieving the dual-carbon target. This paper proposes a mechanism model, and the variable parameters are trained through Particle Swarm Optimization algorithm. Then a hybrid model is established based on long short-term memory network and Attention mechanism. The historical data of electrostatic precipitator in a 330MW unit are used for training and testing finally. The results show that the Relative Root Mean Squared Error of hybrid model on the training set and testing set are 0.5% and 3.99%, accurate outlet dust concentration prediction has been realized.},
  keywords={Training;Accuracy;Predictive models;Prediction algorithms;Data models;Hybrid power systems;Electrostatic precipitators;Long short term memory;Power generation;Testing;electrostatic precipitator;accurate prediction;hybrid model;attention mechanism},
  doi={10.1109/PSGEC62376.2024.10721056},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10611913,
  author={Liu, Shengcai and Chen, Caishun and Qu, Xinghua and Tang, Ke and Ong, Yew-Soon},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Large Language Models as Evolutionary Optimizers}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Evolutionary algorithms (EAs) have achieved remarkable success in tackling complex combinatorial optimization problems. However, EAs often demand carefully-designed operators with the aid of domain expertise to achieve satisfactory performance. In this work, we present the first study on large language models (LLMs) as evolutionary combinatorial optimizers. The main advantage is that it requires minimal domain knowledge and human efforts, as well as no additional training of the model. This approach is referred to as LLM-driven EA (LMEA). Specifically, in each generation of the evolutionary search, LMEA instructs the LLM to select parent solutions from current population, and perform crossover and mutation to generate offspring solutions. Then, LMEA evaluates these new solutions and include them into the population for the next generation. LMEA is equipped with a self-adaptation mechanism that controls the temperature of the LLM. This enables it to balance between exploration and exploitation and prevents the search from getting stuck in local optima. We investigate the power of LMEA on the classical traveling salesman problems (TSPs) widely used in combinatorial optimization research. Notably, the results show that LMEA performs competitively to traditional heuristics in finding high-quality solutions on TSP instances with up to 20 nodes. Additionally, we also study the effectiveness of LLM-driven crossover/mutation and the self- adaptation mechanism in evolutionary search. In summary, our results reveal the great potentials of LLMs as evolutionary optimizers for solving combinatorial problems. We hope our research shall inspire future explorations on LLM-driven EAs for complex optimization challenges.},
  keywords={Training;Large language models;Computational modeling;Sociology;Evolutionary computation;Traveling salesman problems;Temperature control;Evolutionary algorithms;large language model;combinatorial optimization;pre-trained model},
  doi={10.1109/CEC60901.2024.10611913},
  ISSN={},
  month={June},}@INPROCEEDINGS{10257736,
  author={Ming, Yue and Li, Kaiwen},
  booktitle={2023 IEEE International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={A Real-time Reconfiguration Approach for Wireless Energy Networks Using Heterogeneous Graph Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1343-1347},
  abstract={In recent years, drones have found widespread applications in communications, disaster relief, and other fields. However, due to battery capacity constraints, the limited flight endurance of drones hinders their full potential. With the development of wireless charging technology, it can effectively expand the operational range and duration of drones in various scenarios. This paper investigates wireless energy networks based on wireless charging, optimizing the wireless energy network comprising power generators, relays, and energy consumption endpoints to ensure reliable power supply for drones. To enhance system response times in disaster relief and other scenarios, we propose a real-time reconfiguration approach for wireless energy networks using heterogeneous graph neural networks. By modeling the wireless energy network through a heterogeneous graph neural network and utilizing reinforcement learning methods for model training, the trained model can achieve real-time construction of wireless energy networks. Comparative experiments demonstrate the effectiveness and efficiency of the proposed algorithm, which can facilitate real-time construction of wireless energy networks.},
  keywords={Wireless communication;Training;Inductive charging;Reinforcement learning;Real-time systems;Graph neural networks;Time factors;drones;wireless charging;heterogeneous graph neural networks;reinforcement learning;wireless energy network},
  doi={10.1109/ICIPCA59209.2023.10257736},
  ISSN={},
  month={Aug},}@ARTICLE{10133893,
  author={Smith, Robert J. and Heywood, Malcolm I.},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Interpreting Tangled Program Graphs Under Partially Observable Dota 2 Invoker Tasks}, 
  year={2024},
  volume={5},
  number={4},
  pages={1511-1524},
  abstract={Interpretable learning agents directly construct models that provide insight into the relationships learnt. Moreover, to date, there has been a lot of emphasis on interpreting reactive models developed for supervised learning tasks. In this article, we consider the case of models developed to address a suite of six partially observable tasks defined in the Dota 2 Online Battle Arena game engine. This means that learning agents need to make decisions based on the previous state as developed by the learning agent's memory, in addition to a 310-D state vector provided by the game engine. Interpretability is addressed by adopting the tangled program graph approach to developing learning agents. Thus, decision making is explicitly divide-and-conquer, with different parts of the resulting graph visited depending on the task context. We demonstrate that programs comprising the tangled program graph approach self-organize such that: 1) small subsets of task features are identified to define conditions under which index memory is written and 2) the subset of programs responsible for defining actions typically query indexed memory rather than task features. Particular preferences emerge for different tasks; thus, the blocking (or evasion) tasks result in a preference for specific actions, whereas more open-ended tasks assume policies based on combinations of behaviors. In short, the ability to evolve the topology of the learning agent provides insights into how the policies are being constructed for addressing partially observable tasks.},
  keywords={Task analysis;Artificial intelligence;Reinforcement learning;Registers;Genetic programming;Complexity theory;Visualization;Emergence;evolutionary computation;genetic programming (GP);interpretable machine learning},
  doi={10.1109/TAI.2023.3279057},
  ISSN={2691-4581},
  month={April},}@INPROCEEDINGS{10971559,
  author={Akpomedaye, Bennett and Oyewole, Onaopemipo and Izuchukwu, Chiazam and Ajuluchukwu, Melvin and Chen, Lei},
  booktitle={SoutheastCon 2025}, 
  title={Automated Risk Prioritization and Mitigation System (ARPMS)}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Managing risks in Agile IT projects particularly for small and medium enterprises (SMEs), is a complex challenge due to the iterative and dynamic nature of Agile methodologies. Conventional risk management frameworks frequently prove inadequate for these complexities, resulting in possible delays, budget excesses, and diminished quality. In this paper, we present a Risk Prioritization and Mitigation System as a solution that utilizes Artificial Intelligence to automate the risk detection, prioritization, and mitigation processes in Agile workflows. Employing machine-learning algorithms like XGBoost classifiers and data preprocessing methods like Principal Component Analysis (PCA) for dimensionality reduction, ARPMS classifies the data into the required risk levels (low, medium, and high risk) with almost 100% accuracy. The system aims to interface with Agile tools, providing real-time risk alerts and actionable insights via an interactive dashboard. Testing performed on an incident log and credit risk data sets proved ARPMS's capability to mitigate risk impact, enhance decision-making, and optimize project results. Future improvements include scaling the datasets, adding real-time data streams, and further investigation for adaptive prioritization. ARPMS integrates predictive analytics with Agile principles, providing a scalable and robust risk management approach that enables teams to proactively enhance project resilience.},
  keywords={Accuracy;Prevention and mitigation;Real-time systems;Robustness;Predictive analytics;Streams;Principal component analysis;Business;Testing;Resilience;Agile workflows;Artificial Intelligence;Risk Prioritization;Machine-learning;Predictive Analytics},
  doi={10.1109/SoutheastCon56624.2025.10971559},
  ISSN={1558-058X},
  month={March},}
