@INPROCEEDINGS{10356583,
  author={Labba, Chahrazed and Alcouffe, Ameline and Crubézy, Eric and Boyer, Anne},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={IArch: An AI Tool for Digging Deeper into Archaeological Data}, 
  year={2023},
  volume={},
  number={},
  pages={22-29},
  abstract={The use of Artificial Intelligence (AI), notably Machine Learning (ML), is gaining momentum in archaeology, opening up new possibilities such as artifact classification, site location prediction, and remains analysis. One of the major challenges in this regard is the lack of qualified archaeologists who are experts in machine learning. In this study, we introduce IArch, a tool that enables eXplainable Artificial Intelligence (XAI) data analytics for archaeologists without requiring specific programming skills. It specifically allows data analysis performed to either validate existing data-supported hypotheses or generate new ones. The tool covers the entire workflow for applying ML, from data processing to explaining the final results. The tool allows the use of supervised and unsupervised ML algorithms, as well as the SHapley Additive exPlanations (SHAP) technique to provide archaeologists with global and individual explanations for the predictions. We demonstrate its use on data from a Xiongnu cemetery (100 BC/AD 100) in the Mongolian steppes.},
  keywords={Archeology;Data analysis;Additives;Machine learning;Programming;Prediction algorithms;Machine Learning;supervised;unsupervised;Explainability;Archaeology;classification;clustering},
  doi={10.1109/ICTAI59109.2023.00012},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11043078,
  author={Shi, Hongxi and Du, Yonghao and Zhang, Ziyang and Li, Lei and Wang, Feiran},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={LLM Based Bi-Level Online Order Dispatching and Scheduling for Large-Scale Earth Observation Satellites}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={With the increasing demand for scheduling large-scale Earth Observation Satellites (EOS), traditional scheduling models are no longer sufficient to meet the requirements for flexibility and order-driven operations. To address this challenge, this paper proposes a Large Language Model (LLM)-based Bi-level Online Order Dispatching and Scheduling (LLM-BODS) algorithm. The proposed algorithm consists of three key components: a bi-level online optimization framework, an LLM-based order dispatching algorithm, and a metaheuristic algorithm for single-satellite order scheduling. Within the bi-level optimization framework, the upper level dynamically allocates orders to satellites based on real-time order demands and satellite resource states using the LLM-based order dispatching algorithm. The lower level employs an adaptive large neighborhood search (ALNS) metaheuristic to generate optimal task execution sequences for each satellite. Experimental results demonstrate that the proposed algorithm not only maintains scheduling quality but also enhances scheduling efficiency, effectively addressing the flexible scheduling needs of large-scale Earth Observation Satellites.},
  keywords={Earth;Satellites;Scheduling algorithms;Heuristic algorithms;Large language models;Metaheuristics;Dynamic scheduling;Search problems;Dispatching;Resource management;Earth observation satellites;Large language model;Bi-level online optimization;Order dispatching;Adaptive large neighborhood search;Dynamic resource allocation},
  doi={10.1109/CEC65147.2025.11043078},
  ISSN={},
  month={June},}@ARTICLE{10942333,
  author={Saha, Chamak and Saha, Somak and Rahman, Md. Asadur and Milu, Md. Mahmudul Haque and Higa, Hiroki and Rashid, Mohd Abdur and Ahmed, Nasim},
  journal={IEEE Access}, 
  title={Lung-AttNet: An Attention Mechanism-Based CNN Architecture for Lung Cancer Detection With Federated Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={57369-57386},
  abstract={Lung cancer is one of the fatal diseases whose early diagnosis is essential to mitigate the death rate. Computed Tomography (CT) scans are widely used for lung cancer diagnosis, but manual interpretation by health professionals can lead to inconsistent results. To address this, we propose Lung-AttNet, a novel lightweight convolutional neural network (CNN) model enhanced with an attention mechanism. Lung-AttNet incorporates a convolutional block with a Lightweight Global Attention Module (LGAM) to effectively distinguish between lung cancer types. The convolutional block extracts both low- and high-dimensional features, while LGAM captures feature dependencies across channel and spatial dimensions. The model is evaluated using the Kaggle CT scan dataset, which includes four classes: adenocarcinoma, large cell carcinoma, squamous cell carcinoma, and normal. Extensive experiments, including ablation studies, 5-fold cross-validation, and explainable AI (XAI) techniques such as Grad-CAM and LIME, demonstrate that Lung-AttNet achieves an average accuracy of 91.5%. Furthermore, to address medical data sensitivity and privacy concerns, the model is deployed in a Federated Learning (FL) framework, where the global model is trained using weights from local models rather than sharing raw data. In the FL environment, Lung-AttNet achieves an accuracy of 92% with 2 and 3 clients, underscoring its robustness and adaptability for real-world applications.},
  keywords={Lung cancer;Convolutional neural networks;Computed tomography;Data models;Feature extraction;Federated learning;Accuracy;Computer architecture;Residual neural networks;Medical diagnostic imaging;CNN;LGAM;federated learning;XAI;Lung-AttNet},
  doi={10.1109/ACCESS.2025.3554744},
  ISSN={2169-3536},
  month={},}@ARTICLE{11008653,
  author={Syllaidopoulos, Ioannis and Ntalianis, Klimis S. and Salmon, Ioannis},
  journal={IEEE Access}, 
  title={A Comprehensive Survey on AI in Counter-Terrorism and Cybersecurity: Challenges and Ethical Dimensions}, 
  year={2025},
  volume={13},
  number={},
  pages={91740-91764},
  abstract={The advanced capabilities in threat detection and mitigation brought about by the rapid development of Artificial Intelligence (AI) significantly impact the fight against terrorism and cybersecurity threats. However, critical concerns such as algorithmic bias, data quality limitations, and governance challenges introduce significant obstacles to their deployment. This paper provides a comprehensive overview of AI methodologies, such as predictive analytics, Natural Language Processing (NLP), and machine learning architectures (e.g., Support Vector Machines – SVM and Long Short-Term Memory – LSTM), and optimization algorithms (e.g., Particle Swarm Optimization – PSO), assessing their effectiveness in security applications. Additionally, AI-based approaches to surveillance, misinformation management, and anomaly detection are explored, focusing on their impacts on national security. Beyond the technical aspects, the paper highlights ethical concerns and policy issues, putting forward frameworks such as Explainable Artificial Intelligence (XAI) and crowdsourced intelligence (Crosint) to ensure the responsible and transparent deployment of AI. The integration of the technical, ethical, and operational perspectives addressed in this research contributes to a holistic understanding of the potential of AI in cybersecurity, while also ensuring adherence to AI governance standards.},
  keywords={Artificial intelligence;Computer security;Natural language processing;Machine learning;Ethics;Threat assessment;Fake news;Deep learning;Biological system modeling;Surveys;Artificial intelligence;counter-terrorism;cybersecurity;machine learning;explainable artificial intelligence (XAI);misinformation management;natural language processing (NLP);threat detection},
  doi={10.1109/ACCESS.2025.3572348},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9870430,
  author={Hong, Haokai and Jiang, Min and Feng, Liang and Lin, Qiuzhen and Tan, Kay Chen},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Balancing Exploration and Exploitation for Solving Large-scale Multiobjective Optimization via Attention Mechanism}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Large-scale multiobjective optimization problems (LSMOPs) refer to optimization problems with multiple con-flicting optimization objectives and hundreds or even thousands of decision variables. A key point in solving LSMOPs is how to balance exploration and exploitation so that the algorithm can search in a huge decision space efficiently. Large-scale multi-objective evolutionary algorithms consider the balance between exploration and exploitation from the individual's perspective. However, these algorithms ignore the significance of tackling this issue from the perspective of decision variables, which makes the algorithm lack the ability to search from different dimensions and limits the performance of the algorithm. In this paper, we propose a large-scale multiobjective optimization algorithm based on the attention mechanism, called (LMOAM). The attention mechanism will assign a unique weight to each decision variable, and LMOAM will use this weight to strike a balance between exploration and exploitation from the decision variable level. Nine different sets of LSMOP benchmarks are conducted to verify the algorithm proposed in this paper, and the experimental results validate the effectiveness of our design.},
  keywords={Evolutionary computation;Benchmark testing;Optimization;Evolutionary algorithms;large-scale optimization;multiobjective optimization;attention mechanism},
  doi={10.1109/CEC55065.2022.9870430},
  ISSN={},
  month={July},}@ARTICLE{10599558,
  author={Yang, Shangshang and Ma, Haiping and Bi, Ying and Tian, Ye and Zhang, Limiao and Jin, Yaochu and Zhang, Xingyi},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={An Evolutionary Multi-Objective Neural Architecture Search Approach to Advancing Cognitive Diagnosis in Intelligent Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={As a pivotal technique in intelligent education systems, cognitive diagnosis (CD) serves to reveal students’ knowledge proficiency for better tackling subsequent tasks. Unfortunately, due to pursuing high model interpretability, existing manually designed models for CD often hold simplistic architectures, which cannot cope with intricate data in modern education platforms. Furthermore, the bias of human design limits the emergence of novel and effective CD models. To develop interpretable and more effective models, thus this paper proposes an evolutionary multi-objective neural architecture search (NAS) approach for CD. Specifically, we first adopt a comprehensive search space for the NAS task of CD: all candidate models can be encompassed by a general model that deals with three distinct types of inputs. Then, an innovative model interpretability objective is devised to formulate the architecture search task as a bi-objective optimization problem (BOP). To solve the BOP, we employ a multi-objective genetic programming (MOGP) as the search strategy to explore the search space. To make the employed MOGP search well, all architectures are first encoded by trees for easy optimization, and we devise a genetic operation and a population initialization strategy to expedite its convergence. Finally, the proposed approach is actually a MOGP-based NAS approach for CD. Extensive experiments show that CD models searched by the proposed approach exhibit significantly better performance than existing models and hold as good interpretability as handcrafted models. Besides, the effectiveness of the proposed MOGP search strategy, the devised objective, and tailored strategies are validated.},
  keywords={Vectors;Task analysis;Search problems;Computer architecture;Evolutionary computation;Education;Optimization;Cognitive diagnosis;intelligent education;evolutionary neural architecture search;multi-objective optimization;genetic programming},
  doi={10.1109/TEVC.2024.3429180},
  ISSN={1941-0026},
  month={},}@ARTICLE{11018339,
  author={Das, Rhiddhi Prasad and Jena, Junali Jasmine and Satapathy, Suresh Chandra and Hannoon, Naeem M. S.},
  journal={IEEE Access}, 
  title={Solving 0-1 Knapsack and Bin Packing Problem Using Logical Social Group Optimization}, 
  year={2025},
  volume={13},
  number={},
  pages={95665-95691},
  abstract={The 0-1 Knapsack Problem (KP) and Bin Packing Problem (BPP) are NP-hard combinatorial optimization challenges often tackled using metaheuristics. Both problems have prominent utilization in the real world such as in resource allocation, logistics, decision-making, etc. The binarized variant of metaheuristics available in the literature mostly uses transfer functions for conversion of the domain from continuous to binary. Generally, the conversion functions are computationally expensive which demands more utilization of computational resources. Whereas the boolean functions are performed using bitwise operations which are inherent to the digital computer hardware and are less computationally expensive. This prominent research gap has been addressed in this paper by introducing Logical Social Group Optimization (LSGO), a logic-based binarized variant of Social Group Optimization (SGO) that leverages Boolean logic for improved efficiency. In LSGO, after the binarization by replacing the arithmetic operators with logical operators, one of the variables gets cancelled out. To preserve that variable, two versions of LSGO have been proposed. The first one is LSGO-Reduc where one of the initial operands in the equation is removed or reduced and after reducing it, no variables disappear. The second one is LSGO-Rever, where the boolean operators in the equation are reversed or exchanged and hence, no variables are lost. The three algorithms have been simulated with various datasets of knapsack and its variant problems and bin-packing problem for thorough testing on different problem types and scalability. Experimental results demonstrate that LSGO variants outperform conventional algorithms, achieving an average profit of 970 units on the P07 dataset for single knapsack problems, surpassing SGO (950 units) and Genetic Algorithm (GA) (930 units) with greater stability. In multiple knapsack problems, LSGO variants reach a profit of 1925 units, exceeding Particle Swarm Optimization (PSO) (1850 units). For bin packing problems, the binary splitting strategy optimally minimizes bin usage, achieving 5 bins on the P04 dataset, while maintaining solution quality. Unlike conventional methods that rely on transfer functions to solve binary problems, LSGO employs logical operators instead of arithmetic ones, eliminating the need for external functions. This approach significantly reduces computational overhead and offers potential improvements in large-scale instances. LSGO-Rever outperforms LSGO and LSGO-Reduc for most computationally complex problems. The results highlight the effectiveness of LSGO in enhancing solution quality, stability, scalability, and efficiency for discrete optimization problems where Knapsack has been taken as a case study in this paper. Moreover, the practical application of the proposed algorithm for simulation of path finding robots has been discussed to shed some light on the applicability of the algorithm. The results have been validated with ranking algorithm, Nemenyei post hoc statistical test and friedman chi square test which shows promising results with adequate graphs and tables derived from the simulations.},
  keywords={Optimization;Social groups;Metaheuristics;Genetic algorithms;Transfer functions;Particle swarm optimization;Convergence;Computational efficiency;Mathematical models;Logic;0/1 Knapsack;bin packing;binarization;logic social group optimization (LSGO);LSGO-reduc;LSGO-rever},
  doi={10.1109/ACCESS.2025.3575004},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10762654,
  author={Yang, Tinghui and Jiang, Zhiyuan and Wang, Yongjun},
  booktitle={2024 5th International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={LLMSQLi: A Black-Box Web SQLi Detection Tool Based on Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={629-633},
  abstract={Black box detection tools of SQL injection vulnerabilities simulate real-world web attack scenarios, making it essential for evaluating SQLi risks in actual web applications. However, current black-box approaches depend on predefined rules for SQLi vulnerability detection, which limits both their efficiency and accuracy. In this paper, we propose a black-box SQLi detection tool based on large language multi-agent, LLMSQLi, which uses the context understanding and reasoning capabilities of large language models and the cooperative division of labor mode of multi-agent to generate payloads customized for test targets and efficiently detect SQL injection vulnerabilities in Web programs. Drawing inspiration from real-world teams of security experts, LLMSQLi simulates the step-by-step process of human experts in testing tasks through the LLM Muti-Agent collaboration model. We ran experiments on SQLiMicroBenchmark to compare the performance of LLMSQLi and two of the most advanced black-box SQLi testing tools. Experiments show that LLMSQLi successfully detected all 15 targets and outperformed other tools.},
  keywords={Accuracy;Large language models;Closed box;Collaboration;SQL injection;Cognition;Security;Testing;Payloads;Software engineering;SQLi detection;Web Security;Large Language Model;Multi Agents},
  doi={10.1109/ICBASE63199.2024.10762654},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9965326,
  author={Qu, Jiantao and Qi, Chunyu and An, Gaoyun and Ma, Yuxiang},
  booktitle={2022 16th IEEE International Conference on Signal Processing (ICSP)}, 
  title={LTE-R communication quality prediction based on ECA-TCN and EEMD}, 
  year={2022},
  volume={1},
  number={},
  pages={365-370},
  abstract={In recent years, with the increasing demand of social development for transportation, railway transportation technology is also developed continuously. “Heavy haul railway” has gradually become a major development direction of freight railway. For the first time ever, Shuohuang Railway Company uses long-term evolution for railway (LTE-R) technology to conduct heavy haul railway communications in order to support the safe operation of trains weighing 20,000 tons and more. The operation safety of heavy haul railway is directly impacted by the LTE-R base station’s communication quality. Therefore, it has become essential to Figure out how to precisely forecast the communication quality of the LTE-R base station and perform active maintenance on LTE-R system. To smooth the communication quality data and make it easier to predict, we use the ensemble empirical mode decomposition (EEMD) method to remove the high-frequency components. Then, we use the coordinate attention (CA) mechanism to enable temporal convolutional network (TCN) to capture channel attention, and utilize particle swarm optimization (PSO) to optimize the attention weight, so as to accurately predict the communication quality. Experiments on real datasets demonstrate the proposed method’s ability to forcast the communication quality of LTE-R base stations and serve as the foundation for proactive LTE-R system maintenance.},
  keywords={Base stations;Empirical mode decomposition;Convolution;Time series analysis;Transportation;Predictive models;Maintenance engineering;LTE-R;Time series prediction;Ensemble Empirical Mode Decomposition (EEMD);Time Convolution Network (TCN);Coordinate Attention (CA);Particle Swarm optimization (PSO)},
  doi={10.1109/ICSP56322.2022.9965326},
  ISSN={2164-5221},
  month={Oct},}@INPROCEEDINGS{10928510,
  author={Chen, Yu and Xu, Xiangli and Zhu, Lizhen and Liu, Kaile and Yuan, Jianmei},
  booktitle={2024 4th International Conference on Communication Technology and Information Technology (ICCTIT)}, 
  title={PSO-based Prediction Method for CNN-LSTM-Attention Networks}, 
  year={2024},
  volume={},
  number={},
  pages={447-452},
  abstract={In the information age, the open nature of the Internet has made network security issues increasingly severe. Within the domain of network security, predicting the security situation is a fundamental aspect, which aims to identify potential security threats. To effectively quantify the current state of network security, we develop a situational assessment system that evaluates the impact of network attacks. Meanwhile, in order to improve the accuracy of situation prediction, a CNN-LSTM-Attention network prediction method based on particle swarm optimization algorithm is proposed. Simulation experiments demonstrate that the average absolute error of our proposed model is 0.0321 and its determination coefficient is 0.9660, indicating a notable improvement in prediction accuracy.},
  keywords={Accuracy;Neural networks;Network security;Predictive models;Prediction algorithms;Information age;Data models;Internet;Particle swarm optimization;Long short term memory;situational assessment system;situational prediction;LSTM;PSO},
  doi={10.1109/ICCTIT64404.2024.10928510},
  ISSN={},
  month={Dec},}@ARTICLE{10508368,
  author={Rahman, Abdullah Sani Abd and Masrom, Suraya and Rahman, Rahayu Abdul and Ibrahim, Roslina and Gilal, Abdul Rehman},
  journal={IEEE Access}, 
  title={Genetic Programming Based Automated Machine Learning in Classifying ESG Performances}, 
  year={2024},
  volume={12},
  number={},
  pages={59612-59629},
  abstract={AutoML offers significant benefits in solving real-life problems because it accelerates the development of machine learning models. In contexts involving real scenarios like analyzing companies’ environmental, social and governance (ESG), where the dataset presents some challenges, AutoML is anticipated as a promising solution to address these complexities. Although researchers have shown significant interest in exploring Genetic Programming (GP) in AutoML for handling complex datasets, a critical issue that remains unresolved is the comprehensive understanding of GP hyper-parameters that influence machine learning performance. While GP-based AutoML excels in automating many aspects of the modelling, there has been a scarcity of research that provides insight into the significance of individual features and GP population size within the models of GP-based AutoML. This paper presents a comprehensive analysis of the models’ performance evaluation from multiple facets, including feature selection, GP population sizes, and different machine learning algorithms. Furthermore, this study provides insights into the association between Pearson correlations, machine learning performance, and the importance of machine learning features. The findings demonstrate that incorporating all the determinants as features in GP-based AutoML or relying solely on firm characteristics led to superior performance with an excellent trade-off between True Positive Rate and False Positive Rate. Thus, higher accuracy results exceeding 0.9 of Area Under the Curve (AUC) are presented by the proposed models. The novelty of this study lies in its empirical evaluation of different approaches to GP-based AutoML implementation. These findings provide alternative solutions for business investors to identify companies with strong sustainability practices.},
  keywords={Machine learning;Statistics;Sociology;Machine learning algorithms;Task analysis;Optimization;Evolutionary computation;Genetic programming;Machine learning;Business intelligence;Classification algorithms;Evolutionary computing;genetic programming;machine learning;business intelligence;classification},
  doi={10.1109/ACCESS.2024.3393511},
  ISSN={2169-3536},
  month={},}@ARTICLE{10353984,
  author={Hoang, Trang and Quoc, Thang Nguyen and Zhang, Lihong and Duong, Trung Q.},
  journal={IEEE Access}, 
  title={Novel Methods for Improved Particle Swarm Optimization in Designing the Bandgap Reference Circuit}, 
  year={2023},
  volume={11},
  number={},
  pages={139964-139978},
  abstract={Bandgap reference (BGR) circuits play a crucial role as voltage reference generators for other components within a variety of analog integrated circuits. Therefore, their power supply rejection ratio (PSRR), which represents the BGR’s ability to maintain a stable output in the presence of supply ripples, has a substantial impact on the overall circuit performance and is consequently worthy of attention. In this work, the design of a 65nm-CMOS BGR circuit and the computational approach to optimize its PSRR value are presented. Our proposed BGR circuit incorporates a modification in the op-amp structure to enhance the PSRR parameter. Detailed explanations of the proposed op-amp’s differential gain calculation and the PSRR parameter formula are provided. Additionally, we employ the particle swarm optimization (PSO) algorithm to maximize PSRR while satisfying other specifications. Four distinct approaches for utilizing the inertia weight parameter of the PSO algorithm are explored: two newly developed techniques (PSO - local exploitation orienter (PSO-LEO) and PSO - global exploration orienter (PSO-GEO)) together with two conventional approaches. A comprehensive comparative analysis reveals the superiority of our proposed PSO-GEO technique. Ultimately, our 65 nm CMOS bandgap circuit exhibits exceptional performance, featuring a temperature coefficient of 6.4056 ppm/°C and a PSRR of 99.9896 dB at 1 kHz. In conclusion, this work contributes substantially through op-amp architecture modification, PSRR optimization via the PSO algorithm, and introducing new inertia weight parameter utilization strategies and analyzing them.},
  keywords={Optimization;Photonic band gap;Gain;Urban areas;Transistors;Resistance;Transconductance;Analog circuits;Analog circuit optimization;bandgap reference circuit;PSO algorithm;power supply rejection ratio},
  doi={10.1109/ACCESS.2023.3341492},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10704091,
  author={Subbarayudu, Jangam and Michael, G. and Sheeja Kumari, V.},
  booktitle={2024 International Conference on Emerging Techniques in Computational Intelligence (ICETCI)}, 
  title={Neuroimaging-Based Age Prediction with Genetic Algorithm for Feature Optimisation}, 
  year={2024},
  volume={},
  number={},
  pages={155-160},
  abstract={To build an age prediction model using structural brain MRI data. Finding better ways to use evolutionary algorithm for feature optimisation in age prediction models built from neuroimaging datasets is the main goal of this study. For this procedure to work, structural magnetic resonance imaging (MRI), which record minute information about the brain's anatomy, are used as input data. The use of genetic algorithm is employed to improve the feature extraction procedure. That way, we can choose out traits that are discriminative and helpful, which is a huge boon to age prediction. As the evolutionary algorithm iteratively refines the feature subset, the model's performance and processing efficiency are both enhanced. The next step is to make use of the selected attributes while building a regression or other deep learning model to accurately predict chronological age. In addition to assisting with feature selection, the genetic algorithm also refines the predictive model's hyperparameters, making sure the model is set up optimally for age prediction. Researchers hope that this work will lead to an improved neuroimaging-based age prediction model that outperforms current methods in terms of accuracy and interpretability. An improved understanding of the structural changes in the brain that occur with age is expected to result from using genetic algorithm for feature optimisation, which is thought to reveal important neuroanatomical patterns related to ageing.},
  keywords={Neuroimaging;Deep learning;Accuracy;Magnetic resonance imaging;Evolutionary computation;Predictive models;Brain modeling;Feature extraction;Optimization;Genetic algorithms;Age prediction;Feature optimization;Genetic algorithm;Predictive modeling;Deep learning;Chronological age;MRI images},
  doi={10.1109/ICETCI62771.2024.10704091},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10944418,
  author={Vena, Bulumko and Reddy, Kumeshan},
  booktitle={2025 33rd Southern African Universities Power Engineering Conference (SAUPEC)}, 
  title={Distribution Network Reconfiguration via Metaheuristic Optimization Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a review of Metaheuristic Optimization Techniques (MOT) which are methods currently in use for optimization in a vast range of problems. In this paper the application of Cuckoo Search Algorithm (CSA) for strategically modifying the network structure of distribution feeders by changing the open/close status of tie open switches. The application of this technique aims to relieve equipment overloading, reduce power losses, improve reliability and voltage profile on a real distribution network in the Nelson Mandela Bay Metro (NMBM). An explanation of the theoretical bases upon which the algorithm is founded is provided and the relevant mathematical model on how an algorithm attempts to obtain the best solution to a problem. The results of study case considered is reported and discussed to find the most economically feasible solution. The CSA archives an average improvement of 44.75% for power loss reduction, on both High Generation High Load and High Generation Low Load scenarios, with a computation time of 37:14s.},
  keywords={Metaheuristics;Software algorithms;Loading;Distribution networks;Voltage;Reliability engineering;Minimization;Power system reliability;Software reliability;Reliability;Distribution Network Reliability;Network Reconfiguration;Metaheuristic Optimization Techniques;Tie-switches;Real Power Loss Minimization;Voltage Profile},
  doi={10.1109/SAUPEC65723.2025.10944418},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9870323,
  author={MacLachlan, Jordan and Mei, Yi and Zhang, Fangfang and Zhang, Mengjie},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Genetic Programming for Vehicle Subset Selection in Ambulance Dispatching}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Assigning ambulances to emergencies in real-time, ensuring both that patients receive adequate care and that the fleet remains capable of responding to any potential new emergency, is a critical component of any ambulance service. Thus far, most techniques to manage this problem are as convoluted as the problem itself. As such, many real-world medical services resort to using the naive closest-idle rule, whereby the nearest available vehicles are dispatched to serve each new call. This paper explores the feasibility of using a genetic programming hyper heuristic (GPHH) in order to generate intelligible rules of thumb to select which vehicles should attend any given emergency. Such rules, either manually or automatically designed, are evaluated within a novel solution construction procedure which constructs solutions to the ambulance dispatching problem given the parameters of the simulation environment. Experimental results suggest that GPHH is a promising technique to use when approaching the ambulance dispatching problem. Further, a GPHH-evolved rule's interpretability allows for detailed semantic analysis into which features of the environment are valuable to the decision making process, allowing for human dispatching agents to make more informed decisions in practice.},
  keywords={Decision making;Semantics;Genetic programming;Medical services;Evolutionary computation;Dispatching;Real-time systems;Hyper Heuristic;Genetic Programming;Ambulance Dispatch;Evolutionary Computation},
  doi={10.1109/CEC55065.2022.9870323},
  ISSN={},
  month={July},}@INPROCEEDINGS{10500152,
  author={Bacon, Greg and Menon, Vineetha},
  booktitle={SoutheastCon 2024}, 
  title={Use of Large Language Model Embeddings to Predict Research Topic Suitability Based on Organizational Capabilities}, 
  year={2024},
  volume={},
  number={},
  pages={1376-1381},
  abstract={We performed a pilot study on the use of large language model technology to help researchers in industry and academia identify prospective opportunities to pursue for funding or grant awards, especially those that they might otherwise overlook due to reading volume, time pressure, and non-obvious connections. Our goal is to help researchers offload some of the burden to technology. As a use case, we query a recent Department of Defense (DoD) Small Business Innovation Research (SBIR) solicitation with natural language inputs in the form of real-world marketing documents and abstract areas of relevance. We experiment with clustering algorithms to determine which best use embeddings to predict solicitation topics that human team members would recommend for proposal. Investigation into this nascent yet practical application of technology will move toward human-centric automation and personalization of results through human reinforcement learning.},
  keywords={Industries;Technological innovation;Natural languages;Organizations;Reinforcement learning;Prediction algorithms;US Department of Defense;large language model (LLM);embeddings;natural language processing;supervised learning;unsupervised learning;big data},
  doi={10.1109/SoutheastCon52093.2024.10500152},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10915543,
  author={Wang, Yanhu and Afzal, Muhammad Muzammil and Li, Zhengyang and Zhou, Jie and Feng, Chenyuan and Guo, Shuaishuai and Quek, Tony Q. S.},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Large Language Model as a Catalyst: A Paradigm Shift in Base Station Siting Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Traditional base station siting (BSS) methods rely heavily on drive testing and user feedback, which are laborious and require extensive expertise in communication, networking, and optimization. As large language models (LLMs) and their associated technologies advance, particularly in the realms of prompt engineering and agent engineering, network optimization will witness a revolutionary approach. This approach entails the strategic use of well-crafted prompts to infuse human experience and knowledge into these sophisticated LLMs, and the deployment of autonomous agents as a communication bridge to seamlessly connect the machine language based LLMs with human users using natural language. Furthermore, our proposed framework incorporates retrieval-augmented generation (RAG) to enhance the system’s ability to acquire domain-specific knowledge and generate solutions, thereby enabling the customization and optimization of the BSS process. This integration represents the future paradigm of artificial intelligence (AI) as a service and AI for more ease. This research first develops a novel LLM-empowered BSS optimization framework, and heuristically proposes three different potential implementations: the strategies based on Prompt-optimized LLM (PoL), LLM-empowered autonomous BSS agent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa). Through evaluation on real-world data, the experiments demonstrate that prompt-assisted LLMs and LLM-based agents can generate more efficient and reliable network deployments, noticeably enhancing the efficiency of BSS optimization and reducing trivial manual participation.},
  keywords={Base stations;Optimization;Artificial intelligence;Roads;Prompt engineering;Testing;Computational modeling;User experience;Urban areas;Resource management;Base station siting;large language model (LLM);prompt engineering;agent engineering;retrieval-augmented generation (RAG)},
  doi={10.1109/TCCN.2025.3548615},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{10351064,
  author={Arunachalam, Ayush and Das, Sanjay and Rajan, Monikka and Su, Fei and Jin, Xiankun and Banerjee, Suvadeep and Raha, Arnab and Natarajan, Suriyaprakash and Basu, Kanad},
  booktitle={2023 IEEE International Test Conference (ITC)}, 
  title={Enhanced ML-Based Approach for Functional Safety Improvement in Automotive AMS Circuits}, 
  year={2023},
  volume={},
  number={},
  pages={266-275},
  abstract={The extensive adoption of safety-critical applications in high-assurance environments, such as the automotive domain, has laid emphasis on safeguarding the reliability and Functional Safety (FuSa) of the Electrical and/or Electronic (E/E) components constituting such systems. Most modern automotive Systems-on-Chips (SoCs) comprise Analog and Mixed Signal (AMS) circuits, which are more susceptible to faults than their digital equivalents. However, their attributes of operating in the continuous signal region can be leveraged to perform early anomaly detection, which could facilitate the subversion of the eventual hardware failure state, thereby improving the FuSa of the system. To this end, we had proposed a novel unsupervised learning-based early anomaly detection framework catered to automotive AMS circuits (in ITC 2022). However, existing approaches to AMS FuSa violation detection are limited by pre-specified feature inputs, and lack rationale for identifying signals to be monitored to perform anomaly detection. To address these issues as well as further augment our original solution, in this paper, we propose a novel anomaly detection strategy that involves: (1) a genetic algorithm-based feature selection approach, (2) a novel signal selection algorithm that ascertains the best intermediate circuit signal, for furnishing enhanced anomaly detection accuracy, while reducing the associated detection latency, and (3) an explainable AI (XAI)-based framework that boosts user interpretability and transparency of the anomaly detection framework. This XAI approach, in turn, can be provided as feedback to the designer during circuit design and validation. The proposed approach is evaluated using case studies of two representative AMS circuits, which are prevalent in automotive SoCs. Our experimental analyses demonstrate that the proposed approach furnishes up to 100% detection accuracy and 2.3× reduction in detection time compared to our existing framework, in addition to providing insights by improving transparency of the anomaly detection framework, thereby exhibiting the efficacy of our solution.},
  keywords={Predictive models;Feature extraction;Systems engineering and theory;Safety;Circuit synthesis;Reliability;Artificial intelligence;Functional Safety;AMS Circuits;Feature Selection;Signal Selection;Explainable AI},
  doi={10.1109/ITC51656.2023.00043},
  ISSN={2378-2250},
  month={Oct},}@INPROCEEDINGS{10889776,
  author={Pan, Zibin and Zhang, Shuwen and Zheng, Yuesheng and Li, Chi and Cheng, Yuheng and Zhao, Junhua},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Multi-Objective Large Language Model Unlearning}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Machine unlearning in the domain of large language models (LLMs) has attracted great attention recently, which aims to effectively eliminate undesirable behaviors from LLMs without full retraining from scratch. In this paper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is a proactive way to decrease the prediction probability of the model on the target data in order to remove their influence. We analyze two challenges that render the process impractical: gradient explosion and catastrophic forgetting. To address these issues, we propose Multi-Objective Large Language Model Unlearning (MOLLM) algorithm. We first formulate LLM unlearning as a multi-objective optimization problem, in which the cross-entropy loss is modified to the unlearning version to overcome the gradient explosion issue. A common descent update direction is then calculated, which enables the model to forget the target data while preserving the utility of the LLM. Our empirical results verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods in terms of unlearning effect and model utility preservation. The source code is available at https://github.com/zibinpan/MOLLM.},
  keywords={Large language models;Source coding;Signal processing algorithms;Signal processing;Predictive models;Prediction algorithms;Explosions;Data models;Speech processing;Optimization;large language model;machine unlearning;multi-objective optimization},
  doi={10.1109/ICASSP49660.2025.10889776},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10857586,
  author={Chang, Feng-Cheng and Huang, Hsiang-Cheh},
  booktitle={2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, 
  title={Exploring Genetic Programming in Image Processing: Challenges and Enhanced Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In recent years, the advancement of AI has been primarily driven by neural networks, which, despite their success, pose challenges in terms of explainability and high-power consumption. Genetic Programming (GP) offers an interpretable alternative, although its complexity has limited its practical application. This paper explores the potential of GP through experiments on a simple image filtering task, aiming to understand its properties and limitations. We also investigate the integration of transformer concepts into the GP process. Preliminary results suggest that while GP faces convergence challenges, the introduction of symbolic transformers may enhance its effectiveness in image processing tasks. These findings open up new possibilities for optimizing GP in future applications.},
  keywords={Training;Refining;Neural networks;Genetic programming;Transformers;Image filtering;Information management;Reliability;Optimization;Convergence;genetic programming;symbolic transformer;image filtering},
  doi={10.1109/IMCOM64595.2025.10857586},
  ISSN={},
  month={Jan},}@ARTICLE{10839306,
  author={Li, Haoyun and Xiao, Ming and Wang, Kezhi and Kim, Dong In and Debbah, Merouane},
  journal={IEEE Wireless Communications Letters}, 
  title={Large Language Model Based Multi-Objective Optimization for Integrated Sensing and Communications in UAV Networks}, 
  year={2025},
  volume={14},
  number={4},
  pages={979-983},
  abstract={This letter investigates an un-crewed aerial vehicle (UAV) network with integrated sensing and communication (ISAC) systems, where multiple UAVs simultaneously sense the locations of ground users with radars and provide communication services. To find the trade-off between communication and sensing (C&S) in the system, we formulate a multi-objective optimization problem (MOP) to maximize the total network utility and the localization Cramér-Rao bounds (CRB) of ground users, which jointly optimizes the deployment and power control of UAVs. Inspired by the huge potential of large language models (LLM) for prediction and inference, we propose an LLM-enabled decomposition-based multi-objective evolutionary algorithm (LEDMA) for solving the highly non-convex MOP. We first adopt a decomposition-based scheme to decompose the MOP into a series of optimization sub-problems. We second integrate LLMs as black-box search operators with MOP-specifically designed prompt engineering into the framework of MOEA to solve optimization sub-problems simultaneously. Numerical results demonstrate that the proposed LEDMA can find the clear trade-off between C&S and outperforms baseline MOEAs in terms of obtained Pareto fronts and convergence.},
  keywords={Autonomous aerial vehicles;Optimization;Integrated sensing and communication;Vectors;Radar cross-sections;Power control;Evolutionary computation;Air to ground communication;Sorting;Signal to noise ratio;Integrated sensing and communications;multi-objective optimization;large language model},
  doi={10.1109/LWC.2025.3529082},
  ISSN={2162-2345},
  month={April},}@INPROCEEDINGS{9892360,
  author={Gulowaty, Bogdan and Woźniak, Michał},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Search-based framework for transparent non-overlapping ensemble models}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to their generalizing ability, classifier ensembles are considered very powerful predictive models. A typical ensemble consists of a static or dynamic pool of classifiers and a combination method, which translates predictions of many models into one. The combination step is often complex and renders the inner behavior of the whole ensemble incomprehensible to a typical user. In this work, in the light of recent interest in Explainable AI (XAI) research, we are proposing a novel approach to building an interpretable ensemble model. It is based on decision space splitting into non-overlapping regions. Every area has an assigned interpretable classifier and its boundaries are selected using the genetic programming approach. We experimentally evaluate the proposed method and compare it to Decision Tree and Random Forest. The results show that the proposed approach is competitive with the state-of-the-art techniques and prone to further expansion.},
  keywords={Training;Statistical analysis;Predictive models;Programming;Decision trees;Reliability;Task analysis;explainable ai;random forest;decision tree;clustering;genetic programming},
  doi={10.1109/IJCNN55064.2022.9892360},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10400079,
  author={Zhu, Liang and Yu, Meng and Yang, Aichao and Zhu, Junjian and Hao, Pengfei and Wen, He},
  booktitle={2023 13th International Conference on Power and Energy Systems (ICPES)}, 
  title={A Novel Industrial Load Disaggregation model based on CNN-LSTM neural network with attention mechanism and genetic algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={348-352},
  abstract={Non-intrusive load monitoring (NILM) dissects smart meter data to extract individual device consumption, primarily focusing on residential users. However, energy-intensive industries also require precise load monitoring for understanding electricity usage patterns and operational states. This study introduces a novel approach employing convolutional neural networks and long short-term memory networks, enhanced with an attention mechanism and optimized using a genetic algorithm. Leveraging an industrial dataset from a Brazilian feed factory and comparing against common models, our approach demonstrates superior performance, reducing normalized disaggregation errors by at least 56.3% for six devices and increasing normalized aggregate signal errors by a minimum of 10% for three devices.},
  keywords={Load monitoring;Production facilities;Convolutional neural networks;Feeds;Long short term memory;Load modeling;Genetic algorithms;non-intrusive load monitoring;industrial data;energy disaggregation;deep neural network;genetic algorithm},
  doi={10.1109/ICPES59999.2023.10400079},
  ISSN={2767-732X},
  month={Dec},}@ARTICLE{10162012,
  author={Qi, Hongzhuo and An, Yunfei and Hu, Xiaohui and Miao, Shidi and Li, Jing},
  journal={IEEE Access}, 
  title={Explainable Machine Learning Explores Association Between Sarcopenia and Breast Cancer Distant Metastasis}, 
  year={2023},
  volume={11},
  number={},
  pages={65725-65738},
  abstract={The impact of sarcopenia on the prognosis of breast cancer (BC) carries important clinical significance. However, there is no internationally standardized cut-off value for defining sarcopenia. This study proposed an explainable machine learning model for identifying risk factors of BC distant metastases and discussing the division of body composition cut-off values. Combining computed tomography (CT) image data of  $11^{th}$  thoracic vertebrae (T11) and  $4^{th}$  thoracic vertebrae (T4), a multi-objective optimized genetic algorithm was developed to select features and predict BC distant metastasis. Feature selection results were analyzed by Cox regression. The results showed that skeletal muscle index (SMI/T11) was a risk factor for predicting BC distant metastasis and an independent prognostic factor for distant metastasis-free survival (DMFS). A cut-off value of 21cm2/m2 for SMI/T11 was obtained by shapley additive explanations, in addition, The DMFS and overall survival (OS) of the low-risk group were significantly better than those of the high-risk group. The combination of multimodal data further confirms that sarcopenia is associated with poorer DMFS and OS in BC patients, and explores for the first time the issue of the cut-off values of sarcopenia and BC distant metastasis.},
  keywords={Metastasis;Muscles;Computed tomography;Indexes;Correlation;Predictive models;Breast cancer;Pareto optimization;Breast cancer;cut-off value;distant metastasis;multi-objective optimization;multimodal;sarcopenia},
  doi={10.1109/ACCESS.2023.3289403},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10371984,
  author={Greenwood, Garrison W. and Abbass, Hussin and Hussein, Aya},
  booktitle={2023 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Interpretation of Neural Network Players for a Generalized Divide the Dollar Game Using SHAP Values}, 
  year={2023},
  volume={},
  number={},
  pages={1808-1813},
  abstract={Machine learning models can make accurate predictions but trust in the models depends on being able to under-stand why those predictions were made. Unfortunately, machine learning models are black boxes making interpretation difficult. Previously we used an evolutionary algorithm to evolve triplets of neural network players for instances of the Generalized Divide-the-Dollar, which is an economic bargaining game. The players produced fair bids with high bid totals, which is a desirable outcome, but no attempt was made to understand why the players performed so well. In this paper, we interpret the behavior of those neural networks using SHapley Additive exPlanations (or SHAP). Surprisingly, the neural network players exhibited both altruistic and exploitative behavior. Both a global and a local interpretation analysis is presented. The experiments conducted in this work demonstrate a simple method for understanding players' strategies in multi-player gamcs.},
  keywords={Economics;Additives;Biological system modeling;Neural networks;Machine learning;Games;Evolutionary computation;explainable AI;machine learning;model interpretation},
  doi={10.1109/SSCI52147.2023.10371984},
  ISSN={2472-8322},
  month={Dec},}@INPROCEEDINGS{10271096,
  author={Sun, Tianze and Wen, Jie and Gong, Jiale},
  booktitle={2023 4th International Symposium on Computer Engineering and Intelligent Communications (ISCEIC)}, 
  title={Personalized Learning Resource Recommendation using Differential Evolution-Based Graph Neural Network: A GraphSAGE Approach}, 
  year={2023},
  volume={},
  number={},
  pages={636-639},
  abstract={This paper proposes a novel personalized recommendation algorithm for learning resources based on differential evolution(DE) and graph neural networks(GNN). By representing learners and learning resources as graph data and incorporating a multi-head attention mechanism, we have developed an effective method for personalized recommendation. The differential evolution algorithm is utilized to optimize model hyperparameters, resulting in improved recommendation performance. We conducted experiments on a widely used personalized learning resource dataset, comparing our method with several classical recommendation algorithms. The results demonstrate significant advantages of our approach in terms of accuracy, recall, $\Gamma 1$ score, and RMSE value.},
  keywords={Adaptation models;Computational modeling;Graph neural networks;Robustness;Computational complexity;Task analysis;Optimization;personalized recommendation;recommendation algorithm;graph neural network;differential evolution;GraphSAGE},
  doi={10.1109/ISCEIC59030.2023.10271096},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9825292,
  author={Li, Moyan and Cao, Ning and Lu, Hao and Gao, Fan},
  booktitle={2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)}, 
  title={Prediction method of Internet of things operation index based on improved Support vector machine regression model}, 
  year={2022},
  volume={},
  number={},
  pages={119-123},
  abstract={In the power system, the data on the client side is a gold mine to be mined. However, the current data mining lacks a effective influence relationship model, and it is difficult to achieve accurate prediction of power system Internet of things (IoT) indicators. Therefore, in view of the prediction problem of local IoT operation indicators of smart grid customer-side metering equipment under different climatic conditions, a correlation analysis and prediction method based on an improved support vector machine regression (SVR) model is proposed. The method first performs feature selection on climate data to improve model performance while reducing computational complexity, and then uses an optimization algorithm to further optimize model performance. For feature selection, grid search algorithm and K-fold cross-validation are used for Random Forest (RE) parameter selection. For the calculated RF feature importance, a goodness-of-fit-based sequence forward selection (Sequential Forward Selection, SFS) algorithm is used for dimension selection. After feature selection, the Particle Swarm optimization (PSO) algorithm was used to optimize the Support Vector Regression model. The experimental results show that the proposed algorithm has better performance and higher computational efficiency than the traditional combination algorithm.},
  keywords={Support vector machines;Radio frequency;Computational modeling;Predictive models;Prediction algorithms;Feature extraction;Data models;Local IOT operation indicators;Climate;Random forest;Particle swarm optimization;Support vector machine regression},
  doi={10.1109/CVIDLICCEA56201.2022.9825292},
  ISSN={},
  month={May},}@ARTICLE{9765838,
  author={Bhuyan, Hemanta Kumar and Chakraborty, Chinmay},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Explainable Machine Learning for Data Extraction Across Computational Social System}, 
  year={2024},
  volume={11},
  number={3},
  pages={3131-3145},
  abstract={This article addresses the explainable machine learning for data extraction on diverse datasets. In many cases, individual or specific approaches have been developed for feature selection (FS) on a certain dataset, but collecting the diversity dataset and demonstrating it through different FS methods are challenging. Thus, this article proposed multiapproaches for FS with the classification of diverse datasets. The proposed framework is developed using various methods, such as extendable particle swarm optimization (PSO), global and local searching, feature ranking, feature clustering, computational cost-based FS, and multiobjective optimization. We effectively used these methods in our proposed work in a single-setting framework. We focused on three essential computational items in our framework: classification accuracy, selected features, and computational times. Due to the diverse dataset, few methods have been considered challenging during computational evaluation for classification accuracy with test cost. We tried to manage the classification accuracy based on total cost and high accuracy with less cost. The proposed framework is experimented with the above methods and analyzed through comparative results on diversity datasets. For example, when regular parameter values are in the range of  $2^{-13}$ – $2^{-6}$ , the evaluation result affects all items, i.e., decreasing during this range; other values do not affect results. We used thresholds ranging from 0.6 to 0.9 for highly correlated feature pairs as per the support vector machine (SVM) method for recursive feature elimination.},
  keywords={Feature extraction;Costs;Computational efficiency;Data mining;Support vector machines;Testing;Particle swarm optimization;Classification;computational cost;computational social system;data extraction;explainable machine learning;multiobjective optimization},
  doi={10.1109/TCSS.2022.3164993},
  ISSN={2329-924X},
  month={June},}@INPROCEEDINGS{10401388,
  author={Zhang, Kunpeng and Liu, Dingxin and Yang, Hui and An, Chunlan},
  booktitle={2023 IEEE 4th China International Youth Conference On Electrical Engineering (CIYCEE)}, 
  title={Deep Learning -Based Remaining Life Prediction for DC-Link Capacitor in High Speed Train}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The accurate prediction of the remaining useful life of DC-link capacitors is crucial in high-speed railway traction drive systems. In this paper, we propose a method for predicting residual life using deep learning by particle swarm optimization. Firstly, the upper and lower voltage values of the capacitor are selected as the characteristic values. By applying wavelet transform to denoise the voltage, we can calculate failure thresholds. Then, we amplify the input weights in real-time using the long short-term memory neural network with a macro-micro attention mechanism. Finally, we utilize the particle swarm optimization algorithm to optimize the number of input units and the learning rate of the neural network for the purpose of predicting lifetime. The effectiveness of this method is verified through model evaluation indices in a case study of high-speed train traction system.},
  keywords={Deep learning;Wavelet transforms;Capacitors;Neural networks;Prediction methods;Threshold voltage;Particle swarm optimization;Residual life prediction;support capacitors;long short-term memory neural networks;macro-micro attention mechanism;particle swarm optimization},
  doi={10.1109/CIYCEE59789.2023.10401388},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10863929,
  author={Lin, Junhao and Jiang, Weifeng and He, Shaohong and Ma, Junyuan},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Application of Attention Mechanism-Based Neural Networks in Predicting Chemical Molecular Properties}, 
  year={2024},
  volume={},
  number={},
  pages={410-414},
  abstract={The prediction of molecular properties is a hot issue in the field of materials chemistry, and the use of neural networks to predict chemical molecular properties is one of the more effective means. In recent years, with the deepening of the research, a variety of neural network prediction algorithms have appeared, such as the neural network combined with particle swarm algorithm and the prediction method based on RBF neural network. However, all these methods face the problems of difficult hyperparameter adjustment and local optimal solution. In this paper, the prediction of chemical molecule properties based on the attention mechanism-based neural network model is realized through the adaptive adjustment of the attention weights, which significantly improves the accuracy of the prediction of chemical molecule properties. Taking the complex property prediction of 100 chemical molecules as an example, taking the same test set, the loss function mean square deviation of the traditional neural network model on the test set is 978.3049079, and the attentional mechanism neural network model reduces this value to 931.909225, which significantly improves the accuracy of the prediction of chemical molecule properties. The study shows that the attention mechanism-based neural network model outperforms the traditional neural network model in molecular property prediction with higher prediction accuracy.},
  keywords={Adaptation models;Accuracy;Computational modeling;Neural networks;Predictive models;Prediction algorithms;Stability analysis;Robustness;Particle swarm optimization;Chemicals;neural network model;attention mechanism;chemical molecular properties},
  doi={10.1109/ICAICE63571.2024.10863929},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10611976,
  author={Torrijos, Pablo and Gámez, José A. and Puerta, José M.},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Structural Fusion of Bayesian Networks with Limited Treewidth Using Genetic Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper introduces an evolutionary computation approach for consensus in structural Bayesian Network (BN) fusion under the constraint of limited treewidth. The consensus BN aims to reconcile multiple input BNs into a single one that retains key structural features present in the original networks. Treewidth, a graph-based parameter associated with computationally tractable inference, is utilized to restrict the complexity of the resulting network. A genetic algorithm is proposed to look for a BN that codifies as much information about the unrestricted fusion as possible while ensuring the treewidth restriction. Experimental evaluation demonstrates the genetic algorithm's ability to obtain consensus BNs with limited treewidth, providing a valuable tool for aggregating information from diverse sources while returning a computationally actionable model.},
  keywords={Greedy algorithms;Computational modeling;Evolutionary computation;Complex networks;Bayes methods;Complexity theory;Genetic algorithms;Bayesian networks;fusion;consensus;genetic algorithm;combinatorial optimization;federated learning},
  doi={10.1109/CEC60901.2024.10611976},
  ISSN={},
  month={June},}@INPROCEEDINGS{9793975,
  author={Fan, Ming and Wei, Wenying and Jin, Wuxia and Yang, Zijiang and Liu, Ting},
  booktitle={2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)}, 
  title={Explanation-Guided Fairness Testing through Genetic Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={871-882},
  abstract={The fairness characteristic is a critical attribute of trusted AI systems. A plethora of research has proposed diverse methods for individual fairness testing. However, they are suffering from three major limitations, i.e., low efficiency, low effectiveness, and model-specificity. This work proposes ExpGA, an explanation-guided fairness testing approach through a genetic algorithm (GA). ExpGA employs the explanation results generated by interpretable methods to collect high-quality initial seeds, which are prone to derive discriminatory samples by slightly modifying feature values. ExpGA then adopts GA to search discriminatory sample candidates by optimizing a fitness value. Benefiting from this combination of explanation results and GA, ExpGA is both efficient and effective to detect discriminatory individuals. Moreover, ExpGA only requires prediction probabilities of the tested model, resulting in a better generalization capability to various models. Experiments on multiple real-world benchmarks, including tabular and text datasets, show that ExpGA presents higher efficiency and effectiveness than four state-of-the-art approaches.},
  keywords={Software algorithms;Predictive models;Benchmark testing;Software;Artificial intelligence;Genetic algorithms;Software engineering;Explanation result;fairness testing;genetic algorithm},
  doi={10.1145/3510003.3510137},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{10556104,
  author={Negri, Francesco Renato and Nicolosi, Niccolò and Camilli, Matteo and Mirandola, Raffaela},
  booktitle={2024 IEEE/ACM 19th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)}, 
  title={Explanation-Driven Self-Adaptation Using Model-Agnostic Interpretable Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={189-199},
  abstract={Self-adaptive systems increasingly rely on black-box predictive models (e.g., Neural Networks) to make decisions and steer adaptations. The lack of transparency of these models makes it hard to explain adaptation decisions and their possible effects on the surrounding environment. Furthermore, adaptation decisions in this context are typically the outcome of expensive optimization processes. The complexity arises from the inability to directly observe or comprehend the internal mechanisms of the black-box predictive models, which requires employing iterative methods to explore a possibly large search space and optimize according to many goals. Here, balancing the trade-off between effectiveness and cost becomes a crucial challenge. In this paper, we propose explanation-driven self-adaptation, a novel approach that embeds model-agnostic interpretable machine learning techniques into the feedback loop to enhance the transparency of the predictive models and gain insights that help drive adaptation decisions effectively by significantly reducing the cost of planning them. Our empirical evaluation demonstrates the cost-effectiveness of our approach using two evaluation subjects in the robotics domain.},
  keywords={Adaptation models;Costs;Neural networks;Closed box;Machine learning;Predictive models;Planning;Explainable Self-adaptation;Model-agnostic explanations;Inter-pretable Machine Learning},
  doi={10.1145/3643915.3644085},
  ISSN={2157-2321},
  month={April},}@INPROCEEDINGS{10376497,
  author={Huang, Wei and Zhao, Xingyu and Jin, Gaojie and Huang, Xiaowei},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability}, 
  year={2023},
  volume={},
  number={},
  pages={1988-1998},
  abstract={Interpretability of Deep Learning (DL) is a barrier to trustworthy AI. Despite great efforts made by the Explainable AI (XAI) community, explanations lack robustness— indistinguishable input perturbations may lead to different XAI results. Thus, it is vital to assess how robust DL interpretability is, given an XAI method. In this paper, we identify several challenges that the state-of-the-art is unable to cope with collectively: i) existing metrics are not comprehensive; ii) XAI techniques are highly heterogeneous; iii) misinterpretations are normally rare events. To tackle these challenges, we introduce two black-box evaluation methods, concerning the worst-case interpretation discrepancy and a probabilistic notion of how robust in general, respectively. Genetic Algorithm (GA) with bespoke fitness function is used to solve constrained optimisation for efficient worst-case evaluation. Subset Simulation (SS), dedicated to estimate rare event probabilities, is used for evaluating overall robustness. Experiments show that the accuracy, sensitivity, and efficiency of our methods outperform the state-of-the-arts. Finally, we demonstrate two applications of our methods: ranking robust XAI methods and selecting training schemes to improve both classification and interpretation robustness.},
  keywords={Training;Deep learning;Computer vision;Sensitivity;Perturbation methods;Probabilistic logic;Robustness},
  doi={10.1109/ICCV51070.2023.00190},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{10398533,
  author={Huang, Zhixing and Mei, Yi and Zhang, Fangfang and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Toward Evolving Dispatching Rules With Flow Control Operations by Grammar-Guided Linear Genetic Programming}, 
  year={2025},
  volume={29},
  number={1},
  pages={217-231},
  abstract={LGP has been successfully applied to dynamic job shop scheduling (DJSS) to automatically evolve dispatching rules. Flow control operations are crucial in concisely describing complex knowledge of dispatching rules, such as different dispatching rules in different conditions. However, existing linear genetic programming (LGP) methods for DJSS have not fully considered the use of flow control operations. They simply included flow control operations in their primitive set, which inevitably leads to a huge number of redundant and obscure solutions in LGP search spaces. To move one step toward evolving effective and interpretable dispatching rules, this article explicitly considers the characteristics of flow control operations via grammar-guided LGP and focuses on IF operations as a starting point. Specifically, this article designs a new set of normalized terminals to improve the interpretability of IF operations and proposes three restrictions by grammar rules on the usage of IF operations: 1) specifying the available inputs; 2) the maximum number; and 3) the possible locations of IF operations. The experiment results verify that the proposed method can achieve significantly better-test performance than state-of-the-art LGP methods and improves interpretability by IF-included dispatching rules. Further investigation confirms that the explicit introduction of IF operations helps effectively evolve different dispatching rules according to their decision situations.},
  keywords={Dispatching;Genetic programming;Job shop scheduling;Grammar;Dynamic scheduling;Aerospace electronics;Process control;Dynamic job shop scheduling (DJSS);flow control operations;grammar-guided linear genetic programming (LGP);hyper heuristics},
  doi={10.1109/TEVC.2024.3353207},
  ISSN={1941-0026},
  month={Feb},}@INPROCEEDINGS{11017185,
  author={Güllü, Merve and A K, Nurefşan and Dede, Reyhan},
  booktitle={2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)}, 
  title={Enhanced Churn Prediction in Telecom with PSO-Based Feature Selection}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Customer churn is a significant issue threatening sustainability in the telecommunications sector. This study employs the Particle Swarm Optimization (PSO) algorithm for feature selection to predict customer churn. PSO aims to enhance the performance of machine learning models by identifying the most relevant features in high-dimensional datasets. For this purpose, various data preprocessing techniques, including SMOTE, SMOTENN, undersampling, and oversampling, were applied to the widely used Cell2Cell dataset, and several classification algorithms (Naive Bayes, Logistic Regression, XGBoost, KNN, and Random Forest) were tested. Experimental results demonstrate that feature selection using PSO improves model accuracy and creates simpler, more interpretable models by eliminating redundant features. In particular, a high accuracy rate of 88.8% was achieved when used with the Random Forest algorithm. This study demonstrates that PSO is a powerful feature selection method for customer churn prediction in the telecommunications sector and shows promise for future research.},
  keywords={Accuracy;Feature extraction;Prediction algorithms;Telecommunications;Classification algorithms;Churn;Particle swarm optimization;Sustainable development;Random forests;Robots;ustomer churn;particle swarm optimization;feature selection;telecommunications;SMOTE;SMOTENN},
  doi={10.1109/ICHORA65333.2025.11017185},
  ISSN={2996-4393},
  month={May},}@ARTICLE{10769067,
  author={Liu, Shiyu and Chen, Fei and Liu, Zhendong and Qiao, Hongyan},
  journal={IEEE Access}, 
  title={Overcoming Data Scarcity in Wind Power Forecasting: A Deep Learning Approach With Bidirectional Generative Adversarial Network and Neighborhood Search PSO Algorithm}, 
  year={2024},
  volume={12},
  number={},
  pages={183410-183428},
  abstract={The precision and stability of wind power prediction (WPP) are critical for the grid-connected operation of wind farms. However, the insufficient availability of historical data poses challenges for traditional deep learning prediction models to accurately forecast for new-built wind farms (NWF) under the background of a substantial increase in wind power installed capacity worldwide. Hence, there is practical scientific significance in exploring high-precision prediction methods within the domain of NWF WPP. To address the challenge of few sample in WPP, a novel data-enhanced WPP method is proposed, which integrates BiGAN (BiGAN) module, self-attention mechanism (SAM) and neighborhood search particle swarm optimization (NSPSO). Within the data enhancement module, BiGAN is proposed to mitigate convergence difficulties and gradient instability encountered during the training of traditional GANs, thereby fostering closer alignment between the generated distribution and the real distribution. During the prediction stage, SAM is designed to obtain a new input matrix for weight allocation before BiGRU, enhancing its sensitivity to critical input information. Furthermore, to prevent SAM-BiGRU from succumbing to local optima, the Dense layer is optimized by the NSPSO algorithm to improve the prediction accuracy. Extensive experimental results in two scenarios demonstrate that the proposed approach surpasses other advanced methods to a certain extent, achieving one-step-ahead prediction accuracy rates of 0.9775 and 0.9810, respectively. This study provides novel ideas to the field of WPP and demonstrates the potential of the proposed model to improve the accuracy of wind farms in power prediction, especially for those with limited historical data.},
  keywords={Predictive models;Generative adversarial networks;Data models;Numerical models;Accuracy;Wind power generation;Wind forecasting;Autoregressive processes;Atmospheric modeling;Wind farms;New-built wind farms;bidirectional generative adversarial network;self-attention mechanism;bidirectional gate recurrent unit;neighborhood search particle swarm optimization},
  doi={10.1109/ACCESS.2024.3507154},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10302639,
  author={Pandey, Chetraj and Ji, Anli and Nandakumar, Trisha and Angryk, Rafal A. and Aydin, Berkay},
  booktitle={2023 IEEE 10th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Exploring Deep Learning for Full-disk Solar Flare Prediction with Empirical Insights from Guided Grad-CAM Explanations}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={This study progresses solar flare prediction research by presenting a full-disk deep-learning model to forecast $\geq\mathrm{M}$-class solar flares and evaluating its efficacy on both central (within ±70°) and near-limb beyond ±70°) events, showcasing qualitative assessment of post hoc explanations for the model’s predictions, and providing empirical findings fro human-centered quantitative assessments of these explanations. Our model is trained using hourly full-disk line-of-sight magnetogram images to predict $\geq{\mathrm{M}}$-class solar flares within the subsequent 24-hour prediction window. Additionally, we apply the Guided Gradient-weighted Class Activation Mapping (Guided Grad-CAM) attribution method to interpret our model’s predictions and evaluate the explanations. Our analysis unveils that full-disk solar flare predictions correspond with active region characteristics. The following points represent the most important findings of our study: ❨1❩ Our deep learning models achieved an average true skill statistic (TSS) of $\sim 0.51$ and a Heidke skill score (HSS) of $\sim.38$, exhibiting skill to predict solar flares where for central locations the average recall is $\sim 0.75$ (recall values for X- and M-class are 0.95 and 0.73 respectively) and for the near-limb flares the average recall is $\sim 0.52$ (recall values for X- and M- class are 0.74 and 0.50 respectively); ❨2❩ qualitative examination of the model’s explanations reveals that it discerns and leverages features linked to active regions in both central and near-limb locations within full-disk magnetograms to produce respective predictions. In essence, our models grasp the shape and texture-based properties of flaring active regions, even in proximity to limb areas—a novel and essential capability with considerable significance for operational forecasting systems.},
  keywords={Deep learning;Shape;Magnetic resonance imaging;Line-of-sight propagation;Predictive models;Data science;Forecasting;Solar flares;Deep learning;xAI;Interpretability},
  doi={10.1109/DSAA60987.2023.10302639},
  ISSN={},
  month={Oct},}@ARTICLE{10945307,
  author={Phalaagae, Pendukeni and Zungeru, Adamu Murtala and Yahya, Abid and Sigweni, Boyce and Rajalakshmi, Selvaraj},
  journal={IEEE Access}, 
  title={A Hybrid CNN-LSTM Model With Attention Mechanism for Improved Intrusion Detection in Wireless IoT Sensor Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={57322-57341},
  abstract={Wireless Internet of Things (IoT) Sensor Networks (WIoTSNs) are frequently deployed in resource-constrained environments where security threats pose significant challenges. Existing intrusion detection systems (c) often struggle with scalability and efficiency under the unique demands of IoT networks. This work introduces an Intrusion Detection System (IDS) framework that integrates Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks in a hybrid architecture, enhanced by an attention mechanism to improve feature extraction and classification accuracy. To address computational demands, an enhanced Particle Swarm Optimization (PSO) algorithm is implemented for dynamic feature selection, thereby optimizing the system’s efficiency in high-dimensional data environments characteristic of IoT networks. The proposed model enhances IoT intrusion detection by integrating a novel hybrid CNN-LSTM with an attention mechanism, thereby improving feature extraction and temporal pattern recognition. Additionally, the improved dynamic PSO algorithm optimizes feature selection in real time, enhancing classification accuracy and adaptability to evolving IoT network threats. This combination ensures more efficient and robust intrusion detection in dynamic IoT environments. Experimental evaluations using a standard IoT intrusion dataset indicate that the proposed model achieves notable accuracy rates of 98.73% with CNN, 99.87% with LSTM, 99.12% with CNN-LSTM, and 98.88% with the enhanced CNN-LSTM with attention, demonstrating an improvement over existing techniques. The framework’s resilience and adaptability underscore its potential for enhancing network security in real-world IoT applications by addressing evolving threats and computational constraints.},
  keywords={Feature extraction;Intrusion detection;Convolutional neural networks;Security;Accuracy;Internet of Things;Long short term memory;Deep learning;Attention mechanisms;Adaptation models;CNN;LSTM;IDS;attention mechanism;wireless Internet of Things sensor networks (WIoTSNs)},
  doi={10.1109/ACCESS.2025.3555861},
  ISSN={2169-3536},
  month={},}@ARTICLE{10137426,
  author={Khan, Prince Waqas and Byun, Yung Cheol},
  journal={IEEE Sensors Journal}, 
  title={Optimized Dissolved Oxygen Prediction Using Genetic Algorithm and Bagging Ensemble Learning for Smart Fish Farm}, 
  year={2023},
  volume={23},
  number={13},
  pages={15153-15164},
  abstract={The field of aquaculture is one of the numerous scientific disciplines that benefit greatly from machine learning (ML). The amount of dissolved oxygen (DO), an important indicator of water quality in sustainable fish farming, affects the yield of aquatic production. It is essential to make DO projections in fishing ponds to carry out the process of artificial aeration. We present DO forecasts utilizing time series analysis based on data obtained from Hanwha Aqua Planet Jeju, located in South Korea. This information could form the basis of a data foundation for an early detection system and improved aquaculture farm management. This research presents a unique genetic algorithm (GA) called GA-based XGBoost, CatBoost, and extra tree (GA-XGCBXT) bagging ensemble model based on GAs. This model is built on extreme gradient boosting (XGBoost), CatBoost (CB), and extra trees (XTs). To select the most outstanding features, various methodologies that exhibit a strong association with the primary data were applied. The performance of the proposed model was evaluated by comparing it to actual sensor data that had been observed, both in the training and validation sets. The precise evaluation accuracy of the anticipated results of the recommended GA-XGCBXT model was determined using various performance indices. By utilizing the strategy we suggested, we acquired a root mean square error of 0.310. Our objective is to enhance the ML model for aquaculture so that academics and practitioners can employ applications for smart fish farming with complete reliability.},
  keywords={Fish;Temperature sensors;Predictive models;Aquaculture;Bagging;Genetic algorithms;Intelligent sensors;Bagging ensemble learning;dissolved oxygen (DO);electrical conductivity (EC);genetic algorithm (GA);oxidation-reduction potential (ORP);sensor data processing;smart fish farm},
  doi={10.1109/JSEN.2023.3278719},
  ISSN={1558-1748},
  month={July},}@ARTICLE{10418073,
  author={Rao, Zhikang and Guo, Boyu and Zu, Jixiang and Zheng, Weiqiang and Xu, Ying and Yang, Yuting},
  journal={IEEE Sensors Journal}, 
  title={Construction of an ECL-DPV Dual Model Biosensor for Dopamine Detection Based on PSO-ANN Algorithm}, 
  year={2024},
  volume={24},
  number={6},
  pages={7463-7472},
  abstract={In clinical diagnosis, the detection of dopamine (DA) is often interfered by epinephrine (EP), a neurotransmitter drug that shares a similar structure with DA, which affects the accurate prediction of DA concentration. In this study, an electrochemiluminescence (ECL) and differential pulse voltammetry (DPV) dual model biosensor combined with machine learning algorithm was proposed for improving the selective detection of DA under EP interference. First, reduced graphene and gold nanoparticles were applied to enhance the sensitivity and stability of the sensor in ECL and DPV measurement. Compared with single model sensing, the dual model sensor could combine the superiority of ECL and DPV while improving the accuracy and reliability of experimental data. Then, nine graphic features related to concentration prediction were extracted from the ECL and DPV response curves, and Pearson’s correlation coefficient (PCC), as well as random forest (RF) algorithm, was adopted for feature importance analysis. To achieve accurate signal decoupling, an intelligent biologically inspired algorithm, particle swarm optimization (PSO) algorithm, was introduced to optimize initial weights and thresholds of the traditional artificial neural network (ANN) for further model training based on multi-feature fusion, which greatly increased the prediction accuracy of DA in the presence of EP. The results demonstrated that DA could be accurately predicted in the concentration range of 9– $200 ~\mu \text{M}$ , and the  ${R}^{\,{2}}$  between the true and predicted values of DA concentration reached 0.99. The root-mean-square error (RMSE) and mean absolute error (MAE) of the test dataset were 5.77 and  $4.32 ~\mu \text{M}$ , respectively. In addition, the PSO-ANN-assisted ECL-DPV dual model detection scheme has been successfully applied for the determination of DA in real samples, such as goat serum and artificial urine.},
  keywords={Sensors;Electrodes;Biological system modeling;Graphene;Predictive models;Sensitivity;Feature extraction;Dopamine (DA) measurement;electrochemiluminescence and differential pulse voltammetry (ECL-DPV) dual model biosensor;particle swarm optimization artificial neural network (PSO-ANN) prediction model;selective detection},
  doi={10.1109/JSEN.2024.3358413},
  ISSN={1558-1748},
  month={March},}@ARTICLE{11050963,
  author={He, Changhua and Yu, Lean},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={A Multiobjective Genetic Algorithm Based Unilateral Rule Extraction Model for Credit Risk Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper proposes a two-phase unilateral rule extraction method based on a multiobjective genetic algorithm (URE-MOGA) to solve the challenges of sparse categorical features and model interpretability in credit risk classification tasks. In this method, rule encoding is employed to represent the sparse categorical features without increasing data dimensionality. The Pareto dominance theory is utilized to balance the trade-off between model accuracy and interpretability. Additionally, a diversity function and unilateral rule learning strategy are designed to facilitate the acquisition of reasonable rules and classifiers by the URE-MOGA model. Furthermore, three publicly available datasets, along with six derived datasets, are used to validate the feasibility of the proposed URE-MOGA model. Experimental results demonstrate that the proposed model outperforms baseline methods in terms of accuracy, interpretability, and robustness. The adoption of a multiobjective approach enables the URE-MOGA model to extract more concise and comprehensible classification rules while ensuring high accuracy levels. Moreover, both the unilateral rule learning strategy and diversity function play vital roles in enhancing classifier accuracy and robustness within the URE-MOGA model. Overall, the proposed URE-MOGA model provides a novel insight into categorical feature sparsity handling interpretable modeling for credit risk classification tasks.},
  keywords={Encoding;Accuracy;Feature extraction;Data models;Genetic algorithms;Numerical models;Evolutionary computation;Training;Deep learning;Data mining;Risk management;categorical feature sparsity;rule extraction;multiobjective genetic algorithm;interpretability},
  doi={10.1109/TEVC.2025.3582941},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10431852,
  author={Sattiraju, Abhinav and Ellis, Charles A. and Miller, Robyn L. and Calhoun, Vince D.},
  booktitle={2023 IEEE 23rd International Conference on Bioinformatics and Bioengineering (BIBE)}, 
  title={An Explainable and Robust Deep Learning Approach for Automated Electroencephalography-Based Schizophrenia Diagnosis}, 
  year={2023},
  volume={},
  number={},
  pages={255-259},
  abstract={Schizophrenia (SZ) is a neuropsychiatric disorder that affects millions globally. Current diagnosis of SZ is symptom-based, which poses difficulty due to the variability of symptoms across patients. To this end, many recent studies have developed deep learning methods for automated diagnosis of SZ, especially using raw EEG, which provides high temporal precision. For such methods to be productionized, they must be both explainable and robust. Explainable models are essential to identify biomarkers of SZ, and robust models are critical to learn generalizable patterns, especially amidst changes in the implementation environment. One common example is channel loss during EEG recording, which could be detrimental to classifier performance. In this study, we developed a novel channel dropout (CD) approach to increase the robustness of explainable deep learning models trained on EEG data for SZ diagnosis to channel loss. We developed a baseline convolutional neural network (CNN) architecture and implement our approach as a CD layer added to the baseline (CNN-CD). We then applied two explainability approaches to both models for insight into learned spatial and spectral features and show that the application of CD decreases model sensitivity to channel loss. The CNN and CNN-CD achieved accuracies of 81.9% and 80.9% on testing data, respectively. Furthermore, our models heavily prioritized the parietal electrodes and the a-band, which is supported by existing literature. It is our hope that this study motivates the further development of explainable and robust models and bridges the transition from research to application in a clinical decision support role.},
  keywords={Deep learning;Sensitivity;Biological system modeling;Mental disorders;Brain modeling;Electroencephalography;Convolutional neural networks;schizophrenia;deep learning;model robustness;explainable AI},
  doi={10.1109/BIBE60311.2023.00048},
  ISSN={2471-7819},
  month={Dec},}@INPROCEEDINGS{10431640,
  author={Ray, Indrajit and Sreedharan, Sarath and Podder, Rakesh and Bashir, Shadaab Kawnain and Ray, Indrakshi},
  booktitle={2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)}, 
  title={Explainable AI for Prioritizing and Deploying Defenses for Cyber-Physical System Resiliency}, 
  year={2023},
  volume={},
  number={},
  pages={184-192},
  abstract={The adoption of digital technology in industrial control systems (ICS) enables improved control over operation, ease of system diagnostics and reduction in cost of maintenance of cyber physical systems (CPS). However, digital systems expose CPS to cyber-attacks. The problem is grave since these cyber-attacks can lead to cascading failures affecting safety in CPS. Unfortunately, the relationship between safety events and cyber-attacks in ICS is ill-understood and how cyber-attacks can lead to cascading failures affecting safety. Consequently, CPS operators are ill-prepared to handle cyber-attacks on their systems. In this work, we envision adopting Explainable AI to assist CPS oper-ators in analyzing how a cyber-attack can trigger safety events in CPS and then interactively determining potential approaches to mitigate those threats. We outline the design of a formal framework, which is based on the notion of transition systems, and the associated toolsets for this purpose. The transition system is represented as an AI Planning problem and adopts the causal formalism of human reasoning to asssit CPS operators in their analyses. We discuss some of the research challenges that need to be addressed to bring this vision to fruition.},
  keywords={Integrated circuits;Power system protection;Natural language processing;Safety;Power system faults;Cyberattack;Resilience;cyber physical systems;resiliency;AI planning;natural language processing},
  doi={10.1109/TPS-ISA58951.2023.00032},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10446037,
  author={Dutta, Rajdeep and Wang, Qincheng and Singh, Ankur and Kumarjiguda, Dhruv and Xiaoli, Li and Jayavelu, Senthilnath},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Interpretable Policy Extraction with Neuro-Symbolic Reinforcement Learning}, 
  year={2024},
  volume={},
  number={},
  pages={7570-7574},
  abstract={This paper presents a novel RL algorithm, S-REINFORCE, designed by leveraging two types of function approximators, namely Neural Network (NN) and Symbolic Regressor (SR), to produce numerical and symbolic policies for dynamic decision-making tasks, respectively. A symbolic policy uncovers functional relations between the underlying states and action-probabilities. Further, the symbolic policy is utilized through importance sampling (IS) to improve the rewards received during the learning process. The effectiveness of S-REINFORCE has been validated on various dynamic decision-making problems involving low and high dimensional action spaces. The results obtained clearly demonstrate that by leveraging the complementary strengths of NN and SR, S-REINFORCE generates policies that exhibit both good performance and interpretability. This makes S-REINFORCE an excellent choice for real-world applications where transparency and causality play a crucial role.},
  keywords={Training;Heuristic algorithms;Decision making;Signal processing algorithms;Artificial neural networks;Task analysis;Speech processing;interpretable policy;policy gradient;symbolic regression;importance sampling},
  doi={10.1109/ICASSP48485.2024.10446037},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10248890,
  author={Wu, Jia and Guo, Chao},
  booktitle={2023 8th International Conference on Intelligent Computing and Signal Processing (ICSP)}, 
  title={The prediction and optimization of ROP based on MLP-PSO}, 
  year={2023},
  volume={},
  number={},
  pages={1520-1523},
  abstract={In an effort to reduce production costs in the oil and gas industry, this paper addresses the prediction and optimization of the Rate of Penetration (ROP), a critical factor in increasing drilling speed. The study first establishes an ROP prediction model using Multi-Layer Perceptron (MLP) to capture the relationships between real-time ROP and various influencing factors. The model considers adjustable drilling parameters such as weight on bit and drilling rate to establish an ROP maximization objective function, which is subsequently solved using the Particle Swarm Optimization (PSO) method. Results indicate that the MLP model effectively captures the relationship between drilling engineering parameters and ROP, achieving a relative error rate of 2.8%. Furthermore, by employing the optimization algorithm, the actual ROP value increases by 162%, significantly enhancing drilling efficiency. Both theoretical and practical case tests demonstrate that the MLP-PSO model proposed in this paper exhibits superior accuracy, reliability, and interpretability, providing a more dependable foundation for parameter optimization in production.},
  keywords={Drilling;Oils;Signal processing algorithms;Production;Predictive models;Signal processing;Reliability theory;rate of penetration;MLP;PSO;Drill speed increase},
  doi={10.1109/ICSP58490.2023.10248890},
  ISSN={},
  month={April},}@INPROCEEDINGS{10022169,
  author={Zhang, Fangfang and Mei, Yi and Nguyen, Su and Zhang, Mengjie},
  booktitle={2022 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Phenotype Based Surrogate-Assisted Multi-objective Genetic Programming with Brood Recombination for Dynamic Flexible Job Shop Scheduling}, 
  year={2022},
  volume={},
  number={},
  pages={1218-1225},
  abstract={Dynamic flexible job shop scheduling (DFJSS) is an important combinatorial optimisation problem with a large number of real-world applications such as component production in manufacturing. Genetic programming (GP), as a hyper-heuristic approach, has been widely used to learn scheduling heuristics for DFJSS. Brood recombination has been shown its effectiveness to improve the performance of GP by generating more offspring and preselecting only promising individuals into the next generation. However, evaluating more individuals requires more computational cost. Phenotype based surrogate models have been successfully used with GP to speed up the evaluation in single-objective dynamic job shop scheduling. However, its effectiveness on multi-objective dynamic job shop scheduling is unknown. To fill this gap, this paper proposes a novel surrogate-assisted multi-objective GP based on the phenotype of GP individuals for DFJSS. Specifically, we first use phenotypic vector to represent the behaviour of GP individuals in DFJSS. Second, K-nearest neighbour based surrogates are built according to the phenotypic characterisations and multiple fitness values of the evaluated individuals. Last, the built surrogate models are used to predict the fitness of newly generated offspring in GP with brood recombination. The results show that with the same training time, the proposed algorithm can achieve significantly better scheduling heuristics than the compared algorithm. The analyses of population diversity, feature importance, and the number of non-dominated individuals have also shown the effectiveness of the proposed algorithm in different aspects.},
  keywords={Training;Job shop scheduling;Processor scheduling;Heuristic algorithms;Sociology;Genetic programming;Production;Surrogate;Phenotype;Genetic Programming;Brood Recombination;Dynamic Flexible Job Shop Scheduling},
  doi={10.1109/SSCI51031.2022.10022169},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10465874,
  author={Behki, Priyanka and Pal, Rishi},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Optimization Techniques used in Heart Disease Prediction: A Systematic Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={297-302},
  abstract={Today, heart disease is one of the leading causes of death around the world, making it a top priority in healthcare systems everywhere. Predicting cardiac issues with precision is crucial for facilitating prompt medical attention. There is great potential for improved decision-making and data-driven forecasts in healthcare with the application of Particle Swarm Optimization (PSO) in conjunction with machine learning. By utilizing numerous algorithms, this method equips both patients and doctors to intervene early and avoid sickness. It's important to remember that the parameters you pick for your optimization strategy can have a significant impact on how well these models work. This research compares three popular optimization techniques—Particle Swarm Optimization (PSO), Genetic Algorithm (GA), and Ant Colony Optimization—in the context of predicting cardiovascular disease. The fundamental goal of this study is to compare and contrast several optimization strategies, such as Feature Selection, Bayesian optimization, Evolutionary algorithms, and their hybrids, and other tried-and-true approaches from current scholarly literature. The overarching goal of these studies is to develop concepts for better heart illness diagnostics. The research also compares other Machine Learning methods developed to solve specific optimization problems. It is hoped that the knowledge gathered from this study would encourage further study into optimizing methods for cardiac illness diagnostics and the development of more efficient preventative measures.},
  keywords={Heart;Machine learning algorithms;Medical services;Predictive models;Prediction algorithms;Feature extraction;Particle swarm optimization;Optimization techniques;Heart disease;Machine learning;feature selection;Data mining},
  doi={10.1109/ICAICCIT60255.2023.10465874},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11013623,
  author={Fakhouri, Hussam and Hamad, Faten and Akhoirshida, Mohammed and Hwaitat, Ahmad Al},
  booktitle={2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)}, 
  title={Advanced Metaheuristics for Feature Selection and Classification in Medical Datasets}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Feature selection is a critical step in medical classification, where large and complex datasets can obscure clinically relevant patterns. In this work, we employ a wrapper-based feature selection framework built around a k-Nearest Neighbors classifier and compare ten state-of-the-art metaheuristic approaches for identifying minimal yet discriminative feature subsets. These approaches span swarm-intelligence (e.g., Grey Wolf Optimizer, Marine Predators Algorithm) and evolutionary algorithms, including Self-adaptive Differential Evolution and JADE (Just Another Differential Evolution). Experiments on seven medical datasets-spanning cancers (Arcene, Breast, Lung) and cardiac arrhythmia-show that certain methods, notably Moth-Flame Optimizer, Self-adaptive Differential Evolution, and JADE, achieve robust convergence and consistently high classification accuracy, exceeding 98% on multiple benchmarks and reaching 100% on Lung Cancer. Meanwhile, algorithms like Sine Cosine and Marine Predators can surpass 97% accuracy on specific problems but vary depending on dataset characteristics. The results confirm that no single technique excels universally across all clinical datasets; rather, the optimal choice depends on factors such as dataset dimensionality and class distribution. Overall, this study underscores the value of pairing metaheuristics with effective feature selection strategies in enhancing diagnostic accuracy. Future research will integrate multi-objective optimization and domain knowledge to further elevate clinical interpretability and reliability.},
  keywords={Accuracy;Navigation;Metaheuristics;Nearest neighbor methods;Feature extraction;Classification algorithms;Reliability;Medical diagnostic imaging;Tuning;Convergence;Metaheuristics;Feature Selection;Classification;Medical Dataset},
  doi={10.1109/ICCIAA65327.2025.11013623},
  ISSN={},
  month={April},}@INPROCEEDINGS{10548395,
  author={K, Sudhakar and Husain, Saif O. and Babu, D. Raja and Kumar, M. Ashok and Dineshkumar, R.},
  booktitle={2024 Third International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Malware Detection and Classification for Internet of Things Using Self-Attention Based Long Short-Term Memory}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The Internet of Things (IoT) connects numerous intelligent devices providing security features that interact with default settings accessed through applications. Additionally, Deep Learning (DL)-based mechanisms was involved for malware detection to identify and mitigate attacks. The Adaptive Synthetic Sampling (ADASYN) technique addresses class imbalances, especially when splitter class instances are distributed data in complex patterns. The proposed Self-Attention based Long Short-Term Memory (LSTM) classification method facilitates the handling of long-range dependencies in transferred data sequences offering high flexibility and adaptability to varying input lengths. For feature selection Particle Swarm Optimization (PSO) is utilized iteratively optimizes a solution in a high-dimensional space although it may have a low convergence rate due to its iterative process. The obtained results demonstrate the proposed Self-Attention based LSTM model achieves better accuracy reaching 98.05% on the NSL-KDD dataset and 99.01 % on the UNSW-NB15 dataset. These results ensure accurate classification compared to other existing methods, such as Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN).},
  keywords={Adaptation models;Recurrent neural networks;Training data;Malware;Computer networks;Internet of Things;Convolutional neural networks;adaptive synthetic sampling;convolution neural network;deep learning;internet of thing;long short-term memory;particle swarm optimization and self-attention},
  doi={10.1109/ICDCECE60827.2024.10548395},
  ISSN={},
  month={April},}@INPROCEEDINGS{11059179,
  author={A, Agnes Pearly and Karthik, B.},
  booktitle={2024 International Conference on Advances in Computing, Communication and Materials (ICACCM)}, 
  title={Enhanced Feature Selection in Lung Images by Shapley – RRO Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Feature selection is essential for improving the accuracy with which machine learning algorithms identify lung disorders from medical images. This research aims to integrate Shapley Values, grounded in cooperative game theory, with Raven Roosting Optimization (RRO), an advanced metaheuristic technique, to develop an enhanced feature selection methodology. Shapley Values are used to assess the global importance of features derived from X-ray and CT scan images, whereas RRO is employed to optimize the selection of the key features to train the model. Such an approach outperformed conventional techniques when tested on two benchmark datasets, ChestX-ray14 and LIDC-IDRI. The methodology performs well in the ChestX-ray14, with 91.5% accuracy, 0.90 F1-Score, a precision of about 89%, and a recall of approximately 91%. An enhancement on about the same level is reported on the LIDC-IDRI, with 93.2% accuracy, 0.91 F1-Score, 90% precision, and 92% recall.},
  keywords={Accuracy;Lungs;Metaheuristics;Optimization methods;Feature extraction;Performance metrics;Rail to rail outputs;Real-time systems;X-ray imaging;Biomedical imaging;Lung disorder detection;X-ray;Machine learning;Feature selection;Shapley Values;Raven Roosting Optimization},
  doi={10.1109/ICACCM61117.2024.11059179},
  ISSN={2642-7354},
  month={Nov},}@INPROCEEDINGS{10392512,
  author={Tan, Kaiyao and Zhang, Enkai},
  booktitle={2023 IEEE 3rd International Conference on Data Science and Computer Application (ICDSCA)}, 
  title={Load Forecast Based on RF-PSO-VMD-Transformer-LSTM}, 
  year={2023},
  volume={},
  number={},
  pages={684-689},
  abstract={To improve the accuracy of model prediction of load, a prediction method based on random forest, particle swarm optimization, variational modal decomposition, Transformer-LSTM time series prediction model, and interval prediction is proposed. Firstly, the random forest algorithm is used for feature selection, and the variational modal decomposition algorithm based on particle swarm optimization is used to decompose the load time series into several components with different center frequencies. The time series is stabilized and linearized. Secondly, the Transformer-LSTM prediction model is established for prediction, and the prediction results of each component are superimposed. Finally, the interval prediction method is adopted to obtain the final load prediction data. Results show that, compared with several other typical time series forecasting models, the evaluation indicators of the proposed forecasting method are significantly improved.},
  keywords={Time-frequency analysis;Load forecasting;Time series analysis;Predictive models;Transformers;Prediction algorithms;Feature extraction;Transformer;Interval prediction;variational modal decomposition;LSTM},
  doi={10.1109/ICDSCA59871.2023.10392512},
  ISSN={},
  month={Oct},}@ARTICLE{10812807,
  author={Ji, Lixia and Ren, Zhigang and Chen, Yiqiao and Zeng, Hao},
  journal={IEEE Sensors Journal}, 
  title={Large-Scale Sparse Antenna Array Optimization for RCS Reduction With an AM-FCSN}, 
  year={2025},
  volume={25},
  number={3},
  pages={5782-5794},
  abstract={The existing deep learning methods for radar cross section (RCS) reduction are unsuitable for large-scale sparse arrays because their large scales result in large numbers of classes and high network complexity levels. This article proposes a new deep learning method to solve these problems. First, a hybrid-interval particle swarm optimization (HIPSO) algorithm is presented. The number of classes is reduced using the presented HIPSO algorithm, which adaptively adjusts the sampling interval. Then, a fully convolutional shortcut network based on an attention mechanism (AM-FCSN) is designed. The optimal spatial arrangement is selected by the designed AM-FCSN. Finally, simulations show that the proposed HIPSO algorithm reduces the number of classes from  ${O}\text {(} {{10}^{{4}}} \text {)}$  to  ${O}\text {(} {{10}^{{2}}} \text {)}$ . Moreover, compared with different neural networks, the proposed AM-FCSN achieves computational complexity and parameter complexity reductions of 38.46% and 80.2%, respectively, while attaining higher accuracy. The proposed method can effectively reduce the large-scale sparse array RCS in real time.},
  keywords={Antenna arrays;Antennas;Radar cross-sections;Feature extraction;Sensors;Deep learning;Switches;Radar antennas;Accuracy;Particle swarm optimization;Fully convolutional shortcut network based on an attention mechanism (AM-FCSN);hybrid-interval particle swarm optimization (HIPSO);large-scale sparse antenna array;radar cross section (RCS)},
  doi={10.1109/JSEN.2024.3516038},
  ISSN={1558-1748},
  month={Feb},}@INPROCEEDINGS{10653037,
  author={Jiang, Nan and Wu, Yi},
  booktitle={2024 IEEE/ACM International Workshop on Automated Program Repair (APR)}, 
  title={RepairCAT: Applying Large Language Model to Fix Bugs in AI-Generated Programs}, 
  year={2024},
  volume={},
  number={},
  pages={58-60},
  abstract={Automated program repair has been a crucial and popular domain for years, and with the development of large language models (LLMs) and the trend of using LLMs for code generation, there comes the new challenge of fixing bugs in LLM -generated (AI-generated) programs. In this work, we introduce RepairCAT, a simple and neat framework for fine-tuning large language models for automated repairing Python programs. Our experiments built on StarCoder-1B successfully generated patches fixing the failed test cases for 14 out of 100 bugs in the Python programs, 2 of which passed all the public test cases and were considered plausible.},
  keywords={Codes;Large language models;Conferences;Computer bugs;Maintenance engineering;Market research;Python;Automated Program Repair;Large Language Model},
  doi={10.1145/3643788.3648020},
  ISSN={},
  month={April},}@ARTICLE{10015004,
  author={Custode, Leonardo L. and Iacca, Giovanni},
  journal={IEEE Access}, 
  title={Evolutionary Learning of Interpretable Decision Trees}, 
  year={2023},
  volume={11},
  number={},
  pages={6169-6184},
  abstract={In the last decade, reinforcement learning (RL) has been used to solve several tasks with human-level performance. However, there is a growing demand for interpretable RL, i.e., there is the need to understand how a RL agent works and the rationale of its decisions. Not only do we need interpretability to assess the safety of such agents, but also we may need it to gain insights into unknown problems. In this work, we propose a novel optimization approach to interpretable RL that builds decision trees. While techniques that optimize decision trees for RL do exist, they usually employ greedy algorithms or do not exploit the rewards given by the environment. For these reasons, these techniques may either get stuck in local optima or be inefficient. On the contrary, our approach is based on a two-level optimization scheme that combines the advantages of evolutionary algorithms with the benefits of  $\mathcal {Q}$ -learning. This method allows decomposing the problem into two sub-problems: the problem of finding a meaningful decomposition of the state space, and the problem of associating an action to each subspace. We test the proposed method on three well-known RL benchmarks, as well as on a pandemic control task, on which it results competitive with the state-of-the-art in both performance and interpretability.},
  keywords={Reinforcement learning;Optimization;Decision trees;Behavioral sciences;Pandemics;Evolutionary computation;Q-learning;Decision tree;evolutionary algorithm;interpretability;reinforcement learning},
  doi={10.1109/ACCESS.2023.3236260},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10262559,
  author={Zhou, Xiaofeng and Pranolo, Andri and Mao, Yingchi},
  booktitle={2023 International Conference on Computer, Electronics & Electrical Engineering & their Applications (IC2E3)}, 
  title={AB-LSTM: Attention Bidirectional Long Short-Term Memory for Multivariate Time-Series Forecasting}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to its applications in numerous fields, such as weather forecasting, multivariate time series forecasting has attracted significant interest. This paper promotes AB-LSTM (Attention Bidirectional Long Short-Term Memory) as an innovative method for precise multivariate time series forecasting. The AB-LSTM model combines the strengths of bidirectional LSTM (Bi-LSTM) and attention mechanisms to capture the temporal dependencies and interdependencies among multiple time series variables. The bidirectional nature of the LSTM allows the model to incorporate past and future information, enabling more robust predictions. The attention mechanism focuses on the most relevant time steps and variables, enhancing the model's ability to extract meaningful patterns and relationships from the input data. The performance of AB-LSTM is then evaluated in the experiment to the public datasets of Beijing PM2.5. The results were compared with state-of-the-art baseline models. The results demonstrate that AB-LSTM outperforms the baseline models regarding forecasting accuracy based on RMSE 20.966, particularly for long-range predictions and complex datasets. The AB-LSTM model offers interpretability by providing attention weights, indicating the relative importance of each input variable at different time steps.},
  keywords={Error analysis;Input variables;Time series analysis;Weather forecasting;Predictive models;Prediction algorithms;Forecasting;Multivariate time series;Bidirectional LSTM;Attention mechanism;hyperparameter tuning;PSO},
  doi={10.1109/IC2E357697.2023.10262559},
  ISSN={},
  month={June},}@INPROCEEDINGS{9985179,
  author={Zhao, Dongmei and Wu, Yaxing and Li, Qingru},
  booktitle={2022 International Conference on Networking and Network Applications (NaNA)}, 
  title={Network Security Situation Prediction Implemented by Attention and BiLSTM}, 
  year={2022},
  volume={},
  number={},
  pages={213-219},
  abstract={With the increasing diversification and complexity of network security attacks, it is becoming more and more difficult to predict the network situation. In order to improve the effect of situation prediction, this paper constructs a network security situation prediction model for a Improved Particle Swarm Optimization and Attention fusion Bidirectional Long Short-Term Memory (IPSO-ABiLSTM). First, there is no real situation value for the UNSW-NB15 data set, and a situation value is generated based on the impact of the attack. Secondly, the particle swarm algorithm is improved. The IPSO algorithm makes the algorithm's global and local search capabilities more balanced and faster to converge. Finally, optimizing the hyperparameters of the BiLSTM network fused with the attention mechanism to obtain the final model, and combined with PSO-BiLSTM network, PSO-LSTM network, BiLSTM model for performance comparison. The experimental results show that the IPSO-ABiLSTM in this paper has a fitting degree of up to 0.9922, and the error value is relatively smaller, which verifies the effectiveness of the model proposed in this paper in the network security situation prediction problem.},
  keywords={Correlation;Fitting;Predictive models;Network security;Prediction algorithms;Data models;Complexity theory;network security;situation prediction;Attention mechanism;Bidirectional Long Short-term Memory;Improved Particle Swarm Optimization},
  doi={10.1109/NaNA56854.2022.00043},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10744295,
  author={Almeida, José and Lezama, Fernando and Soares, João and Vale, Zita},
  booktitle={2024 22nd International Conference on Intelligent Systems Applications to Power Systems (ISAP)}, 
  title={Differential MAP-Elites Considering Energy Resource Management Behaviors in Power Distribution Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Problems like energy resource management take into account high dimensionality, nonlinear constraints, parameter uncertainty, or the dispersed nature of resources, and classical optimization tools that were not built for such a new paradigm are nearing the end of their useful life. In the process of striking a balance between “optimal” and “practical” answers, metaheuristic optimization emerges. This optimization presents some disadvantages as it does not guarantee the global optimum and lacks explainability in its processes, as it is considered a black-box algorithm. This work proposes a differential Multi-dimensional Archive of Phenotypic Elites (MAP-Elites) algorithm based on multiple differential evolution strategies to illuminate metaheuristic performance. We compare the multiple strategies for day-ahead energy resource management in a 33-bus distribution network with a high penetration of renewables and electric vehicle users. Results show that incorporating the differential MAP-Elites algorithm introduces an understanding of algorithm performance for the chosen behaviors.},
  keywords={Uncertain systems;Renewable energy sources;Energy resources;Metaheuristics;Closed box;Distribution networks;Electric vehicles;Power systems;Intelligent systems;differential evolution;energy resource management;illumination algorithms;MAP-Elites;optimization},
  doi={10.1109/ISAP63260.2024.10744295},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10711527,
  author={Wang, Ziqi and Wu, Xiangxi and Bi, Jing and Yuan, Haitao and Zhang, Jia and Zhou, MengChu},
  booktitle={2024 IEEE 20th International Conference on Automation Science and Engineering (CASE)}, 
  title={Long-term Water Quality Prediction based on Intelligent Optimization and Seasonal-trend Decomposition}, 
  year={2024},
  volume={},
  number={},
  pages={264-269},
  abstract={Nowadays, the applications of water quality prediction in the field of regional water environment management are increasing. It refers to predicting the elemental values of the water environment in the future based on past monitoring data, which is essential to realize the real-time evaluation of water quality and dynamic control of pollution sources. However, the water environment indicators are affected by various elements, which have a large volatility and non-linear characteristics. In addition, most of the existing water quality predictions focus on single-step predictive modeling of single elements of the water environment and lack multi-step predictive analysis of multifactor data of the water environment. In this paper, a novel long-term prediction model based on genetic simulated annealing-based particle swarm optimization (GSPSO) with seasonal-trend decomposition using LOESS (STL) is proposed and named GSPSO-STL-Autoformer (GS-Autoformer). It realizes the multi-factor and long-term prediction of water quality time series data. Firstly, the Autoformer’s hyperparameters are optimized by the GSPSO to improve its convergence speed. Secondly, the multi-factor features are decomposed by the STL to make the model more focused on learning feature information of each component. Finally, the long-term prediction is realized by the Autoformer. Comparative experiments with state-of-the-art peers show that the GS-Autoformer can effectively improve the accuracy of multi-factor and long-term predictions.},
  keywords={Accuracy;Time series analysis;Water quality;Simulated annealing;Predictive models;Water pollution;Data models;Predictive analytics;Particle swarm optimization;Water resources;Time series forecasting;seasonal-trend decomposition;intelligent optimization algorithms},
  doi={10.1109/CASE59546.2024.10711527},
  ISSN={2161-8089},
  month={Aug},}@INPROCEEDINGS{10874316,
  author={Zhang, Lili and Liang, Kun},
  booktitle={2024 4th International Signal Processing, Communications and Engineering Management Conference (ISPCEM)}, 
  title={Research on multi-objective optimization model of enterprise performance evaluation based on big data}, 
  year={2024},
  volume={},
  number={},
  pages={735-739},
  abstract={]In the enterprise performance evaluation driven by big data, how to effectively extract key features from massive data and carry out multi-objective optimization is an important topic of current research. In this paper, an innovative Recursive Feature Multi-Objective Evolutionary (RFMOE) algorithm is proposed, which combines the advantages of recursive feature elimination (RFE) and decomposition based multi-objective evolutionary algorithm (MOEA/D). In the multi-objective optimization model of enterprise performance evaluation based on big data, RFMOE first utilizes the iterative feature selection mechanism of RFE to effectively eliminate redundant and unimportant features, reduce data dimensions, and improve model efficiency. Then, the multi-objective optimization problem is decomposed into multiple single-objective subproblems by MOEA/D, and the information exchange of adjacent subproblems is used to optimize the solution process to obtain a set of Pareto optimal solutions. Finally, by comparing the model architecture with the traditional model, the results show that RFMOE has significant advantages in improving the evaluation accuracy, enhancing the robustness of the model and improving the decision-making efficiency, which provides a powerful tool for the performance management and strategic planning of enterprises. The feasibility and effectiveness of this model in enterprise performance evaluation are proved.},
  keywords={Performance evaluation;Computational modeling;Optimization models;Decision making;Evolutionary computation;Big Data;Feature extraction;Data models;Robustness;Optimization;recursive feature elimination;multi-objective evolutionary algorithm;performance evaluation},
  doi={10.1109/ISPCEM64498.2024.00131},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10831279,
  author={Jiang, Cheng and Lu, Gang and Ma, Xue and Wu, Di},
  booktitle={2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Cloud-Model-Improved Transformer for Robust Load Prediction of Power Network Clusters}, 
  year={2024},
  volume={},
  number={},
  pages={185-190},
  abstract={Load data from power network clusters indicates economic development in each area, crucial for predicting regional trends and guiding power enterprise decisions. The Transformer model, a leading method for load prediction, faces challenges modeling historical data due to variables like weather, events, festivals, and data volatility. To tackle this, the cloud model's fuzzy feature is utilized to manage uncertainties effectively. Presenting an innovative approach, the Cloud Model Improved Transformer (CMIT) method integrates the Transformer model with the cloud model utilizing the particle swarm optimization algorithm, with the aim of achieving robust and precise power load predictions. Through comparative experiments conducted on 31 real datasets within a power network cluster, it is demonstrated that CMIT significantly surpasses the Transformer model in terms of prediction accuracy, thereby highlighting its effectiveness in enhancing forecasting capabilities within the power network cluster sector.},
  keywords={Accuracy;Clouds;Clustering algorithms;Predictive models;Transformers;Prediction algorithms;Data models;Particle swarm optimization;Forecasting;Load modeling;Power network cluster;Transformer model;CMIT method;Cloud model;Particle swarm optimization algorithm;Prediction accuracy},
  doi={10.1109/SMC54092.2024.10831279},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10914759,
  author={K, Jayakumar and Muthupandi, G and R, Dhayanidhi and Pavithra, S.},
  booktitle={2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, 
  title={Advances in Deep Learning for Tuberculosis Detection in Chest X-Rays: A Review of Diagnostic Accuracy}, 
  year={2025},
  volume={},
  number={},
  pages={1158-1162},
  abstract={Tuberculosis (TB) is one of the leading causes of deaths globally, mainly in low- and middle-income countries. Early and accurate detection is crucial for effective treatment and disease control. In this paper, models like CNNs-VGG16, ResNet, and DenseNet, to name a few, are taken into an exhaustive study. Optimization techniques, including transfer learning and ensemble methods, which can increase accuracy in the challenging diverse clinical settings, will be presented. Equitable healthcare outcome is achieved in terms of future research directions which include representative datasets and interpretability of the model.},
  keywords={Deep learning;Accuracy;Tuberculosis;Transfer learning;Medical services;Feature extraction;X-ray imaging;Optimization;Tuning;Biomedical imaging;Deep Learning;Tuberculosis Detection;Chest X-Rays;CNN;Diagnostic Accuracy;Optimization Techniques;AI in Healthcare},
  doi={10.1109/IDCIOT64235.2025.10914759},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10896428,
  author={Babic, Lepa and Stoean, Ruxandra and Cadjenovic, Jelena and Jovanovic, Luka and Zivkovic, Miodrag and Bacanin, Nebojsa},
  booktitle={2024 26th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}, 
  title={The NLP for Employee Review Sentiment Analysis: An Explainable Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={285-291},
  abstract={Main goal of the research presented in this manuscript is to analyze employees satisfaction by employing hybrid methods between machine learning and metaheuristics. Furthermore, the proposed work utilizes term frequency-inverse document frequency (TF-IDF), natural language processing (NLP) method, for the identification of important segments of the employees' statements towards their workplaces, while the extreme gradient boosting (XGBoost) model is used for predicting the outcomes. Since each machine learning technique should be calibrated to particular problem, the XGBoost has been optimized by a modified swarm metaheuristics based on red fox optimizer (RFO) algorithm and its performance is evaluated against other high-performing swarm intelligence approaches. The results indicate the superiority of proposed solution, which has been further evaluated with the Shapley additive explanations (SHAP) analysis.},
  keywords={Sentiment analysis;Machine learning algorithms;Scientific computing;Reviews;Computational modeling;Metaheuristics;Employment;Predictive models;Prediction algorithms;Particle swarm optimization;employee satisfaction;natural language processing;sentiment analysis;red fox optimizer;swarm intelligence},
  doi={10.1109/SYNASC65383.2024.00054},
  ISSN={2470-881X},
  month={Sep.},}@INPROCEEDINGS{10771015,
  author={Ilani, Mohsen Asghari and Banad, Yaser Mike},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={XGBoost Algorithm for Interpretable AI Prediction of Melt Pool Geometry in IoT-Enabled Additive Manufacturing within Industry 4.0 Utilizing NSGA-II}, 
  year={2024},
  volume={},
  number={},
  pages={222-227},
  abstract={Additive manufacturing (AM), particularly with Laser Powder Bed Fusion (LPBF), excels in fabricating intricate geometries and custom components through layer-by-layer deposition. However, precise control over melt pool geometry is crucial for ensuring high quality and performance. This study uses Extreme Gradient Boosting (XGBoost) regression techniques to manage melt pool geometry in AM processes. The primary goal is to evaluate these models' effectiveness in predicting and optimizing melt pool depth, width, and length using extensive datasets of process parameters and material properties. The models produced promising results. The best performance was for melt pool length, with an MSE of 0.0036, RMSE of 0.0600, MAE of 0.0300, and an R-squared score of 0.9456. Integrating these models into Multi-Objective Optimization Using Non-Dominated Sorting Genetic Algorithm II (NSGA-II) enhances real-time monitoring, control, and optimization of melt pool geometry during production. This approach leverages IoT-enabled capabilities within Industry 4.0 frameworks, improving decision-making and operational efficiency in AM. By providing interpretable AI predictions, this study aims to enhance the quality, reliability, and efficiency of AM processes, contributing to optimized production outcomes in digital manufacturing environments.},
  keywords={Geometry;Production;Predictive models;Three-dimensional printing;Fourth Industrial Revolution;Reliability;Artificial intelligence;Optimization;Sorting;Genetic algorithms;Additive Manufacturing;Melt Pool Geometry;Extreme Gradient Boosting;Non-Dominated Sorting Genetic Algorithm II},
  doi={10.1109/AIxSET62544.2024.00043},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9998240,
  author={Ghoualmi, Lamis and Benkechkache, Mohamed El Amine},
  booktitle={2022 3rd International Informatics and Software Engineering Conference (IISEC)}, 
  title={Feature Selection Based on Machine Learning Algorithms: A weighted Score Feature Importance Approach for Facial Authentication}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={The emergence of biometric-based face detection and recognition technology has attracted the attention of all industries. Facial recognition allows you to recognize people by their facial features. This technology has been a part of our daily lives and has been utilized in security, forensic investigation, and check-ins at airports. Feature selection allows for finding the most distinct facial biometric traits from the first feature set. In addition to identifying the most important features, feature selection also aids in lowering the feature size dimension. It is an essential step in the process since biometric authentication occurs in real-time. This paper presents a novel feature selection method based on the fusion feature importance scores of machine learning models. A weighted score level fusion method based on the Genetic Algorithm (GA) is used to combine the scores collected from various machine learning models. The objective function, which represents the accuracy of the biometrics system, is optimized by the GA, which is utilized as an optimizer to choose the optimal weights. The Fetch Olivetti Faces database has been used to test the proposed method. According to the stated results, the proposed approach increased accuracy from 93.5 percent to 95.62 percent while enabling a decrease in feature size from 4096 to 964.},
  keywords={Machine learning algorithms;Databases;Face recognition;Biological system modeling;Software algorithms;Authentication;Machine learning;facial biometric authentication;feature selection;machine learning algorithm;genetic algorithm},
  doi={10.1109/IISEC56263.2022.9998240},
  ISSN={},
  month={Dec},}@ARTICLE{10713207,
  author={Chen, Fengxiang and Gao, Yunpeng and Wang, Jiangzhao and Wu, Maio and Zhang, Wei and Teng, Fei},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Real-Time Carbon Emission Estimation for Industrial Users With Low RMSE Based on NILM and Evolutionary Algorithm}, 
  year={2024},
  volume={73},
  number={},
  pages={1-11},
  abstract={User-side carbon emission accounting is a means to sort out the amount and source of user carbon emissions. Real-time carbon estimation methods based on nonintrusive load monitoring (NILM) tend to miss the fact that there is not a negative correlation between equipment identification accuracy and carbon emission estimation error. Higher accuracy does not mean lower error. A two-stage training NILM network, LRMSE-ResNeSt, is proposed to reduce the error of real-time carbon emission monitoring results. It emphasizes the low root-mean-square error (RMSE) of carbon emissions’ monitoring. The feature extraction network is first constructed using convolution and split-attention mechanism, and then, the model is trained using a two-stage training approach. In the first stage, backpropagation is used to update the network parameters for accurate device identification. In the second stage, the parameters of the fully connected layer are tuned using particle swarm optimization (PSO) to make the classifier more focused on the identification accuracy of devices with high carbon emissions. Finally, the proposed LRMSE-ResNeSt is validated using the industrial appliance identification dataset (IAID) industrial dataset. The experimental results show that the LRMSE-ResNeSt successfully reduces the RMSE of real-time carbon estimation by an average of 14.94%, which addresses the problem that the NILM method only focuses on the accuracy of the equipment identification but ignores the error of the carbon emission estimation results.},
  keywords={Carbon dioxide;Estimation;Accuracy;Real-time systems;Object recognition;Greenhouse gases;Load monitoring;Feature extraction;Training;Support vector machines;Appliance identification;carbon emission estimation;low root-mean-square error (RMSE);particle swarm optimization (PSO);split-attention},
  doi={10.1109/TIM.2024.3476562},
  ISSN={1557-9662},
  month={},}@ARTICLE{10586218,
  author={de Franca, F. O. and Virgolin, M. and Kommenda, M. and Majumder, M. S. and Cranmer, M. and Espada, G. and Ingelse, L. and Fonseca, A. and Landajuela, M. and Petersen, B. and Glatt, R. and Mundhenk, N. and Lee, C. S. and Hochhalter, J. D. and Randall, D. L. and Kamienny, P. and Zhang, H. and Dick, G. and Simon, A. and Burlacu, B. and Kasak, Jaan and Machado, Meera and Wilstrup, Casper and Cavaz, W. G. La},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={SRBench++: Principled Benchmarking of Symbolic Regression With Domain-Expert Interpretation}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Symbolic regression searches for analytic expressions that accurately describe studied phenomena. The main promise of this approach is that it may return an interpretable model that can be insightful to users, while maintaining high accuracy. The current standard for benchmarking these algorithms is SRBench, which evaluates methods on hundreds of datasets that are a mix of real-world and simulated processes spanning multiple domains. At present, the ability of SRBench to evaluate interpretability is limited to measuring the size of expressions on real-world data, and the exactness of model forms on synthetic data. In practice, model size is only one of many factors used by subject experts to determine how interpretable a model truly is. Furthermore, SRBench does not characterize algorithm performance on specific, challenging sub-tasks of regression such as feature selection and evasion of local minima. In this work, we propose and evaluate an approach to benchmarking SR algorithms that addresses these limitations of SRBench by 1) incorporating expert evaluations of interpretability on a domain-specific task, and 2) evaluating algorithms over distinct properties of data science tasks. We evaluate 12 modern symbolic regression algorithms on these benchmarks and present an in-depth analysis of the results, discuss current challenges of symbolic regression algorithms and highlight possible improvements for the benchmark itself.},
  keywords={Benchmark testing;Task analysis;Accuracy;Evolutionary computation;Prediction algorithms;Machine learning algorithms;Current measurement;Symbolic Regression;Competition;Interpretable Machine Learning},
  doi={10.1109/TEVC.2024.3423681},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10611932,
  author={Xu, Jizhong and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A New Concordance Correlation Coefficient based Fitness Function for Genetic Programming for Symbolic Regression}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={Coefficients learning has long been challenging in genetic programming based symbolic regression (GPSR). Recent GPSR methods employ Pearson correlation coefficient for fitness assessment with post-hoc linear scaling for coefficient learning. However, this approach often leads to sub-optimal coefficient learning and inadequate consideration of nonlinear relationships between input variables and outputs. To solve those issues, this study introduces an innovative approach to integrating the Concordance Correlation Coefficient (CCC) into GPSR. Unlike Pearson correlation, CCC can effectively assess both linear and non-linear agreements between two sets of variables. Experimental results on eight regression datasets highlight the potential of CCC as a promising fitness function for GPSR without the need of a more advanced coefficient optimisation method for linear scaling.},
  keywords={Correlation coefficient;Correlation;Input variables;Genetic programming;Optimization methods;Evolutionary computation;Genetic Programming;Symbolic Regression;Fitness Function;Correlation;Linear Scaling;Concordance Correlation Coefficient},
  doi={10.1109/CEC60901.2024.10611932},
  ISSN={},
  month={June},}@INPROCEEDINGS{11043003,
  author={Luo, Yi and Liu, Chang and Ji, Dong},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A Convolutional Sparse Representations Integration Strategy Based on Self-Attention Genetic Programming for Multimodal Image Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Multimodal image fusion (MIF) seeks to amalgamate complementary information from various image modalities, offering a more comprehensive and accurate representation of data. Convolutional sparse coding (CSC) based methods have demonstrated effectiveness in this domain. However, they encounter difficulties in adaptively discerning and leveraging cross-modality feature correlations, which essentially presents a multi-objective optimization challenge, such as maximizing information retention while minimizing feature distortion. To address this issue, we introduce a self-attention based multi-objective genetic programming (SA-MOGP) method. SA-MOGP frames the quest for an optimal fusion strategy as a multi-objective optimization problem. By integrating the self-attention mechanism into strongly typed genetic programming (STGP), it enables efficient exploration of associations between sparse features across different modalities. Our approach is structured in three hierarchical layers. The feature extraction (FE) layer automatically generates Q, K, V sub-trees according to a predefined function set. These are then input into the self-attention (SA) layer for computation. Finally, the output layer estimates the fusion weights. We utilize the NSGAII framwork to solve this multi-objective problem, aiming for Pareto front solutions. Experiments on infrared-visible and medical image datasets attest to the superior performance of the SAGP method in multimodal image fusion.},
  keywords={Convolutional codes;Measurement;Visualization;Correlation;Genetic programming;Feature extraction;Encoding;Image fusion;Optimization;Biomedical imaging;multimodal image fusion;genetic programming;self-attention;convolutional sparse coding},
  doi={10.1109/CEC65147.2025.11043003},
  ISSN={},
  month={June},}@INPROCEEDINGS{11030427,
  author={Jiang, Shibo and Xia, Mingming and Cheng, Fan},
  booktitle={2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)}, 
  title={An Evolutionary Multitasking Multiobjective Algorithm for High-Dimensional Feature Selection: Utilizing Implicit and Explicit Information}, 
  year={2025},
  volume={},
  number={},
  pages={461-467},
  abstract={Evolutionary computation (EC) has been successful in feature selection. However, when tackling high-dimensional feature selection (HDFS) problem, EC-based algorithms face the challenge known as the “curse of dimensionality”. Recently, many EC-based HDFS algorithms have been developed and achieve promising results. Despite that, they often fail to share information and optimize collaboratively, which may make them fall into local optima. To this end, we propose a multitasking evolutionary algorithm that utilizing the sharing of implicit and explicit information between tasks to solve the HDFS problem. Firstly, the original FS task is modeled as the multi-objective HDFS problem, which is viewed as the main task and aims to explore the entire search space. Secondly, multiple auxiliary tasks with low dimensions are constructed to solve the “curse of dimensionality”, where potential feature subsets can be searched quickly. To fully leverage the advantages of both the main FS task and the auxiliary FS tasks, a knowledge transfer strategy is developed. By sharing implicit and explicit information between tasks, high-quality feature subsets can be obtained. Experimental results on 12 high-dimensional datasets show that the proposed algorithm outperforms the state-of-the-art.},
  keywords={Cloud computing;Evolutionary computation;Big Data;Multitasking;Feature extraction;Search problems;Knowledge transfer;Faces;Feature selection;evolutionary computation;multi-objective;high-dimensional;multitasking},
  doi={10.1109/ICCCBDA64898.2025.11030427},
  ISSN={2832-3734},
  month={April},}@INPROCEEDINGS{9870301,
  author={Reuter, Julia and Cendrollu, Manoj and Evrard, Fabien and Mostaghim, Sanaz and van Wachem, Berend},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Towards Improving Simulations of Flows around Spherical Particles Using Genetic Programming}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The simulation of particle-laden flows is a crucial task in fluid dynamics, requiring high computational cost owing to the complex interactions between numerous particles. Typically, the flow velocity is described with the equations proposed by Stokes. While there is an analytical solution for the Stokes flows around a single spherical particle, the Stokes flows around many particles are still unsolved. In this paper, we study Genetic Programming (GP) for symbolic regressions to explore the potentials of multi-objective GP in recovering analytical expressions for two and, in the future, N particles. We propose a new GP approach containing building blocks to scale up the problem and provide a new benchmark with 22 cases for this application. To identify the strengths and limitations of GP, we generate fully resolved training data from simulations. We compare the results of our algorithm to the superimposition method and a multi-layer perceptron as two baseline methods. The results show that GP can find comparable and sometimes better solutions with smaller failure rates than the two baseline methods. In addition, the produced solutions by GP are explainable and certain function patterns inline with physical laws can be identified across the benchmark problems.},
  keywords={Computational modeling;Fluid dynamics;Genetic programming;Training data;Evolutionary computation;Benchmark testing;Mathematical models;Genetic Programming;Stokes Flow;Explain-ability},
  doi={10.1109/CEC55065.2022.9870301},
  ISSN={},
  month={July},}@INPROCEEDINGS{11042987,
  author={Cao, Lulu and Feng, Yinglan and Jiang, Min and Tan, Kay Chen},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={NetGP: A Hybrid Framework Combining Genetic Programming and Deep Reinforcement Learning for PDE Solutions}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Partial differential equations (PDEs) are fundamental in various scientific and engineering fields. Methods based on symbolic regression to solve PDEs have gained attention due to their inherent interpretability. However, existing symbolic regression methods rely solely on genetic programming (GP) during the search process, which presents opportunities for improvement in both precision and stability. We introduce a novel framework, itemd NetGP, which enhances symbolic regression for PDEs in three key aspects. First, NetGP employs prefix notation arrays to represent symbolic expressions, simplifying the evaluation process. Second, to improve the stability of the evolutionary process, deep reinforcement learning is integrated to generate new individuals. Additionally, a novel operator is proposed to avoid the generation of invalid expressions during crossover and mutation of array-based individuals. Empirical evaluations across five types of PDEs demonstrate that NetGP achieves outstanding accuracy and stability in solving these PDEs. The code can be found at https://github.com/grassdeerdeer/NetGP.},
  keywords={Accuracy;Codes;Partial differential equations;Diversity reception;Genetic programming;Evolutionary computation;Deep reinforcement learning;Hybrid power systems;Generators;Partial Differential Equation;Symbolic Regression;Genetic Programming;Physics-informed Machine Learning},
  doi={10.1109/CEC65147.2025.11042987},
  ISSN={},
  month={June},}@ARTICLE{9913210,
  author={Jian, Shi-Jie and Hsieh, Sun-Yuan},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={A Niching Regression Adaptive Memetic Algorithm for Multimodal Optimization of the Euclidean Traveling Salesman Problem}, 
  year={2023},
  volume={27},
  number={5},
  pages={1413-1426},
  abstract={The traveling salesman problem (TSP) has been studied for many years. In particular, the multimodal optimization of the TSP is important for practical applications, because decision-makers can select the best candidate based on current conditions and requirements. In the Euclidean TSP, there are  $n$  points in  $\mathbb {R}^{d}$  space with Euclidean distance between any two points, that is,  $d(x, y) =||x-y||_{2}$ . The goal is to find a tour of minimum length visiting each point. In this article, we only focus on the case that  $d=2$ . Recently, in order to efficiently handle the multimodal optimization of the TSP, some methods have been developed to deal with it. Nevertheless, these methods usually perform poorly for large-scale cases. In this article, we propose a niching regression adaptive memetic algorithm (MA) to handle the multimodal optimization of the Euclidean TSP. We use the MA as the baseline algorithm and incorporate the neighborhood strategy to maintain the population diversity. In addition, we design a novel regression partition initialization and adaptive parameter control to enhance our algorithm, and propose the concept of the redundant individual to improve the search efficiency. To validate the performance of the proposed algorithm, we comprehensively conduct experiments on the multimodal optimization of TSP benchmark and the well-known TSPLIB library. The experimental results reveal that the proposed method outperforms other methods, especially for large-scale cases.},
  keywords={Optimization;Memetics;Heuristic algorithms;Urban areas;Approximation algorithms;Traveling salesman problems;Partitioning algorithms;Euclidean traveling salesman problem (TSP);evolutionary computation;intelligent computing;memetic algorithms (MAs);multimodal optimization;neighborhood niching technique;parameter control},
  doi={10.1109/TEVC.2022.3211954},
  ISSN={1941-0026},
  month={Oct},}@INPROCEEDINGS{10202034,
  author={Samleepant, Jiraphat and Ratanavilisagul, Chiabwoot},
  booktitle={2023 20th International Joint Conference on Computer Science and Software Engineering (JCSSE)}, 
  title={Modified Feature Extraction to apply PSO for solving Handwritten Digits}, 
  year={2023},
  volume={},
  number={},
  pages={356-361},
  abstract={Handwritten Digit Recognition (HDR) is a widely used technology that has been demonstrated in various research topics. However, there are many limitations because everyone's handwriting is different, including important handwriting characteristics. The experimental results of the previously proposed methods were unsatisfactory when using limited amounts of the datasets for the training model and inefficient pre-processing. Therefore, we describe a new method for increasing the recognition rate through well-planned pre-processing and enhanced feature extraction for applying Particle Swarm Optimization (PSO). When compared to other techniques, the proposed method performed well when tested against an individual's handwritten digits and the original MNIST database. Our results are a high recognition rate and short runtime.},
  keywords={Training;Computer science;Handwriting recognition;Runtime;Image recognition;Databases;Feature extraction;Handwritten Digits Recognition;Particle Swarm Optimization (PSO);Feature Extraction},
  doi={10.1109/JCSSE58229.2023.10202034},
  ISSN={2642-6579},
  month={June},}@INPROCEEDINGS{10412730,
  author={Kong, Beibei and Ni, Xiaomei and Wang, Ting and Xu, Xiushan and Li, Xiangbao},
  booktitle={2023 Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)}, 
  title={Simulation of Manipulator Control Model Based on Improved Differential Evolution Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={499-503},
  abstract={The goal of trajectory tracking control of the manipulator is to make the joints of the manipulator cooperate with each other through a certain control algorithm, and finally make the end effector reach the desired target position according to the pre-designed path, so as to complete the corresponding required tasks. For different fields, such as aerospace, power grid, agriculture, etc., the trajectory optimization requirements of the manipulator are also very different, which leads to different degrees of adjustment of the end pose of the manipulator. Industrial manipulator is a complex system with high nonlinearity, strong coupling and uncertain model, and its motion process is often repetitive. In this paper, a manipulator control model based on improved differential evolution (DE) algorithm is proposed, and the simulation experiment is compared with the standard PID algorithm. The simulation results show that this model can get a recall rate of 95.83%, and the error is obviously reduced compared with the traditional algorithm. Compared with PID algorithm, the tracking trajectory, optimal trajectory and ideal trajectory of the improved DE algorithm are more similar with less error.},
  keywords={Torque;Trajectory planning;Heuristic algorithms;Manipulators;Control systems;Manipulator dynamics;Trajectory optimization;Manipulator control;Differential evolution algorithm;Trajectory tracking},
  doi={10.1109/IPEC57296.2023.00093},
  ISSN={},
  month={April},}@ARTICLE{11004052,
  author={Fan, Qinglan and Zhang, Yunfeng and Yao, Xunxiang and Bi, Ying and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={ES-GP: An Ensemble Surrogate-Assisted Genetic Programming Approach to Image Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Genetic Programming (GP) is a promising evolutionary machine learning technique for image classification, known for its ability to evolve flexible, effective, and interpretable models. However, the high computational cost of fitness evaluations in evolutionary learning restricts its practical applications. While Surrogate models offer efficient approximations for costly fitness evaluations, their application in GP-based image classification remains in its early stages, facing challenges such as handing flexible tree-based representations with variable lengths, designing an effective surrogate, and the limited performance of a single surrogate across various image classification tasks. To address these issues, this paper proposes an ensemble surrogate-assisted GP approach to image classification. The new approach constructs one global surrogate model to explore broad areas and three local surrogate models within specific subspaces to exploit local regions, enabling more accurate predictions of GP individuals’ fitness. Moreover, a dynamic weighting strategy is developed to assign different weights to the base surrogate models in the ensemble, improving prediction accuracy. Additionally, the proposed approach refines the surrogate training set1 construction method, previously limited to single-tree GP, enabling it to accelerate both single-tree and multi-tree GP 2 for image classification. Experimental results on five datasets of varying difficulty demonstrate that the new ensemble surrogate method significantly reduces the number of expensive fitness evaluations of both single-tree and multi-tree GP-based image classification methods while achieving competitive performance. The comparisons with other state-of-the-art methods also confirm its effectiveness.},
  keywords={Image classification;Computational modeling;Training;Feature extraction;Computational efficiency;Predictive models;Optimization;Evolutionary computation;Biological system modeling;Accuracy;Image Classification;Genetic Programming;Fitness Evaluations;Surrogate Models;Ensemble},
  doi={10.1109/TEVC.2025.3569832},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10730057,
  author={Prajapati, Yogendra Narayan and Baloni, Dev},
  booktitle={2024 1st International Conference on Advanced Computing and Emerging Technologies (ACET)}, 
  title={Detailed Explanation: Optimizing COVID-19 CT-Scan Classification with Feature Engineering and Genetic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research delves into the optimization of a genetic algorithm for the categorization of COVID-19 CT scan images through the amalgamation of a high-level grayscale cooccurrence matrix (GCLM) elimination technique, color consistency vector (CCV), and discrete wavelet transform (DWT). The primary objective of this combination is to enhance the discriminatory capabilities of specific criteria, thereby elevating the precision of the machine learning model. Specifically, the crafting of the classification was executed through Fisher-KNN (F-KNN), linear support vector machine (L-SVM), and the Fisher visual decision tree (F-Tree).Genetic algorithms were employed for targeted selection to amplify the efficiency of these models in accurately identifying COVID-19 samples within CT images. The outcomes of this investigation offer valuable insights for continuous endeavors aimed at enhancing COVID-19 diagnostics by integrating architecture, genetic algorithms, and machine learning models. Notably, among the proposed methodologies, the fuzzy tree classifier achieved an impressive accuracy of 93.55%, while alternative classifiers such as Naive Bayes, L-SVM, and F-KNN attained accuracies of 92.6%, 92.12%, and 92.33% respectively. This research underscores the significance of leveraging advanced computational techniques in the field of medical imaging for improved disease detection and classification. The fusion of genetic algorithms with machine learning frameworks unveils an exciting pathway to boost the precision and effectiveness of COVID-19 detection via CT imaging. The results of this research play a significant role in the evolving conversation surrounding the incorporation of cutting-edge technologies in the medical field, aiming for enhanced disease control and accurate diagnosis.},
  keywords={COVID-19;Machine learning algorithms;Accuracy;Computed tomography;Data models;Discrete wavelet transforms;Random forests;Optimization;Genetic algorithms;Diseases;Machine learning model;Genetic Algorithms-KNN;L-SVM;GCLM;CCV;DWT;Genetic Algorithms},
  doi={10.1109/ACET61898.2024.10730057},
  ISSN={},
  month={Aug},}@ARTICLE{10698776,
  author={Nie, Ying and Chai, Zheng-Yi and Lu, Li and Li, Ya-Lun},
  journal={IEEE Internet of Things Journal}, 
  title={Task Offloading in Edge Computing: An Evolutionary Algorithm With Multimodel Online Prediction}, 
  year={2025},
  volume={12},
  number={3},
  pages={2347-2358},
  abstract={With the rapid development of Internet of Things (IoT) technology, the number of IoT devices has increased dramatically and a large amount of data has been generated. In order to further reduce the resource cost required for task offloading, it is necessary to design task offloading methods with high-energy efficiency and low latency. Considering the correlation between task offloading process and time in real-time interactive scenarios, we propose an evolutionary algorithm (EA) framework with online load prediction based on CNN-GRU hybrid model and channel attention mechanism (AM). In the model construction stage, we first combined convolutional neural network (CNN) and gated recurrent unit (GRU) to learn the features and patterns of historical data. In order to reduce the loss of historical information, the channel AM is introduced into the CNN-GRU model to enhance the influence of important features between information. In the model training stage, the optimal individual training model generated by the EA is used to further optimize the training accuracy and training effect of CNN-GRU-AM. In the test phase, the optimized CNN-GRU-AM network is used to predict the task load online and dynamically allocate computing resources while training the model online iteratively, which further reduces the delay and energy consumption of the task and improves the offloading performance of the system. The simulation results show that the proposed algorithm effectively reduces the system delay and the overall energy consumption.},
  keywords={Computational modeling;Delays;Predictive models;Convolutional neural networks;Mathematical models;Prediction algorithms;Internet of Things;Training;Energy consumption;Edge computing;Evolutionary algorithm (EA);hybrid neural network;prediction;resource allocation;task offloading},
  doi={10.1109/JIOT.2024.3459019},
  ISSN={2327-4662},
  month={Feb},}@ARTICLE{10915596,
  author={Liu, Mengya and Cheng, Xu and Cao, Yu and Zhou, Qian},
  journal={IEEE Access}, 
  title={Blueberry Remaining Shelf-Life Prediction Based on the PSO-CNN-BiLSTM-MHA Model}, 
  year={2025},
  volume={13},
  number={},
  pages={43238-43248},
  abstract={Remaining shelf-life prediction of blueberries is crucial in reducing economic losses and enhancing market competitiveness. To meet the demand for high accuracy in predicting the remaining shelf-life of blueberries, this paper proposes a fusion model (PSO-CNN-BiLSTM-MHA) that combines Particle Swarm Optimization (PSO), Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory network (BiLSTM), and Multi-Head Attention (MHA) mechanisms for predicting the remaining shelf-life of ‘Emerald’ blueberries under two temperature conditions,  $4^{\circ } \text {C}$  and  $25^{\circ } \text {C}$ . In this study, seven key features were selected from fifteen quality indicators of blueberries using the embedded method, and the PSO algorithm was used to determine the optimal hyperparameter combination of the model, which effectively improved its prediction performance. The experimental results show that our model outperforms other models in all evaluation metrics under both temperature conditions and demonstrates excellent prediction ability and stability. This study provides an effective technical approach for the accurate prediction of the remaining shelf-life of blueberries and other fruits.},
  keywords={Predictive models;Data models;Feature extraction;Accuracy;Kinetic theory;Convolutional neural networks;Time series analysis;Prediction algorithms;Data mining;Deep learning;Bidirectional long short-term memory network;convolutional neural network;multi-head attention mechanisms;particle swarm optimization;remaining shelf-life prediction},
  doi={10.1109/ACCESS.2025.3548720},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10421455,
  author={Hussein, Abbas Hameed Abdul and Adnan, Myasar Mundher and Hemalatha, K.L and Malathy, V. and Rajesh, N},
  booktitle={2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Coordinate Attention Mechanism with Convolutional Neural Network for Tomato Leaf Diseases}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The tomatoes are worldwide grown important vegetable and taken as economic pillar of several states. Although, plants are susceptible to diversity of weakness which minimize and affect generation of healthy plant, made accurate and initial identification of this disease is challenging. By using of cutting-edge and computer vision gives a solution of this problems. In this research, the Coordinate Attention Mechanism (CAM) with Convolutional Neural Network (CNN) is proposed for detecting tomato leaf disease. The dataset utilized for the research is plant village dataset and data pre-processing are performed. The detection and classification of tomato leaf disease is performed by proposed CAM with CNN method. The proposed method is evaluated with performance measures of accuracy (%), precision (%), recall (%) and f1-score (%). The proposed method attained huge accuracy of 99.98%, precision of 99.45% and recall of 99.53% which is superior than other existing methods like Convolutional Neural Network (CNN), Multinomial Logistic Regression (MLR), CNN based Genetic Algorithm (GA) and Faster Region based Convolutional Neural Network (Faster-RCNN).},
  keywords={Training;Economics;Logistic regression;Computer vision;Convolutional neural networks;Diseases;Genetic algorithms;Coordinate Attention Mechanism;Convolutional Neural Network;Computer Vision;Plant Village and Tomato Leaf Disease},
  doi={10.1109/ICIICS59993.2023.10421455},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10431564,
  author={Hu, Sihao and Huang, Tiansheng and İlhan, Fatih and Tekin, Selim Furkan and Liu, Ling},
  booktitle={2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)}, 
  title={Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives}, 
  year={2023},
  volume={},
  number={},
  pages={297-306},
  abstract={This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing Large Language Models (LLMs) such as GPT-4 to dig out vulnerabilities within smart contracts based on our ongoing research. For the task of smart contract vulnerability detection, achieving practical usability hinges on identifying as many true vulnerabilities as possible while minimizing the number of false positives. Nonetheless, our empirical study reveals contradictory yet interesting findings: generating more answers with higher randomness largely boosts the likelihood of producing a correct answer but inevitably leads to a higher number of false positives. To mitigate this tension, we propose an adversarial framework dubbed GPTLENS that breaks the conventional one-stage detection into two synergistic stages - generation and discrimination, for progressive detection and refinement, wherein the LLM plays dual roles, i.e., AUDITOR and CRITIC, respectively. The goal of AUDITOR is to yield a broad spectrum of vulnerabilities with the hope of encompassing the correct answer, whereas the goal of CRITIC that evaluates the validity of identified vulnerabilities is to minimize the number of false positives. Experimental results and illustrative examples demonstrate that AUDITOR and CRITIC work together harmoniously to yield pronounced improvements over the conventional one-stage detection. GPTLENS is intuitive, strategic, and entirely LLM-driven without relying on specialist expertise in smart contracts, showcasing its methodical generality and potential to detect a broad spectrum of vulnerabilities. Our code is available at: https://github.com/git-disl/GPTLens.},
  keywords={Analytical models;Systematics;Smart contracts;Cognition;Security;Usability;Task analysis;Large language model;GPT;smart contract;vulnerability detection},
  doi={10.1109/TPS-ISA58951.2023.00044},
  ISSN={},
  month={Nov},}@ARTICLE{10614890,
  author={Namakshenas, Danyal and Yazdinejad, Abbas and Dehghantanha, Ali and Parizi, Reza M. and Srivastava, Gautam},
  journal={IEEE Transactions on Industrial Cyber-Physical Systems}, 
  title={IP2FL: Interpretation-Based Privacy-Preserving Federated Learning for Industrial Cyber-Physical Systems}, 
  year={2024},
  volume={2},
  number={},
  pages={321-330},
  abstract={The expansion of Industrial Cyber-Physical Systems (ICPS) has introduced new challenges in security and privacy, highlighting a research gap in effective anomaly detection while preserving data confidentiality. In the ICPS landscape, where vast amounts of sensitive industrial data are exchanged, ensuring privacy is not just a regulatory compliance issue but a critical shield against industrial espionage and cyber threats. Existing solutions often compromise data privacy for enhanced security, leaving a significant void in protecting sensitive information within ICPS networks. Addressing this, our research presents the IP2FL model, an Interpretation-based Privacy-Preserving Federated Learning approach tailored for ICPS. This model combines Additive Homomorphic Encryption (AHE) for privacy with advanced feature selection methods and Shapley Values (SV) for enhanced explainability. The proposed solution mitigates privacy concerns in federated learning, where traditional methods fall short due to computational constraints and lack of interpretability. By integrating AHE, the IP2FL model minimizes computational overhead and ensures data privacy. Our dual feature selection approach optimizes system performance while incorporating SV to provide critical insights into model decisions, advancing the field towards more transparent and understandable AI systems in ICPS. The validation of our model using ICPS-specific datasets demonstrates its effectiveness and potential for practical applications.},
  keywords={Computational modeling;Privacy;Data models;Security;Data privacy;Cyber-physical systems;Federated learning;Machine learning;Cyber-physical systems;Industrial engineering;Federated learning;ICPS;interpretable ML;privacy-preserving},
  doi={10.1109/TICPS.2024.3435178},
  ISSN={2832-7004},
  month={},}@INPROCEEDINGS{9870280,
  author={Moravvej, Seyed Vahid and Mousavirad, Seyed Jalaleddin and Oliva, Diego and Schaefer, Gerald and Sobhaninia, Zahra},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={An Improved DE Algorithm to Optimise the Learning Process of a BERT-based Plagiarism Detection Model}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Plagiarism detection is a challenging task, aiming to identify similar items in two documents. In this paper, we present a novel approach to automatic plagiarism detection that combines BERT (bidirectional encoder representations from transformers) word embedding, attention mechanism-based long short-term memory (LSTM) networks, and an improved differential evolution (DE) algorithm for weight initialisation. BERT is used to pretrain deep bidirectional representations in all layers, while the pre-trained BERT model can be fine-tuned with only one extra output layer without significant changes in architecture. Deep learning algorithms often use the random weighting method for initialisation, followed by gradient-based optimisation algorithms such as back-propagation for training, making them susceptible to getting trapped in local optima. To address this, population- based metaheuristic algorithms such as DE can be used. We propose an improved DE algorithm with a clustering-based mutation operator, where first a winning cluster of candidate solutions is identified and a new updating strategy is then applied to include new candidate solutions in the current population. The proposed DE algorithm is used in LSTM, attention mechanism, and feed- forward neural networks to yield the initial seeds for subsequent gradient-based optimisation. We compare our proposed model with conventional and population-based approaches on three datasets (SNLI, MSRP and SemEval2014) and demonstrate it to give superior plagiarism detection performance.},
  keywords={Deep learning;Training;Plagiarism;Bit error rate;Sociology;Neural networks;Clustering algorithms;Plagiarism detection;BERT;LSTM;attention mechanism;differential evolution},
  doi={10.1109/CEC55065.2022.9870280},
  ISSN={},
  month={July},}@INPROCEEDINGS{10431591,
  author={Wang, Huanjing and Liang, Qianxin and Hancock, John T. and Khoshgoftaar, Taghi M.},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={A Comparative Study of Model-Agnostic and Importance-Based Feature Selection Approaches}, 
  year={2023},
  volume={},
  number={},
  pages={75-82},
  abstract={In the context of high-dimensional credit card fraud data, feature selection techniques are commonly employed by researchers and practitioners to enhance the performance of credit card fraud detection models. This study presents a comparison in model performance using the most important features selected by SHAP (SHapley Additive exPlanations) values and the model's built-in feature importance list. Both methods rank features and select the most important features for model evaluation. The performance of these feature selection techniques is assessed by building classification models using two classifiers: XGBoost and Decision Tree. The evaluation metric used to measure effectiveness is the Area under the Precision-Recall Curve (AUPRC). All experiments are conducted on the Credit Card Fraud Detection Dataset from Kaggle. The experimental results and z-tests demon-strate that, in most cases, there is no significant difference between the two feature selection methods, regardless of the feature subset size and classifier used. However, for models trained on larger datasets, it is suggested to use the model's built-in feature importance list as the preferred feature selection method over SHAP. The rationale behind this recommendation is that computing SHAP feature importance is a separate activity, and models provide feature importance as a side-effect of training, thus requiring no extra effort. Therefore, opting for the model's built-in feature importance list can offer a more efficient and manageable approach for larger datasets and more complex models.},
  keywords={Training;Computational modeling;Machine learning;Feature extraction;Credit cards;Fraud;Machine intelligence;Credit Card Fraud;Feature Selection;SHAP;Feature Importance},
  doi={10.1109/CogMI58952.2023.00020},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10528577,
  author={Zhao, Shuxian},
  booktitle={2023 7th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Implementation of Intelligent Grasping of Intelligent Robot Based on Graph Attention Mechanism}, 
  year={2023},
  volume={},
  number={},
  pages={697-701},
  abstract={To solve the problem of low accuracy of traditional robots in perceiving and grasping objects, a GA-PointNet++intelligent grasping robot based on graph attention mechanism and deep learning network architecture is designed. Firstly, binocular vision was utilized to collect the point cloud information of the target objects. Then, the 3D perception algorithm was used to process 3D reconstruction information, and the processing results were transmitted to the intelligent robot. Finally, GA-PointNet++ network model was used to locate and grasp the 3D reconstruction information. The results show that the average classification accuracy and overall accuracy of the proposed model are 88.8% and 91.3%, respectively, which are higher than those of the traditional VoxNet network, PointNet network and PointNet++ network models. Moreover, the grasping success rate of the intelligent robot based on GA-PointNet++ network model is up to 96.7%, and the grasping accuracy is significantly improved. Therefore, the model can effectively improve the grasping accuracy of intelligent robots, and its grasping effect is remarkable.},
  keywords={Deep learning;Point cloud compression;Solid modeling;Three-dimensional displays;Target recognition;Grasping;Network architecture;graph attention mechanism;binocular vision;intelligent robot;GA-Point++;intelligent grasping},
  doi={10.1109/ACAIT60137.2023.10528577},
  ISSN={},
  month={Nov},}@ARTICLE{10753588,
  author={Rivera-López, Rafael and Ceballos, Hector G.},
  journal={IEEE Access}, 
  title={A Differential-Evolution-Based Approach to Extract Univariate Decision Trees From Black-Box Models Using Tabular Data}, 
  year={2024},
  volume={12},
  number={},
  pages={169850-169868},
  abstract={The growing demand for complex machine learning models has increased the use of black-box models, such as random forests and artificial neural networks, posing significant challenges regarding explainability and interpretability. This manuscript addresses the critical problem of understanding and interpreting decisions from these opaque models, as a lack of interpretability can hinder their adoption in sensitive applications. To tackle this issue, we propose an evolutionary approach to induce univariate decision trees that accurately mimic the behavior of black-box models using tabular data. Our method employs two differential evolution algorithm variants, focusing on building univariate decision trees to enhance model explainability. Key contributions of this work include the development of a fitness function that balances accuracy with tree compactness to reduce overfitting and improve explanability. Additionally, we introduce a novel selection scheme that evaluates candidate solutions using synthetic instances, further enhancing the robustness against variance of the decision trees. Experimental results demonstrate that the proposed approach yields more precise and compact decision trees than traditional methods, significantly improving the explainability of complex machine learning models.},
  keywords={Computational modeling;Closed box;Focusing;Artificial neural networks;Data models;Robustness;Decision trees;Data mining;Random forests;Overfitting;Agnostic model;explainable artificial intelligence;evolutionary computation;decision trees},
  doi={10.1109/ACCESS.2024.3498907},
  ISSN={2169-3536},
  month={},}@ARTICLE{9906532,
  author={Alwarthan, Sarah and Aslam, Nida and Khan, Irfan Ullah},
  journal={IEEE Access}, 
  title={An Explainable Model for Identifying At-Risk Student at Higher Education}, 
  year={2022},
  volume={10},
  number={},
  pages={107649-107668},
  abstract={Nowadays, researchers from various fields have shown great interest in improving the quality of learning in educational institutes in order to improve student achievement and learning outcomes. The main objective of this study was to predict the at-risk student of failing the preparatory year at an early stage. This study applies several educational data mining algorithms including RF, ANN, and SVM to build three classification models to meet the objectives of this study. Moreover, different features selection methods namely RFE, and GA have been examined to find the best subset of the highest influential features. Furthermore, several sampling approaches are applied to balance the dataset used in this study, including SMOTE, and SMOTE-Tomek Link. Three datasets related to the preparatory year student from the humanities track at IAU were used in this study. The collected datasets are imbalanced datasets, SMOTE-Tomek Link technique has been used to balance the three proposed datasets. The results showed that RF outperformed other techniques as it records the highest performance for building the models. Moreover, RFE with Mutual Information finds the best subset of features to build the first model. Finally, this study not only developed several classification models to identify at-risk students, but it also went a step further by employing XAI techniques such as LIME, SHAP, and the global surrogate model to explain the proposed prediction models, explaining the output and highlighting the reasons for the student failure.},
  keywords={Predictive models;Data mining;Data models;Computational modeling;Radio frequency;Classification algorithms;Artificial neural networks;Random forests;Education;Identification of persons;Educational data mining;identifying at-risk student;LIME;preparatory year;random forest;SHAP},
  doi={10.1109/ACCESS.2022.3211070},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10647812,
  author={Saini, Abhishek and Moazeni, Sajjad},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={Accelerating Cascade Classifier Training with Genetic Algorithms for Edge ML Applications}, 
  year={2024},
  volume={},
  number={},
  pages={589-595},
  abstract={Object detection is a crucial task in computer vision with applications spanning from face recognition to autonomous driving. While today’s CNN-based methods have shown great success for this aim, their relatively large model size and computational complexity limit their use for edge devices such as micro-controllers. On the other hand, the Viola-Jones algorithm has long been a cornerstone in this field, offering robustness and accuracy. This algorithm can be more compact than even compressed CNN models. However, as datasets and feature spaces grow, the computational demands of training an Adaboost classifier can become prohibitively high. This can be a bottleneck where training of the model needs to also be performed at the edge for cost and privacy reasons. In this paper, we present an innovative approach to address this challenge by incorporating Genetic Algorithms (GA) and LightGBM into the Adaboost framework for efficient feature selection, reducing training time by a factor of $50 \times$ without sacrificing accuracy. Additionally, our model exhibits a significantly lower memory footprint, with a size of 20 kB compared to a compressed CNN-based YOLOX architecture with a model size of 314 kB. This makes our approach particularly suitable for detection in edge devices and TinyML community.},
  keywords={Training;Deep learning;Accuracy;Image edge detection;Computational modeling;Object detection;Feature extraction;Object Detection;Genetic Algorithm;Cascade Classifier;Viola-Jones Algorithm;Edge ML},
  doi={10.1109/ICIP51287.2024.10647812},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{9521243,
  author={Zhang, Yong and Wang, Yan-Hu and Gong, Dun-Wei and Sun, Xiao-Yan},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Clustering-Guided Particle Swarm Feature Selection Algorithm for High-Dimensional Imbalanced Data With Missing Values}, 
  year={2022},
  volume={26},
  number={4},
  pages={616-630},
  abstract={Feature selection (FS) in data with class imbalance or missing values has received much attention from researchers due to their universality in real-world applications. However, for data with both the two characteristics above, there is still a lack of the corresponding FS algorithm. Due to the complex coupling relationship between missing data and class imbalance, the need for better FS method becomes essential. To tackle high-dimensional imbalanced data with missing values, this article studies a new evolutionary FS method. First, an improved  $F$ -measure based on filling risk (RF-measure) is defined to evaluate the influence of missing data on the performance of FS in the case of class imbalance. Following that taking the RF-measure as an objective function, a particle swarm optimization-based FS method with fuzzy clustering (PSOFS-FC) is proposed. Two new problem-specific operators or strategies, i.e., the swarm initialization strategy guided by fuzzy clustering and the local pruning operator based on feature importance, are developed to improve the performance of PSOFS-FC. Compared with state-of-the-art FS algorithms on several public datasets, experimental results show that PSOFS-FC can achieve excellent classification performance with relatively less running time, indicating its superiority on tackling high-dimensional imbalanced data with missing values.},
  keywords={Clustering algorithms;Feature extraction;Particle swarm optimization;Mutual information;Search problems;Computational efficiency;Sun;Class imbalance;feature selection (FS);fuzzy clustering;missing value;particle swarm optimization (PSO)},
  doi={10.1109/TEVC.2021.3106975},
  ISSN={1941-0026},
  month={Aug},}@ARTICLE{10584528,
  author={Lee, Sanghoon and Aminul Islam, Kazi and Chandana Koganti, Sai and Yaganti, Varshini and Ramya Sri Mamillapalli, Sai and Vitalos, Hannah and Williamson, Drew F. K.},
  journal={IEEE Access}, 
  title={SN-FPN: Self-Attention Nested Feature Pyramid Network for Digital Pathology Image Segmentation}, 
  year={2024},
  volume={12},
  number={},
  pages={92764-92773},
  abstract={Digital pathology has played a key role in replacing glass slides with digital images, enhancing various pathology workflows. Whole slide images are digitized pathological images improving the capabilities of digital pathology and contributing to the overall turnaround time for diagnoses. The digitized images have been successfully integrated with artificial intelligence algorithms assisting pathologists in many tasks, but there are still demands to develop a new algorithm for a better diagnosis process. In this paper, we propose a new deep convolutional neural network model integrating a feature pyramid network with a self-attention mechanism in three pathways: encoder, decoder, and self-attention nested for providing accurate tumor region segmentation on whole slide images. The encoder pathway adopts ResNet50 architecture for the bottom-up network. The decoder pathway adopts the feature pyramid network for the top-down network. The self-attention nested pathway forms the attention map represented by the distribution of attention scores focusing on localizing tumor regions and avoiding irrelevant information. The results of our experiment show that the proposed model outperforms the state-of-the-art deep convolutional neural network models in terms of tumor and stromal region segmentation. Moreover, various encoder networks were equipped with the proposed model and compared with each other. The results indicate that the ResNet series using the proposed model outperforms other encoder networks.},
  keywords={Image segmentation;Feature extraction;Pathology;Decoding;Object detection;Image color analysis;Computational modeling;Personal digital devices;Digital pathology images;deep learning;encoder;decoder;image segmentation},
  doi={10.1109/ACCESS.2024.3423701},
  ISSN={2169-3536},
  month={},}@ARTICLE{10705308,
  author={Jim, Abdullah Al Jaid and Rafi, Ibrahim and Tiang, Jun Jiat and Biswas, Uzzal and Nahid, Abdullah-Al},
  journal={IEEE Access}, 
  title={KUNet-An Optimized AI Based Bengali Sign Language Translator for Hearing Impaired and Non Verbal People}, 
  year={2024},
  volume={12},
  number={},
  pages={155052-155063},
  abstract={Sign language is the most prevalent form of communication among people with speech and hearing disabilities. The most widely used types of sign language involve the creation of static or dynamic gestures using hand(s). Among many sign languages, Bengali Sign Language (BdSL) is one of the most complicated sign languages to learn and comprehend because of its enormous alphabet, vocabulary, and variation in expression techniques. Existing solutions include learning BdSL or hiring an interpreter. Besides, BdSL interpreter support is hard to come by and expensive (if not voluntary). Disabled people might find it more comfortable to converse with generals implementing machine translation of sign language. Deep learning that mimics the human brain, a subset of the machine learning domain, seems to be a viable solution. For the hearing impaired and non verbal community, computer vision, in particular, may hold the key to finding a solution. Therefore, we have created a novel model, KUNet (“Khulna University Network” a CNN based model), a classification framework optimized by the genetic algorithm (GA), has been proposed to classify BdSL. This model and the dataset contribute to creating a BdSL machine translator. GA-optimized KUNet acquired an accuracy of 99.11% on KU-BdSL. After training the model on KU-BdSL, we demonstrated a comparison of the model with state-of-the-art studies and interpreted the black-box nature of the model using explainable AI (XAI). Additionally, we have found that our model outperformed several well-known models trained on the KU-BdSL dataset. This study will benefit the hearing impaired and non verbal community by allowing them to communicate effortlessly and minimizing their hardship.},
  keywords={Sign language;Accuracy;Computational modeling;Support vector machines;Genetic algorithms;Image recognition;Feature extraction;Databases;Assistive technologies;Zero shot learning;Deep learning;Machine learning;Bengali sign language (BdSL);classification;computer vision;deep learning;machine learning;sign language recognition},
  doi={10.1109/ACCESS.2024.3474011},
  ISSN={2169-3536},
  month={},}@ARTICLE{9142403,
  author={Chen, Qi and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Cybernetics}, 
  title={Rademacher Complexity for Enhancing the Generalization of Genetic Programming for Symbolic Regression}, 
  year={2022},
  volume={52},
  number={4},
  pages={2382-2395},
  abstract={Model complexity has a close relationship with the generalization ability and the interpretability of the learned models. Simple models are more likely to generalize well and easy to interpret. However, too much emphasis on minimizing complexity can prevent the discovery of more complex yet more accurate solutions. Genetic programming (GP) has a trend of generating overcomplex models that are difficult to interpret while not being able to generalize well. This work proposes a novel complexity measure based on the Rademacher complexity for GP for symbolic regression. The complexity of an evolved model is measured by the maximum correlation between the model and the Rademacher variables on the selected training instances. Taking minimizing the training error and the Rademacher complexity of the models as the two objectives, the proposed GP method has shown to be much superior to the standard GP on generalization performance. Compared with GP equipped with two state-of-the-art complexity measures, the proposed method still has a notable advance on generating a better front consisting of individuals with lower generalization errors and being simpler in the behavioral complexity. Further analyses reveal that compared with the state-of-the-art methods, the proposed GP method evolves models that are much closer to the target models in the model structure, and have better interpretability.},
  keywords={Complexity theory;Predictive models;Mathematical model;Training;Data models;Genetic programming;Measurement uncertainty;Generalization;genetic programming (GP);Rademacher complexity},
  doi={10.1109/TCYB.2020.3004361},
  ISSN={2168-2275},
  month={April},}@INPROCEEDINGS{10485683,
  author={Sen, Anuvab and Roy, Subhabrata and Debnath, Ariv and Jha, Gourav and Ghosh, Rahul},
  booktitle={2024 National Conference on Communications (NCC)}, 
  title={DE-ViT: State-Of-The-Art Vision Transformer Model for Early Detection of Alzheimer's Disease}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={A number of life threatening neuro-degenerative disorders had degraded the quality of life for the older generation in particular. Dementia is one such symptom which may lead to a severe condition called Alzheimer's disease if not detected at an early stage. It has been reported that the progression of such disease from a normal stage is due to the change in several parameters inside the human brain. In this paper, a novel DE-ViT model has been proposed for the identification of dementia at different stage. A sizeable number of test data have been utilized for the validation of the proposed scheme. It has also been demonstrated that our model exhibits superior performance in terms of accuracy, precision, recall as well as F1-score.},
  keywords={Neurological diseases;Metaheuristics;Transformers;Brain modeling;Alzheimer's disease;ADNI;alzheimer's disease;differential evolution;healthy control;mild cognitive impairment;multilayer perception;vision transformer},
  doi={10.1109/NCC60321.2024.10485683},
  ISSN={2993-2645},
  month={Feb},}@INPROCEEDINGS{10930010,
  author={Jeon, Yeong-Eun and Hwangbo, Minseo and Heo, Minyoung and Kim, Ho-Jung and Son, Ga-Hyun and Won, Dong-Ok},
  booktitle={2025 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={A Multi-CAM Based Robust Interpretations Framework in Medical Image Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-3},
  abstract={Recently, methods for interpreting the decision of deep learning models have been actively used in medical imaging. Still, some studies provide interpretations based solely on a singular method, such as GradCAM. This approach has the limitation to reduce reliability by providing only fragmentary information about model predictions. In this study, we propose a framework that multi-interpretations of model results to improve the reliability of deep learning based diagnostic assistance systems. We combined several CAM based methods and deep learning model and analyzed the differences in interpretation based on the CAM methods. The results show that the same image has different interpretations depending on the CAM, which means that multiple interpretations through a combination of appropriate CAM and deep learning models are essential. Consequently, the proposed framework can improve diagnostic reliability and increase the usability of AI-based diagnostic assistance systems by providing multiple interpretations of model predictions.},
  keywords={Deep learning;Analytical models;Electric potential;Image analysis;Predictive models;Transformers;Reliability;Usability;Medical diagnostic imaging;Consumer electronics;Deep learning;eXplainable AI(XAI);Medical Imaging},
  doi={10.1109/ICCE63647.2025.10930010},
  ISSN={2158-4001},
  month={Jan},}@ARTICLE{10121456,
  author={Oh, Sanghoun and Ahn, Chang Wook},
  journal={IEEE Access}, 
  title={Evolutionary Approach for Interpretable Feature Selection Algorithm in Manufacturing Industry}, 
  year={2023},
  volume={11},
  number={},
  pages={46604-46614},
  abstract={Feature selection techniques in prediction play a role in manufacturing industries of late. However, it is very challenging to achieve an optimal subset of features as well as interpretable relationship among features due to computation complexity and variable diversity. In order to address those difficulties, this paper presents a novel evolutionary approach for feature selection algorithm to improve the effectiveness of existing meta-heuristic approaches. In other words, their optimal combinations with minimal difference between prediction and actual values can be achieved by applying an estimation of distribution algorithms (i.e., extended compact genetic algorithm) on the collected candidate feature sets. The approach discovers a less complicated and more closely related probabilistic-model structure on population space in each generation, thereby encouraging the comprehension power of feature selection results. We tested our method on six real-world data sets from manufacturing industries (open to the public). It demonstrated that higher interpretability on features selection results is achieved in comparison with well-known methods.},
  keywords={Feature extraction;Statistics;Sociology;Metaheuristics;Classification algorithms;Genetic algorithms;Prediction algorithms;Evolutionary computation;Evolutionary-based approach;feature selection;extended compact genetic algorithm;manufacturing industries},
  doi={10.1109/ACCESS.2023.3274490},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9761034,
  author={Pahurkar, Archana and Deshmukh, Ravindra},
  booktitle={2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={PDMBM: Design of a High-Efficiency Plant Disease Classification Method using Multiparametric Bio Inspired Modelling}, 
  year={2022},
  volume={},
  number={},
  pages={1607-1615},
  abstract={A wide variety of machine learning and deep learning models are proposed by researchers, which assist in effective plant segmentation, feature extraction & selection, disease classification and post-processing operations. But these models are designed for disease-specific applications, which limits their scalability & performance when applied to larger plant datasets. To improve this scalability, a novel two stage bioinspired model that assists in high-efficiency feature selection & classifier selection is proposed in this text. To reduce these redundancies, a particle swarm optimization (PSO) model is applied to the feature set. This model aims at inter-class feature variance maximization, and intra-class feature variance minimization, which assists in high-density feature selection & control. The selected features are given to an ensemble classification layer, which is controlled via a customized Genetic Algorithm (GA) model. This model selects optimum configuration of support vector machine (SVM), logistic regression (LR), Naïve Bayes (NB), and random forest (RF) classifiers for the given dataset. These configurations are initialized from the training set, and then fine-tuned via cross-validation operations. Due to combination of PSO & GA for feature selection & classification, the proposed model is able to identify diseases from Maize, Wheat, Rice, Cotton, and Apple plants, which assists in deploying it for large-scale disease detection scenarios. It was also observed that the proposed model was capable of reducing the delay needed for classification by 8.3% when compared with various state-of-the-art methods. This delay reduction was possible due to use of PSO, that assists in high-efficiency feature reduction across multiple datasets.},
  keywords={Support vector machines;Deep learning;Biological system modeling;Computational modeling;Scalability;Feature extraction;Delays;component;Plant;disease;classification;bioinspired;multiple;GA;PSO;SVM;LR;NB;RF;feature;selection;validation;saliency;features},
  doi={10.1109/ICSCDS53736.2022.9761034},
  ISSN={},
  month={April},}@INPROCEEDINGS{10612166,
  author={Tianrungroj, Yossathorn and Iba, Hitoshi},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={ROIL: Rule Optimization via Large Language Model for Imitation Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Recent improvements in pretrained Large Language Models (LLMs) have demonstrated increasing capabilities in various natural language processing tasks, such as instruction following. However, effectively utilizing LLMs in interactive environments that require advanced reasoning, planning, and decision-making skills remains a challenge. In this study, we integrate Learning Classifier Systems (LCS) with LLMs, thereby extending their capabilities to interact in natural language domains. To accommodate the integration, especially the rule represented in natural language, we propose a novel Rule Optimization method using LLMs for Imitation Learning (ROIL) in text-based interactive environments. ROIL addresses rule learning by lever-aging LLMs to optimize rules based on human demonstrations, thus eliminating the need for trial-and-error learning processes and ensuring both interpretability and safety. It also tackles the challenge of learning transferable skills in these environments. We evaluate the efficacy of ROIL in the WebShop environment, a text-based e-commerce website navigation problem. The method achieved a significant performance and efficiency improvement over a strong baseline, while demonstrating performance close to a gradient-based imitation learning approach. Additionally, this study explores the enhancement of ROIL using meta-heuristic optimization algorithms, providing foundational research for further investigation in this area.},
  keywords={Imitation learning;Large language models;Decision making;Optimization methods;Evolutionary computation;Safety;Classification algorithms;Prompt Optimization;Large Language Model;Imitation Learning;Learning Classifier System},
  doi={10.1109/CEC60901.2024.10612166},
  ISSN={},
  month={June},}@INPROCEEDINGS{11043089,
  author={Zhang, Hengzhe and Chen, Qi and Xue, Bing and Banzhaf, Wolfgang and Zhang, Mengjie},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A General Feature-Informed Crossover for Two-Stage Feature Selection in Symbolic Regression}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Genetic programming-based symbolic regression is a widely used machine learning technique, but its effectiveness can be limited as the number of input features increases. In genetic programming, two-stage feature selection has been extensively applied to enhance performance when dealing with a large number of input features. Existing two-stage feature selection methods typically require reinitializing new GP trees based on the selected features after feature selection, which disrupts the building blocks accumulated during evolution. In this paper, we propose a crossover operator that is aware of the selected features to leverage the feature selection results, thereby bypassing the need for reinitialization. This operator guides the crossover process to prioritize selected features, gradually eliminating unimportant features while preserving evolved building blocks. Experimental results validate the proposed method across three different feature-selection mechanisms on 98 datasets, demonstrating its effectiveness and broad applicability across various feature-selection strategies.},
  keywords={Training;Genetic programming;Machine learning;Evolutionary computation;Feature extraction;Iterative methods;Symbolic Regression;Feature Selection;Genetic Programming},
  doi={10.1109/CEC65147.2025.11043089},
  ISSN={},
  month={June},}@INPROCEEDINGS{10865411,
  author={Gong, Jixiang and Pei, Laifan and Zhou, Xian and Chen, Shuo and Li, Jicheng and Wang, Chao and Zhao, Man and Li, Hui and Cai, Zhihua},
  booktitle={2024 China Automation Congress (CAC)}, 
  title={Multi-Target Round-Up Allocation Strategy for Unmanned Aerial Vehicle Swarm Based on Improved Adaptive Genetic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={68-75},
  abstract={Aiming at the multi-target round-up allocation for unmanned aerial vehicle (UAV) swarms, this paper proposes a multi-target round-up allocation strategy for UAV swarms based on an improved adaptive genetic algorithm. Firstly, to accelerate the convergence of the genetic algorithm and inhibit the “early maturity” to maintain the diversity of the population, the genetic algorithm was improved by combining the evolutionary stage, individual fitness value, and individual similarity. Secondly, based on the improved genetic algorithm, multiple independent round-up teams are generated by considering the three elements of total distance traveled, completion rate, and success rate. Thirdly, the Hungarian algorithm is used to allocate the round-up points within the round-up teams, and the correspondence between UAV and round-up points is established with the goal of the shortest total distance traveled by the teams so that each UAV only needs to arrive at the corresponding round-up point to complete the multi-target round-up task. Simulation results show that the adaptation value of the proposed round-up allocation strategy is 16.77% and 22.78% higher than that of the IAGA algorithm and the TAGA algorithm respectively, and the superiority of the proposed round-up allocation strategy is verified in the simulation experiments of two application scenarios.},
  keywords={Simulation;Diversity reception;Autonomous aerial vehicles;Market research;Regulation;Resource management;Genetic algorithms;Convergence;Payloads;Meteorology;improved adaptive genetic algorithm;unmanned aerial vehicle swarm;multi-target;cooperative round-up;task allocation strategy;Hungarian algorithm},
  doi={10.1109/CAC63892.2024.10865411},
  ISSN={2688-0938},
  month={Nov},}@ARTICLE{10720181,
  author={Yang, Bin and Yin, Zhangqiang},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Spectral Variability Augmented Multilinear Mixing Model for Hyperspectral Nonlinear Unmixing}, 
  year={2024},
  volume={21},
  number={},
  pages={1-5},
  abstract={This letter presents an unsupervised unmixing method to interpret both nonlinear mixing effects and spectral variability (SV). First, the traditional multilinear mixing model (LMM) is augmented by introducing physically meaningful factors representing wavelength-dependent SV into the modeling. This model-driven improvement effectively provides a concise numerical explanation for the nonlinearity and SV, facilitating the consideration of their coupled effects on unmixing. Second, based on the augmented model, total variation (TV) regularizers to improve abundances’ spatial smoothness and scaling factors’ local similarity, and a constraint to confine the perturbations’ energy of SV, are exploited to formulate the unmixing problem. A multiswarm particle swarm optimization (PSO) algorithm is employed as the solver for this problem to achieve robust unmixing results with higher accuracy. Finally, experiments on numerical model-based and physical-based simulated data and real hyperspectral remote sensing images demonstrate the proposed method’s superiority over the state-of-the-art methods.},
  keywords={Numerical models;Perturbation methods;Accuracy;Adaptation models;Particle swarm optimization;Optimization;Mathematical models;Land surface;Vectors;TV;Augmented multilinear mixing model (MLM);hyperspectral imagery (HSI);nonlinear unmixing;particle swarm optimization (PSO);spectral variability (SV)},
  doi={10.1109/LGRS.2024.3482103},
  ISSN={1558-0571},
  month={},}
