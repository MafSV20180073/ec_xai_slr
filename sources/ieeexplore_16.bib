@ARTICLE{10100892,
  author={Kamal, Imam Mustafa and Bae, Hyerim and Liu, Ling},
  journal={IEEE Transactions on Services Computing}, 
  title={Metric Learning as a Service With Covariance Embedding}, 
  year={2023},
  volume={16},
  number={5},
  pages={3508-3522},
  abstract={Metric learning as a service (MLaaS) represents one of the main learning streams to handle complex datasets in service computing research communities and industries. A common approach for dealing with high-dimensional and complex datasets is employing a feature embedding algorithm to compress data through dimension reduction while optimizing intra-class distance. To create generalizable MLaaS for high-performance artificial intelligence applications with high-dimensional Big Data, a robust and meaningful embedding space representation by efficiently optimizing both intra-class and inter-class relationships is required. We developed a novel MLaaS methodology that incorporates covariance to signify the direction of the linear relationship between data points in an embedding space. Our covariance-based feature embedding architecture introduces three different yet complementary mapping functions: inner-class mapping, intra-class with semi-inter-class mapping, and intra- and inter-class mapping. Unlike conventional metric learning, our covariance-embedding-enhanced approach is more expressive and explainable for computing similar or dissimilar measures and can capture positive, negative, or neutral relationships. Our MLaaS framework ensures efficient, composable, and extensible metric learning by supporting the selection of dimension reduction and data compression methods. Experiments conducted using various benchmark datasets demonstrate that the proposed model can obtain higher-quality, more separable, and more expressive embedding representations than existing models.},
  keywords={Measurement;Data models;Semantics;Dimensionality reduction;Task analysis;Standards;Speech recognition;AI-as-a-service;metric learning;semantic similarity;siamese network;covariance metric},
  doi={10.1109/TSC.2023.3266445},
  ISSN={1939-1374},
  month={Sep.},}@ARTICLE{9913948,
  author={Huang, Yicong and Yu, Zhu Liang},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Associating Latent Representations With Cognitive Maps via Hyperspherical Space for Neural Population Spikes}, 
  year={2022},
  volume={30},
  number={},
  pages={2886-2895},
  abstract={Recently, there has been a focus on drawing progress on representation learning to obtain more identifiable and interpretable latent representations for spike trains, which helps analyze neural population activity and understand neural mechanisms. Most existing deep generative models adopt carefully designed constraints to capture meaningful latent representations. For neural data involving navigation in cognitive space, based on insights from studies on cognitive maps, we argue that the good representations should reflect such directional nature. Due to manifold mismatch, models utilizing the Euclidean space learn a distorted geometric structure that is difficult to interpret. In the present work, we explore capturing the directional nature in a simpler yet more efficient way by introducing hyperspherical neural latent variable models (SNLVM). SNLVM is an improved deep latent variable model modeling neural activity and behavioral variables simultaneously with hyperspherical latent space. It bridges cognitive maps and latent variable models. We conduct experiments on modeling a static unidirectional task. The results show that while SNLVM has competitive performance, a hyperspherical prior naturally provides more informative and significantly better latent structures that can be interpreted as spatial cognitive maps.},
  keywords={Navigation;Statistics;Sociology;Manifolds;Data models;Neurons;Dynamical systems;Latent variable models;neural population spikes;hyperspherical latent space;cognitive navigation},
  doi={10.1109/TNSRE.2022.3212997},
  ISSN={1558-0210},
  month={},}@ARTICLE{10614132,
  author={Lehmann, Isabell and Hasija, Tanuj and Gabrielson, Ben and Akhonda, Mohammad A. B. S. and Calhoun, Vince D. and Adali, Tülay},
  journal={IEEE Access}, 
  title={Identifying the Relationship Structure Among Multiple Datasets Using Independent Vector Analysis: Application to Multi-Task fMRI Data}, 
  year={2024},
  volume={12},
  number={},
  pages={109443-109456},
  abstract={Identifying relationships among multiple datasets is an effective way to summarize information and has been growing in importance. In this paper, we propose a robust 3-step method for identifying the relationship structure among multiple datasets based on Independent Vector Analysis (IVA) and bootstrap-based hypothesis testing. Unlike previous approaches, our theory-backed method eliminates the need for user-defined thresholds and can effectively handle non-Gaussian data. It achieves this by incorporating higher-order statistics through IVA and employing an eigenvalue decomposition-based feature extraction approach without distributional assumptions. This way, our method estimates more interpretable components and effectively identifies the relationship structure using hierarchical clustering. Simulation results demonstrate the effectiveness of our method, as it achieves perfect Adjusted Mutual Information (AMI) for different values of the correlation between the components. When applied to multi-task fMRI data from patients with schizophrenia and healthy controls, our method successfully reveals activated brain regions associated with the disorder, and identifies the relationship structure of task datasets that matches our prior knowledge of the experiment. Moreover, our proposed method extends beyond task datasets, offering broad applicability in subgroup identification in neuroimaging and other domains.},
  keywords={Functional magnetic resonance imaging;Multitasking;Covariance matrices;Feature extraction;Vectors;Eigenvalues and eigenfunctions;Correlation;Blind source separation;Blind source separation;bootstrap;data-driven;fMRI;independent vector analysis;relationship structure},
  doi={10.1109/ACCESS.2024.3435526},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10820751,
  author={Sollenberger, Zachariah and Patel, Jay and Munley, Christian and Jarmusch, Aaron and Chandrasekaran, Sunita},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={LLM4VV: Exploring LLM-as-a-Judge for Validation and Verification Testsuites}, 
  year={2024},
  volume={},
  number={},
  pages={1885-1893},
  abstract={Large Language Models (LLM) continue to improve and are revolutionizing the landscape of software development. These large models have demonstrated potential to generate, debug, test, analyze, document, and even translate code. Thus they are a valuable tool in the software development cycle. If used correctly, such tools can often accelerate the development cycle. Though the tools are powerful and new, the community is cautious of training using biased or sensitive data, which can lead to biased, dangerous, or incorrect outputs along with the inadvertent release of confidential information. Additionally, the carbon footprints and the un-explainability of these "black box" models continue to raise questions about the reliability of LLMs.With these opportunities and these challenges ahead, this paper explores the idea of "judging" LLM-generated code to better understand and "open up" the un-explainable "black box" models used by LLMs. We probe into the black box of one such LLM that has generated the best compiler tests for the directive-based programming models OpenMP and OpenACC in our earlier research. We challenge DeepSeek’s deepseek-coder-33B-instruct model with intentionally-erroneous code, and we also define relevant metrics and adopt an agent-based approach to evaluate the LLM and assess its capabilities as an LLM-as-a-judge. We also develop a pipeline-based approach to streamline the entire workflow. Finally, we make use of all of these strategies together to develop a more reliable method for automatically validating LLM-generated compiler tests. Based on our results, utilizing an agent-based prompting approach and setting up a validation pipeline structure drastically increased the quality of deepseek-coder-33B-instruct evaluation of tests which are used to validate compiler implementations of directive-based parallel programming models.},
  keywords={Training;Codes;Program processors;Translation;Pipelines;Closed box;Reliability;Test pattern generators;Software development management;Testing;validation;large langauge model;high performance computing},
  doi={10.1109/SCW63240.2024.00238},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11058440,
  author={Amichi, Licia and Kim, Joon-Seok and Thakur, Gautam Malviya and Christopher, Carter},
  booktitle={2025 26th IEEE International Conference on Mobile Data Management (MDM)}, 
  title={Exploring the Utility-Privacy Trade-Off: Impacts of Semantic and Visit Types Ambiguities on Human Mobility Simulation}, 
  year={2025},
  volume={},
  number={},
  pages={90-95},
  abstract={Humans are in perpetual movement, constantly traversing buildings, cities, waters, oceans, and countries. Mobility stands out as a major driving force shaping our modern societies. Capturing and explaining human behavior in a world of eight billion distinct mobility agendas is a complex challenge. With the rise of interconnected devices and platforms, such as smartphones, wearables, and point-of-interest data, largescale behavioral data has become more accessible, enabling rich insights into mobility patterns. However, the widespread availability of such data introduces significant ethical challenges. Detailed mobility data can inadvertently reveal sensitive personal information, including individuals' locations, habits, social interactions, and even political or religious affiliations. Beyond privacy breaches, the ethical implications of uncovering and potentially manipulating underlying behavioral patterns demand attention. Striking a balance between the utility of mobility models and the protection of individual privacy is therefore paramount. This paper explores the utility-privacy trade-offs in human mobility modeling, focusing on the impacts of introducing semantic and visit type ambiguities. By systematically examining how these ambiguities affect the fidelity of simulated trajectories and privacy risks, we provide a framework for evaluating ethical and privacy-conscious modeling practices. Our findings emphasize the need for methods that safeguard privacy without undermining the usefulness of mobility models, contributing to the responsible advancement of mobility science in alignment with ethical standards and societal expectations.},
  keywords={Ethics;Data privacy;Mobility models;Semantics;Urban areas;Complexity theory;Trajectory;Wearable devices;Standards;Smart phones;Mobility;Simulation;Utility-Privacy},
  doi={10.1109/MDM65600.2025.00030},
  ISSN={2375-0324},
  month={June},}@INPROCEEDINGS{10944691,
  author={Jia, Chunying and Wang, Weixin and Vu, Trung and Yang, Hanlu and Gabrielson, Ben and Calhoun, Vince D. and Adali, Tülay},
  booktitle={2025 59th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Adaptive Constrained ICA with Mixing Matrix Column Constraints: Application to fMRI Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Independent Component Analysis (ICA) is a powerful data-driven method that has been widely applied in functional magnetic resonance imaging (fMRI) data analysis to uncover underlying sources. An attractive way to boost ICA performance is via constraints to guide ICA factors to be similar to user-supplied "references", allowing incorporation of prior-knowledge into the factorization. However, most of existing constrained ICA methods typically only impose source constraints and are unable to impose constraints on the mixing matrix. With multi-subject medical imaging datasets, constraining the mixing matrix with subjects’ symptom-related measurements, such as clinical scores or cognitive variables, enhances the algorithm’s ability to identify brain activities associated with these symptoms. This offers a novel perspective for understanding the pathologies underlying various psychiatric disorders. Therefore, to overcome the limitations of existing constrained ICA algorithms, we introduce a new constrained ICA algorithm: adaptive-reverse constrained matrix entropy bound minimization (arc-M-EBM), which imposes constraints on the mixing matrix and uses adaptive-reverse thresholding to avoid overfitting or underfitting. This approach ensures flexibility and leads to more accurate and interpretable source separation. Simulations demonstrate that arc-M-EBM outperforms traditional ICA methods. Application to resting-state fMRI data from 176 subjects from healthy controls and patients reveals significant relationships between constrained components and clinical measures, enhancing our understanding of brain-behavior relationships.},
  keywords={Adaptation models;Thresholding (Imaging);Source separation;Correlation;Loading;Independent component analysis;Functional magnetic resonance imaging;Brain modeling;Data models;Context modeling;Constrained Independent Component Analysis;Adaptive Reverse Scheme;fMRI Analysis},
  doi={10.1109/CISS64860.2025.10944691},
  ISSN={2837-178X},
  month={March},}@ARTICLE{10834497,
  author={Awais, Muhammad and Naseer, Muzammal and Khan, Salman and Anwer, Rao Muhammad and Cholakkal, Hisham and Shah, Mubarak and Yang, Ming-Hsuan and Khan, Fahad Shahbaz},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Foundation Models Defining a New Era in Vision: A Survey and Outlook}, 
  year={2025},
  volume={47},
  number={4},
  pages={2245-2264},
  abstract={Vision systems that see and reason about the compositional nature of visual scenes are fundamental to understanding our world. The complex relations between objects and their locations, ambiguities, and variations in the real-world environment can be better described in human language, naturally governed by grammatical rules and other modalities such as audio and depth. The models learned to bridge the gap between such modalities and large-scale training data facilitate contextual reasoning, generalization, and prompt capabilities at test time. These models are referred to as foundation models. The output of such models can be modified through human-provided prompts without retraining, e.g., segmenting a particular object by providing a bounding box, having interactive dialogues by asking questions about an image or video scene or manipulating the robot's behavior through language instructions. In this survey, we provide a comprehensive review of such emerging foundation models, including typical architecture designs to combine different modalities (vision, text, audio, etc.), training objectives (contrastive, generative), pre-training datasets, fine-tuning mechanisms, and the common prompting patterns; textual, visual, and heterogeneous. We discuss the open challenges and research directions for foundation models in computer vision, including difficulties in their evaluations and benchmarking, gaps in their real-world understanding, limitations of contextual understanding, biases, vulnerability to adversarial attacks, and interpretability issues. We review recent developments in this field, covering a wide range of applications of foundation models systematically and comprehensively.},
  keywords={Adaptation models;Computational modeling;Foundation models;Data models;Surveys;Visualization;Reviews;Computer vision;Computer architecture;Context modeling;Contrastive learning;language and vision;large language models;masked modeling;self-supervised learning},
  doi={10.1109/TPAMI.2024.3506283},
  ISSN={1939-3539},
  month={April},}@ARTICLE{10129973,
  author={Bi, Xia-An and Chen, Ke and Jiang, Siyu and Luo, Sheng and Zhou, Wenyan and Xing, Zhaoxu and Xu, Luyun and Liu, Zhengliang and Liu, Tianming},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Community Graph Convolution Neural Network for Alzheimer’s Disease Classification and Pathogenetic Factors Identification}, 
  year={2025},
  volume={36},
  number={2},
  pages={1959-1973},
  abstract={As a complex neural network system, the brain regions and genes collaborate to effectively store and transmit information. We abstract the collaboration correlations as the brain region gene community network (BG-CN) and present a new deep learning approach, such as the community graph convolutional neural network (Com-GCN), for investigating the transmission of information within and between communities. The results can be used for diagnosing and extracting causal factors for Alzheimer’s disease (AD). First, an affinity aggregation model for BG-CN is developed to describe intercommunity and intracommunity information transmission. Second, we design the Com-GCN architecture with intercommunity convolution and intracommunity convolution operations based on the affinity aggregation model. Through sufficient experimental validation on the AD neuroimaging initiative (ADNI) dataset, the design of Com-GCN matches the physiological mechanism better and improves the interpretability and classification performance. Furthermore, Com-GCN can identify lesioned brain regions and disease-causing genes, which may assist precision medicine and drug design in AD and serve as a valuable reference for other neurological disorders.},
  keywords={Diseases;Correlation;Deep learning;Convolution;Genetics;Feature extraction;Convolutional neural networks;Alzheimer's disease (AD);community graph convolution (Com-GC) neural network;deep learning;imaging genetics},
  doi={10.1109/TNNLS.2023.3269446},
  ISSN={2162-2388},
  month={Feb},}@INPROCEEDINGS{10429919,
  author={Liu, Xinyi and Wang, Ruijie and Sun, Dachun and Li, Jinning and Youn, Christina and Lyu, You and Zhan, Jianyuan and Wu, Dayou and Xu, Xinhe and Liu, Mingjun and Lei, Xinshuo and Xu, Zhihao and Zhang, Yutong and Li, Zehao and Yang, Qikai and Abdelzaher, Tarek},
  booktitle={2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Influence Pathway Discovery on Social Media}, 
  year={2023},
  volume={},
  number={},
  pages={105-109},
  abstract={This paper addresses influence pathway discovery, a key emerging problem in today's online media. We propose a discovery algorithm that leverages recently published work on unsupervised interpretable ideological embedding, a mapping of ideological beliefs (done in a self-supervised fashion) into interpretable low-dimensional spaces. Computing the ideological embedding at scale allows one to analyze correlations between the ideological positions of leaders, influencers, news portals, or population segments, deriving potential influence pathways. The work is motivated by the importance of social media as the preeminent means for global interactions and collaborations on today's Internet, as well as their frequent (mis-)use to wield influence that targets social beliefs and attitudes of selected populations. Tools that enable the understanding and mapping of influence propagation through population segments on social media are therefore increasingly important. In this paper, influence is measured by the perceived ideological shift over time that is correlated with influencers' activity. Correlated shifts in ideological embed dings indicate changes, such as swings/switching (among competing ideologies), polarization (depletion of neutral ideological positions), escalation/radicalization (shifts to more extreme versions of the ideology), or unification/cooldown (shifts towards more neutral stances). Case-studies are presented to explore selected influence pathways (i) in a recent French election, (ii) during political discussions in the Philippines, and (iii) for some Russian messaging during the Russia/Ukraine conflict.},
  keywords={Social networking (online);Voting;Sociology;Pipelines;Collaboration;User interfaces;Internet;Social Network Analysis;Influence Network;Ideological Embedding;Social Analysis Pipeline},
  doi={10.1109/CIC58953.2023.00023},
  ISSN={},
  month={Nov},}@ARTICLE{10073528,
  author={Lavrova, Elizaveta and Salahuddin, Zohaib and Woodruff, Henry C. and Kassem, Mohamed and Camarasa, Robin and Van Kolk, Anja G. Der and Nederkoorn, Paul J. and Bos, Daniel and Hendrikse, Jeroen and Kooi, M. Eline and Lambin, Philippe},
  journal={IEEE Access}, 
  title={UR-CarA-Net: A Cascaded Framework With Uncertainty Regularization for Automated Segmentation of Carotid Arteries on Black Blood MR Images}, 
  year={2023},
  volume={11},
  number={},
  pages={26637-26651},
  abstract={We present a fully automated method for carotid artery (CA) outer wall segmentation in black blood MRI using partially annotated data and compare it to the state-of-the-art reference model. Our model was trained and tested on multicentric data of patients (106 and 23 patients, respectively) with a carotid plaque and was validated on different MR sequences (24 patients) as well as data that were acquired with MRI systems of a different vendor (34 patients). A 3D nnU-Net was trained on pre-contrast T1w turbo spin echo (TSE) MR images. A CA centerline sliding window approach was chosen to refine the nnU-Net segmentation using an additionally trained 2D U-Net to increase agreement with manual annotations. To improve segmentation performance in areas with semantically and visually challenging voxels, Monte-Carlo dropout was used. To increase generalizability, data were augmented with intensity transformations. Our method achieves state-of-the-art results yielding a Dice similarity coefficient (DSC) of 91.7% (interquartile range (IQR) 3.3%) and volumetric intraclass correlation (ICC) with ground truth of 0.90 on the development domain data and a DSC of 91.1% (IQR 7.2%) and volumetric ICC with ground truth of 0.83 on the external domain data outperforming top-ranked methods for open-source CA segmentation. The uncertainty-based approach increases the interpretability of the proposed method by providing an uncertainty map together with the segmentation.},
  keywords={Magnetic resonance imaging;Blood flow;Carotid arteries;Biomedical imaging;Three-dimensional displays;Auto-segmentation;carotid MRI;vessel segmentation;U-Net;uncertainty regularization},
  doi={10.1109/ACCESS.2023.3258408},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10793151,
  author={Huang, Yafan and Di, Sheng and Li, Guanpeng and Cappello, Franck},
  booktitle={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={CUSZP2: A GPU Lossy Compressor with Extreme Throughput and Optimized Compression Ratio}, 
  year={2024},
  volume={},
  number={},
  pages={1-18},
  abstract={Existing GPU lossy compressors suffer from expensive data movement overheads, inefficient memory access patterns, and high synchronization latency, resulting in limited throughput. This work proposes cuSZP2, a generic single-kernel error-bounded lossy compressor purely on GPUs designed for applications that require high speed, such as large-scale GPU simulation and large language model training. In particular, CUSZP2 proposes a novel lossless encoding method, optimizes memory access patterns, and hides synchronization latency, achieving extreme end-to-end throughput and optimized compression ratio. Experiments on NVIDIA A100 GPU with 9 real-world HPC datasets demonstrate that, even with higher compression ratios and data quality, CUSZP2 can deliver on average 332.42 and $513.04 \mathrm{~GB} / \mathrm{s}$ end-to-end throughput for compression and decompression, respectively, which is around $2 \times$ of existing pure-GPU compressors and $200 \times$ of CPU-GPU hybrid compressors.},
  keywords={Training;Large language models;High performance computing;Data integrity;Graphics processing units;Throughput;Compressors;Encoding;Synchronization;Data Compression;Parallel Computing;GPU},
  doi={10.1109/SC41406.2024.00021},
  ISSN={},
  month={Nov},}@ARTICLE{10504606,
  author={Chen, Hang and Wang, Qing and Du, Jun and Wan, Gen-Shun and Xiong, Shi-Fu and Yin, Bao-Ci and Pan, Jia and Lee, Chin-Hui},
  journal={IEEE Transactions on Multimedia}, 
  title={Collaborative Viseme Subword and End-to-End Modeling for Word-Level Lip Reading}, 
  year={2024},
  volume={26},
  number={},
  pages={9358-9371},
  abstract={We propose a viseme subword modeling (VSM) approach to improve the generalizability and interpretability capabilities of deep neural network based lip reading. A comprehensive analysis of preliminary experimental results reveals the complementary nature of the conventional end-to-end (E2E) and proposed VSM frameworks, especially concerning speaker head movements. To increase lip reading accuracy, we propose hybrid viseme subwords and end-to-end modeling (HVSEM), which exploits the strengths of both approaches through multitask learning. As an extension to HVSEM, we also propose collaborative viseme subword and end-to-end modeling (CVSEM), which further explores the synergy between the VSM and E2E frameworks by integrating a state-mapped temporal mask (SMTM) into joint modeling. Experimental evaluations using different model backbones on both the LRW and LRW-1000 datasets confirm the superior performance and generalizability of the proposed frameworks. Specifically, VSM outperforms the baseline E2E framework, while HVSEM outperforms VSM in a hybrid combination of VSM and E2E modeling. Building on HVSEM, CVSEM further achieves impressive accuracies on 90.75% and 58.89%, setting new benchmarks for both datasets.},
  keywords={Lips;Hidden Markov models;Feature extraction;Visualization;Task analysis;Convolutional neural networks;Training;Deep learning;hidden markov model;lip reading;multitask learning viseme},
  doi={10.1109/TMM.2024.3390148},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10099058,
  author={Das, Debasree and Chakraborty, Sandip and Mitra, Bivas},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={DriCon: On-device Just-in-Time Context Characterization for Unexpected Driving Events}, 
  year={2023},
  volume={},
  number={},
  pages={12-21},
  abstract={Driving is a complex task carried out under the influence of diverse spatial objects and their temporal inter-actions. Therefore, a sudden fluctuation in driving behavior can be due to either a lack of driving skill or the effect of various on-road spatial factors such as pedestrian movements, peer vehicles' actions, etc. Therefore, understanding the context behind a degraded driving behavior just-in-time is necessary to ensure on-road safety. In this paper, we develop a system called DriCon that exploits the information acquired from a dashboard-mounted edge-device to understand the context in terms of micro-events from a diverse set of on-road spatial factors and in-vehicle driving maneuvers taken. DriCon uses the live in-house testbed and the largest publicly available driving dataset to generate human interpretable explanations against the unexpected driving events. Also, it provides a better insight with an improved similarity of 80% over 50 hours of driving data than the existing driving behavior characterization techniques.},
  keywords={Pervasive computing;Fluctuations;Behavioral sciences;Spatiotemporal phenomena;Safety;Task analysis;Intelligent systems;Driving behavior;spatial events;context analysis},
  doi={10.1109/PERCOM56429.2023.10099058},
  ISSN={2474-249X},
  month={March},}@INPROCEEDINGS{10748211,
  author={Zobel, Theresa and Meinel, Christoph},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Comparing AI in Online Learning: The Transition and Trade-offs Between Intent-Based Learning Assistants and LLM-Chatbots in MOOCs}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the evolving landscape of Massive Open Online Courses (MOOCs), Artificial Intelligence (AI) technologies, notably intent-based learning assistants and Large Language Model (LLM)-Chatbots, present innovative avenues for personalizing and enhancing online education. This paper conducts a succinct comparative analysis of these AI approaches, highlighting their respective strengths and limitations in MOOC environments. Intent-based assistants offer precise, tailored support by responding to specific user intents, facilitating a more structured learning experience. Conversely, LLM-Chatbots, with their vast knowledge bases and conversational capabilities, provide flexible and wide-ranging interactions, encouraging exploratory learning.This analysis further considers the impact of these technologies on fostering social learning communities, addressing ethical and privacy concerns, and their applicability across diverse educational contexts. By comparing the trade-offs between intent-based assistants and LLM-Chatbots, the paper aims to equip educators and technologists with insights into their optimal integration for improving MOOCs. It underscores the importance of aligning AI technologies with educational goals to enhance learning accessibility and quality, especially for underrepresented groups, thereby contributing to the development of more inclusive and effective online learning environments. This research serves as a guide for future AI applications in education, emphasizing the need for a balanced approach in leveraging AI to benefit learners globally.},
  keywords={Ethics;Privacy;Computer aided instruction;Electronic learning;Navigation;Education;Learning (artificial intelligence);Transforms;Artificial intelligence;Lenses;Artificial Intelligence in Education;MOOC Enhancement;Intent-Based Learning Assistants;LLM-Chatbots;Comparative Analysis},
  doi={10.1109/DEMOcon63027.2024.10748211},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10913847,
  author={Wadood, Hamid and Haris, Muhammad and Hassan, Aqib and Malik, Muhammad Osama and Yousaf, Hamza and Ullah, Kaleem},
  booktitle={2024 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Deep Learning Applications for Wind Energy Forecasting in Smart Grids}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Driven by the pressing need for sustainable and reliable energy sources, this paper critically evaluates deep learning's role in advancing wind energy forecasting, highlighting its potential to address current energy demands through improved prediction accuracy. Due to the inherent unpredictability of wind, conventional forecasting models often fall short; however, deep learning models offer enhanced reliability by effectively identifying complex, embedded patterns within wind data. The paper examines techniques such as time-series recurrent neural networks, restricted Boltzmann machines, convolutional neural networks, and autoencoders, each targeting distinct challenges in wind forecasting to strengthen grid integration and ensure energy reliability. Future directions-including hybrid model approaches and model interpretability-are discussed, underscoring deep learning's promise as a powerful tool for optimizing wind energy utilization and supporting a more sustainable, low-carbon energy infrastructure.},
  keywords={Deep learning;Recurrent neural networks;Wind energy;Predictive models;Data models;Reliability;Convolutional neural networks;Forecasting;Wind forecasting;Long short term memory;Wind Energy Systems;Machine Learning Methods;convolutional neural networks (CNN);recurrent neural networks (RNN);long short-term memory (LSTM)},
  doi={10.1109/ICEET65156.2024.10913847},
  ISSN={2831-3682},
  month={Dec},}@INPROCEEDINGS{10500258,
  author={Procko, Tyler Thomas and Ochoa, Omar},
  booktitle={SoutheastCon 2024}, 
  title={Semantic Science: Publication Beyond the PDF}, 
  year={2024},
  volume={},
  number={},
  pages={207-215},
  abstract={Scientific papers have evolved since the establishment of the Royal Society in the mid-17th century. Today, despite the interconnectedness of Internet discourse, scientific papers are released as relatively static, inflexible artifacts, to wit, as Portable Document Format (PDF) files. This fact is an egregious slight to the base principle of science: that it is to be mutable and evolutionary. Thus, the present paper proposes a means of writing scientific papers that allows for change and explicit connection to other papers, through the use of (1) Linked Data knowledge graphs, (2) the Findable-Accessible-Interoperable-Reusable (FAIR) data principles, (3) the Markdown language, and (4) OpenAI“s Large Language Model, the Generative Pre-trained Transformer, GPT -4. A handful of extant tools exist; these will be introduced in turn. The present paper cogently synthesizes the topic at hand and calls for science to be semantic.},
  keywords={Semantic Web;Resistance;Reviews;Linked data;Semantics;Portable document format;Transformers;scientific writing;knowledge graphs;FAIR data;GPT},
  doi={10.1109/SoutheastCon52093.2024.10500258},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{11077500,
  author={Wang, Lingxiao and Hassan, Sunzid and Mahmud, Khan Raqib},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Semantic Odor Source Localization via Visual and Olfactory Integrated Navigation}, 
  year={2025},
  volume={},
  number={},
  pages={87-93},
  abstract={Odor Source Localization (OSL) is a technology that navigates a mobile robot to autonomously locate a hidden odor source. Unlike traditional OSL navigation algorithms, which rely solely on olfactory data, this paper introduces a semantic OSL navigation algorithm that integrates both visual and olfactory sensing to enhance the search performance. By combining these two modalities, the proposed system can infer potential odor sources and their locations. For example, when detecting the smell of smoke in a kitchen, our system can associate the odor source with an oven or microwave. To leverage the semantic relationships between visual and olfactory observations, we employ a Large Language Model (LLM) to process the multi-modal sensory data and guide the navigation. The proposed LLMbased navigation algorithm is evaluated in a simulated household environment. Simulated results demonstrate that the proposed method can achieve a higher success rate and shorter travel distance, compared to random walk, vision-only, and olfactiononly approaches.},
  keywords={Location awareness;Visualization;Navigation;Large language models;Olfactory;Semantics;Robot sensing systems;Microwave theory and techniques;Sensors;Mobile robots;Robotic Odor Source Localization;large language models;robot navigation;household robots},
  doi={10.1109/AIRC64931.2025.11077500},
  ISSN={},
  month={May},}@INPROCEEDINGS{10977491,
  author={Sahoo, Subham and Wang, Huai and Blaabjerg, Frede},
  booktitle={2025 IEEE Applied Power Electronics Conference and Exposition (APEC)}, 
  title={Uncertainty-Aware Artificial Intelligence for Gear Fault Diagnosis in Motor Drives}, 
  year={2025},
  volume={},
  number={},
  pages={912-918},
  abstract={This paper introduces a novel approach to quantify the uncertainties in fault diagnosis of motor drives using Bayesian neural networks (BNN). Conventional data-driven approaches used for fault diagnosis often rely on point-estimate neural networks, which merely provide deterministic outputs and fail to capture the uncertainty associated with the inference process. In contrast, BNNs offer a principled framework to model uncertainty by treating network weights as probability distributions rather than fixed values. It offers several advantages: (a) improved robustness to noisy data, (b) enhanced interpretability of model predictions, and (c) the ability to quantify uncertainty in the decision-making processes. To test the robustness of the proposed BNN, it has been tested under a conservative dataset of gear fault data from an experimental prototype of three fault types at first, and is then incrementally trained on new fault classes and datasets to explore its uncertainty quantification features and model interpretability under noisy data and unseen fault scenarios.},
  keywords={Fault diagnosis;Uncertainty;Gears;Neural networks;Decision making;Power electronics;Data models;Robustness;Bayes methods;Artificial intelligence;Power electronics;Artificial intelligence;Fault diagnosis;Uncertainty-aware AI;Uncertainty quantification},
  doi={10.1109/APEC48143.2025.10977491},
  ISSN={2470-6647},
  month={March},}@INPROCEEDINGS{11077484,
  author={Jain, Aditi M and Jain, Ayush},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Scaling LLM Inference Architectures: A Performance Analysis for Chatbot Applications}, 
  year={2025},
  volume={},
  number={},
  pages={8-16},
  abstract={This paper presents a systematic evaluation of architectural patterns for Large Language Model (LLM) inference in production chatbot applications, addressing the critical challenge of balancing performance, cost, and scalability. We analyze five distinct architectures-monolithic, microservices, edge computing, event-driven, and hybrid edge-microservices-using a novel experimental framework with 100 concurrent users as a baseline. Our methodology incorporates precise measurements of latency profiles, throughput, resource utilization, and cost metrics, employing GPT-3.5-turbo with vLLM optimization. Key findings reveal that hybrid edge-microservices architecture offers 46% lower P99 latency and 67% higher throughput compared to monolithic approaches, while edge computing demonstrates 37% lower CPU usage. We introduce a scaling factor analysis methodology for accurate performance predictions at larger scales, validated through controlled experiments. This research contributes: (1) a systematic evaluation methodology for LLM inference architectures, (2) empirical evidence for architectural decision-making, (3) novel scaling factors for performance prediction, and (4) a detailed cost-benefit analysis across architectural patterns. These insights advance the scientific understanding of LLM deployment strategies and provide crucial guidance for both researchers and practitioners in optimizing large-scale neural inference systems.},
  keywords={Systematics;Scalability;Large language models;Microservice architectures;Computer architecture;Chatbots;Throughput;Resource management;Robots;Edge computing;Large Language Models;Distributed Inference;Edge Computing;Microservices Architecture;Performance Optimization;Scalability Analysis;Chatbot Systems;Cost-Efficiency;Hybrid Architectures;Benchmarking},
  doi={10.1109/AIRC64931.2025.11077484},
  ISSN={},
  month={May},}@INPROCEEDINGS{9751887,
  author={Srinivas, Kandala Kalyana and Peddi, Anudeep and Srinivas, B G Sai and Vardhini, P A Harsha and Prasad, Hemanth Lakshmi Phani and Choudhary, Santosh Kumar},
  booktitle={2022 International Mobile and Embedded Technology Conference (MECON)}, 
  title={Artificial Intelligence Techniques for Chatbot Applications}, 
  year={2022},
  volume={},
  number={},
  pages={292-296},
  abstract={Nowadays in a variety of businesses, the use of chatbots has grown including cultural heritage, entertainment, education, marketing, health care, and support systems. Let’s discuss what chatbots are in general and later know about them in detail. In a detailed explanation first, we must know how dialogue management will be done in chatbots later we will focus on how chatbots can be an entertainment source for elderly people. How using bio-inspired chatbots can increase e-learning efficiency will also be studied. Not only that, as information cannot be conveyed in a un fashioned manner, so to give the information in a neat and detailed matter we will learn about polishing the generated response in chatbots. And also in this paper, we discuss chatbots whose data neither be manipulated nor their training data is used but end users want to test the trustworthiness which can be explained in detail. Whenever the usage of chatbots comes they are only restricted to certain languages for example like English but due to rapid growth in technology, the development of chatbots or upgradation of chatbots is needed for other regional languages too. Chatbots can also be used to communicate with humans and also clarify their queries mainly across the internet. Chatbots can replace the human power needed in sectors like call centers, etc and many tech giants are also investing in it},
  keywords={Electronic learning;Education;Entertainment industry;Training data;Medical services;Chatbots;Cultural differences;ArtificialIntelligence;Natural language processing;Stemming and lemmatization;K-bot;Chatbots in various fields},
  doi={10.1109/MECON53876.2022.9751887},
  ISSN={},
  month={March},}@INPROCEEDINGS{9962700,
  author={Li, Tiantian and Holloway, Eric A. and Bill, Victoria G. and Douglas, Kerrie A. and Martin, Julie P.},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Professional Skill Opportunities Survey: Development and Exploratory Factor Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={This full research paper presents the exploratory factor analysis (EFA) results for the Professional Skill Opportunities survey (PSO) we designed to measure undergraduate engineering students’ opportunities to develop and practice important nontechnical professional skills. We use Dall’alba’s "ways of being" as the theoretical framework for the survey development and generated construct definitions based on past literature, expert review, and cognitive think-aloud interviews. We administered the survey in an engineering class at the beginning of the Spring 2022 semester. After comparing the three EFA models based on goodness-of-fit indices and model interpretability aligned to the theoretical model, the researchers selected a five-factor model. The EFA result and literature on leadership and teamwork showed these two skills are highly interrelated and could be combined into one construct to stress the "sharedness" of leadership responsibilities in teams. The result allowed our team to refine our item pool, revise construct definitions, and generate new items. In future work, we will administer the revised PSO survey to the same population at the end of the same semester as further validation. We also plan to explore the relationship between professional skill development opportunities and students’ social support. We hope the PSO survey can provide educators and institutions a means to offer scaffoldings and more opportunities for professional skill development and better prepare students for the engineering workforce.},
  keywords={Leadership;Instruments;Sociology;Teamwork;Problem-solving;Statistics;Springs;professional skills development;exploratory factor analysis;instrument validation;ways of being},
  doi={10.1109/FIE56618.2022.9962700},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10477706,
  author={La Torraca, Paolo and Padovani, Andrea and Wernersson, Lars-Erik and Cherkaoui, Karim and Hurley, Paul and Larcher, Luca},
  booktitle={2023 IEEE International Integrated Reliability Workshop (IIRW)}, 
  title={Electrically active defects in Al2O3-InGaAs MOS stacks at cryogenic temperatures}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The effects of defects in In0.47Ga0.53As/Al2O3/Ni metal-oxide-semiconductor (MOS) stacks at cryogenic temperatures are investigated. The MOS stacks exhibit a hysteresis in the capacitance-voltage (CV) curve, both at room temperature and at 100K, indicating the presence of effective charge capture/emission dynamics in the oxide even at cryogenic temperatures. Border traps (BTs) in the Al2O3 close to the In0.47Ga0.53As/Al2O3 interface are recognized as the best candidate for explaining the experimental CV. The hysteresis shape and its temperature dependence are used to profile the oxide defects’ properties, which allow correctly predicting the MOS stacks CV and conductance-voltage (GV) frequency dispersions and gaining insights on the hysteresis dynamics.},
  keywords={Temperature dependence;Temperature;Shape;Conferences;Capacitance-voltage characteristics;Cryogenics;Reliability;Al2O3;capacitance;cryogenic;hysteresis;InGaAs},
  doi={10.1109/IIRW59383.2023.10477706},
  ISSN={2374-8036},
  month={Oct},}@INPROCEEDINGS{10135418,
  author={Yi, Jixuan and Li, Yiwen and Zhang, Kai},
  booktitle={2023 4th International Conference on Computer Engineering and Application (ICCEA)}, 
  title={Material Stiffness Prediction Based on Neural Network and Symbolic Regression}, 
  year={2023},
  volume={},
  number={},
  pages={475-480},
  abstract={The effective stiffness of multi-inclusion composite materials is difficult to derive using theoretical methods since the localization relationships are usually complicated. In the past decades, researchers used numerical methods represented by the finite element method (FEM) to calculate the effective stiffness of multi-inclusion composites. However, FEM is time costly and cannot achieve real-time stiffness prediction. The emergence of machine learning methods provides a solution for realizing accurate real-time prediction, but making the machine learning model explainable in physical problems remains a crucial challenge. In this work, a machine learning method based on the convolutional neural network (CNN) and symbolic regression algorithm is used to achieve real-time stiffness prediction and give explicable expressions. The CNN model can predict the effective stiffness coefficients of multi-inclusion composites with all the mean absolute errors less than 2%. Using the data generated by the CNN model, the symbolic regression model based on the genetic algorithm can derive the expression of stiffness coefficients and provides a fast and explainable solution for stiffness prediction of multi-inclusion composites.},
  keywords={Location awareness;Machine learning;Predictive models;Prediction algorithms;Data models;Real-time systems;Finite element analysis;Machine learning;Stiffness prediction;Symbolic regression;Multi-inclusion composites},
  doi={10.1109/ICCEA58433.2023.10135418},
  ISSN={2159-1288},
  month={April},}@INPROCEEDINGS{10448964,
  author={Zhang, Qiqi and Zhang, Yingwei and Ding, Yanhui and Chen, Yiqiang and Song, Shuchao and Wu, Shuang},
  booktitle={2023 IEEE Smart World Congress (SWC)}, 
  title={A Weighted Ensemble Causal Discovery Method for Effective Connectivity Estimation}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Exploring and explaining the effective connectivity (EC) between brain regions can help us understand the mechanisms behind neurodegenerative diseases such as Alzheimer’s disease, thus helping us to diagnose patients better. Causal discovery techniques have been widely used in this domain recently, but diverse methods may produce conflicting outcomes because of the differences in underlying principles and search methods. To solve this problem, we integrate the causal relationships generated by different algorithms to obtain high-confidence inferences, resulting in a more reliable weighted ensemble causal discovery (WECD) method with higher accuracy. First of all, WECD defines a distribution metric function to measure the weights of different individual methods. Then, WECD adaptively chooses the critical threshold to obtain the confident edges set based on the generated directed edge confident metric curve. Finally, the directed acyclic graph condition is used to refine the confident edges set and acquire the final causal graph. We validate the effectiveness of WECD with both the simulated dataset and real functional near-infrared spectroscopy (fNIRS) dataset collected on AD patients, MCI patients and healthy controls. By comparing with other existing methods, experimental results demonstrate the potential of WECD as an effective tool for estimating brain EC.},
  keywords={Measurement;Weight measurement;Directed acyclic graph;Search methods;Robustness;Functional near-infrared spectroscopy;Alzheimer's disease;Alzheimer’s disease;effective connectivity;ensemble learning;causal discovery;functional near-infrared spectroscopy},
  doi={10.1109/SWC57546.2023.10448964},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10896297,
  author={Petngam, Pat and Ongwattanakul, Songpol and Prasertsakul, Thunyanoot and Charoensuk, Warakorn},
  booktitle={2024 16th Biomedical Engineering International Conference (BMEiCON)}, 
  title={Estimation of Human Postural Models Using Artificial Neural Networks Under Normal and Overweight Conditions}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The study of human postural control has been a continuous area of research due to the complexity of postural mechanisms, which are not fully understood. Existing models of human postural control provide partial explanations but often face limitations such as lack of generalization. This study aims to investigate postural models for two weight groups-normal weight (NW) and overweight (OW)-across three balance conditions: eyes-opened (EO), eyes-closed (EC), and single stance (SS). Using data collected from 11 participants, simulations were conducted using two time series models: the Autoregressive (AR) model and the Non-linear Autoregressive Moving Average (NARMA) model. Additionally, Artificial Neural Networks (ANNs) were employed to determine the optimal model orders. The results reveal different postural control mechanisms for each weight group. In stable conditions (EO), NARMA(4,1) and NARMA(8,10) models yielded center of pressure (COP) estimations with Mean Squared Errors (MSE) of 7.20 × 10–5 and 2.03 × 10–4 for NW and OW groups, respectively. The findings indicate that OW individuals require different mechanisms to maintain balance, with a higher reliance on previous COP information.},
  keywords={Analytical models;Time series analysis;Estimation;Artificial neural networks;Predictive models;Data models;Maintenance;Complexity theory;Faces;Autoregressive processes;human posture;postural control;NARMA model},
  doi={10.1109/BMEiCON64021.2024.10896297},
  ISSN={2473-7607},
  month={Nov},}@INPROCEEDINGS{10104763,
  author={Gowtham, R and Jebakumar, R},
  booktitle={2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={Analysis and Prediction of Lettuce Crop Yield in Aeroponic Vertical Farming using Logistic Regression Method}, 
  year={2023},
  volume={},
  number={},
  pages={759-764},
  abstract={Human population growth strains food supplies, resulting in more than one billion of the world’s 6.5 billion people facing hunger, which is the leading cause of death. In consequence, increasing crop production through traditional farming methods will not address the global food scarcity problem. As a precision agriculture approach, aeroponics, a soilless agriculture technique, can assist in cultivating in-demand food crops, which will help serve the people. Because aeroponics is an indoor farming technology, factors such as pH, EC, light, temperature, PPM, and turbidity will affect crop growth. Hence, monitoring an aeroponic crop growth system efficiently is crucial for achieving a high crop yield and reducing the need for food crops. Even though, many crop monitoring systems use IoT and machine learning algorithms, their prediction accuracy is not up to the level and if they are deployed in the real world, they may not meet customer expectations. In order to efficiently monitor crops, more advanced models are needed. However, understanding the large volume of data can be very tedious. Data visualization techniques can help make the distribution of the dataset easier to understand. Machine learning methods and packages can be used for environmental monitoring and visualization of the data where, the collection of crop growth dataset is carried out using various IoT sensors deployed in the growth environment. This study provides a comprehensive explanation of the data visualization techniques used to study the lettuce crop dataset and predict lettuce yield using the logistic regression machine learning method which is been implemented using Python coding language.},
  keywords={Temperature sensors;Temperature measurement;Temperature;Crops;Data visualization;Machine learning;Agriculture;Aeroponics;Machine Learning;Lettuce;Indoor Farming;Data Visualization;Data Science},
  doi={10.1109/ICSCDS56580.2023.10104763},
  ISSN={},
  month={March},}@INPROCEEDINGS{10150351,
  author={Yamagata, Taku and Tonkin, Emma L. and Sanchez, Benjamin Arana and Craddock, Ian and Nieto, Miquel Perello and Santos-Rodriguez, Raul and Yang, Weisong and Flach, Peter},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={When the Ground Truth is not True: Modelling Human Biases in Temporal Annotations}, 
  year={2023},
  volume={},
  number={},
  pages={527-533},
  abstract={In supervised learning, low quality annotations lead to poorly performing classification and detection models, while also rendering evaluation unreliable. This is particularly apparent on temporal data, where annotation quality is affected by multiple factors. For example, in the post-hoc self-reporting of daily activities, cognitive biases are one of the most common ingredients. In particular, reporting the start and duration of an activity after its finalisation may incorporate biases introduced by personal time perceptions, as well as the imprecision and lack of granularity due to time rounding. Here we propose a method to model human biases on temporal annotations and argue for the use of soft labels. Experimental results in synthetic data show that soft labels provide a better approximation of the ground truth for several metrics. We showcase the method on a real dataset of daily activities.},
  keywords={Measurement;Pervasive computing;Annotations;Conferences;Computational modeling;Supervised learning;Rendering (computer graphics);Temporal Annotations;Human biases;soft labels;Bayesian inference},
  doi={10.1109/PerComWorkshops56833.2023.10150351},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10426145,
  author={Mamaev, Kirill M. and Greshnyakov, George V. and Dubitsky, Simon D. and Chesnokov, Evgenii A. and Lebedeva, Alla A.},
  booktitle={2023 Seminar on Industrial Electronic Devices and Systems (IEDS)}, 
  title={Transient Thermal Analysis of Coaxial Pulse Power Cable}, 
  year={2023},
  volume={},
  number={},
  pages={167-171},
  abstract={The transient heating of a coaxial power cable under pulsed load is considered. The cable is designed for pulsed energy transfer from the ITER thermonuclear reactor and can be used in two modes: current pulse train and rare single pulses. Transient finite element temperature analysis under pulsed load allows a small number of pulses to be simulated. Extrapolation of numerical data for long-term cable life cycle is performed with symbolic regression in the Eureqa software. Eureqa uses genetic algorithms to find an optimal approximation of the experimental data in the form of a closed formula. This type of data fitting allows to extract the physical regularities explaining the process of thermal aging of the pulse cable},
  keywords={Coaxial cables;Power cables;Cable insulation;Thermal analysis;Communication cables;Thermal loading;Transient analysis;coaxial cable;pulse loading;cable insulation aging;FEA simulation},
  doi={10.1109/IEDS60447.2023.10426145},
  ISSN={},
  month={Nov},}@ARTICLE{10147811,
  author={Argotty-Erazo, Mauricio and Blázquez-Zaballos, Antonio and Argoty-Eraso, Carlos A. and Lorente-Leyva, Leandro L. and Sánchez-Pozo, Nadia N. and Peluffo-Ordóñez, Diego H.},
  journal={IEEE Access}, 
  title={A Novel Linear-Model-Based Methodology for Predicting the Directional Movement of the Euro-Dollar Exchange Rate}, 
  year={2023},
  volume={11},
  number={},
  pages={67249-67284},
  abstract={Predicting the price and trends of financial instruments is a major challenge in the financial industry, impacting investment decision-making efficiency for various stakeholders. Although numerous and effective artificial intelligence techniques have been applied to time series analysis, the prediction of exchange rate movements in the Forex market still necessitates parsimonious, interpretable, and accurate solutions. This paper presents a novel methodology for predicting the short-term directional movement of the euro-dollar exchange rate using market data, specifically by measuring price action. The proposed methodology prioritizes using market inflection points and the multidimensional nature of the differences between uptrends and downtrends to construct a linear discriminant function (LDA). The core of our methodology is our novel Linear Classifier Configurator (LCC) which includes stages for data preparation, feature selection, and detection of underlying structures. We validate the results and interpretations using the statistical power of parametric tests. The experiments use market data of the euro-dollar exchange rate in 15-minute and 1-week time frames. Additionally, we incorporate a collection of intraday winning trades provided by an algorithmic trading model applied between January 1999 and April 2023. The proposed LCC methodology achieves an out-of-sample classification accuracy of 98.77%, outperforming other methodologies based on sophisticated approaches such as Long Short-Term Memory (LSTM), Deep reinforcement learning (DRL), Wavelet analysis (WA), Sentiment analysis of textual content, Support Vector Machines (SVM), and Genetic Algorithms (GA). Furthermore, our methodology improves financial performance and reduces risk exposure in trading strategies, as well as it is useful in selecting variables and transferable to other financial assets.},
  keywords={Market research;Investment;Exchange rates;Predictive models;Forecasting;Data models;Support vector machines;Linear discriminant analysis (LDA);foreign exchange market (FOREX);machine learning (ML);supervised learning (SL);time series forecasting (TSF);trading systems},
  doi={10.1109/ACCESS.2023.3285082},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10063602,
  author={Verma, Dinesh C},
  booktitle={2022 IEEE 4th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Inference for Trustworthy Machine Intelligence: Challenges and Solutions}, 
  year={2022},
  volume={},
  number={},
  pages={27-34},
  abstract={In order to create AI/ML based solutions that will be trusted during production, issues that hamper usage of AI models in practical solutions needs to be addressed. Despite a significant interest in the area of AI/ML, the primary focus of the research community has been on the training of AI models, including their performance, trustworthiness, explainability and scalability. Training, however, is only one half of the work required to create an AI-based solution. The other half, using the trained model for inference during operations, is mistakenly considered a relatively mundane task. As a result, challenges arising in model inference time has received comparatively scant attention. Inference is when AI model is put into practice, resulting in many challenges that are worth the attention of the research community. Despite the existence of several pre-trained models on many Internet sites, anyone trying to build an AI/ML based solution would be hard-pressed to find a model that is useful, trustworthy and reliable, or suitable for the task. Even when a custom model is trained, the solution often falters because the use of model fails to account for the differences in the training and inference environment. In this paper, we identify those challenges and discuss how we can design a generic inference server for trustworthy AI/ML based solutions.},
  keywords={Training;Scalability;Production;Internet;Servers;Reliability;Artificial intelligence;Trustworthy AI;Inference Server;IoT Solutions;Self-Improving Systems},
  doi={10.1109/CogMI56440.2022.00014},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10356467,
  author={Kraus, Vivien and Benabdeslem, Khalid and Benkabou, Seif-Eddine and Mansouri, Dou El Kefel and Canitia, Bruno},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={RSMS: Robust Semi-supervised Multi-label Feature Selection for Regression}, 
  year={2023},
  volume={},
  number={},
  pages={99-105},
  abstract={Feature selection is a very important part of successful data mining applications, because it contributes to the simplification and explainability of the resulting model through dimensionality reduction. Feature selection methods exist for semi-supervised scenarios, in which a small subset of labeled instances is combined with a large batch of unlabeled instances to improve the learning performance. In a multi-label setting, feature selection identifies important features for all labels at once. However, some labels can also be irrelevant and then deteriorate feature selection. In a robust learning framework, removing these noisy labels can decrease the generalization error for the resulting regression model. In this work, we present a novel algorithm performing multi-label semi-supervised feature selection and label seleciton, and show its effectiveness on some publicly available datasets.},
  keywords={Dimensionality reduction;Benchmark testing;Feature extraction;Data models;Noise measurement;Data mining;Task analysis;Feature selection;Semi-supervised learning;Multi-label learning;Regression},
  doi={10.1109/ICTAI59109.2023.00022},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9867616,
  author={Ahmadzadeh, Omidreza and Rodriguez, Renato and Soudbakhsh, Damoon},
  booktitle={2022 American Control Conference (ACC)}, 
  title={Modeling of Li-ion batteries for real-time analysis and control: A data-driven approach}, 
  year={2022},
  volume={},
  number={},
  pages={392-397},
  abstract={This paper presents a data-driven model (DDM) of Li-ion batteries (LIBs). Accurate real-time modeling of LIBs allows for faster and more aggressive inputs and operations, improving their performance and safety. The DDM was developed using the enhanced single-particle model with electrolyte as the plant dynamics. A sparse model of the system was developed based on a library of potential terms. A sparsity-promoting optimization algorithm was used to balance the trade-off between the model accuracy and complexity. We compared the Sequentially Thresholded Ridge regression (STRidge) and a LASSO optimization and showed the advantages of using the STRidge. First, we developed a model using only voltage and current signals (Model I). Model I’s performance and robustness were assessed via validation and generalization tests, where the model achieved normalized root mean square error (NRMSE) values of less than 1.6%. Additionally, we evaluated Model I’s robustness to noise, achieving NRSME< 2%. We showed the trend of Model I parameters with the charge/discharge curves. However, this model required switching parameters as state-of-charge (SOC) changes. Therefore, we augmented the model by including terms related to the SOC in the library (Model II) to avoid switching. We showed the performance of Model II using the US06 highway driving cycle as the cell’s charge varied from 40%SOC to 20%SOC with small errors (NRMSE=4.78%). The results showed that the models accurately predict the dynamic response of the cells in the simulated scenarios. The models are interpretable as they have explicit input and output terms and allow for efficient control design.},
  keywords={Lithium-ion batteries;Switches;Predictive models;Robustness;Real-time systems;Libraries;Data models},
  doi={10.23919/ACC53348.2022.9867616},
  ISSN={2378-5861},
  month={June},}@INPROCEEDINGS{10150312,
  author={Rezabek, Filip and Bosk, Marcin and Carle, Georg and Ott, Jörg},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={TSN Experiments Using COTS Hardware and Open-Source Solutions: Lessons Learned}, 
  year={2023},
  volume={},
  number={},
  pages={466-471},
  abstract={Time-Sensitive Networking (TSN) brings deterministic behavior to Ethernet-based systems, resulting in hardware and software supporting various TSN standards. Using TSN-capable Commercial off-the-Shelf (COTS) hardware and open-source software brings several challenges. These are especially visible while performing performance evaluation of various TSN standards. In this work, we present the most significant challenges we faced using such deployments. Starting with the Precision Time Protocol, we observe its implementation being incompatible with that of the Time-Aware Priority Shaper. We present several solutions on how to overcome the identified behavior and compare them proposing best fitting solution for any setup. Next, we focus on the Network Interface Cards (NICs) and their behavior in presence of various TSN standards. We observe that the hardware offload features aiming to improve performance sometimes introduce performance artifacts worthwhile of investigation. Further, even though the Credit-Based Shaper configuration parameters can theoretically be computed for various NICs, due to the internal optimization of some, the calculated parameters may not hold. Our findings are intended to help the community improve observed results and solve challenges in using the COTS hardware and open-source software. We believe additional documentation detailing the implementation aspects of TSN standards in hardware would be beneficial in explanation of observed behavior.},
  keywords={Pervasive computing;Performance evaluation;Protocols;Conferences;Hardware;Behavioral sciences;Network interfaces;TSN;COTS;Open-Source;PTP;Experiments},
  doi={10.1109/PerComWorkshops56833.2023.10150312},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10793185,
  author={Jin, Hongwei and Papadimitriou, George and Raghavan, Krishnan and Zuk, Pawel and Balaprakash, Prasanna and Wang, Cong and Mandal, Anirban and Deelman, Ewa},
  booktitle={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Large Language Models for Anomaly Detection in Computational Workflows: From Supervised Fine-Tuning to In-Context Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-17},
  abstract={Anomaly detection in computational workflows is critical for ensuring system reliability and security. However, traditional rule-based methods struggle to detect novel anomalies. This paper leverages large language models (LLMs) for workflow anomaly detection by exploiting their ability to learn complex data patterns. Two approaches are investigated: (1) supervised fine-tuning (SFT), where pretrained LLMs are fine-tuned on labeled data for sentence classification to identify anomalies, and (2) in-context learning (ICL), where prompts containing task descriptions and examples guide LLMs in few-shot anomaly detection without fine-tuning. The paper evaluates the performance, efficiency, and generalization of SFT models and explores zeroshot and few-shot ICL prompts and interpretability enhancement via chain-of-thought prompting. Experiments across multiple workflow datasets demonstrate the promising potential of LLMs for effective anomaly detection in complex executions.},
  keywords={Training;Analytical models;Accuracy;Large language models;Computational modeling;High performance computing;Transfer learning;Reliability;Security;Anomaly detection;anomaly detection;large language models;supervised fine-tuning;in-context learning;computational workflows},
  doi={10.1109/SC41406.2024.00098},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9867338,
  author={Breese, Bennett and Kumar, Manish and Bolender, Michael and Casbeer, David W.},
  booktitle={2022 American Control Conference (ACC)}, 
  title={Physics-Based Neural Networks for Modeling & Control of Aerial Vehicles}, 
  year={2022},
  volume={},
  number={},
  pages={3218-3223},
  abstract={In recent years artificial intelligence (AI) and machine learning techniques have found immense success in the fields of pattern recognition, classification, and data analytics. These techniques also have shown to provide viable means of controlling and modeling of uncertain, nonlinear dynamic systems. However, such techniques have not yet found widespread adoption in controls due to concerns in reliability, interpretability, and stability. In the past, much of the work in the field of dynamics has been based on well understood physical principles (i.e., Newtonian, Lagrangian, and Hamiltonian mechanics), while control has been model-based, as they adequately address the aforementioned concerns. The presented work attempts to retain the benefits of both AI and physics-based control, by using recently developed neural networks that incorporate Lagrangian mechanics into the learning scheme to create an inverse dynamic model of a quadcopter. The inverse dynamic model is utilized in developing a control scheme that is shown to learn the changes in system parameters effectively in an online fashion. The proposed control scheme is validated with the help of extensive simulation studies performed on a quadcopter, and the performance is compared to simple adaptive control for cases where mass and inertia change in flight for complex trajectories.},
  keywords={Adaptation models;Data analysis;Neural networks;Machine learning;Stability analysis;Trajectory;Pattern recognition},
  doi={10.23919/ACC53348.2022.9867338},
  ISSN={2378-5861},
  month={June},}@INPROCEEDINGS{10356238,
  author={Chaddad, Ahmad and Wu, Yihang},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Domain Adaptation in Machine Learning: A Practical Simulation Study}, 
  year={2023},
  volume={},
  number={},
  pages={754-761},
  abstract={Domain adaptation (DA) is a critical technique in machine learning, designed to alleviate distribution differences between training and test sets by leveraging information from similar datasets. This paper presents a practical simulation of both widely-used and recent DA techniques, with a specific focus on unsupervised learning scenarios where labels are only available in the source domain. We thoroughly investigate the impact of these methods on various publicly available datasets, providing detailed explanations of our findings. Furthermore, we conduct an ablation study and elaborate extensively on the simulation results. Our study offers valuable information on the resilience of selected DA algorithms, highlighting the importance of appropriate datasets and neural network architectures with training methodologies to achieve optimal performance in DA tasks.},
  keywords={Training;Machine learning algorithms;Simulation;Neural networks;Training data;Machine learning;Task analysis;Domain adaptation;machine learning;deep learning},
  doi={10.1109/ICTAI59109.2023.00116},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10429928,
  author={Miller, John A. and Barna, Nasid Habib and Rana, Subas and Arpinar, I. Budak and Liu, Ninghao},
  booktitle={2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Knowledge Enhanced Deep Learning: Application to Pandemic Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={42-51},
  abstract={Deep Learning has been successfully applied to many problem domains, yet its advantages have been slow to emerge for time series forecasting. For example, in the well-known M Competitions, until recently, hybrids of traditional statistical or machine learning (e.g., gradient boosting) techniques were the top performers. With the recent architectural advances in deep learning being applied to time series forecasting, such as encoder-decoders with attention, transformers, representation learning, and graph neural networks, deep learning has begun to show its advantages. Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, ignorance of accumulated scientific knowledge, and interpretability of the model. Today, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge. There is ongoing research examining how to utilize or inject knowledge into deep learning models. The state-of-the-art approaches are reviewed and suggestions for further work are provided. Recommendations for how this can be applied to future pandemics are given.},
  keywords={Deep learning;Training;Pandemics;Time series analysis;Predictive models;Transformers;Forecasting;Time series;pandemic;deep learning},
  doi={10.1109/CIC58953.2023.00016},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10356598,
  author={Peng, Tao and Xue, Yulin and Li, Jun and Xu, Jianhua},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={A Novel Label Selection Algorithm Based on Principal Component Analysis and Sparse Approximation Solution for Multi-label Classification*}, 
  year={2023},
  volume={},
  number={},
  pages={532-537},
  abstract={In multi-label classification, an instance may be associated with multiple labels simultaneously and thus the class labels are correlated one another. As various applications emerge, besides large instance size and high feature dimensionality, the dimensionality of label space also grows quickly, which would increase computational costs and even deteriorate classification performance. To this end, dimensionality reduction strategy is applied to label space via exploiting label correlation information, which covers label embedding and label selection techniques. Recently a lot of label embedding work has been conducted, but less attention has been paid to label selection techniques due to its difficulty. In this case, it is still an open problem how to design more effective label selection techniques for multi-label classification. Column subset selection problem (CSSP) originally is a mathematical issue in matrix theory to select a small portion of columns from a large-scale matrix for more interpretable data summarization. Therefore, such a CSSP naturally becomes an attractive mathematical representation for label selection, which is NP-hard and generally is solved via greedy strategy. In this paper, we build a two-stage label selection algorithm. At first, we apply principal component analysis (PCA) to reduce the dimensionality of the label matrix to obtain a low dimensional real matrix as the right side term in linear systems. Then, we use sparse approximation (SA) solution for linear systems to choose several informative columns from the label matrix as approximations of the low dimensional real matrix, which ultimately obtains the sub-optimal label subset of original label matrix. This new label selection method based on PCA and SA is referred to as PCASA simply. Our proposed method is validated experimentally to work well on six benchmark data sets with more than 100 labels.},
  keywords={Linear systems;Performance evaluation;Dimensionality reduction;Correlation;Benchmark testing;Sparse representation;Approximation algorithms;multi-label classification;principal component analysis;sparse approximation solution;label selection},
  doi={10.1109/ICTAI59109.2023.00085},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11032057,
  author={Pavel, Saidur R. and Haider, Mirza A. and Zhang, Yimin D. and Ding, Yanwu and Shen, Dan and Pham, Khanh and Chen, Genshe},
  booktitle={2025 IEEE International Radar Conference (RADAR)}, 
  title={Time-Varying Direction-of-Arrival Estimation Exploiting Mamba Network}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Direction-of-arrival (DOA) estimation for moving targets presents a significant challenge in array signal processing. Traditional DOA estimation and tracking methods often encounter limitations due to the infeasibility of acquiring large volumes of stationary data and performing subspace-based processing over many snapshots, and lead to high computational costs. Recently, deep learning techniques have been effectively applied in DOA estimation, owing to their reduced complexity during inference. In this paper, we propose the use of Mamba network as a state-space model-based approach to estimate and track DOAs that vary snapshot-by-snapshot. The proposed network is interpretable and hardware-efficient, making it advantageous for training and real-time inference.},
  keywords={Deep learning;Training;Direction-of-arrival estimation;Target tracking;Simulation;Estimation;Radar;Radar tracking;Real-time systems;State-space methods;Time-varying DOA estimation;state-space model;deep learning;Mamba},
  doi={10.1109/RADAR52380.2025.11032057},
  ISSN={},
  month={May},}@INPROCEEDINGS{10256581,
  author={Yang, Yifan and Quan, Xinyi and Sun, Yue},
  booktitle={2023 IEEE 13th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)}, 
  title={Enhanced Social Force Model for Service Robots in Various Environments: Calibration and Simulation}, 
  year={2023},
  volume={},
  number={},
  pages={89-94},
  abstract={With the increasing emphasis on social-awareness navigation of service robots, traditional social force models require improvements and recalibration. This paper proposes an enhanced social force model that integrates robot and group forces with the traditional one. The model is simulated in various scenes of the JRDB dataset, which is categorized into three categories — outdoor, indoor&open, and indoor&narrow. We use the maximum likelihood estimation method and genetic algorithm to calibrate parameters separately for each category and provide an explanation of optimal parameter values based on environmental characteristics. Through comparisons of predicted trajectories with real ones, we demonstrate that our model enables robots to behave more like humans in different environments.},
  keywords={Maximum likelihood estimation;Service robots;Navigation;Force;Predictive models;Control systems;Trajectory},
  doi={10.1109/CYBER59472.2023.10256581},
  ISSN={2642-6633},
  month={July},}@INPROCEEDINGS{11032063,
  author={Hicks, Bruce and Biswas, Sabyasachi and Gurbuz, Ali Cafer},
  booktitle={2025 IEEE International Radar Conference (RADAR)}, 
  title={Learnable Gaussian Filter-Based Automatic RF Waveform Modulation Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In this work, we propose an automatic modulation recognition (AMR) method leveraging complex-valued convolutional neural networks (CV-CNNs) with parameterized, learnable Gaussian filters. Traditional AMR techniques often require complex pre-processing and transformation stages, which are computationally expensive and hinder real-time applications. Our proposed architecture processes raw complex IQ radiofrequency(RF) data directly, incorporating parameterized filters as learnable bandpass-like functions for efficient time-frequency feature extraction. This filter structure reduces the number of learnable parameters, enhancing interpretability and robustness in dynamic RF environments. We evaluate the model on a synthetic dataset of 15 radar waveform classes across three channel types-ideal, Rayleigh, and Rician-spanning signal-tonoise ratios (SNRs) from -20 dB to 18 dB. The proposed method outperforms traditional models in all key classification metrics, achieving an average accuracy above 85 % and demonstrating consistently high performance across varying SNRs. Additionally, it exhibits greater resilience to noise compared to baseline models. Comparative analysis shows that the proposed approach effectively distinguishes between diverse radar modulation classes, even under challenging conditions.},
  keywords={Radio frequency;Time-frequency analysis;Filters;Modulation;Radar;Robustness;Sensors;Convolutional neural networks;Synthetic data;Signal to noise ratio;Waveform modulation recognition;Learnable filters;Complex-valued CNN;CVG-Net;RF sensing},
  doi={10.1109/RADAR52380.2025.11032063},
  ISSN={},
  month={May},}@INPROCEEDINGS{10371666,
  author={Juang, Chia-Feng and Chen, Yu-Jhong},
  booktitle={2023 14th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)}, 
  title={Multiobjective Evolutionary Learning of Interval Type-2 Fuzzy Controllers for a Wall-Following Wheeled Mobile Robot}, 
  year={2023},
  volume={},
  number={},
  pages={697-698},
  abstract={This paper proposes a multiobjective evolutionary learning approach of interval type-2 fuzzy controllers (IT2FC) to train a wheeled robot to execute the task of wall following. The data-driven approach optimizes a set of non-dominated IT2FCs through the multiobjective non-dominated sorting genetic algorithm II (NSGA II). The employment of the IT2FC instead of a type-1 fuzzy controller is to improve the resistance ability of the controller to sensor measurement noise. In the robot wall-following control task, three objectives are defined, including proper robot-wall distance, high moving speed, and high model interpretability. This paper formulates the learning task as a multiobjective optimization problem and finds solutions through the NSGA II. Simulations are performed to show the effectiveness and advantage of the proposed method.},
  keywords={Training;Resistance;Robot sensing systems;Mobile robots;Noise measurement;Task analysis;Informatics;data-driven learning;evolutionary robots;fuzzy control;wall-following control},
  doi={10.1109/IIAI-AAI59060.2023.00139},
  ISSN={2472-0070},
  month={July},}@INPROCEEDINGS{10859661,
  author={Zhao, Xueqi},
  booktitle={2024 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Optimization Design Method of Ventilation System Based on Fuzzy Logic in Industrial Ventilation Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Traditional design methods based on empirical formulas or deterministic models are difficult to effectively cope with the complexity and uncertainty of the factory production environment. In this paper, a fuzzy logic-based design method for industrial ventilation system optimization is proposed. The method first establishes a fuzzy optimization model containing objective functions such as ventilation effect, energy consumption and investment cost. Then the fuzzy optimization model is solved using a genetic algorithm to generate a set of potential optimal solutions. Finally, these solutions are comprehensively evaluated using fuzzy decision theory, and the optimal solution is selected as the final ventilation system design. The results of the study show that the start-up time is 10–18 minutes, which is 3–5 minutes faster than the previous system. The introduction of fuzzy logic also makes the method highly interpretable, providing engineers with clear decision support.},
  keywords={Fuzzy logic;Energy consumption;Uncertainty;Design methodology;Optimization models;Ventilation;Cognition;Optimization;Intelligent control;Indoor air quality;ventilation system optimization;fuzzy logic;industrial ventilation;fuzzy inference},
  doi={10.1109/ICIICS63763.2024.10859661},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10820588,
  author={Winnicki, John and Poitevin, Frédéric and Li, Haoyuan and Darve, Eric},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Matrix Sketching for Online Analysis of LCLS Imaging Datasets}, 
  year={2024},
  volume={},
  number={},
  pages={2144-2153},
  abstract={X-ray light source facilities such as the Linac Coherence Light Source (LCLS) at SLAC National Accelerator Laboratory generate massive amounts of data that need to be analyzed quickly to inform ongoing experiments. The analysis of data streams coming from various parts of the instrument has potential to feed back into instrument operation or experiment steering. For example, shot-to-shot images of the beam profile inform on the quality of the beam delivery while downstream data read from large area detectors inform on the state of diffraction experiments carried on samples of interests at various beamlines. However, the high repetition rate and high dimensionality of these data streams make their analysis challenging, both in terms of scalability and interpretability. In this work, we propose an image monitoring and classification framework that follows a three-stage process: dimensionality reduction using principal component analysis on a matrix sketch, visualization using UMAP, and clustering using OPTICS. In the dimensionality reduction step, we combine the Priority Sampling algorithm with a modified Frequent Directions algorithm to produce a rank-adaptive accelerated matrix sketching (ARAMS) algorithm, wherein practitioners specify the target error of the sketch as opposed to the rank. Furthermore, the framework is parallel, enabling real-time analysis of the underpinning structure of the data. This framework demonstrates strong empirical performance and scalability. We explore its effectiveness on both beam profile data and diffraction data from recent LCLS experiments.},
  keywords={Dimensionality reduction;Scalability;Instruments;Clustering algorithms;X-ray diffraction;Real-time systems;Classification algorithms;Streams;Monitoring;Light sources;matrix sketching;dimension reduction;parallel processing;approximation;rank-adaptive;data exploration},
  doi={10.1109/SCW63240.2024.00269},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10747920,
  author={Yang, Tianqin and Tam, Vincent W.L. and Lam, Edmund Y. and Kan, Alex H.S. and Aung, Khant Nyar and Lee, Allie},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={MetaNODES: A Virtual Reality-Based Approach to Intelligent Neuro-Ophthalmology Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Virtual Reality (VR), as the technological cornerstone of the metaverse, has attracted much attention in the digital transformation of medical education. In the medical education of ophthalmology, teaching neuro-ophthalmologic disease diagnosis is considered crucial but challenging due to its complex principles of neurology and anatomy. Leveraging its high interactivity and immersion, the VR can turn the conventional and difficult learning process to gain professional neuro-ophthalmologic knowledge into an intuitive experience with explainable physiological and anatomical features. Inspired by this idea, this paper presented the Metaverse Neuro-Ophthalmologic Disorder Education System (MetaNODES), a VR-based intelligent pedagogical solution for neuro-ophthalmology education deployed on Meta’s Oculus Quest 2. The Unity game engine was adopted to replicate the realistic clinical diagnostic process of various neuro-ophthalmologic disorders. Under the guidance of professional ophthalmology experts, our team designed a quantitative visualization model for sophisticated gaze direction, face morph, and the body motion control of a VR patient to reproduce the real-time symptom responses based on the user interface (UI) operation and motion state change of the Quest controller. Dedicated scenario modes were carefully designed and implemented for the precision of the clinical manifestations as well as the hardware characteristics of the VR device. The evaluation conducted on a group of students revealed that the MetaNODES system can assist them to better appreciate the apparent symptoms and comprehending the underlying mechanisms with a deeper engagement. To the best of our knowledge, the MetaNODES system is a pioneering effort to integrate VR into neuro-ophthalmology education. It initiated a fundamental framework of leveraging common VR devices to deploy Metaverse to ophthalmology education in online learning environments.},
  keywords={Visualization;Solid modeling;Metaverse;Education;Games;Virtual reality;User interfaces;Ophthalmology;Medical diagnostic imaging;Engines;virtual reality;metaverse;medical education;neuro-ophthalmology;gamified learning;Oculus Quest;Unity game engine},
  doi={10.1109/DEMOcon63027.2024.10747920},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10429920,
  author={Laugier, Léo and Vadapalli, Raghuram and Bonald, Thomas and Dixon, Lucas},
  booktitle={2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={KNNs of Semantic Encodings for Rating Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={82-91},
  abstract={This paper explores a novel application of textual semantic similarity to user-preference representation for rating prediction. The approach represents a user's preferences as a graph of textual snippets from review text, where the edges are defined by semantic similarity. This textual, memory-based approach to rating prediction enables review-based explanations for recommendations. The method is evaluated quantitatively, highlighting that leveraging text in this way outperforms both strong memory-based and model-based collaborative filtering baselines.},
  keywords={Text analysis;Computational modeling;Collaborative filtering;Semantics;Natural languages;Encoding;Internet;Natural Language Processing;Graphs and net-works;Web text analysis},
  doi={10.1109/CIC58953.2023.00020},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11077563,
  author={Ramasamy, Vijayalakshmi and Barett, Seth and Dorai, Gokila and Zumbach, Jessica},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing}, 
  year={2025},
  volume={},
  number={},
  pages={514-520},
  abstract={Privacy policy documents are often lengthy, complex, and difficult for non-expert users to interpret, leading to a lack of transparency regarding the collection, processing, and sharing of personal data. As concerns over online privacy grow, it is essential to develop automated tools capable of analyzing privacy policies and identifying potential risks. In this study, we explore the potential of interactive graph visualizations to enhance user understanding of privacy policies by representing policy terms as structured graph models. This approach makes complex relationships more accessible and enables users to make informed decisions about their personal data (RQ1). We also employ graph mining algorithms to identify key themes, such as User Activity and Device Information, using dimensionality reduction techniques like t-SNE and PCA to assess clustering effectiveness. Our findings reveal that graph-based clustering improves policy content interpretability. It highlights patterns in user tracking and data sharing, which supports forensic investigations and identifies regulatory non-compliance. This research advances AI-driven tools for auditing privacy policies by integrating interactive visualizations with graph mining. Enhanced transparency fosters accountability and trust.},
  keywords={Dimensionality reduction;Privacy;Data privacy;Text analysis;Forensics;Data visualization;Natural language processing;Object recognition;Robots;Principal component analysis;Privacy Policy Document Analysis Graph Mining Dimensionality Reduction (DR) Machine Learning (ML) NLP Legal Documents AI-driven Compliance Data Transparency},
  doi={10.1109/AIRC64931.2025.11077563},
  ISSN={},
  month={May},}@INPROCEEDINGS{10830968,
  author={Petrov, Marios and Atyabi, Adham},
  booktitle={2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Enhancing MI-BCI Classification with Subject-Specific Spatial Evolutionary Optimization and Transfer Learning}, 
  year={2024},
  volume={},
  number={},
  pages={4770-4777},
  abstract={Motor imagery BCI systems have demonstrated success in single-subject laboratory settings, where a classifier is trained using data from a single BCI user. Typically, multiple training sessions are needed to enhance the user's performance. To address this, the BCI community has developed Subject Transfer techniques, which reduce training time by leveraging data from other subjects, primarily as pretraining samples. This study introduces a novel subject transfer method that employs Wavelet Packet Decomposition (WPD) followed by Common Spatial Patterns (CSP) for feature extraction. Once the spatial features are extracted, binary particle swarm optimization (BPSO) is applied for feature selection. In this approach, 40% of the target subject's data is used to derive a BPSO filter, which is then applied to the data from all subjects before training and testing. The binary vector produced by BPSO acts as a filter, optimizing model performance by focusing on the most class-representative features. Classification is performed using linear support vector machines (SVMs) trained via Stochastic Gradient Descent (SGD), enabling the hyperplane to be pre-trained and allowing for the effective use of data collected outside of the user session in an interpretable way. The proposed method was evaluated using three benchmark BCI Competition datasets: III-IVa, IV-I, and IV-IIa. It outperformed the single-trial MI-EEG classification state-of-the-art by 3.4% on the BCI Competition III dataset IVa and by 8.4% on the BCI Competition IV dataset IIa. Additionally, it surpassed the subject-transfer MI-EEG classification state-of-the-art by 4.1 % on the BCI Competition III-IVa dataset.},
  keywords={Training;Support vector machines;Protocols;Transfer learning;Stochastic processes;Feature extraction;Motors;Brain modeling;Wavelet packets;Vectors},
  doi={10.1109/SMC54092.2024.10830968},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10356464,
  author={Zheng, Renjie and Chen, Qin and Zhou, Jie and Tian, Junfeng and He, Liang},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Modeling Intra- and Inter-Modal Alignment with Optimal Transport for Visual Dialog}, 
  year={2023},
  volume={},
  number={},
  pages={805-812},
  abstract={Visual dialog aims to address a sequence of questions by effectively reasoning over both the dialog history and image content. While existing methods primarily focus on devising various attention mechanisms to capture interactions between different modalities, explicit signals encouraging semantic alignment in the visual dialog are seldom utilized. In this paper, we present a novel approach that leverages Optimal Transport to provide explicit and interpretable training signals to guide intra- and inter-modal alignment for the text and image in the visual dialog. Specifically, our approach consists of two kinds of alignment modules, Word-Word Alignment (WWA) and Region-Word Alignment (RWA). The WWA module learns latent relationships between a given question and a dialog history to align different concepts or pronouns that represent the same entity. As for the RWA module, it models the internal structures of text and images with graphs and performs graph matching for region-word alignment. We perform experiments on the benchmark dataset Visdial v1.0, and the experimental results show that our proposed approach achieves new state-of-the-art performance with respect to most metrics.},
  keywords={Training;Measurement;Visualization;Adaptation models;Semantics;Benchmark testing;Cognition;visual dialog;alignment;optimal transport},
  doi={10.1109/ICTAI59109.2023.00123},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9973767,
  author={Shi, Hongquan and Zhang, Xu and Chen, Yingling},
  booktitle={2022 8th International Symposium on System Security, Safety, and Reliability (ISSSR)}, 
  title={Air Defense Mission Planning of Ship Formation based on Event Network and Monte Carlo Simulation}, 
  year={2022},
  volume={},
  number={},
  pages={55-60},
  abstract={Modern ship formation air defense requires rapid organization of combat resources in the environment of multi-directional high-speed invasion of enemy targets, making full use of interception windows to defense efficiently. Aiming at the characteristics of complex resource combinations and the high requirement of dynamic optimization in this process, to implement global optimization decisions for the overall situation and evolution prediction of air defense, an air defense mission planning method for fleet formation based on an event network model is studied. By defining the type of each element-event in the event graph, the causal relationship between events is determined, the local probability is determined, and the real transition probability between two events is dynamically adjusted. Aiming at the lowest expected cost target, an automatic generation algorithm of air defense mission scheme based on decision event priority allocation and Monte Carlo simulation is designed. The method verification was carried out through the case. The two preferred regulatory algorithms: genetic algorithm and simulation annealing were compared. The results showed that the model proposed can clearly express the battlefield situation, have a global optimization ability for multiple targets, and be interpretable.},
  keywords={Monte Carlo methods;Atmospheric modeling;Heuristic algorithms;Simulated annealing;Planning;Safety;Security;ship formation air defense;mission planning;event network;monte Carlo simulation},
  doi={10.1109/ISSSR56778.2022.00016},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10150309,
  author={Kawashima, Hiroaki},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={Estimating Networks of Interaction in Fish Schools with a Minimal Model}, 
  year={2023},
  volume={},
  number={},
  pages={194-199},
  abstract={This paper addresses the problem of interaction-network estimation in fish schooling to identify individuals in a group that drives the overall group behavior. We propose a simple linear approximation of the interaction of a group so that the influence among individuals can be estimated in an interpretable manner. Specifically, we build our model based on a well-known attraction term in collective behavior models where the velocity of each individual is assumed to be determined by the relative position of other individuals. The extended model with the addition of an autonomous term is shown to enable stable estimation of the interaction network and analysis of the characterization of each individual.},
  keywords={Pervasive computing;Analytical models;Navigation;Conferences;Estimation;Linear approximation;Data models;collective behavior;interaction network;fish school;group navigation},
  doi={10.1109/PerComWorkshops56833.2023.10150309},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10820702,
  author={Padovani, G. and Anantharaj, V. and Sacco, L. and Kurihana, T. and Bunino, M. and Tsolaki, K. and Girone, M. and Antonio, F. and Sopranzetti, C. and Fronza, M. and Fiore, S.},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={A software ecosystem for multi-level provenance management in large-scale scientific workflows for AI applications}, 
  year={2024},
  volume={},
  number={},
  pages={2024-2031},
  abstract={Scientific workflows and provenance are two faces of the same medal. While the former addresses the coordinated execution of multiple tasks over a set of computational resources, the latter relates to the historical record of data from its original sources. This paper highlights the importance of tracking multi-level provenance metadata in complex, AI-based scientific workflows as a way to (i) foster and (ii) expand documentation of experiments, (iii) enable reproducibility, (iv) address interpretability of the results, (v) facilitate performance bottlenecks diagnosis, and (vi) advance provenance exploration and analysis opportunities.},
  keywords={High performance computing;Conferences;Ecosystems;Documentation;Metadata;Software;Reproducibility of results;Artificial intelligence;Faces;Provenance;workflow;ML tasks;multi-level},
  doi={10.1109/SCW63240.2024.00253},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10099308,
  author={Jiang, Xiaopeng and On, Thinh and Phan, NhatHai and Mohammadi, Hessamaldin and Mayyuri, Vijaya Datta and Chen, An and Jin, Ruoming and Borcea, Cristian},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={Zone-based Federated Learning for Mobile Sensing Data}, 
  year={2023},
  volume={},
  number={},
  pages={141-148},
  abstract={This paper proposes Zone-based Federated Learning (ZoneFL) to simultaneously achieve good model accuracy while adapting to user mobility behavior, scaling well as the number of users increases, and protecting user data privacy. ZoneFL divides the physical space into geographical zones mapped to a mobile-edge-cloud system architecture for good model accuracy and scalability. Each zone has a federated training model, called a zone model, which adapts well to data and behaviors of users in that zone. Benefiting from the FL design, the user data privacy is protected during the ZoneFL training. We propose two novel zone-based federated training algorithms to optimize zone models to user mobility behavior: Zone Merge and Split (ZMS) and Zone Gradient Diffusion (ZGD). ZMS optimizes zone models by adapting the zone geographical partitions through merging of neighboring zones or splitting of large zones into smaller ones. Different from ZMS, ZGD maintains fixed zones and optimizes a zone model by incorporating the gradients derived from neighboring zones' data. ZGD uses a self-attention mechanism to dynamically control the impact of one zone on its neighbors. Extensive analysis and experimental results demonstrate that ZoneFL significantly outperforms traditional FL in two models for heart rate prediction and human activity recognition. In addition, we developed a ZoneFL system using Android phones and AWS cloud. The system was used in a heart rate prediction field study with 63 users for 4 months, which demonstrated the feasibility of ZoneFL in real-life.},
  keywords={Training;Heart rate;Adaptation models;Data privacy;Federated learning;Systems architecture;Data models;federated learning;smart phones;mobile sensing;edge computing},
  doi={10.1109/PERCOM56429.2023.10099308},
  ISSN={2474-249X},
  month={March},}@ARTICLE{10374089,
  author={Wan, Genyi and Ye, Zhen and Xu, Yusheng and Huang, Rong and Zhou, Yingying and Xie, Huan and Tong, Xiaohua},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Multimodal Remote Sensing Image Matching Based on Weighted Structure Saliency Feature}, 
  year={2024},
  volume={62},
  number={},
  pages={1-16},
  abstract={Matching multimodal remote sensing images (MRSIs) is a challenging task. Due to significant nonlinear radiation differences (NRDs), traditional image-matching methods cannot achieve satisfactory results. This article shows that structural information can get more robust matching results compared with texture information (i.e., gradient features) from images. In order to better explore the structural information of images, this article proposes an MRSI matching method using structure saliency features, called weighted structure saliency feature (WSSF). Two strategies are investigated and integrated into WSSF to improve the matching performance. The scale space is constructed based on the pointwise shape-adaptive texture scale filtering, which can better retain the structure features, and the second-order Gaussian steerable filtering, edge confidence map, and phase features are combined to establish the structural saliency map combined with second-order Gaussian steerable filtering, which is much more robust to NRD than traditional gradient map. The performance of the proposed method was evaluated on a total of 120 image pairs from two MRSI datasets and compared with the state-of-the-art matching methods, including the histogram of the orientation of weighted phase (HOWP), locally normalized image feature transform (LNIFT), co-occurrence filter space matching (CoFSM), radiation-variation insensitive feature transform (RIFT), local phase sharpness orientation (LPSO), and position-scale-orientation scale-invariant feature transform (SIFT) (PSO-SIFT). The experimental results indicate that WSSF obtains satisfactory and reliable results in terms of success rate (SR) and matching accuracy. Compared with the above six methods, the matching accuracy of WSSF is improved by more than 20.275%, and the SR is improved by over 5.833%. The source code will be publicly available at https://github.com/WGY-RS/ WSSF.},
  keywords={Feature extraction;Filtering;Image edge detection;Learning systems;Remote sensing;Image matching;Power capacitors;Log-polar descriptor;multimodal image matching;pointwise shape-adaptive texture filtering (PSATF);structure saliency feature},
  doi={10.1109/TGRS.2023.3347259},
  ISSN={1558-0644},
  month={},}@ARTICLE{10050437,
  author={Liu, Chang and Tang, Lixin and Zhao, Chenche},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Novel Dynamic Operation Optimization Method Based on Multiobjective Deep Reinforcement Learning for Steelmaking Process}, 
  year={2024},
  volume={35},
  number={3},
  pages={3325-3339},
  abstract={This article studies a dynamic operation optimization problem for a steelmaking process. The problem is defined to determine optimal operation parameters that bring smelting process indices close to their desired values. The operation optimization technologies have been applied successfully for endpoint steelmaking, but it is still challenging for the dynamic smelting process because of the high temperature and complex physical and chemical reactions. A framework of deep deterministic policy gradient is applied to solve the dynamic operation optimization problem in the steelmaking process. Then, an energy-informed restricted Boltzmann machine method with physical interpretability is developed to construct the actor and critic networks in reinforcement learning (RL) for dynamic decision-making operations. It can provide a posterior probability for each action to guide training in each state. Furthermore, in terms of the design of neural network (NN) architecture, a multiobjective evolutionary algorithm is used to optimize the model hyperparameters, and a knee solution strategy is designed to balance the model accuracy and complexity of neural networks. Experiments are conducted on real data from a steelmaking production process to verify the practicability of the developed model. The experimental results show the advantages and effectiveness of the proposed method compared with other methods. It can meet the requirements of the specified quality of molten steel.},
  keywords={Optimization;Steel;Furnaces;Smelting;Production;Process control;Closed box;Deep reinforcement learning (DRL);dynamic operation optimization;energy-informed restricted Boltzmann machine (EIRBM);multiobjective optimization;steelmaking process},
  doi={10.1109/TNNLS.2023.3244945},
  ISSN={2162-2388},
  month={March},}@INPROCEEDINGS{10434597,
  author={Chauhan, Navdeep Kaur and Kaur, Navdeep},
  booktitle={2023 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Predicting Cardiovascular Diseases Using Machine Learning Integrated with Feature Selection Through Blue Whale Optimization}, 
  year={2023},
  volume={10},
  number={},
  pages={464-469},
  abstract={Cardiovascular diseases (CVDs) continue to be a significant global health concern, demanding the creation of precise and timely prediction models for efficient disease treatment. In particular, the feature selection through the blue whale optimization algorithm is used in this study's early prediction in the classification of cardiovascular disorders utilizing machine learning techniques. Machine learning has become a potent tool for deciphering intricate medical data and producing precise forecasts. The blue whale optimization algorithm, a metaheuristic algorithm inspired by blue whale feeding behavior, is used in this study for feature selection. This algorithm enhances the effectiveness and performance of the prediction model by efficiently navigating the search space to locate the most pertinent information for CVD classification. The suggested process is broken down into various steps. An extensive dataset encompassing clinical data, demographic data, medical history, and the results of diagnostic tests is initially gathered from a wide range of patients. The most insightful characteristics from the dataset are then chosen using the blue whale optimization process, which lowers the model's dimensionality and improves its interpretability. The efficiency of the suggested methodology is shown by the experimental findings from real-world CVD datasets. In comparison to conventional methods, the machine learning model with feature selection through the blue whale optimization algorithm achieves higher accuracy and increased performance. This emphasizes the importance of using cutting-edge optimization strategies for feature selection in CVD classification.},
  keywords={Machine learning algorithms;Machine learning;Feature extraction;Prediction algorithms;Whale optimization algorithms;Classification algorithms;Cardiovascular diseases;Cardiovascular diseases (CVDs);Blue whale optimization (BWO);Random Forest (RF)},
  doi={10.1109/UPCON59197.2023.10434597},
  ISSN={2687-7767},
  month={Dec},}@ARTICLE{10947268,
  author={Wang, Jihao and Wang, Xiaochan and Shi, Yinyan and Wu, Zhongxian and Zhang, Xiaolei},
  journal={IEEE Sensors Journal}, 
  title={Real-Time Variable-Weight Aquaculture Water Quality Index Evaluation Method Based on Adaptive Sliding Window}, 
  year={2025},
  volume={25},
  number={10},
  pages={17293-17308},
  abstract={Establishing an aquaculture water quality index (WQI) enables comprehensive water quality assessment and ensures aquaculture safety; however, existing WQI techniques are constrained by delays in conventional sampling and analysis methods, and their fixed weighting coefficients lack responsiveness to real-time changes. This article proposes a real-time variable-weight assessment method, termed “dynamic improvement entropy method (D-IEM),” based on an adaptive sliding window (AVSW). An Internet of Things (IoT) water quality monitoring system is developed to acquire real-time data, and a variable-weight WQI model is designed using pH, nonionic ammonia, chemical oxygen demand (COD), and phosphate. The D-IEM method dynamically calculates WQI weighting coefficients through information entropy and AVSW. In order to address the high cost and potential data loss in phosphate detection, interpretable evolutionary algorithms (EAs) optimize an extremely randomized trees (ERTs) model, which predicts phosphate concentrations and ensures WQI stability. The model demonstrates excellent performance, achieving a mean error of 1.136% for phosphate prediction under an equally weighted WQI assessment. Experimental results confirm that D-IEM effectively captures WQI weight change trends, enabling dynamic weight calculation and facilitating online, real-time aquaculture water quality assessment.},
  keywords={Sensors;Real-time systems;Water quality;Monitoring;Correlation;Intelligent sensors;Aquaculture;Ammonia;Predictive models;Internet of Things;Adaptive sliding window;aquaculture monitoring;dynamic entropy weighting;Internet of Things (IoT);machine learning;variable-weight water quality index (WQI)},
  doi={10.1109/JSEN.2025.3554797},
  ISSN={1558-1748},
  month={May},}@INPROCEEDINGS{11051406,
  author={Alla, Abhiram and Prabhu, Hemanth and Azhar, Salman and Jain, Yash and Ramachandra, L Sri and C, Anitha A},
  booktitle={2024 International Conference on Augmented Reality, Intelligent Systems, and Industrial Automation (ARIIA)}, 
  title={A Rigorous Comparative Analysis on the MNIST Dataset: Proposing an Elaborate Neural Network Model for Handwritten Digit Classification using Deep Learning Methodologies}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The present research examines the efficacy of various neural network methodologies for digit classification using the MNIST dataset, encompassing a fundamental Neural Network (Sequential API in Keras), Capsule Networks (CapsNet), and Neural Architecture Search (NAS). The study commences with the formulation of a neural network model with Keras’s Sequential API, which entails the assembly of a model comprising layers such as Flatten, Dense, and various activation functions. The dataset consists of 60,000 training and 10,000 test grayscale images of handwritten digits, which are preprocessed by pixel value normalization. The model underwent training for 10 epochs, attaining a commendable accuracy. CapsNet, developed to overcome the shortcomings of conventional CNNs, enhances the retention of spatial hierarchy via capsules that represent both feature probability and spatial orientation. The dynamic routing system of CapsNet facilitates improved management of fluctuations in picture orientation and location. While CapsNet demonstrates promise for improved accuracy and interpretability, it requires greater computational resources than traditional CNNs. Neural Architecture Search (NAS) automates the creation of neural network designs, optimizing performance and efficiency. Techniques like Google’s AutoML and EfficientNet are utilized to identify designs that surpass those created manually. Neural Architecture Search utilizes reinforcement learning or evolutionary algorithms to ascertain the most optimal network architectures, exhibiting enhanced accuracy and computational efficiency.The study evaluates the efficacy of these methodologies utilizing criteria such as accuracy, precision, recall, and F1-score. The findings demonstrate that CapsNet and NAS models significantly enhance performance compared to the fundamental Sequential API model, with CapsNet excelling in spatial connection management and NAS identifying architectures that yield superior performance metrics. This study emphasizes the progress in neural network methodologies and their applications in digit recognition tasks, facilitating future research in the optimization and implementation of neural networks for diverse picture classification issues.},
  keywords={Training;Deep learning;Solid modeling;Accuracy;Fluctuations;Computational modeling;Neural networks;Neural architecture search;Optimization;Resilience;Digit recognition;Neural Networks;Capsule Networks;Neural Architecture Search;MNIST dataset;Model optimization},
  doi={10.1109/ARIIA63345.2024.11051406},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10928005,
  author={Verma Panwar, Sheily and Aqle, Aboubakr},
  booktitle={2024 International Conference on Computer and Applications (ICCA)}, 
  title={Deep Learning Based Traffic Detection in Cloud Computing Environment}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This work uses the characteristics of both architectures to present a novel hybrid model combining LSTM and GRU units to enhance anomaly detection in cloud environments. Separately integrating outputs from LSTM and GRU cells, a new fusion layer simultaneously captures long-term and short-term dependencies. Using attention mechanisms improves emphasis on pertinent sequence data, hence increasing detectability and interpretability. While a novel feature extraction technique emphasises important anomalies, adaptive learning rates customised to different model sections maximise learning efficiency. Custom loss functions improve sensitivity to small variations by punishing false negatives. The model distinguishes itself by being dynamically retrained on streaming data sets, therefore providing a self-adj usting mechanism for changing traffic patterns. Transparency in decision-making made possible by explain ability tools such as SHAP and LIME deepens anomaly detection. Genetic algorithms and reinforcement learning among other optimisation techniques help to fine-tune parameters, thereby improving accuracy and efficiency. Emphasising strong performance benchmarks, the model shows scalability and low-latency deployment in large-scale cloud systems. Novel methods of data augmentation replicate different traffic patterns, hence improving model adaptability and resilience. Combining creativity with pragmatic scalability for real-world use, this method offers a convincing, modern solution for difficult anomaly detection in cloud computing.},
  keywords={Deep learning;Cloud computing;Adaptation models;Accuracy;Computational modeling;Scalability;Decision making;Traffic control;Long short term memory;Anomaly detection;Deep learning;Anomaly detection;Traffic detection;Cloud computing;Hybrid Long short term memory LSTM- Gated Recurrent Unit GRU;Machine learning},
  doi={10.1109/ICCA62237.2024.10928005},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10963581,
  author={Prasetya, Ratih and Djuhana, Dede and Saputro, Adhi Harmoko and Permana, Donaldi Sukma},
  booktitle={2024 7th International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)}, 
  title={Daily Rainfall Prediction based on Gradient Boosting Regression Model using NEX-GDDP-CMIP6}, 
  year={2024},
  volume={},
  number={},
  pages={882-887},
  abstract={Rainfall prediction is crucial in guiding climate adaptation and mitigation strategies, particularly in regions vulnerable to climate variability like Indonesia. This study presents a machine learning approach for developing a rainfall prediction model using the NEX-GDDP-CMIP6 dataset from the EC-Earth3 model. Gradient Boosting Decision Trees (GBDT) was used to predict daily rainfall prediction due to their robustness, flexibility, and interpretability. A total of 5,372,741 samples from the Indonesian region, representing its climate conditions and atmospheric states, were utilized, with five climate-related features serving as input variables. The model's performance assessment has been conducted using evaluation metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R2). Results demonstrated that Gradient Boosting model outperformed other tree-based methods, achieving an RMSE of 0.02 and an R2 of 0.99, indicating high predictive accuracy. The findings suggest that GBDT is well-suited for daily rainfall prediction tasks using climate model datasets, offering a reliable tool for enhancing climate decision-making processes.},
  keywords={Adaptation models;Temperature distribution;Rain;Accuracy;Atmospheric modeling;Predictive models;Boosting;Data models;Robustness;Tuning;Machine Learning;Regression;Gradient Boosting;Rain fall Prediction;NEX-GDDP-CMIP6},
  doi={10.1109/ISRITI64779.2024.10963581},
  ISSN={2832-1456},
  month={Dec},}@INPROCEEDINGS{10692540,
  author={Du, Fangyuan and Chen, Hao and Chen, Kunjun and Yang, Xuelian},
  booktitle={2024 6th International Conference on Natural Language Processing (ICNLP)}, 
  title={A Multi-Objective Evolutionary Stacking Integration Approach for Survival Prediction in GBM Patients}, 
  year={2024},
  volume={},
  number={},
  pages={231-237},
  abstract={To address the challenge of predicting survival rates for patients with Glioblastoma (GBM) after radiation therapy, we propose a two-stage integrated learning method that is based on Stacking and multi-objective differential evolution algorithm. Our aim is to achieve a balance between accuracy and interpretability. We have created a framework for survival prediction using radiomics features of gliomas that are imaged in subregions. Our method constructs a model for predicting GBM survival and visualizes decision rules that are easy to interpret. The method involves two primary steps: 1) Various combinations of MRI sequences and glioma subregions were evaluated to determine the optimal sequence, and the GBM long and short survival classification task in the first stage of the task was achieved by compressing features using spectral clustering. 2) An evolutionary integrated learning method based on Stacking was proposed. It uses a Random Forest classifier as the basic learning module of the integrated model and relies on the multi-objective optimization algorithm NSGA-II to continuously iterate with the aim of maximizing the regression accuracy while minimizing the model's integration complexity. We used 119 GBM patients in the BraTS2020 dataset as our study data. Based on the five-fold cross-validation, the survival classification Accuracy and Recall of our long- and short-term classification algorithm for GBM patients were 0.981 and 0.943, respectively; and the Mean-Square Error (MSE) of the survival prediction of GBM patients with the stack-based evolutionary integration method was 55713.08. The experimental results showed that our proposed method for GBM survival days prediction is significantly better than existing Machine Learning (ML) methods. This finding enables us to stratify patients more effectively and provides a more reliable basis for achieving personalized treatment for GBM patients.},
  keywords={Learning systems;Accuracy;Protocols;Stacking;Semantics;Classification algorithms;Radiation therapy;Reliability;Random forests;Radiomics;glioblastoma;survival prediction;stacking;multi-objective optimization;integrated learning},
  doi={10.1109/ICNLP60986.2024.10692540},
  ISSN={},
  month={March},}@INPROCEEDINGS{10838800,
  author={Houser, Ethan and Shashaani, Sara},
  booktitle={2024 Winter Simulation Conference (WSC)}, 
  title={Robust Screening and Partitioning for Feature Selection: A Binary Simulation Optimization Problem}, 
  year={2024},
  volume={},
  number={},
  pages={3229-3240},
  abstract={Feature selection is the process of eliminating irrelevant or redundant covariates in a dataset to construct generalizable interpretable predictions. It is an NP-hard combinatorial problem with only heuristic or model-dependent greedy solution methods. To improve robustness, previous work proposed a zero-one simulation optimization by independently replicating model construction and out-of-sample error calculation. Genetic algorithms were used to solve feature selection showing improved robustness compared to existing techniques, albeit being slow, sensitive to hyperparameters, and lacking convergence guarantees. We propose a stochastic binary search method based on nested partitioning informed by an initial rapid screening phase. With new mechanisms for sampling, we propose steps to efficiently reduce the feature space and obtain an intelligent partitioning scheme. Our experiments show that our proposed algorithm finds fewer irrelevant features, is less sensitive to the data size, and is faster than competing methods.},
  keywords={Numerical analysis;Search methods;Noise;Stochastic processes;Feature extraction;Robustness;Computational efficiency;Partitioning algorithms;Optimization;Testing},
  doi={10.1109/WSC63780.2024.10838800},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{11022777,
  author={Chang, Ching-Yi and Nigh, Matthew and Carulli, John and Makris, Yiorgos},
  booktitle={2025 IEEE 43rd VLSI Test Symposium (VTS)}, 
  title={Enhancing Metrology to E-test Correlation Model Accuracy through Process Expertise Integration}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={We demonstrate the value of integrating expert-level domain knowledge into Machine Learning (ML) model training, which becomes particularly important when modeling complex processes such as semiconductor manufacturing. Specifically, we discuss a machine learning-based methodology which correlates physical metrology measurements with process control monitoring electrical measurements by employing Multivariate Adaptive Regression Splines (MARS) and Non-Dominating Sorting Genetic Algorithm II (NSGA-II). Baseline effectiveness of this solution in predicting critical measurements for maintaining fabrication process integrity, such as yield shorts, ring oscillator active mode current (IDDA) and frequency differences, is assessed using actual High Volume Manufacturing (HVM) production data from an advanced FinFET technology node. Further improvements, however, can be obtained by leveraging domain-specific expertise. Indeed, as we demonstrate experimentally, model accuracy, training time, and explainability all improve when such expertise is integrated in the training process. Our results highlight the pitfalls of blindly applying machine learning and illustrate the value of including semiconductor experts in the development of machine learning models for process optimization-related tasks.},
  keywords={Semiconductor device modeling;Training;Semiconductor device measurement;Correlation;Accuracy;Current measurement;Machine learning;Semiconductor device manufacture;Metrology;Predictive models},
  doi={10.1109/VTS65138.2025.11022777},
  ISSN={2375-1053},
  month={April},}@INPROCEEDINGS{11036074,
  author={Kishore, P. Ravi and Reddy, G.Sai Kiran and A.Shinjith and P.Vikas},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={A New Approach for Sleeping Disorder Classification using Supervised Machine Learning Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={1100-1106},
  abstract={Sleep disorders are now a prevalent health condition worldwide and are identified as contributory causes of several chronic diseases like cardiovascular diseases, obesity, and reduced intellectual functions. Intemperate rates of sleep disorders such as insomnia and sleep apnea are shown to be related to abnormal sleeping hours, unsatisfactory lifestyles, and demographic variables. Here, we propose a machine learning method to predict sleep disorders with high accuracy on the Sleep Health and Lifestyle dataset, using key features like age, gender, BMI, physical activity, occupational type, sleep duration, and quality. We employ four supervised machine learning models: Logistic Regression, XGBoost, Decision Tree (DT), and Support Vector Machine (SVM). Data preprocessing techniques such as handling missing values, normalization, and label encoding are conducted to ensure data quality. Feature importance analysis is also performed to identify influential attributes such as BMI, blood pressure, and sleep quality in the prediction of sleep disorders. The measurements of precision, accuracy, recall, and F1-score are utilized to evaluate the models' performance. Hyperparameter tuning techniques are used for maximizing model performance. Our results indicate that these machine learning models are capable of classifying sleep disorders with high accuracy, with XGBoost and SVM demonstrating greater prediction accuracy. This study shows how machine learning technology can be utilized in medicine to analyze and treat sleep disorders early, helping medical professionals make better decisions and enhancing patient outcomes. The addition of genetic algorithm-based optimization methods further boosts classification accuracy by optimizing the parameters of the model. Comparative studies find the dominance of ensemble methods over traditional classifiers in solving high-dimensional healthcare data. Additionally, the system's ability to include variable lifestyle-related factors presents an integrated solution for individual healthcare. Such findings unveil pathways for future research in designing effective and automated diagnostic systems for sleep disorders.},
  keywords={Support vector machines;Logistic regression;Accuracy;Social networking (online);Medical services;Sleep apnea;Vectors;Decision trees;Medical diagnostic imaging;Tuning;Support Vector Machine(SVM);Logistic Regression (LRg);XGBoost;Decision Tree (DT)},
  doi={10.1109/ICPCSN65854.2025.11036074},
  ISSN={},
  month={May},}@INPROCEEDINGS{11082926,
  author={Abdullah, Atesam and Ali, Raja Hashim and Koutaly, Rand and Khan, Talha Ali and Ahmad, Iftikhar},
  booktitle={2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT)}, 
  title={Enhancing Student Retention: Predictive Machine Learning Models for Identifying and Preventing University Dropout}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Student dropout in higher education poses a critical challenge with far-reaching academic and socio-economic consequences. This study proposes a machine learning-based multi-class classification framework to predict student status—categorized as dropout, enrolled, or graduate—by leveraging a comprehensive dataset that includes academic, demographic, and socio-economic variables. Feature selection techniques, including variance thresholding, SelectKBest, Principal Component Analysis (PCA), and Genetic Algorithms, were employed to enhance model efficiency and accuracy. An ensemble learning approach with multi-source data fusion yielded the highest performance, achieving an overall accuracy of 93.5%, thereby surpassing traditional predictive models. The methodology incorporates both classification and clustering techniques, with evaluation based on precision, recall, F1-score, and clustering indices to ensure robustness. Key predictors identified include academic performance, behavioral patterns, and socio-economic conditions, offering valuable insights for developing targeted intervention strategies. The proposed model demonstrates strong potential in mitigating dropout rates, with future work aimed at broader dataset generalization and enhanced model interpretability.},
  keywords={Deep learning;Technological innovation;Accuracy;Education;Data integration;Predictive models;Robustness;Ensemble learning;Socioeconomics;Principal component analysis;Academic outcomes;Ensemble models;Machine learning in education;Multi-class classification},
  doi={10.1109/AIIT63112.2025.11082926},
  ISSN={},
  month={May},}@INPROCEEDINGS{10860046,
  author={Nandhakumar, A. and Muthukumar, R.},
  booktitle={2024 9th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={A Comparative Study on Combined Economic Emission Dispatch Using Machine Learning Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1467-1472},
  abstract={Economic Emission Load Dispatch (EELD), the combination of economic efficiency and environmental sustainability in power system operation, has arisen as a critical challenge in the current era of power generation and distribution. This review paper provides an in-depth review of the application of machine learning methods to tackle the inherent complexity of EELD. It encompasses the latest advancements and notable trends in this sector. The review begins by explaining the essential concepts and goals of EELD, highlighting the importance of balancing operating costs and lowering greenhouse gas emissions. EELD solutions have been built on traditional optimization approaches such as Linear Programming and Genetic Algorithms. However, machine learning techniques have recently gained popularity due to their capacity to deal with power systems' complex, non-linear interactions. This paper aims to analyze the strengths and limits of several algorithms in optimizing generation schedules while ensuring that they adhere to emission regulations. Moreover, this paper explores the role of data-driven methodologies in EELD, highlighting the importance of precise data collection and preprocessing. This statement elucidates the incorporation of exogenous variables, such as meteorological predictions and energy consumption trends, into EELD (Energy Efficient Load Dispatch) models, emphasizing their influence on augmenting the efficacy of decision-making procedures.},
  keywords={Schedules;Machine learning algorithms;Reviews;Machine learning;Predictive models;Prediction algorithms;Market research;Regulation;Power systems;Optimization;Economic Emission load dispatch;Optimization Algorithms;Machine learning Algorithm},
  doi={10.1109/ICCES63552.2024.10860046},
  ISSN={},
  month={Dec},}@ARTICLE{9451178,
  author={Huang, Wei and Sun, Youcheng and Zhao, Xingyu and Sharp, James and Ruan, Wenjie and Meng, Jie and Huang, Xiaowei},
  journal={IEEE Transactions on Reliability}, 
  title={Coverage-Guided Testing for Recurrent Neural Networks}, 
  year={2022},
  volume={71},
  number={3},
  pages={1191-1206},
  abstract={Recurrent neural networks (RNNs) have been applied to a broad range of applications, including natural language processing, drug discovery, and video recognition. Their vulnerability to input perturbation is also known. Aligning with a view from software defect detection, this article aims to develop a coverage-guided testing approach to systematically exploit the internal behavior of RNNs, with the expectation that such testing can detect defects with high possibility. Technically, the long short-term memory network (LSTM), a major class of RNNs, is thoroughly studied. A family of three test metrics are designed to quantify not only the values but also the temporal relations (including both stepwise and bounded-length) exhibited when LSTM processing inputs. A genetic algorithm is applied to efficiently generate test cases. The test metrics and test case generation algorithm are implemented into a tool testRNN, which is then evaluated on a set of LSTM benchmarks. Experiments confirm that testRNN has advantages over the state-of-the-art tool DeepStellar and attack-based defect detection methods, owing to its working with finer temporal semantics and the consideration of the naturalness of input perturbation. Furthermore, testRNN enables meaningful information to be collected and exhibited for users to understand the testing results, which is an important step toward interpretable neural network testing.},
  keywords={Measurement;Testing;Tools;Semantics;Recurrent neural networks;Software;Logic gates;Coverage-guided testing;coverage metrics;recurrent neural networks (RNNs);test case generation},
  doi={10.1109/TR.2021.3080664},
  ISSN={1558-1721},
  month={Sep.},}@ARTICLE{9403894,
  author={Feng, Yi and Wang, Xianglin and Zhang, Juan},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Heterogeneous Ensemble Learning Method For Neuroblastoma Survival Prediction}, 
  year={2022},
  volume={26},
  number={4},
  pages={1472-1483},
  abstract={Neuroblastoma is a pediatric cancer with high morbidity and mortality. Accurate survival prediction of patients with neuroblastoma plays an important role in the formulation of treatment plans. In this study, we proposed a heterogeneous ensemble learning method to predict the survival of neuroblastoma patients and extract decision rules from the proposed method to assist doctors in making decisions. After data preprocessing, five heterogeneous base learners were developed, which consisted of decision tree, random forest, support vector machine based on genetic algorithm, extreme gradient boosting and light gradient boosting machine. Subsequently, a heterogeneous feature selection method was devised to obtain the optimal feature subset of each base learner, and the optimal feature subset of each base learner guided the construction of the base learners as a priori knowledge. Furthermore, an area under curve-based ensemble mechanism was proposed to integrate the five heterogeneous base learners. Finally, the proposed method was compared with mainstream machine learning methods from different indicators, and valuable information was extracted by using the partial dependency plot analysis method and rule-extracted method from the proposed method. Experimental results show that the proposed method achieves an accuracy of 91.64%, recall of 91.14%, and AUC of 91.35% and is significantly better than the mainstream machine learning methods. In addition, interpretable rules with accuracy higher than 0.900 and predicted responses are extracted from the proposed method. Our study can effectively improve the performance of the clinical decision support system to improve the survival of neuroblastoma patients.},
  keywords={Cancer;Support vector machines;Learning systems;Predictive models;Radio frequency;Feature extraction;Prediction algorithms;Heterogeneous ensemble learning;Neuroblastoma;Survival prediction;Feature selection},
  doi={10.1109/JBHI.2021.3073056},
  ISSN={2168-2208},
  month={April},}@ARTICLE{10578024,
  author={Cui, Zongyong and Mou, Liqiang and Zhou, Zheng and Tang, Kailing and Yang, Zhiyuan and Cao, Zongjie and Yang, Jianyu},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Feature Joint Learning for SAR Target Recognition}, 
  year={2024},
  volume={62},
  number={},
  pages={1-20},
  abstract={The features employed for synthetic aperture radar (SAR) target recognition have evolved from traditional SAR target geometric features and pattern features to modern deep features, indicating a trend of increasing recognition accuracy but decreasing feature interpretability. Therefore, the fusion of multidimensional features has been investigated by many researchers. Existing feature fusion methods typically involve simple concatenation or addition of geometric features and pattern features with deep features, or directly incorporating them into deep networks. However, such fusion methods mentioned above inadequately consider the potential conflicts between features and hard to fully exploit multidimensional features. To solve the above problem, a multidimensional feature joint learning framework (MFJL-Framework) that serves the SAR target recognition task is proposed in this article, which consists of three models. Specifically, the SGC-GA-Model can select pattern features for SAR targets based on geometric feature constraints, the Global and local Feature Information interaction Capture model (GFIC-Model) can select deep features with high-level abstract semantics, and the MFFS-Model can complement and fuse these two types of features to maximize the utilization of feature information. Experiments and comprehensive ablation studies on four datasets, namely OpenSARShip-1.0, FUSAR-Ship, MSTAR-T72Variants, and SAR-AIRcraft-1.0, collectively demonstrate that the recognition performance of our proposed FJL-Framework outperforms the current state-of-the-art methods.},
  keywords={Feature extraction;Target recognition;Synthetic aperture radar;Task analysis;Semantics;Mathematical models;Accuracy;Feature joint learning;pattern features;SAR target recognition;synthetic aperture radar (SAR)},
  doi={10.1109/TGRS.2024.3421269},
  ISSN={1558-0644},
  month={},}@ARTICLE{10979646,
  author={Aquib, Mohd and Verma, Nishchal K. and Akhtar, M. Jaleel},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Enhancing Facial Expression Recognition with AI Agents: A Semi-Supervised Guided Adaptive β-VAE coupled with Interval Type-2 Fuzzy Classifier}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Facial Expression Recognition (FER) is a complex task, hindered by subtle distinctions between expression classes, significant variability within each class, and external influences like identity, pose, age, and ethnicity. As a result, achieving pure expression encodings that are resilient to exogenous factors proves elusive, thereby compromising the downstream classification tasks. This study presents a novel intelligent facial expression recognition scheme that mitigates the impact of external confounders by integrating disentangled representation learning with fuzzy logic. Building on Adaptive β-VAE [1] as a backbone, we develop a semi-supervised Guided Adaptive β Variational Autoencoder (GA-β-VAE) capable of isolating expression features from exogenous factors. Specifically, the adaptive β-VAE is augmented with two additional branches: a deformable PCA-based secondary decoder that disentangles expression-irrelevant transformations from the core expression content, and an adversarial excitation–inhibition branch that forces the “target” (expression) latent variables to be informative only of expressions. This yields well-separated, expression-centric embeddings that are subsequently processed by an Interval Type-2 (IT2) fuzzy classification unit to predict the corresponding expression classes. By avoiding reliance on paired data or explicit annotations, this approach offers a scalable and flexible solution for FER. Experimental evaluations on benchmark datasets (CK+, FER+, and RAF-DB) demonstrate the framework’s effectiveness in addressing the challenges posed by exogenous factors, achieving superior accuracy and interpretability compared to state-of-the-art methods.},
  keywords={Accuracy;Face recognition;Fuzzy logic;Artificial intelligence;Uncertainty;Training;Disentangled representation learning;Scalability;Robustness;Noise;Facial Expression Recognition;Adversarial Learning;β-VAE;Kalman Filtering (KF);Interval Type-2 fuzzy classifier},
  doi={10.1109/TAI.2025.3565225},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{11066130,
  author={Vanegas, Sofia Milagros Castaño and Riascos, Jhon Edward Gonzalez and Becker, Marcelo and Medeiros, Vivian Suzano and Garcia, Javier Ferney Castillo},
  booktitle={2025 Brazilian Conference on Robotics (CROS)}, 
  title={Evaluation of Noise Parameters Influence in an Invariant Extended Kalman Filter for Quadruped Robots Using Regression Analysis}, 
  year={2025},
  volume={1},
  number={},
  pages={1-6},
  abstract={The study investigates the optimization of noise parameters for an Invariant Extended Kalman Filter (InEKF) applied to state estimation in the Unitree B2 quadruped robot. Real sensor data was used to inform the state estimation process, while a genetic algorithm was employed to tune the noise parameters. The research identifies crucial parameter sets that significantly enhance estimation accuracy. Ordinary least squares regression analysis of the generated data demonstrates the interaction of parameters concerning X, Y, and Z estimation errors, explaining variances of 35.3%, 20.9%, and 85.0%, respectively. The results highlight the critical role of the gyroscope, accelerometer, and contact velocity noise parameters in achieving robust state estimation. This work contributes to the field of quadruped robotics by offering insights into parameter tuning methods for improved filter performance. Future efforts are directed toward refining parameterization techniques and exploring optimization strategies focused on the most influential noise parameters.},
  keywords={Accelerometers;Noise;Refining;Robot sensing systems;Regression analysis;Quadrupedal robots;Kalman filters;State estimation;Tuning;Optimization},
  doi={10.1109/CROS66186.2025.11066130},
  ISSN={},
  month={April},}@ARTICLE{10948500,
  author={Cheng, Wenrui and Yuan, Qixuan and Zhu, Tiantian and Chen, Tieming and Ying, Jie and Zheng, Aohan and Ma, Mingjun and Xiong, Chunlin and Lv, Mingqi and Chen, Yan},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={TAGAPT: Toward Automatic Generation of APT Samples With Provenance-Level Granularity}, 
  year={2025},
  volume={20},
  number={},
  pages={4137-4151},
  abstract={Detecting advanced persistent threats (APTs) at a host via data provenance has emerged as a valuable yet challenging task. Compared with attack rule matching, machine learning approaches offer new perspectives for efficiently detecting attacks by leveraging their inherent ability to autonomously learn from data and adapt to dynamic environments. However, the scarcity of APT samples poses a significant limitation, rendering supervised learning methods that have demonstrated remarkable capabilities in other domains (e.g., malware detection) impractical. Therefore, we propose a system called TAGAPT, which is able to automatically generate numerous APT samples with provenance-level granularity. First, we introduce a deep graph generation model to generalize various graph structures that represent new attack patterns. Second, we propose an attack stage division algorithm to divide each generated graph structure into stage subgraphs. Finally, we design a genetic algorithm to find the optimal attack technique explanation for each subgraph and obtain fully instantiated APT samples. Experimental results demonstrate that TAGAPT can learn from existing attack patterns and generalize to novel attack patterns. Furthermore, the generated APT samples 1) exhibit the ability to help with efficient threat hunting and 2) provide additional assistance to the state-of-the-art (SOTA) attack detection system (Kairos) by filtering out 73% of the observed false positives. We have open-sourced the code and the generated samples to support the development of the security community.},
  keywords={Cyber threat intelligence;Filtering;Image edge detection;Anomaly detection;Security;Machine learning;Hands;Supervised learning;Malware;Generative adversarial networks;Advanced persistent threat samples;provenance graph;graph generation;endpoint threat detection},
  doi={10.1109/TIFS.2025.3557742},
  ISSN={1556-6021},
  month={},}@ARTICLE{10833638,
  author={Abdelhalim, Ibrahim and Nadmid, Namuunaa and Elsharkawy, Mohamed and Ghazal, Mohammed and Mahmoud, Ali H. and El-Baz, Ayman},
  journal={IEEE Access}, 
  title={Mask-UnMask Regions (MUMR) Framework for Classifying AMD Grades Using Inter-Regional Interaction Analysis}, 
  year={2025},
  volume={13},
  number={},
  pages={8286-8296},
  abstract={Early diagnosis and effective treatment of age-related macular degeneration (AMD), a leading cause of vision impairment, are critically dependent on accurate grading. This paper presents a novel framework, named Mask-UnMask Regions (MUMR), designed to differentiate between normal retina, intermediate AMD, geographic atrophy (GA), and wet AMD using standardized retinal fundus images with an input resolution of  $1024 \times 1024$  pixels. The framework initiates with the downscaling of images to a quarter of their original size via a Preserving High-Frequency Information (PHFI) module, which retains key details essential for further analysis. Additionally, we developed a simple, lightweight, yet efficient ResNet-like network for feature extraction and introduced a Region Interaction (RI) module. This module incorporates Adaptive Mask and UnMask Sub-Modules, identifying significant regions while reconstructing less relevant areas using a direction-constrained self-attention mechanism to ensure the learning of global structural cues critical for AMD grade classification. The proposed method was evaluated on a dataset comprising 864 retinal fundus images. Our model consistently outperforms state-of-the-art approaches, achieving mean accuracy, mean F1-score, and mean Cohen’s Kappa of 92.55%, 92.59%, and 89.97%, respectively. In the binary classification task of distinguishing between Non-AMD and AMD cases, the proposed approach also surpasses competing models, achieving mean accuracy, mean F1-score, and mean Cohen’s Kappa of 97.11%, 97.03%, and 94.06%, respectively. Furthermore, statistical analysis of these metrics confirms that the improvements are statistically significant, demonstrating the robustness and improved performance of our proposed framework in AMD grading.},
  keywords={Accuracy;Retina;Diseases;Computational modeling;Sensitivity;Transformers;Deep learning;Biological system modeling;Transfer learning;Training;Age-related macular degeneration;retinal diseases;deep learning;transformer},
  doi={10.1109/ACCESS.2025.3526948},
  ISSN={2169-3536},
  month={},}@ARTICLE{10788675,
  author={Yao, Shiao and Chang, Daofang and Song, Haitao and Wu, Congming and Huang, Jingsen},
  journal={IEEE Access}, 
  title={Joint Optimization of Time-Aware Condition-Based Maintenance and Repair Resource Management for Gantry Crane Clusters Based on Improved MADDPG}, 
  year={2024},
  volume={12},
  number={},
  pages={187081-187098},
  abstract={Conventional maintenance strategies for port cranes often lack intelligence, flexibility, and global optimization, with insufficient consideration of time awareness. To optimize condition-based maintenance and resource management for crane clusters, this study decouples maintenance decisions for individual cranes from the overall cluster resource management. We formulate a decision-making model, incorporating uncertainties in procurement lead times, costs, equipment downtime, and spare parts shortages. To improve the model-solving process, we present the evolutionary multi-head attention critic with adaptive strategy–multi-agent deep deterministic policy gradient (EMACAS-MADDPG) algorithm, an enhanced version of the multi-agent deep deterministic policy gradient (MADDPG) algorithm. This algorithm initially evolves policy network parameters through a genetic algorithm and subsequently refines them using experience buffer data. Furthermore, a multi-head self-attention mechanism is embedded into the critic network, and an adaptive exploration strategy is utilized during action execution. The implementation of the EMACAS-MADDPG algorithm in the joint optimization model significantly reduces the average maintenance cost by 22.37% compared to the original MADDPG and by 51.73% compared to the Independent Proximal Policy Optimization (IPPO) algorithm.},
  keywords={Maintenance;Cranes;Resource management;Costs;Optimization;Inspection;Degradation;Maintenance engineering;Decision making;Containers;Gantry crane condition-based maintenance;repair resource management;time-aware;multi-agent reinforcement learning},
  doi={10.1109/ACCESS.2024.3514834},
  ISSN={2169-3536},
  month={},}@ARTICLE{10547163,
  author={Liu, Tianming and Zhu, Dajiang and Wang, Fei and Rekik, Islem and Hu, Xia and Shen, Dinggang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Editorial Special Issue on Explainable and Generalizable Deep Learning for Medical Imaging}, 
  year={2024},
  volume={35},
  number={6},
  pages={7271-7274},
  abstract={The rapid advancements in deep learning technologies have profoundly influenced the field of medical image analysis, yet their full integration into clinical radiology practices has not progressed as quickly as expected. A significant hurdle to their widespread adoption among radiologists and clinicians is the prevailing lack of trust and confidence in the outcomes produced by these technologies. This concern primarily stems from concerns regarding the explainability and generalizability of deep learning models within the realm of medical imaging. As part of the responses from the Medical Image Analysis Community to address these critical issues, we organized the IEEE Transactions on Neural Networks and Learning Systems (TNNLS) Special Issue on explainable and generalizable deep learning for medical imaging. This IEEE TNNLS Special Issue calls for original and innovative methodological contributions that aim to address the key challenges on explainability and generalizability of deep learning for medical imaging. This IEEE TNNLS Special Issue emphasizes the research and advanced development of the technical aspects of new image analysis methodologies, and all the developed new methods should also be evaluated or validated on real and large-scale medical imaging data.},
  keywords={Special issues and sections;Deep learning;Biomedical imaging;Explainable AI;Image analysis},
  doi={10.1109/TNNLS.2024.3395937},
  ISSN={2162-2388},
  month={June},}
