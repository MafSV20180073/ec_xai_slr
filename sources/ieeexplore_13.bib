@ARTICLE{9383091,
  author={Li, Ting and Liu, Wei and Zeng, Zhiwen and Xiong, Neal N.},
  journal={IEEE Internet of Things Journal}, 
  title={DRLR: A Deep-Reinforcement-Learning-Based Recruitment Scheme for Massive Data Collections in 6G-Based IoT Networks}, 
  year={2022},
  volume={9},
  number={16},
  pages={14595-14609},
  abstract={Recently, rapid deployment on the fifth-generation (5G) networks has brought great opportunities for enabling data-intensive applications and brings an extending expectation on the developments of 6G. A basic requirement to develop 6G networks is to reach data with low latency, low cost, and high coverage in smart Internet of Things (IoT). Therefore, this article proposes a novel machine learning-based approach to collect data from multiple sensor devices by cooperation between vehicle and unmanned aerial vehicle (UAV) in IoT. First, a genetic algorithm is utilized to select vehicular collectors to collect massive data from sensor devices, which aims to maximize coverage ratio and to minimize employment cost. Second, we design a novel deep reinforcement learning (DRL)-based route policy to plan collection routes of UAVs with constrain energy, which simplifies the network model, accelerates training speeds, and realizes dynamic planning of flight paths. The optimal collection route of a UAV is a series of outputs based on the proposed DRL-based route policy. Finally, our extensive experiments demonstrate that the proposed scheme can comprehensively improve the coverage ratio of massive data collections and reduce collection costs in smart IoT for the future 6G networks.},
  keywords={Data collection;6G mobile communication;Internet of Things;Genetic algorithms;Unmanned aerial vehicles;Optimization;Reinforcement learning;6G;deep reinforcement learning (DRL);massive data collections;unmanned aerial vehicles (UAVs);vehicle},
  doi={10.1109/JIOT.2021.3067904},
  ISSN={2327-4662},
  month={Aug},}@ARTICLE{9901466,
  author={Zhang, Rongkai and Zhang, Cong and Cao, Zhiguang and Song, Wen and Tan, Puay Siew and Zhang, Jie and Wen, Bihan and Dauwels, Justin},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Learning to Solve Multiple-TSP With Time Window and Rejections via Deep Reinforcement Learning}, 
  year={2023},
  volume={24},
  number={1},
  pages={1325-1336},
  abstract={We propose a manager-worker framework (the implementation of our model is publically available at: https://github.com/zcaicaros/manager-worker-mtsptwr) based on deep reinforcement learning to tackle a hard yet nontrivial variant of Travelling Salesman Problem (TSP), i.e., multiple-vehicle TSP with time window and rejections (mTSPTWR), where customers who cannot be served before the deadline are subject to rejections. Particularly, in the proposed framework, a manager agent learns to divide mTSPTWR into sub-routing tasks by assigning customers to each vehicle via a Graph Isomorphism Network (GIN) based policy network. A worker agent learns to solve sub-routing tasks by minimizing the cost in terms of both tour length and rejection rate for each vehicle, the maximum of which is then fed back to the manager agent to learn better assignments. Experimental results demonstrate that the proposed framework outperforms strong baselines in terms of higher solution quality and shorter computation time. More importantly, the trained agents also achieve competitive performance for solving unseen larger instances.},
  keywords={Task analysis;Costs;Routing;Reinforcement learning;Time factors;Training data;Market research;Travelling salesman problem;graph neural network;deep reinforcement learning},
  doi={10.1109/TITS.2022.3207011},
  ISSN={1558-0016},
  month={Jan},}@INPROCEEDINGS{10376686,
  author={Slyman, Eric and Kahng, Minsuk and Lee, Stefan},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={VLSlice: Interactive Vision-and-Language Slice Discovery}, 
  year={2023},
  volume={},
  number={},
  pages={15245-15255},
  abstract={Recent work in vision-and-language demonstrates that large-scale pretraining can learn generalizable models that are efficiently transferable to downstream tasks. While this may improve dataset-scale aggregate metrics, analyzing performance around hand-crafted subgroups targeting specific bias dimensions reveals systemic undesirable behaviors. However, this subgroup analysis is frequently stalled by annotation efforts, which require extensive time and resources to collect the necessary data. Prior art attempts to automatically discover subgroups to circumvent these constraints but typically leverages model behavior on existing task-specific annotations and rapidly degrades on more complex inputs beyond "tabular" data, none of which study vision-and-language models. This paper presents VLSlice, an interactive system enabling user-guided discovery of coherent representation-level subgroups with consistent visiolinguistic behavior, denoted as vision-and-language slices, from unlabeled image sets. We show that VLSlice enables users to quickly generate diverse high-coherency slices in a user study (n=22) and release the tool publicly1.},
  keywords={Measurement;Computer vision;Art;Annotations;Interactive systems;Data aggregation;Data models},
  doi={10.1109/ICCV51070.2023.01403},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{10822262,
  author={Li, Xinran and Xu, Xiujuan and Liu, Yu and Zhao, Xiaowei},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={CheX-DS: Improving Chest X-ray Image Classification with Ensemble Learning Based on DenseNet and Swin Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={5295-5301},
  abstract={The automatic diagnosis of chest diseases is a popular and challenging task. Most current methods are based on convolutional neural networks (CNNs), which focus on local features while neglecting global features. Recently, self-attention mechanisms have been introduced into the field of computer vision, demonstrating superior performance. Therefore, this paper proposes an effective model, CheX-DS, for classifying long-tail multi-label data in the medical field of chest X-rays. The model is based on the excellent CNN model DenseNet for medical imaging and the newly popular Swin Transformer model, utilizing ensemble deep learning techniques to combine the two models and leverage the advantages of both CNNs and Transformers. The loss function of CheX-DS combines weighted binary cross-entropy loss with asymmetric loss, effectively addressing the issue of data imbalance. The NIH ChestX-ray14 dataset is selected to evaluate the model’s effectiveness. The model outperforms previous studies with an excellent average AUC score of 83.76%, demonstrating its superior performance.},
  keywords={Deep learning;Heavily-tailed distribution;Computational modeling;Biological system modeling;Multi label classification;Transformers;Ensemble learning;Convolutional neural networks;X-ray imaging;Medical diagnostic imaging;Automated medical diagnosis;Swin Transformer;Long-tail multi-label classification;ensemble deep learning},
  doi={10.1109/BIBM62325.2024.10822262},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10569999,
  author={Ha, Myoung Hoon and Chi, Seunggeun and Lee, Sang Wan},
  booktitle={2024 IEEE International Conference on Evolving and Adaptive Intelligent Systems (EAIS)}, 
  title={Learning to Escape: Multi-mode Policy Learning for the Traveling Salesmen Problem}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The traveling salesmen problem (TSP)-one of the most fundamental NP-hard problems in combinatorial optimization-has received considerable attention owing to its direct applicability to real-world routing. Recent studies on TSP have adopted a deep policy network to learn a stochastic acceptance rule. Despite its success in some cases, the structural and functional complexity of the deep policy networks makes it hard to explore the problem space while performing a local search at the same time. We found in our empirical analyses that searching processes are often stuck in the local region, leading to severe performance degradation. To tackle this issue, we propose a novel method for multi-mode policy learning. In the proposed method, a conventional exploration-exploitation scheme is reformulated as the problem of learning to escape from a local search area to induce exploration. We present a multi-mode Markov decision process, followed by policy and value design for local search and escaping modes. Experimental results show that the performance of the proposed method is superior to that of various baseline models, suggesting that the learned escaping policy allows the model to initiate a new local search in promising regions efficiently.},
  keywords={Degradation;NP-hard problem;Markov decision processes;Stochastic processes;Search problems;Routing;Space exploration;Traveling Salesmen Problem;Neural Combinatoric Optimization;Deep Reinforcement Learning;Transformer},
  doi={10.1109/EAIS58494.2024.10569999},
  ISSN={2473-4691},
  month={May},}@INPROCEEDINGS{10709327,
  author={Yu, Cizhen and Xu, Fangfang},
  booktitle={2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Research on Travel Route Recommendation Algorithm Based on Graph Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={855-859},
  abstract={Aiming at the complexity and diversity of tourism information processing, this paper proposes an innovative graph neural network method for the study of tourist route recommendation. In this study, a heterogeneous graph model system is constructed, in which the nodes cover three key elements: users, tourist attractions and tourist attraction types, which are interwoven through diversified links such as users' travel history behavior, the theme content of scenic spots and their thematic associations among each other. In this model, the user node reveals the individual's unique travel preferences and behavior patterns, the scenic spot node carries the detailed feature description of the scenic spot, and the tourism theme node highly summarizes the content, characteristics and style attributes of various scenic spots. By constructing a Graph structure that integrates the multi-dimensional relationship between users, attractions and topics, the proposed GC-GA (Graph Convolution with Graph Attention) algorithm is used to capture and integrate these rich and diverse information. In the actual application scenario, GC-GA adopts hierarchical learning strategy, and firstly uses multi-level graph convolutional neural network to deeply explore the characteristics of different types of nodes. Each level of GCN focuses on exploring and refining the unique attribute information contained in specific types of nodes, which may correspond to multiple levels of semantic understanding such as the user's focus of interest, the intrinsic quality characteristics of scenic spots, or the content of tourism themes. With the increase of the number of convolution layers in the graph, the model gradually understands and learns the embedded expression of each node in the complex graph structure environment from the local to the whole. Then, after completing multi-layer graph convolution learning, the graph attention mechanism is further integrated to effectively fuse different types of node features. The experimental results show that the travel route recommendation algorithm based on graph neural network performs significantly better than the traditional recommendation method on a series of tourism data sets, especially in the travel route recommendation scenario with strong personalized needs of users, it can more fully reflect the efficient use of complex association information and in-depth analysis ability.},
  keywords={Technological innovation;Attention mechanisms;Convolution;Semantics;Refining;Information processing;Feature extraction;Graph neural networks;Complexity theory;Convolutional neural networks;Classification algorithm;Graph neural network;Graph attention network},
  doi={10.1109/ICIPCA61593.2024.10709327},
  ISSN={},
  month={June},}@ARTICLE{10903679,
  author={Khan, Bilal and Usman, Muhammad and Khan, Inayat and Khan, Jawad and Hussain, Dildar and Gu, Yeong Hyeon},
  journal={IEEE Access}, 
  title={Next-Generation Text Summarization: A T5-LSTM FusionNet Hybrid Approach for Psychological Data}, 
  year={2025},
  volume={13},
  number={},
  pages={37557-37571},
  abstract={Automatic text summarization (ATS) has developed as a vital method for compressing massive amounts of textual content into concise and useful summaries, to retrieve more effective and useful information. ATS reduces textual statistics into coherent and shorter versions especially focusing on psychological text summarization to extract insights and emotional states, assisting in better analysis and understanding of psychological contents. In this context, this study proposes a new hybrid model T5-LSTM FusionNet, to enhance textual content summarization in the field of psychology. The motivation derives from the developing extent and accessibility of psychological literature online, which necessitates exceptional techniques for extracting significant findings quickly and reliably. The recommended T5-LSTM FusionNet model combines the benefits of Text-to-Text Transfer Transformer (T5) and Long Short-Term Memory (LSTM). The dataset with 5480 records, accumulated from numerous psychology-associated websites, has been used to verify its performance. T5-LSTM FusionNet’s overall performance is evaluated against several latest models along with T5, LSTM, BERT, and DistilBERT. Measures such as accuracy, precision, recall, F1-score, and ROUGE rankings are used to evaluate the model’s exceptional summarization. With T5-LSTM FusionNet accomplishing a precision of 0.72, recall of 0.72, F1-score of 0.71, and accuracy of 0.74, the effects show significant improvement over individual models like T5 and LSTM, as well as competitive models like BERT and DistilBERT, in terms of summarization effectiveness and accuracy. Furthermore, T5-LSTM FusionNet plays thoroughly in catching both unigram and bigram overlaps concerning summaries, as proven through a comparison study using ROUGE metrics. This suggests that T5-LSTM FusionNet can retain sequence integrity and relevance in summarizing tasks. This work advances ATS techniques in psychology by presenting a hybrid model that combines sequential and transformer-based learning strategies.},
  keywords={Psychology;Text summarization;Long short term memory;Accuracy;Transformers;Feature extraction;Computational modeling;Analytical models;Mental health;Law;Automatic text summarization;T5-LSTM FusionNet;psychology;natural language processing;machine learning},
  doi={10.1109/ACCESS.2025.3540590},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10602661,
  author={He, Tao},
  booktitle={2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)}, 
  title={Student Performance Prediction in College Using Artificial Bee Colony Algorithm and Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={629-632},
  abstract={Student performance prediction in college is improved by adopting an artificial bee colony (ABC) algorithm paired with machine learning techniques. The fundamental problem was the prediction accuracy of individualized learning, early intervention, and academic planning. To solve the challenge, an innovative method was developed by incorporating the ABC algorithm to improve predictive accuracy and interpretability. Data was preprocessed for cleansing the input, using the feature selection approach, ABC. A machine learning model was trained for prediction. The experimental results showed the effectiveness of the suggested method in determining the students' performances. The model helps teachers make the right decisions to promote the students' success.},
  keywords={Accuracy;Scalability;Education;Data preprocessing;Machine learning;Predictive models;Artificial bee colony algorithm;student performance prediction;abc;machine learning;feature selection;educational data mining;personalized learning;early intervention},
  doi={10.1109/ICEIB61477.2024.10602661},
  ISSN={},
  month={April},}@ARTICLE{10601324,
  author={Ur Rehman Siddiqui, Hafeez and Russo, Riccardo and Ali Saleem, Adil and Dudley, Sandra and Rustam, Furqan},
  journal={IEEE Access}, 
  title={Improving Automated PSN Assessment in Type 2 Diabetes: A Study on Plantar Lesion Recognition and Probe Avoidance Techniques}, 
  year={2024},
  volume={12},
  number={},
  pages={102904-102917},
  abstract={Peripheral Sensory Neuropathy (PSN) affects a large proportion of individuals suffering from type 2 diabetes. To avoid ulceration and other damage to the patient’s feet, regular PSN testing, and assessment must be undertaken. Currently, the Semmes-Weinstein Monofilament Examination (SWME) is one of the most widely accepted techniques for PSN assessment. This process is time-consuming, requires special training, and is prone to errors. The number of type 2 diabetes sufferers globally is growing at alarming rates with healthcare workers under enormous pressure to continue to provide one-to-one regular care. In order to reduce the burden on existing services whilst providing the necessary care to patients, automated approaches for PSN detection provide many advantages. Importantly, with respect to an automated SWME method, there will be areas on the plantar surface where the SWM probe should not be applied i.e., areas with lesions or suspect regions. The research presented in this manuscript conducted a comprehensive analysis of different feature sets and classifiers for the task of lesion classification. Three distinct feature sets Local Binary Pattern (LBP), Mel Frequency Cepstral Coefficients (MFCC), and Scale-Invariant Feature Transform (SIFT) were evaluated across various classifiers, including Support Vector Machine (SVM), Multi-layer Perceptron (MLP), Random Forest (RF), Naïve Bayes (NB), and XGBoost. The results revealed nuanced performances across the combinations of feature sets and classifiers. While each feature set demonstrated strengths, the NB classifier applied to the LBP feature set emerged as the most notable performer with an accuracy score of 100%. This combination achieved perfect accuracy, precision, recall, and F1-score metrics, showcasing its robustness in accurately classifying lesion instances. The 5-fold cross-validation results underscored the stability of NB on the LBP feature set, with a negligible standard deviation, affirming its consistent performance across different data subsets. Additionally, the computational time complexity of 0.91 seconds highlighted its efficiency, making NB on the LBP feature set a practical and reliable choice for real-world applications. Statistical analysis using the one-way ANOVA test revealed significant differences in classifier performance across feature sets, with MFCC resulting in significantly lower accuracy compared to LBP and SIFT, which showed similar performance. The Tukey HSD post-hoc test confirmed these findings, highlighting the crucial role of feature set selection in classifier effectiveness.},
  keywords={Lesions;Diabetes;Foot;Accuracy;Skin;Mel frequency cepstral coefficient;Support vector machines;Neuropathology;Genetic algorithms;Image processing;Plantar sensory neuropathy;diabetes;Semmes-Weinstein monofilament;image processing;plantar surface;lesion;LBP;MFCC;genetic algorithm;SVM;MLP},
  doi={10.1109/ACCESS.2024.3430194},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10840421,
  author={Bansal, Divyansh and Al-Jawahry, Hassan M. and Al-Farouni, Mohammed and Kumar, Raman and Kaur, Kamaljeet and Bhosle, Nilesh},
  booktitle={2024 4th International Conference on Technological Advancements in Computational Sciences (ICTACS)}, 
  title={Neural Architecture Search (NAS) for Vision Tasks}, 
  year={2024},
  volume={},
  number={},
  pages={1964-1969},
  abstract={NAS is one of the recent techniques that help in the automation of the process of coming up with the best neural network architecture for a given vision task and has been enhanced by using various methods to the architecture to enhance its performance. In this regard, this article provides the background information on the NAS, the approaches used in the NAS, the current issues and the future of the NAS. Several NAS techniques have been proposed in this work, which includes RL and DARTS, and that have enhanced the efficiency and accuracy of the neural network architecture search. However, there are some problems, which significantly influence NAS. Some of the issues that remain include; the fact that the process is computationally expensive since search and training of numerous candidate architectures is a very time consuming and requires a lot of computational power. In addition, the search space defined in advance can hinder the discovery of new architectures; problems of generalization are related to the question of how the obtained results can be applied to other tasks and datasets. The problem with NAS results is that it is not always clear why specific architectures perform well and this requires future work to consider the following; better search algorithms, the dynamic nature of the search space, and a better understanding of how NAS results can be transferred across different domains and easily explained. Further work could be done to use NAS with other optimization algorithms or other features of the problem or the domain that can improve the solutions found. It means, that NAS has the unique potential for increasing the automation level of the developing neural networks, and has many open issues which should be solved to reach the defined goal.},
  keywords={Training;Technological innovation;Automation;Heuristic algorithms;Neural networks;Computer architecture;Search problems;Neural architecture search;Computational efficiency;Optimization;Neural Architecture Search (NAS);Differen-tiable Architecture Search (DARTS);Reinforcement Learning (RL);Computational Cost;Search Space Design;Generalizability;Interpretability},
  doi={10.1109/ICTACS62700.2024.10840421},
  ISSN={},
  month={Nov},}@ARTICLE{9819858,
  author={Lai, Qifeng and Tian, Jinyu and Wang, Wei and Hu, Xiping},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Spatial-Temporal Attention Graph Convolution Network on Edge Cloud for Traffic Flow Prediction}, 
  year={2023},
  volume={24},
  number={4},
  pages={4565-4576},
  abstract={Accurate short-term traffic flow prediction plays an important role in providing road condition information in the immediate future. With the information, intelligent vehicles can plan and adjust the route to prevent congestion. As a result, many models for short-term traffic flow forecasting have been proposed to date. However, most of them focus on the prediction of the entire traffic network, which could lead to several problems: (1) the entire traffic network could have a large scale and a complex structure, for which the model training is likely to be time-consuming as well as inefficient; (2) processing a large amount of training data on the central cloud could cause much calculation pressure on the server and increase the risk of privacy leakage. In this paper, we propose a Spatial-Temporal Attention Graph Convolution Network on Edge Cloud model (STAGCN-EC). We first divide the entire traffic network into several parts to reduce its scale and complexity. Then, we allocate each part of the network to a certain Roadside Unit (RSU) for training, thus there is no need to process all data on the central server. Besides, we utilize spatial-temporal attention and features extracting module that fits the low computational power devices like RSUs, to capture spatial-temporal dependence and predict traffic flow. At last, we use two highway datasets from District 7 and District 4 in California to validate our model. Through the experiments, we find out that our model performs well both in predicted precision and efficiency compared with the five baseline methods.},
  keywords={Cloud computing;Data models;Predictive models;Servers;Convolution;Training;Feature extraction;Egde cloud;traffic flow prediction;Internet of Vehicles;attention mechanism;graph convolution network},
  doi={10.1109/TITS.2022.3185503},
  ISSN={1558-0016},
  month={April},}@INPROCEEDINGS{10895711,
  author={Harne, Sachin and Dhanamalar, M and Chanakya, Devika and Busa, Kalesh and Bramhe, Pooja and Tiwari, Rovin},
  booktitle={2024 International Conference on Recent Advances in Science and Engineering Technology (ICRASET)}, 
  title={Advanced Deep Learning Approaches for Personalized Medical Image Analysis: Revolutionizing Healthcare with Precision Imaging}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Awareness of high precision deep learning in personalized medical image analysis can be regarded as a portend of a new healthcare paradigm shift by making a breakthrough in diagnostic accuracy, treatment effect, and the prognosis of diseases. This work is the description of the entire procedure that incorporates techniques that are perfectly for location trying to put into consideration the inherent challenges and opportunities in this profession. Applying enriched datasets with modern state-of-the-art deep learning architectures that include CNN’s (convolutionneural networking), RNN’s (recurrent neural networking), and hybrid models enables our approach to have higher performance across several tasks, among them is image segmentation, disease classification and lesion detection. A feasibility study in real clinical settings shows that these deep learning models improve the patient care pathway, ease the use for doctors, and integrate into the existing health care organizations very well. On top of that, performance evaluation indicators emphasize to what extent our models are scalable, resourced, and efficient which is in a turn ensures timely and accurate interpretation of medical imagery..The performance of our approach never stops with the improvement systems and the measure that make it better each time, and it would be perfect for future development of more enduring precision medicine. The use of basement advanced deep learning methodologies renders it possible to liberate the inner heights of the individualized medical image analysis, which in result translates into the whole world change of medical care delivery and the improvement of patient care worldwide.},
  keywords={Deep learning;Image analysis;Accuracy;Recurrent neural networks;Precision medicine;Medical services;Time measurement;Prognostics and health management;Medical diagnostic imaging;Diseases;Deep Learning;Convolutional Neural Networks;Recurrent Neural Networks;Medical Image Analysis;Model Interpretability;Federated Learning},
  doi={10.1109/ICRASET63057.2024.10895711},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10487439,
  author={Mosaiyebzadeh, Fatemeh and Pouriyeh, Seyedamin and Parizi, Reza M. and Han, Meng and Dehbozorgi, Nasrin and Dorodchi, Mohsen and Batista, Daniel Macêdo},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Empowering Healthcare Professionals and Patients with ChatGPT: Applications and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={01-07},
  abstract={ChatGPT is a recently developed Large Language Model (LLM) and an effective tool to produce human-like dialogue with users and answering to questions. It is trained on a massive amount of online content and can provide textual answers to questions from several domains, such as healthcare. In this paper, we investigate the application of ChatGPT in the healthcare domain and provide an analysis on its limitations and challenges. While ChatGPT can offer valuable support and information, it is crucial to recognize that it should not be seen as a replacement for the expertise and personalized care provided by healthcare professionals. Instead, its purpose lies in augmenting healthcare services and enhancing access to information. It can be a useful tool for providing general guidelines and educational resources. However, when it comes to medical advice or diagnosis, it is essential to consult qualified healthcare professionals who can consider individual factors, interpret complex medical information, and provide tailored recommendations based on a comprehensive understanding of the patient's situation.},
  keywords={Drugs;Data privacy;Telemedicine;Medical services;Chatbots;Real-time systems;Medical diagnostic imaging;ChatGPT;Healthcare;Applications;Challenges;Artificial intelligence},
  doi={10.1109/CSCE60160.2023.00233},
  ISSN={},
  month={July},}@INPROCEEDINGS{10500057,
  author={Pantha, Nishan and Ramasubramanian, Muthukumaran and Gurung, Iksha and Maskey, Manil and Sanders, Lauren M. and Casaletto, James and Costes, Sylvain V.},
  booktitle={SoutheastCon 2024}, 
  title={Feature Selection in High-Dimensional Space with Applications to Gene Expression Data}, 
  year={2024},
  volume={},
  number={},
  pages={6-15},
  abstract={Recent years have seen rapid growth in high-dimensional datasets. Most existing machine learning (ML) algorithms fail in high-dimensional settings where many features could be redundant. A critical process of feature selection is thus applied in such a setting that helps in identifying the most relevant features while removing redundant ones. With the increase in high dimensionality, one is also faced with problems of efficiency and interpretation in performing such selection methods. Therefore, this paper proposes a “novel” feature selection framework that uses an ensemble of interpretable ML algorithms to perform feature selection and the ranking of final features. Finally, this framework is applied to a gene expression dataset obtained through collaboration with the National Aeronautics and Space Administration (NASA)'s Biological and Physical Sciences (BPS) team and helps identify important and relevant genes contributing to specific target attributes through classification tasks.},
  keywords={Machine learning algorithms;Computational modeling;NASA;Predictive models;Metadata;Feature extraction;Gene expression},
  doi={10.1109/SoutheastCon52093.2024.10500057},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{11077540,
  author={Mohan, Manoj Krishna and Kulkarni, Sahana Shreedhar},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Temporal-Aware Fraud Detection Using Knowledge Graph, Embeddings and Variable Change Analysis: An Evidence Based Risk Scoring Framework}, 
  year={2025},
  volume={},
  number={},
  pages={413-418},
  abstract={The exponential growth in digital payment systems has fundamentally transformed global commerce while simultaneously creating new vulnerabilities for financial fraud. The increasing sophistication and frequency of fraudulent activities on e-commerce websites, pose significant challenges to the seller and buyer alike. This results in substantial economic losses across the global financial ecosystem. To address this abuse, this paper proposes a hybrid approach combining Knowledge Graphs constructed with embeddings generated on the IEEE-CIS fraud dataset and a novel evidence-based scoring system for online transactions. The embeddings capture both temporal and behavioral patterns in transaction data through time-delta features and other transaction characteristics such as distance, transaction amounts and bank information. This rich representation, combined with our novel Rate of Variable Change (RVC) analysis through the knowledge graph, enables detection of suspicious behavioral patterns in online transactions and assigning an evidence-based risk score. In this paper, we aim to increase recall score for fraudulent transactions, since the cost of a missing fraud transaction is considered much higher than the cost of a false positive.},
  keywords={Costs;Ecosystems;Finance;Knowledge graphs;Machine learning;Hybrid power systems;Fraud;Electronic commerce;Risk analysis;Robots;Knowledge Graphs;Embeddings;Financial Fraud;Machine Learning;Variable Change;Temporal Patterns;Risk Analysis;Behavioral Analysis;E-commerce;Online Transactions;Explainable Decisions;Autoencoders},
  doi={10.1109/AIRC64931.2025.11077540},
  ISSN={},
  month={May},}@ARTICLE{10337772,
  author={Stokes, Chase and Bearfield, Cindy Xiong and Hearst, Marti A.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={The Role of Text in Visualizations: How Annotations Shape Perceptions of Bias and Influence Predictions}, 
  year={2024},
  volume={30},
  number={10},
  pages={6787-6800},
  abstract={This paper investigates the role of text in visualizations, specifically the impact of text position, semantic content, and biased wording. Two empirical studies were conducted based on two tasks (predicting data trends and appraising bias) using two visualization types (bar and line charts). While the addition of text had a minimal effect on how people perceive data trends, there was a significant impact on how biased they perceive the authors to be. This finding revealed a relationship between the degree of bias in textual information and the perception of the authors’ bias. Exploratory analyses support an interaction between a person's prediction and the degree of bias they perceived. This paper also develops a crowdsourced method for creating chart annotations that range from neutral to highly biased. This research highlights the need for designers to mitigate potential polarization of readers’ opinions based on how authors’ ideas are expressed.},
  keywords={Ear;Annotations;Appraisal;Data visualization;Voting;Task analysis;Market research;Annotation;judgment;perceived bias;prediction;text;visualization},
  doi={10.1109/TVCG.2023.3338451},
  ISSN={1941-0506},
  month={Oct},}@INPROCEEDINGS{10612011,
  author={Sánchez, Luis and Rodríguez-Fernández, Victor and Vasile, Massimiliano},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Robust Classification with Belief Functions and Deep Learning Applied to STM}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This work proposes an approach to robust con-junction risk assessment given a sequence of Conjunction Data Messages (CDM). Dempster-Shafer theory of evidence (DSt) is used to account for epistemic uncertainty in the sequence of CDMs and derive a robust classification of conjunction events. We then use Artificial Intelligence (AI) to bypass the computationally expensive parts of DSt and directly produce a robust classification from a given sequence of CDMs. Five AI techniques are proposed: Random Forest (RF) with DSt structures, RF with CDMs, Light Gradient Boosting machine (LGBm) with CDMs, autoregressive LGBm (aLGBm), and Transformers for time series. These meth-ods were trained and tested both on synthetic and in real datasets to study their applicability to real scenarios. The results show the potential of AI techniques, especially LGBm, for robustly classifying encounters from the sequence of CDMs, provided balanced datasets are available.},
  keywords={Radio frequency;Training;Databases;Computational modeling;Time series analysis;Transformers;Boosting;Space Traffic Management;Transformers;Ran-dom Forest;Light Gradient Boosting machine;Dempster-Shafer},
  doi={10.1109/CEC60901.2024.10612011},
  ISSN={},
  month={June},}@ARTICLE{11025554,
  author={Li, Hanbei and Zhang, Yu and Zuo, Qiang},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Multi-Objective Evolutionary Optimization Boosted Deep Neural Networks for Few-Shot Medical Segmentation With Noisy Labels}, 
  year={2025},
  volume={29},
  number={6},
  pages={4362-4373},
  abstract={Fully-supervised deep neural networks have achieved remarkable progress in medical image segmentation, yet they heavily rely on extensive manually labeled data and exhibit inflexibility for unseen tasks. Few-shot segmentation (FSS) addresses these issues by predicting unseen classes from a few labeled support examples. However, most existing FSS models struggle to generalize to diverse target tasks distinct from training domains. Furthermore, designing promising network architectures for such tasks is expertise-intensive and laborious. In this paper, we introduce MOE-FewSeg, a novel automatic design method for FSS architectures. Specifically, we construct a U-shaped encoder-decoder search space that incorporates capabilities for information interaction and feature selection, thereby enabling architectures to leverage prior knowledge from publicly available datasets across diverse domains for improved prediction of various target tasks. Given the potential conflicts among disparate target tasks, we formulate the multi-task problem as a multi-objective optimization problem. We employ a multi-objective genetic algorithm to identify the Pareto-optimal architectures for these target tasks within this search space. Furthermore, to mitigate the impact of noisy labels due to dataset quality variations, we propose a noise-robust loss function named NRL, which encourages the model to de-emphasize larger loss values. Empirical results demonstrate that MOE-FewSeg outperforms manually designed architectures and other related approaches.},
  keywords={Training;Image segmentation;Training data;Predictive models;Multitasking;Reliability engineering;Noise robustness;Noise measurement;Optimization;Biomedical imaging;Few-shot segmentation (FSS);multi-objective evolution (MOE);neural architecture search (NAS)},
  doi={10.1109/JBHI.2025.3541849},
  ISSN={2168-2208},
  month={June},}@INPROCEEDINGS{10683236,
  author={Chen, Jinhua and Zhao, Zihan and Yu, Keping and Mumtaz, Shahid and Rodrigues, Joel J. P. C. and Guizani, Mohsen and Sato, Takuro},
  booktitle={2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring)}, 
  title={Enhancing Production Planning in the Internet of Vehicles: A Transformer-based Federated Reinforcement Learning Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The Internet of Vehicles (10V) brings significant economic benefits to countries. However, large-scale smart vehicle production planning remains challenging in the 10V. Currently, heuristic algorithms and solvers commonly used for these problems often lack scalability and fall into local optima. Moreover, security concerns about wireless data transfer arising from multi-factory manufacturing processes are garnering attention. To address these issues, this paper introduces an algorithm, TRL, which is a Transformer-based Reinforcement Learning for vehicle production planning problems. Furthermore, we propose a Transformer-based Federated Reinforcement Learning algorithm, named TFRL, tailored for large-scale manufacturing and secure wireless communication. Experimental results showcase the high performance and security of TFRL. It schedules 1000 orders in about 14 seconds and avoids exchanging plaintext during the interaction. Compared to Non-dominated Sorting Genetic Algorithm II(NSGA-II), the TFRL enhances computational speed by 95.12% and reduces constraint violation scores by 93.18%.},
  keywords={Wireless communication;Vehicular and wireless technologies;Schedules;Production planning;Reinforcement learning;Transformers;Manufacturing;Federated Reinforcement Learning;Intelligent Manufacturing;Transformer;Internet of Vehicle},
  doi={10.1109/VTC2024-Spring62846.2024.10683236},
  ISSN={2577-2465},
  month={June},}@ARTICLE{10547061,
  author={Furkan Tekin, Selim and Fazla, Arda and Serdar Kozat, Suleyman},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Numerical Weather Forecasting Using Convolutional-LSTM With Attention and Context Matcher Mechanisms}, 
  year={2024},
  volume={62},
  number={},
  pages={1-13},
  abstract={Numerical weather forecasting with high-resolution physical models requires extensive computational resources on supercomputers, often making it impractical for real-life applications. Alternatively, deep learning methods can provide results within minutes of receiving data. Although baseline deep learning models can make accurate short-term predictions, their performance deteriorates rapidly as the output sequence length increases. However, many real-life scenarios require long-term prediction of certain weather features to mitigate and take advantage of the effects of high-impact weather events. In response, we introduce the Weather Model, which provides rapid and accurate long-term spatial predictions for high-resolution spatio-temporal weather data. We integrate a stacked convolutional long-short term memory (ConvLSTM) network as our building block, given its accuracy in capturing spatial data patterns through convolution operations. Furthermore, we additionally incorporate attention and context matcher mechanisms. The attention mechanism allows the effective usage of the side-information vector by selectively focusing on different parts of the input sequence at each time step. Concurrently, the context matcher mechanism enhances the network’s ability to preserve long-term dependences. Our Weather Model achieves significant performance improvements compared to baseline deep learning models, including ConvLSTM, TrajGRU, and U-Net. Our experimental evaluation involves high-scale, real-world benchmark numerical weather datasets, namely the ERA5 hourly dataset on pressure levels and WeatherBench. Our results demonstrate substantial improvements in identifying spatial and temporal correlations, with attention matrices focusing on distinct parts of the input series to model atmospheric circulations. We also compare our model with high-resolution physical models using benchmark metrics to confirm our Weather Model’s accuracy and interpretability.},
  keywords={Meteorology;Predictive models;Weather forecasting;Forecasting;Deep learning;Decoding;Data models;Attention;convolutional long-short term memory (ConvLSTM);convolutional neural network (CNN);numerical weather forecasting},
  doi={10.1109/TGRS.2024.3409084},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10463227,
  author={Moon, Hyunwoo and Bae, Beom Jun and Bae, Sangwon},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Developing a ChatGPT-Based Text Extraction Model to Analyze Effective Communication Elements in Pandemic-Related Social Q&A Responses}, 
  year={2024},
  volume={},
  number={},
  pages={728-731},
  abstract={The present study attempts to use the large language model (LLM) to create a model that identifies Aristotle's rhetorical principles - ethos (source credibility), pathos (emotional appeal), and logos (logic) - in response to COVID-19 information on a question-and-answer community (social Q&A platform). The model differentiates between the most upvoted and random answers to analyze the presence of subdimensions of these rhetorical principles. The research utilized answers to COVID-19 questions on Naver Knowledge-iN, the most popular social Q&A platform in South Korea. A set of 193 answer pairs was randomly selected for training (135 pairs) and testing (58 pairs). These answers were coded for the three rhetorical principles and their subdimensions by researchers, which were used to refine models based on GPT 3.5 technology. The F1 scores were improved to. 88 (ethos),. 81 (pathos), and. 69 (logos). The fine-tuned models were employed to analyze 128 newly drawn answer pairs of the most upvoted answers and random answers. The paired sample t-tests indicated that rhetorical elements of logos such as factual information and logical reasoning were positively associated with health consumers' preference of information (answers) while the other rhetorical principles of ethos and pathos were not associated with consumer preference of health information. By utilizing the LLM for the analysis of persuasive content, which has been typically conducted manually with much labor and time, this study not only demonstrates feasibility of using the LLM in studies of the humanities and social sciences, but also contributes to expanding the horizon in the field of AI text extraction.},
  keywords={COVID-19;Training;Analytical models;Social sciences;Rhetoric;Encoding;Cognition;COVID-19;artificial intelligence;machine learning;Aristotle's rhetoric;ChatGPT;social Q&A;persuasion;question and answer community},
  doi={10.1109/ICAIIC60209.2024.10463227},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{11022271,
  author={Wang, Ying},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Study on the State Evaluation of Novel Nanocomposite Waterborne Polyurethane Material Based on Image Analysis and Improved U-Net Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={1691-1695},
  abstract={To further improve the precision and reliability of material status assessment, the new nanocomposite waterborne polyurethane is taken as the research object, and a material state assessment method based on improved U-Net neural network is proposed. Firstly, images of research materials are collected and preprocessed. Then, U-Net neural network is used as the basic image classification recognition method, and attention mechanism and residual network are adopted to improve it, so as to improve its feature extraction ability. Finally, the improved U-Net neural network is utilized for precise evaluation of the state of new materials. Experimental results show that compared with FCN network, U-Net neural network after improvement can converge faster to smaller loss values. When performing state recognition on materials, the improved U-Net neural network has higher precision, with accuracy, precision, recall and IOU reaching 0.980, 0.981, 0.971 and 0.969 respectively. Compared with PCA-GA-BP method and CNNSVM method, the evaluation precision and efficiency of the proposed method are better. This shows that this method can achieve the accurate state evaluation of the new nanocomposite waterborne polyurethane, and can be applied to the actual material state assessment scenario, which is highly feasible.},
  keywords={Image segmentation;Image recognition;Accuracy;Neural networks;Materials reliability;Feature extraction;Nanostructured materials;Optimization;Residual neural networks;Image classification;image analysis;state assessment;feature extraction;U-Net neural network},
  doi={10.1109/ACAIT63902.2024.11022271},
  ISSN={},
  month={Nov},}@ARTICLE{10551416,
  author={Zhao, Jieru and Shen, Guan and Ding, Wenchao and Chen, Quan and Guo, Minyi},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Automatic Mapping of Heterogeneous DNN Models on Adaptive Multiaccelerator Systems}, 
  year={2024},
  volume={43},
  number={12},
  pages={4701-4714},
  abstract={As DNNs are developing rapidly, the computational and memory burden imposed on hardware systems grows exponentially. This becomes even more severe for large language models (LLMs) and multimodal models. As a promising solution that achieves high scalability and low manufacturing cost, multiaccelerator systems widely exist in data centers, cloud platforms, and mobile SoCs. Thus, a challenging problem arises: selecting a proper combination of accelerators from available designs and searching for efficient DNN mapping strategies, to fully exploit computation resources and communication bandwidth in the system. To this end, we propose MARS, a novel mapping framework that performs computation-aware accelerator selection and applies communication-aware sharding strategies to maximize parallelism. We also provide optimizations to overlap the computation and communication latency. Considering the high complexity of the design space, we propose two effective mapping algorithms to explore it. Experiments show that MARS achieves 34.3% latency reduction for DNN workloads compared to the baseline and 63.0% latency reduction on heterogeneous models compared to the corresponding state-of-the-art method.},
  keywords={Parallel processing;Complexity theory;Computational modeling;Field programmable gate arrays;Random access memory;Adaptive systems;Task analysis;Heterogeneous DNNs;mapping framework;multiaccelerator systems;parallelism strategy;Transformers},
  doi={10.1109/TCAD.2024.3410841},
  ISSN={1937-4151},
  month={Dec},}@ARTICLE{10571776,
  author={Wang, Yunlong and Kieu, Minh and Ranjitkar, Prakash},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Enabling Continuous Operation of Shared Autonomous Vehicles With Dynamic Wireless Charging}, 
  year={2024},
  volume={25},
  number={11},
  pages={18805-18814},
  abstract={Shared Autonomous Vehicles (SAVs), serving as an alternative to private cars, are emerging as a pivotal solution to severe traffic problems. Leveraging Dynamic Wireless Charging (DWC) technology, SAVs can potentially operate continuously meet passenger demands, presenting a complex challenge known as the SAV routing and dynamic wireless charging problem (SVRCP). However, traditional heuristic algorithms, which typically reliant on extensive experiential rule settings, fall short in addressing the multiple objectives and complex constraints of SVRCP. Therefore, we propose a Deep Slack Induction by String Removals-based Reinforcement Learning (DSRL) framework, specifically designed to optimise cost-efficiency and energy stabilisation in SAVs operating with DWC conditions. First, a traffic-vehicle cooperation model, grounded in real-world road networks, is constructed to facilitate interactions for the DSRL’s encoder. We then integrate the Slack Induction by String Removals algorithm to adaptively optimise the DSRL parameters, enhancing the decoder’s ability to find reliable solutions. Experiments show that DSRL outperforms heuristic methods in optimising route cost and stabilising the State-of-Charge (SOC) of SAVs, while achieving a more centralised  $\Delta $  SOC distribution, ensuring the continuous operational capability of the SAVs. The results across instance sizes and DWC power demonstrate DSRL’s robust generalisation capabilities and efficient training capabilities facilitated by transfer learning. Additionally, sensitivity analysis from the perspectives of depot location, passenger distribution, and power levels offers insights for DWC road layout.},
  keywords={Batteries;Roads;Heuristic algorithms;Costs;Vehicle dynamics;Routing;Inductive charging;Shared autonomous vehicles;dynamic wireless charging;deep reinforcement learning;multi-objective optimisation},
  doi={10.1109/TITS.2024.3416412},
  ISSN={1558-0016},
  month={Nov},}@INPROCEEDINGS{10872229,
  author={Liu, Wenkun and Wang, Chuan},
  booktitle={2024 4th International Conference on Mobile Networks and Wireless Communications (ICMNWC)}, 
  title={Power Dispatch Automation System for Fault Prediction and Diagnosis Based on Long Short-Term Memory and Spatial-AlexNet}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Now a days, the rapid evolution of electrical networks has given rise to the smart grid, a next-generation network that has captured the attention of the scientific community. However, smart grids are largely limited to basic threshold-based approaches using single-system data, indicating a need for more sophisticated solutions. This research proposes a method for faults prediction and diagnosis in automation power distribution. Initially, the input data is collected from the dataset of power forecasting then, preprocessing is performed using the Short-Time Fourier Transform (STFT) which is a time-frequency energy mapping method remove the noise from input data. Then the features are selected by Time series Generative Adversarial Networks (Time GAN) whereas it captures patterns and for the generation of real time series. Finally, the prediction is done through Long Short-Term Memory with Spatial-AlexNet (LSTM-S-AlexNet), it detects the faults and handles complex patterns to select the best structure for accurate diagnosis. From the results, the proposed LSTM-S-AlexN et shows better performance in terms of accuracy of (98.56%), precision of (99.38%), recall of (97.84%) and F1-Score of (98.42%) when compared to existing method of Bidirectional Sliced Gated Recurrent Unit with Gated Attention mechanism (BiSGRU-GA) respectively.},
  keywords={Time-frequency analysis;Accuracy;Automation;Time series analysis;Noise;Power distribution;Logic gates;Generative adversarial networks;Smart grids;Long short term memory;long short-term memory;power dispatch automation;prediction and diagnosis;short-time fourier transform and spatial-alexnet},
  doi={10.1109/ICMNWC63764.2024.10872229},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10505579,
  author={An, Yuan and Chen, Guangjian and Huang, Dehua and Zheng, Huiqin and Wang, Qin and Jian, Cairen and Weng, Qian},
  booktitle={2023 13th International Conference on Information Technology in Medicine and Education (ITME)}, 
  title={A Hyperspectral Band Selection Network Combining Siamese Network and Local-Global Attention}, 
  year={2023},
  volume={},
  number={},
  pages={705-710},
  abstract={Hyperspectral images can provide dozens to hundreds of continuous spectral bands, greatly enhancing the richness of information. However, the redundancy among adjacent bands leads to increased data processing complexity. Despite the recent introduction of numerous band selection methods, there has been limited focus on incorporating context information from the entire spectral range into this task. Furthermore, researchers have primarily concentrated on band informativeness and sparse representation for reconstructing all bands, often overlooking the separability of classes in downstream tasks. To address these challenges, we propose a hyperspectral band selection network combining Siamese Network Local-Global Attention (SLGA). This approach first segments the hyperspectral image into homogeneous regions and constructs sample pairs based on a random elimination strategy. Next, it utilizes the Local-Global Attention (L-GA) mechanism to obtain band weights that capture both local and global spectral structures. These reweighted bands are then fed into a twin network to obtain their high-dimensional representations, compute loss values, and update network parameters. Finally, extensive classification experiments using SVM, KNN, and LDA classifiers are conducted on the Indian Pines and Botswana hyperspectral image datasets. The results from these experiments on benchmark datasets demonstrate that the proposed SLGA method performs exceptionally well, outperforming state-of-the-art algorithms.},
  keywords={Support vector machines;Image segmentation;Sparse approximation;Neural networks;Diversity reception;Land surface;Termination of employment;hyperspectral image;band selection;siamese network;convolutional neural network (CNN);attention mechanism},
  doi={10.1109/ITME60234.2023.00146},
  ISSN={2474-3828},
  month={Nov},}@INPROCEEDINGS{9892587,
  author={Zhang, Rongsheng and Yang, Cai and Peng, Xinxin},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Dynamic Graph Attention Network For Traveling Officer Problem}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={The proliferation of illegal parking has a major impact on traffic safety and efficiency. The problem of studying how to capture as many parking infringements as possible in a limited time is called Traveling Officer Problem (TOP), which is a variant of Traveling Salesman Problem (TSP). Compared with TSP, the state of the nodes in the path of TOP changes (0 or 1) over time and the time is limited. The purpose of TOP is to capture as many points with the state of 1 as possible in a limited time. According to the parking information provided by the traffic management system, we propose a Dynamic Graph Attention Network (DGAT) to address this problem. The results on real datasets from Melbourne, Australia show that our model has clear advantages over other optimization algorithms in many metrics, especially the capture rate.},
  keywords={Training;Measurement;Adaptation models;Heuristic algorithms;Neural networks;Traveling salesman problems;Safety;Dynamic Graph Attention Network;Traveling officer problem},
  doi={10.1109/IJCNN55064.2022.9892587},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10331381,
  author={Nichols, Christopher and Crane, H. Trask and Ewart, Dave and Inan, Omer T.},
  booktitle={2023 IEEE 19th International Conference on Body Sensor Networks (BSN)}, 
  title={Combining Knee Acoustic Emissions, Patient-Reported Measures, and Machine Learning to Assess Osteoarthritis Severity}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Current methods for quantifying osteoarthritis severity have limited resolution and accessibility. Patient-recorded outcome measures such as the Knee Injury and Osteoarthritis Outcome Score (KOOS) capture symptom severity, but are subjectively reported and have little correlation with quantifiable metrics of disease such as Kellgren-Lawrence x-ray grade or MRI findings. Knee acoustic emissions (KAEs) offer a convenient, noninvasive option for quantifying joint health. Here, we use machine learning and wearable design to create an interpretable two-stage algorithm for combining KAEs and KOOS scores into an objective, more accessible method of quantifying disease severity. Our algorithm successfully discriminated between early and late-stage osteoarthritis (balanced accuracy = 85%, ROC-AUC = 0.88). The addition of KAEs improved classification of osteoarthritis severity over the use of KAEs (balanced accuracy = 53%, ROC-AUC = 0.786) or KOOS scores alone (balanced accuracy = 63%, ROC-AUC = 0.593). The findings suggest that KAEs combined with patient-recorded metrics can be used to make a more objective and accessible metric for digitally monitoring knee joint health.},
  keywords={Machine learning algorithms;Magnetic resonance imaging;Machine learning;Acoustic emission;Acoustic measurements;Classification algorithms;Osteoarthritis;Biomedical monitoring;Monitoring;Diseases;osteoarthritis;knee acoustic emissions;KOOS;musculoskeletal health},
  doi={10.1109/BSN58485.2023.10331381},
  ISSN={2376-8894},
  month={Oct},}@ARTICLE{10093876,
  author={Tragoudaras, Antonios and Antoniadis, Charalampos and Massoud, Yehia},
  journal={IEEE Access}, 
  title={Enhancing DNN Models for EEG/ECoG BCI With a Novel Data-Driven Offline Optimization Method}, 
  year={2023},
  volume={11},
  number={},
  pages={35888-35900},
  abstract={A better understanding of ElectroEncephaloGraphy (EEG) and ElectroCorticoGram (ECoG) signals would get us closer to comprehending brain functionality, creating new avenues for treating brain abnormalities and developing novel Brain-Computer Interface (BCI)-related applications. Deep Neural Networks (DNN)s have lately been employed with remarkable success to decode EEG/ECoG signals for BCI. However, the optimal architectural/training parameter values in these DNN architectures have yet to receive much attention. In addition, new data-driven optimization methodologies that leverage significant advancements in Machine Learning, such as the Transformer model, have recently been proposed. Because an exhaustive search on all possible architectural/training parameter values of the state-of-the-art DNN model (our baseline model) decoding the motor imagery EEG and finger tension ECoG signals comprising the BCI IV 2a and 4 datasets, respectively, would require prohibitively much time, this paper proposes an offline model-based optimization technique based on the Transformer model for the discovery of the optimal architectural/training parameter values for that model. Our findings indicate that we could pick better values for the baseline model’s architectural/training parameters, enhancing the baseline model’s performance by up to 14.7% in the BCI IV 2a dataset and by up to 61.0% in the BCI IV 4 dataset.},
  keywords={Brain modeling;Biological system modeling;Electroencephalography;Optimization;Decoding;Electrodes;Recording;ECoG/EEG signals;BCI;CNN;self-attention model;deep learning;data-driven optimization},
  doi={10.1109/ACCESS.2023.3265040},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10150366,
  author={Uchiyama, Tomoki},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={Transformer-Based Time Series Classification for the OpenPack Challenge 2022}, 
  year={2023},
  volume={},
  number={},
  pages={264-266},
  abstract={This report describes a solution for the OpenPack Challenge 2022 developed by tomoon team. We present a transformer-based network for time-series classification on various data modalities. Time series data for each modality is segmented at a fixed interval and then each of the segments is fed into a transformer encoder. After that, we fuse the extracted features and learn multimodal features using a transformer encoder. We achieved 0.963 F1-macro and took first place in the competition.},
  keywords={Pervasive computing;Fuses;Conferences;Time series analysis;Transformers;Feature extraction;Task analysis;Activity recognition;Machine learning;Packaging task;Transformer},
  doi={10.1109/PerComWorkshops56833.2023.10150366},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{9845107,
  author={Chi, Huang and Lin, Chen},
  booktitle={2022 International Conference on Blockchain Technology and Information Security (ICBCTIS)}, 
  title={Industrial Intrusion Detection System Based on CNN-Attention -BILSTM Network}, 
  year={2022},
  volume={},
  number={},
  pages={32-39},
  abstract={In view of the existing intrusion detection system for real-time control, the problem of accuracy is not high, this algorithm with improved genetic algorithm to optimize the input vector of belief network, after dimension convolution layer is utilized to extract local features, recycling attention mechanism to explore the characteristics of the different impact on the weights of attack types of prediction, finally USES two-way LSTM extraction sequence. In this paper, the model based on CNN-attention-BILSTM network is compared with the model based on convolutional neural network and attention-BILSTM network and other technologies, and the performance is evaluated from the perspectives of accuracy, false alarm rate, processing performance and completeness. Finally, the experimental results show that, compared with the other models, the model based on CNN-attention-BILSTM network has the best performance on the KDD 99 test set. Using belief network dimension reduction can effectively reduce program running time.},
  keywords={Dimensionality reduction;Convolution;Intrusion detection;Feature extraction;Prediction algorithms;Real-time systems;Recycling;CNN;attention-BILSTM;IDS},
  doi={10.1109/ICBCTIS55569.2022.00019},
  ISSN={},
  month={July},}@INPROCEEDINGS{9867247,
  author={Shen, Heran and Zhou, Xingyu and Wang, Zejiang and Wang, Junmin},
  booktitle={2022 American Control Conference (ACC)}, 
  title={State of Charge Estimation for Lithium-ion Batteries in Electric Vehicles by Transformer Neural Network and L1 Robust Observer}, 
  year={2022},
  volume={},
  number={},
  pages={370-375},
  abstract={Accurately estimating the lithium-ion battery’s state of charge (SOC) is of great importance to the electric vehicle (EV) operations. In this paper, an innovative duo-layered algorithm consolidates a Transformer neural-network and an L1 robust observer is originated to estimate the SOC of an EV’s battery. For the upper layer, the current, voltage, and temperature data are imported into the novel Transformer to predict the SOC. Subsequently, the lower-layer L1 robust observer strives for smoothing the output from the upper-layer machine learning model. Such a novel SOC estimator is advantageous in two aspects. On the one hand, the Transformer outpaces other recurrent neural networks (RNNs) owing to its competency of finding the dependency between any two positions in the input and output sequences, and of acquiring richer information. On the other hand, the L1 robust observer concomitantly achieves the peak-to-peak attenuation from the disturbance to the estimation error and the robustness against the model uncertainties. The new method is evaluated based on experimentally collected data in US06 cycle, and the result manifests its improved accuracy over a baseline method.},
  keywords={Training;Temperature distribution;Recurrent neural networks;Uncertainty;Smoothing methods;Observers;Transformers;Lithium-ion battery;L1 robust observer;SOC;estimation;Transformer;Machine Learning},
  doi={10.23919/ACC53348.2022.9867247},
  ISSN={2378-5861},
  month={June},}@ARTICLE{10668817,
  author={Lu, Hao and Wei, Zhiqiang and Zhang, Kun and Wang, Xuze and Ali, Liaqat and Liu, Hao},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={CTsynther: Contrastive Transformer Model for End-to-End Retrosynthesis Prediction}, 
  year={2024},
  volume={21},
  number={6},
  pages={2235-2245},
  abstract={Retrosynthesis prediction is a fundamental problem in organic chemistry and drug synthesis. We proposed an end-to-end deep learning model called CTsynther (Contrastive Transformer for single-step retrosynthesis prediction model) that could provide single-step retrosynthesis prediction without external reaction templates or specialized knowledge. The model introduced the concept of contrastive learning in Transformer architecture and employed a contrastive learning language representation model at the SMILES sentence level to enhance model inference by learning similarities and differences between various samples. Mixed global and local attention mechanisms allow the model to capture features and dependencies between different atoms to improve generalization. We further investigated the embedding representations of SMILES learned automatically from the model. Visualization results show that the model could effectively acquire information about identical molecules and improve prediction performance. Experiments showed that the accuracy of retrosynthesis reached 53.5% and 64.4% for with and without reaction types, respectively. The validity of the predicted reactants is improved, showing competitiveness compared with semi-template methods.},
  keywords={Predictive models;Transformers;Contrastive learning;Accuracy;Feature extraction;Data models;Computational modeling;Contrastive learning;retrosynthesis prediction;transformer},
  doi={10.1109/TCBB.2024.3455381},
  ISSN={1557-9964},
  month={Nov},}@ARTICLE{10829645,
  author={Yuan, Haitao and Hu, Qinglong and Wang, Meijia and Wang, Shen and Bi, Jing and Buyya, Rajkumar and Shi, Shuyuan and Yang, Jinhong and Zhang, Jia and Zhou, Mengchu},
  journal={IEEE Internet of Things Journal}, 
  title={Data-Filtered Prediction With Decomposition and Amplitude-Aware Permutation Entropy for Workload and Resource Utilization in Cloud Data Centers}, 
  year={2025},
  volume={12},
  number={12},
  pages={19189-19201},
  abstract={In recent years, cloud computing has witnessed widespread applications across numerous organizations. Predicting workload and computing resource data can facilitate proactive service operation management, leading to substantial improvements in Quality of Service and cost efficiency. However, these data often exhibit nonlinearity, high volatility, and interdependencies across different categories, presenting challenges for accurate forecasting. Consequently, there is a critical need to develop a method that thoroughly and comprehensively analyzes all available data to forecast future trends effectively. This work proposes a novel integrated data-enhanced prediction model named SVAPI for achieving high-accuracy workload prediction in cloud computing systems. SVAPI employs the Savitzky-Golay filter, Variational mode decomposition, and the mode selection based on Amplitude-aware Permutation entropy for feature processing, whose features are subsequently utilized by Informer for multivariate joint analysis of the enhanced data, achieving high-precision prediction. Ablation and comparative experiments with advanced prediction models are conducted on the Google cluster trace and other typical datasets. Realistic data-driven results indicate that SVAPI improves the prediction accuracy by 37.7% compared to the original Informer, with each module contributing to the performance enhancement. Furthermore, compared with Autoformer, SVAPI enhances the prediction accuracy of workload, CPU, and memory by 65.6%, 66.9%, and 70.8%, respectively, demonstrating that SVAPI owns strong abilities in noise filtering, feature processing, and multivariate joint analysis for achieving higher prediction accuracy.},
  keywords={Cloud computing;Resource management;Time series analysis;Predictive models;Quality of service;Data centers;Costs;Computational modeling;Accuracy;Polynomials;Amplitude-aware permutation entropy (AAPE);cloud computing;deep learning;informer;Savitzky-Golay (SG) filter;variational mode decomposition (VMD)},
  doi={10.1109/JIOT.2024.3525301},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{10356448,
  author={Yu, Shufang and Song, Beibei and Du, Wenwang and Yuan, Jieran and Sun, Wenfang},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Multispectral Image Demosaicking Based on Multi-scale Dense Connections and Large-kernel Attention}, 
  year={2023},
  volume={},
  number={},
  pages={1007-1011},
  abstract={Single-sensor multispectral cameras generally employ a multispectral filter array (MSFA) to rapidly acquire spatial-spectral information. However, MSFA cameras capture only one spectral band’s information at each pixel location. Thus, to fully utilize the spatial-spectral information recorded by MSFA cameras, demosaicing methods are necessary. In this paper, we propose a novel two-stage demosaicing method that combines the traditional method and the deep learning method. We first use a weighted bilinear interpolation convolution filter to preliminarily interpolate the raw MSFA image. And then a multi-scale dense connections large kernel attention method (MDLKA) is proposed to further reconstruct the full-resolution spectral images. MDLKA can effectively increase the image receptive field and capture long-range dependence. Through dense connections, attention maps of different scales are fused to enrich image features. Finally, compared with current advanced demosaicing methods on the dataset provided by NTIRE 2022, we exceed traditional interpolation methods by 11–15 dB in PSNR. Compared with the mosaic convolution-attention network (MCAN) and Res2Unet network based on deep learning methods, we exceed them by 5.4 dB and 1.95 dB in PSNR, respectively.},
  keywords={Deep learning;Interpolation;Visualization;Convolution;Cameras;Information filters;Kernel;multispectral filter array;demosaicing;deep learning;dense connections;large kernel attention},
  doi={10.1109/ICTAI59109.2023.00151},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10500140,
  author={Khurdula, Harsha Vardhan and Pagutharivu, Anbilparithi and Soung Yoo, Jin},
  booktitle={SoutheastCon 2024}, 
  title={The Future of Feelings: Leveraging Bi-LSTM, BERT with Attention, Palm V2 & Gemini Pro for Advanced Text-Based Emotion Detection}, 
  year={2024},
  volume={},
  number={},
  pages={275-278},
  abstract={This research explores advanced text based emotion detection by leveraging Bidirectional Long Short-Term Memory (Bi-LSTM), Bidirectional Encoder Representations from Trans-formers (BERT) with attention mechanisms, and the latest in Generative Artificial Intelligence, including Palm V2 and Gemini Pro. Unlike traditional supervised learning approaches that rely on pre-defined labels, our methodology employs generative models to adaptively recognize a broad spectrum of human emotions in real-time. By finetuning generative AI, we aim to surpass current approaches in emotion detection accuracy and provide a more nuanced understanding of textual sentiment. Our work outlines the novel approach, dataset preparation, model architecture adjustments, and comprehensive evaluation metrics to demonstrate the efficacy of combining these technologies for enhanced emotion detection.},
  keywords={Emotion recognition;Adaptation models;Recurrent neural networks;Generative AI;Supervised learning;Bidirectional control;Transformers;Emotion Detection;Natural Language Pro-cessing;Recurring Neural Networks;Transformers;Generative Artificial Intelligence},
  doi={10.1109/SoutheastCon52093.2024.10500140},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10364171,
  author={Pavlus, Jan and Pijackova, Kristyna and Koscova, Zuzana and Smisek, Radovan and Viscor, Ivo and Travnicek, Vojtech and Nejedly, Petr and Plesinger, Filip},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={Using Embedding Extractor and Transformer Encoder for Predicting Neurological Recovery from Coma After Cardiac Arrest}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={This research presents a deep-learning framework designed to forecast neurological recovery following a cardiac arrest-induced coma. The framework is created by the team ISIBrno-AIMT as part of the Predicting Neurological Recovery from Coma After Cardiac Arrest: The George B. Moody PhysioNet Challenge 2023. Our approach involves a two-stage model: initially, the model derives low-dimensional embeddings from short electroencephalogram (EEG) segments (5 minutes), and subsequently, it combines the temporal progression (72 hours) of these embeddings to yield a comprehensive likelihood assessment of recovery outcomes. Regrettably, our submission was not evaluated in the ranking phase due to issues with the Docker pipeline.},
  keywords={Deep learning;Pipelines;Cardiac arrest;Medical services;Predictive models;Electrocardiography;Brain modeling},
  doi={10.22489/CinC.2023.054},
  ISSN={2325-887X},
  month={Oct},}@ARTICLE{11078839,
  author={Yang, Yaoqi and Du, Hongyang and Xiong, Zehui and Niyato, Dusit and Jamalipour, Abbas and Han, Zhu},
  journal={IEEE Wireless Communications}, 
  title={Enhancing Wireless Networks with Attention Mechanisms: Insights from Mobile Crowdsensing}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The increasing demand for sensing, collecting, transmitting, and processing vast amounts of data poses significant challenges for resource-constrained mobile users, thereby impacting the performance of wireless networks. In this regard, from a case of mobile crowdsensing (MCS), we aim at leveraging attention mechanisms in machine learning approaches to provide solutions for building an effective, timely, and secure MCS. Specifically, we first evaluate potential combinations of attention mechanisms and MCS by introducing their preliminaries. Then, we present several emerging scenarios about how to integrate attention into MCS, including task allocation, incentive design, terminal recruitment, privacy preservation, data collection, and data transmission. Subsequently, we propose an attention-based framework to solve network optimization problems with multiple performance indicators in large-scale MCS. The designed case study has evaluated the effectiveness of the proposed framework. Finally, we outline important research directions for advancing attention-enabled MCS.},
  keywords={Sensors;Attention mechanisms;Mobile computing;Data models;Resource management;Data collection;Artificial intelligence;Wireless sensor networks;Crowdsensing;Recruitment},
  doi={10.1109/MWC.003.2400231},
  ISSN={1558-0687},
  month={},}@INPROCEEDINGS{10250630,
  author={Panchal, Nisha and Garg, Dweepna},
  booktitle={2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={Image Captioning: A Comprehensive Survey, Comparative Analysis of Existing Models, and Research Gaps}, 
  year={2023},
  volume={},
  number={},
  pages={1120-1127},
  abstract={Image captioning is a research area that focuses on the development of algorithms and models that can automatically generate descriptive and coherent captions. This study provides a comprehensive overview of image captioning techniques, research gaps, and a comparative analysis of existing models. The main goal of image captioning is to generate captions that effectively convey an image's content, context, and salient features without human intervention. However, several research gaps have been identified in this area. These gaps include the need for models that can capture complex relationships and contextual nuances within images, creating fine-grained descriptions that provide detailed and precise information, and the challenge of ambiguity and multimodal interpretations. In addition, incorporating common sense, dealing with rare or unseen objects and scenarios, developing improved evaluation metrics to assess caption quality, and exploring real-time captioning are important research gaps in caption creation. In addition, this work presents a comparative analysis of existing captioning models, highlighting their strengths, limitations, and performance metrics. Various techniques such as deep learning, attentional mechanisms, transfer learning, reinforcement learning, Generative adversarial Networks, and evaluation metrics are explored in the context of image captioning. The findings from this comprehensive survey and analysis contribute to a better understanding of the current state-of-the-art in image captioning, identify research gaps that require further investigation, and serve as a valuable resource for researchers and practitioners working in the field.},
  keywords={Measurement;Surveys;Deep learning;Analytical models;Visualization;Technological innovation;Transfer learning;Image Captioning;Convolutional Neural Networks (CNNs);recurrent neural network (RNN);Long Short-Term Memory (LSTM);Reinforcement learning (RL);Generative adversarial network (GAN);Research gap},
  doi={10.1109/ICAISS58487.2023.10250630},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10607487,
  author={Sun, Kaiwei and Yang, Meng and Wang, Zhicheng and Zhou, Ta},
  booktitle={2024 International Conference on Electronic Engineering and Information Systems (EEISS)}, 
  title={Evolutionary Reinforcement Learning-based Optimization Method for Ship Concept Schemes}, 
  year={2024},
  volume={},
  number={},
  pages={47-54},
  abstract={This paper proposes an efficient optimization algorithm for ship conceptual design solutions. The algorithm is based on Evolutionary Reinforcement Learning (ERL) and is designed to address the issues of slow optimization speed and unclear optimization results in traditional optimization algorithms. It utilizes expert preferences to design intelligent body environment, state, action, and reward models based on the parameter library of the ship concept design. An improved ERL algorithm is developed to enhance optimization speed and optimization stability, and simulation results demonstrate that the proposed improved ERL model architecture and experts' experience can optimize multiple ship conceptual design solutions within 7.5 seconds. The optimization results obtained from the subjective and objective evaluation show 14.61% and 11.11% improvements over the traditional optimization method, respectively. Compared to the traditional optimization methods NSGA-II and ERL algorithm, the improved algorithm achieves a 59.57% and 5.63% improvement, respectively. The proposed algorithm can serve as a valuable reference for optimizing ship conceptual design schemes.},
  keywords={Technological innovation;Simulation;Fitting;Reinforcement learning;Multitasking;Libraries;Stability analysis;evolutionary reinforcement learning;ship design;adaptive fuzziness Borda score;reward model},
  doi={10.1109/EEISS62553.2024.00015},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10393165,
  author={Zhao, Ziwei},
  booktitle={2023 IEEE 6th International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={Research on the classification task of online bookstore sample nodes based on neural network}, 
  year={2023},
  volume={},
  number={},
  pages={741-745},
  abstract={With the continuous development and changes of social information transmission methods and data structure, graphs are increasingly used in many fields. In many fields such as bioinformatics, social network analysis, and transportation network planning, graph representation learning is also constantly advancing. In the real world, labeled sample data is often sparse and labeling costs are high, so small sample node classification learning has gradually become a popular research direction. The online bookstore is an Internet-based e-commerce platform that provides rich book resources and personalized reading services. To solve these problems, this paper proposes an improvement strategy. First, a small sample node classification model based on meta-learning subgraph sampling is proposed. Specifically, the model uses two layers of GCN to perform embedding learning on all data to obtain feature representations, and then uses information entropy to sort and select the previous sample of each new class. Then, these sample data are used to generate characteristic sample data according to standard deviation and variance, and are adjusted and corrected in combination with the base class data samples. Finally, the newly generated feature data is used to generate new sample data using Gaussian distribution, and subgraphs are generated for these new data. In summary, this paper proposes a neural network-based research method for sample node classification tasks, constructing users and books in an online bookstore into a heterogeneous graph, and using graph neural networks and attention mechanisms to learn the node representations of users and books. This method can effectively extract feature information of users and books, and achieves high accuracy and F1 value in the sample node classification task, surpassing traditional graph-based methods and other neural network methods.},
  keywords={Representation learning;Metalearning;Social networking (online);Transportation;Information processing;Feature extraction;Planning;graph representation learning;small sample learning;information entropy;node classification},
  doi={10.1109/ICISCAE59047.2023.10393165},
  ISSN={2770-663X},
  month={Sep.},}@INPROCEEDINGS{10364143,
  author={Moussa, Mostafa and Alfalahi, Hessa and Alkhodari, Mohanad and Hadjileontiadis, Leontios and Khandoker, Ahsan},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={Random Forest and Attention-Based Networks in Quantifying Neurological Recovery}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={Introduction: Cardiovascular disease is generally considered the most prevalent cause of morbidity in the modern world, and cardiac arrest, in particular, causes nearly 50 % of deaths linked with heart attack and stroke in the US. Surviving cardiac arrest could still lead to brain injury and, consequently, death. Our main aim is to mitigate incorrect prognoses in measuring patients' recovery by exploiting the power of machine learning. Methods: We use the training set from the unofficial phase comprising 607 comatose adults following recovery from cardiac arrest to develop two attention-based networks using various features. 486 subjects are used for training and 10-fold cross-validation; the remainder is used for testing and evaluation. Results: Despite an official challenge score of 0.00, Team_KU's best attention-based models yielded a testing accuracy of 62.00 %, an F-measure of 61.20 %; beating our random forest used in the unofficial phase at 55.58 %, and an area under the receiver operating characteristics (AUC) of 0.63 for outcome classification and a mean absolute error of 2.49 for CPC prediction with 607 subjects; nearly half of the provided data in the official phase. Conclusion: This study paves the way toward implementing efficient machine learning to assess brain injury in comatose patients, even in resource-restricted settings. Thus allowing early, automated prediction of recovery.},
  keywords={Training;Computational modeling;Cardiac arrest;Brain modeling;Feature extraction;Time factors;Prognostics and health management},
  doi={10.22489/CinC.2023.023},
  ISSN={2325-887X},
  month={Oct},}@INPROCEEDINGS{11077528,
  author={Xia, Zeyu and Chen, Carol Yx and Fok, Wilton W. T. and Zhang, Baoheng},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Efficient Tennis Player Tracking Using Online Video Highlights}, 
  year={2025},
  volume={},
  number={},
  pages={133-137},
  abstract={In tennis game analysis, player tracking serves as a foundational task before any advanced analysis. However, current methods encounter numerous challenges. The most accessible resources are tennis videos from the internet, which often include post-processed shots, posing challenges for frame-based tracking. Moreover, there is significant potential for enhancing tracking performance by striking a balance between accuracy and efficiency. In this paper, we present a holistic solution for efficient player tracking utilizing online tennis videos. For each video, we employ a lightweight image classifier as a pre-filter to bypass undesired post-processed frames. In player tracking, leveraging the distinctive movement patterns of tennis players, we introduce a novel tracking method, called T-tracker, aims to streamline calculations by eliminating unnecessary computations while maintaining the accuracy. We build up the corresponding baselines to evaluate the efficiency. The results show that the frequency of ID switch is reduced by 68.85% in “Rally” frames, and 73.11% in total when compared to SORT. Moreover, the speed for tracking is increased by 15.27% compared to DeepSORT. Additionally, the total processing speed for a 30second video sees an improvement of 2.01% compared to DeepSORT.},
  keywords={Accuracy;Tracking;Switches;Games;Streaming media;Artificial intelligence;Robots;Sports;Videos;Tracking;Tennis;Classifier;T-tracker;DeepSORT;SORT},
  doi={10.1109/AIRC64931.2025.11077528},
  ISSN={},
  month={May},}@INPROCEEDINGS{10363806,
  author={Obianom, Ekenedirichukwu and Mäkynen, Marko and Qaqos, Noor and Abdullahi, Shamsu Idris and Schlindwein, Fernando S and Ng, G André and Li, Xin},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={Predicting Cardiac Arrest Recovery with Shallow and Deep Learning Models}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={Most resuscitated cardiac arrest patients are comatose and often die due to severe brain injury. With the uncertainty of which patient will survive or not, it is important for the right prognosis to be given. This would help decide which patient intensive care should be focused on. Machine learning, which is a revolutionary computer program that can work without explicit instructions, could be used to study neurological patterns, and make better prognosis. As part of the Predicting Neurological Recovery from Coma After Cardiac Arrest: The George B. Moody Physionet Challenge 2023, our team, Leicester Fox, focused on the comparison of the effectiveness of shallow and deep learning machine learning models in giving the right prognosis on chances of survival of cardiac arrest comatose patients. Features extracted from the electroencephalography (EEG) of 607 patients are used for this analysis. Three groups of features (18 features) were extracted and use for training. The official result was a challenge score of 51% for the shallow model. Locally, we had an accuracy of 76% and 65% for shallow and deep learning models respectively. In conclusion, when dealing with smaller number of patients and using features for analysis, shallow classifiers would usually give a better result.},
  keywords={Deep learning;Training;Uncertainty;Cardiac arrest;Predictive models;Brain modeling;Feature extraction},
  doi={10.22489/CinC.2023.394},
  ISSN={2325-887X},
  month={Oct},}@ARTICLE{10272337,
  author={Nistor, Sergiu Cosmin and Jaradat, Mohammad and Nistor, Răzvan Liviu},
  journal={IEEE Access}, 
  title={Developing an Algorithm for Fast Performance Estimation of Recurrent Memory Cells}, 
  year={2023},
  volume={11},
  number={},
  pages={112877-112890},
  abstract={We propose a novel graph-oriented machine learning algorithm which we use for estimating the performance of a recurrent memory cell on a given task. Recurrent neural networks have been successfully used for solving numerous tasks and usually, for each new problem, generic architectures are used. Adapting the architecture could provide superior results, but would be time-consuming if it would not be automated. Neural architecture search algorithms aim at optimizing the architectures for each specific task, but without a fast performance estimation strategy it is difficult to discover high-quality architectures, as evaluating each candidate takes a long period of time. As a case study, we selected the task of sentiment analysis on tweets. Analyzing the sentiments expressed in posts on social networks offers important insights into what are the opinions on different topics and this has applications in numerous domains. We present the architecture of the estimation algorithm, discussing each component. Using this algorithm, we were able to evaluate one million recurrent memory cell architectures and we discovered novel designs that obtain good performances on sentiment analysis. We describe the discovered design that obtains the best performances. We also describe the methodology that we designed, such that it can be applied to other tasks.},
  keywords={Estimation;Task analysis;Computer architecture;Recurrent neural networks;Machine learning algorithms;Prediction algorithms;Sentiment analysis;Neural architecture search;graph neural network;performance estimation strategy;recurrent neural network;sentiment analysis;tweet},
  doi={10.1109/ACCESS.2023.3322367},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10395257,
  author={Vayadande, Kuldeep and Nemade, Mokshad and Parbhanikar, Shripad and Rathod, Saish and Raut, Anurag and Thorat, Rushikesh},
  booktitle={2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Efficient Content Exploration on YouTube: Automatic Speech Recognition-Based Video Summarization}, 
  year={2023},
  volume={},
  number={},
  pages={1056-1062},
  abstract={The exponential growth of online video content has resulted in an overwhelming amount of data that requires efficient organization and accessibility. YouTube, being the largest video-sharing platform, contains an immense collection of video content. So, the main aim is to build a system which is focused on developing a YouTube summarizer that utilizes Hugging Face's Automatic Speech Recognition (ASR) technology and incorporates native language support. The YouTube summarizer system, with its integration of Hugging Face's ASR and native language support, aims to enhance accessibility and user experience by providing automated, accurate, and concise summaries of YouTube videos. The system serves as a valuable resource for individuals seeking efficient content exploration and information retrieval, irrespective of language barriers or audio content complexity.},
  keywords={Video on demand;Hidden Markov models;Training data;Watches;User experience;Web sites;Context modeling;Web technology;Machine Learning;Hugging Face ASR;Smart Automation},
  doi={10.1109/ICECA58529.2023.10395257},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10363924,
  author={Aarotale, Parshuram N. and Rattani, Ajita},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={Deep Learning Models for Arrhythmia Classification Using Stacked Time-frequency Scalogram Images from ECG Signals}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={Electrocardiograms (ECGs), a medical monitoring technology recording cardiac activity, are widely used for diagnosing cardiac arrhythmia. The diagnosis is based on the analysis of the deformation of the signal shapes due to irregular heart rates associated with heart diseases. Due to the infeasibility of manual examination of large volumes of ECG data, this paper aims to propose an automated AI-based system for ECG-based arrhythmia classification. To this front, a deep-learning-based solution has been proposed for ECG-based arrhythmia classification. Twelve lead electrocardiograms (ECG) of length 10 sec from 45, 152 individuals from Shaoxing People's Hospital (SPH) dataset from PhysioNet with four different types of arrhythmias were used. The sampling frequency utilized was 500 Hz. Median filtering was used to preprocess the ECG signals. For every 1 sec of ECG signal, the time-frequency (TF) scalogram was estimated and stacked row-wise to obtain a single image from 12 channels, resulting in 10 stacked TF scalograms for each ECG signal. These stacked TF scalograms are fed to the pretrained convolutional neural network (CNN), 1D CNN, and 1D CNN-LSTM (Long short-term memory) models, for arrhythmia classification. The fine-tuned CNN models obtained the best test accuracy of about 98% followed by 95% test accuracy by basic CNN-LSTM in arrhythmia classification.},
  keywords={Time-frequency analysis;Shape;Arrhythmia;Computational modeling;Self-supervised learning;Electrocardiography;Lead},
  doi={10.22489/CinC.2023.350},
  ISSN={2325-887X},
  month={Oct},}@ARTICLE{11087560,
  author={Vincent, Amala Mary and Jidesh, P. and Bini, A.A.},
  journal={IEEE Access}, 
  title={Optimizing Hyperparameters in Meta-learning for Enhanced Image Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper investigates the significance of hyperparameter optimization in meta-learning for image classification tasks. Despite advancements in deep learning, real-time image classification applications often suffer from data inadequacy. Few-shot learning addresses this challenge by enabling learning from limited samples. Meta-learning, a prominent tool for few-shot learning, learns across multiple classification tasks. We explore different types of meta-learners, with a particular focus on metric-based models. We analyze the potential of hyperparameter optimization techniques, specifically Bayesian optimization and its variants, to enhance the performance of these models. Experimental results on the Omniglot and ImageNet datasets demonstrate that incorporating Bayesian optimization, particularly its evolutionary strategy variant, into meta-learning frameworks leads to improved accuracy compared to settings without hyperparameter optimization. Here, we show that by optimizing hyperparameters for individual tasks rather than using a uniform setting, we achieve notable gains in model performance, underscoring the importance of tailored hyperparameter configurations in meta-learning.},
  keywords={Metalearning;Adaptation models;Optimization;Training;Hyperparameter optimization;Accuracy;Few shot learning;Image classification;Data models;Benchmark testing;Meta-learning;Few-shot learning;Image classification;Hyperparameter optimization;Evolutionary algorithms},
  doi={10.1109/ACCESS.2025.3591142},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10977530,
  author={Grigoryan, Davit and Liao, Mian and Li, Haoran and Wang, Shukai and Sen, Tanuj and Tan, Matthew and Chen, Minjie},
  booktitle={2025 IEEE Applied Power Electronics Conference and Exposition (APEC)}, 
  title={PiezoNet and Data-Driven Models for Time-Domain Characterization of Piezoelectric Resonators}, 
  year={2025},
  volume={},
  number={},
  pages={1882-1888},
  abstract={This paper presents a fully automated data acquisition platform and the resulting database – PiezoNet1 – for data-driven time-domain characterization of piezoelectric resonators used in power electronics. The platform measures the voltage and the current over piezoelectric resonators across a wide range of excitation waveforms and ambient temperatures. The power stage dynamically adjusts to efficient operating points for best operation under different load conditions. This system is mechanically versatile, accommodating crystals of diverse materials and dimensions. The platform enables comprehensive and precise characterization by automating the data collection process, thereby providing extensive datasets essential for training data-driven models (e.g., neural networks) to predict operating points and nonlinear behaviors, and to quantify the sample-to-sample variation of piezoelectric resonators. A family of sequence-to-sequence neural network models were trained and tested to validate the feasibility of time-domain data-driven models for piezoelectric resonators.},
  keywords={Temperature measurement;Voltage measurement;Databases;Neural networks;Data acquisition;Predictive models;Power electronics;Data models;Resonators;Time-domain analysis;piezoelectric resonator;hysteresis loop;machine learning;data acquisition;data-driven methods},
  doi={10.1109/APEC48143.2025.10977530},
  ISSN={2470-6647},
  month={March},}@ARTICLE{10040987,
  author={Gao, Hao and Zhou, Xing and Xu, Xin and Lan, Yixing and Xiao, Yongqian},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={AMARL: An Attention-Based Multiagent Reinforcement Learning Approach to the Min-Max Multiple Traveling Salesmen Problem}, 
  year={2024},
  volume={35},
  number={7},
  pages={9758-9772},
  abstract={In recent years, the multiple traveling salesmen problem (MTSP or multiple TSP) has received increasing research interest and one of its main applications is coordinated multirobot mission planning, such as cooperative search and rescue tasks. However, it is still challenging to solve MTSP with improved inference efficiency as well as solution quality in varying situations, e.g., different city positions, different numbers of cities, or agents. In this article, we propose an attention-based multiagent reinforcement learning (AMARL) approach, which is based on the gated transformer feature representations for min-max multiple TSPs. The state feature extraction network in our proposed approach adopts the gated transformer architecture with reordering layer normalization (LN) and a new gate mechanism. It aggregates fixed-dimensional attention-based state features irrespective of the number of agents and cities. The action space of our proposed approach is designed to decouple the interaction of agents’ simultaneous decision-making. At each time step, only one agent is assigned to a non-zero action so that the action selection strategy can be transferred across tasks with different numbers of agents and cities. Extensive experiments on min-max multiple TSPs were conducted to illustrate the effectiveness and advantages of the proposed approach. Compared with six representative algorithms, our proposed approach achieves state-of-the-art performance in solution quality and inference efficiency. In particular, the proposed approach is suitable for tasks with different numbers of agents or cities without extra learning, and experimental results demonstrate that the proposed approach realizes powerful transfer capability across tasks.},
  keywords={Urban areas;Logic gates;Feature extraction;Transformers;Task analysis;Inference algorithms;Costs;Attention mechanism;multiagent reinforcement learning (MARL);the multiple traveling salesmen problem (MTSP);transfer capability},
  doi={10.1109/TNNLS.2023.3236629},
  ISSN={2162-2388},
  month={July},}@INPROCEEDINGS{10393253,
  author={Motiramani, Maanaav and Shinde, Abhitay},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Simplifying Watermark Removal: Efficiently Enhancing Visual Integrity through Traditional Image Processing Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper presents a watermark removal technique for digital images using image processing methods, specifically thresholding with the Otsu method. Unlike complex deep learning algorithms, this approach focuses on simplicity and computational efficiency while achieving effective results. The Otsu method automatically determines an optimal threshold to separate the watermark from the background based on image segmentation. Experimental results demonstrate the efficacy of the proposed technique, showcasing high accuracy in removing watermarks with minimal distortion. Moreover, the method's computational efficiency makes it suitable for real-time applications. This research contributes to the field by highlighting the potential of traditional image processing techniques. The simplicity and interpretability of the approach make it accessible to researchers and practitioners with limited expertise in advanced methods. The results indicate promising performance in watermark removal for a diverse dataset of digital images with different watermark types and complexities. This research contributes valuable insights into effective and efficient watermark removal techniques, providing a practical solution for copyright protection, image authentication, and content restoration tasks.},
  keywords={Deep learning;Image segmentation;Thresholding (Imaging);Image processing;Digital images;Watermarking;Real-time systems;watermark removal;image processing;visual integrity;traditional techniques;thresholding;Otsu method;image restoration;digital images;computational efficiency;content preservation;copyright protection;image authentication;post-processing;noise reduction;real-time application},
  doi={10.1109/EASCT59475.2023.10393253},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10500051,
  author={Kim, Donghoon and Jun, Se-ran and Hwang, Doosung},
  booktitle={SoutheastCon 2024}, 
  title={Employing Machine Learning for the Prediction of Antimicrobial Resistance (AMR) Phenotypes}, 
  year={2024},
  volume={},
  number={},
  pages={1519-1524},
  abstract={Antimicrobial resistance (AMR) poses a significant global public health challenge, responsible for the rise in hospital-acquired infections and increased levels of illness and death. The misuse and overuse of antibiotics have played a role in fostering drug resistance among pathogens, creating a pressing need for effective strategies to predict AMR phe-notypes. Employing machine learning techniques has emerged as valuable tools in this endeavor, enabling the analysis of vast datasets to identify patterns and predict the resistance or susceptibility of microorganisms to specific antibiotics. The utilization of machine learning presents a promising approach to combat the growing threat of AMR, with the potential to significantly enhance patient outcomes. The objective of this study is to enhance AMR prediction employing machine learning techniques, leveraging insights from the cybersecurity domain due to the similarities between AMR and malware datasets. The approach involves employing k-mer frequency analysis and feature importance algorithms to extract significant features. The experimental outcomes highlight the following key findings: (1) Our approach demonstrates competitive performance, even with a small dataset; and (2) Utilizing 10-mers yields better outcomes than 7-mers. This research has shown that by applying cross-domain research methodologies and capitalizing on the shared characteristics among different datasets, the performance of AMR prediction can be improved.},
  keywords={Antibiotics;Biological system modeling;Machine learning;Pressing;Predictive models;Feature extraction;Prediction algorithms;Antimicrobial resistance;phenotypes;machine learning;features;k-mers},
  doi={10.1109/SoutheastCon52093.2024.10500051},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10900563,
  author={Lv, Xianwei and Persello, Claudio and Li, Wangbin and Huang, Xiao and Ming, Dongping and Stein, Alfred},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Deep Merge: Deep-Learning-Based Region Merging for Remote Sensing Image Segmentation}, 
  year={2025},
  volume={63},
  number={},
  pages={1-20},
  abstract={Image segmentation represents a fundamental step in analyzing very high-spatial-resolution (VHR) remote sensing imagery. Its objective is to partition an image into segments that best match with geo-objects. However, the diverse appearances of geospatial objects often lead to interobject homogeneity and intraobject heterogeneity. Existing segmentation methods often struggle to accurately segment geo-objects with varying shapes and scales. To address these challenges, we propose DeepMerge, a novel method that integrates deep learning and region adjacency graphs (RAGs) to accurately segment complete geo-objects in large VHR images. DeepMerge begins with an initial over-segmentation of the image and then iteratively merges similar regions to achieve complete geo-object segmentation. A deep learning model is employed to learn the similarity between adjacent superpixel pairs. This approach only requires labels indicating whether adjacent superpixels belong to the same geo-object eliminating the need for object-level annotations, enabling weakly supervised segmentation. A cross-scale module is incorporated to capture multiscale information, enhancing the representation of superpixels. In addition, the feature distances between neighboring super-pixels are deemed as scale parameters (thresholds) to control the merging procedure, thus yielding an interpretable, predictable, stable, and optimal scale parameter 0.5. DeepMerge can achieve high segmentation accuracy in a weakly supervised manner, which is validated on large-scale remote sensing images of 0.55-m resolution covering an area of 5660 km2. The experimental results demonstrate that DeepMerge achieves the highest F value (0.9552) and the lowest total error (TE) (0.0827), accurately segmenting geo-objects of varying sizes and outperforming all competing methods.},
  keywords={Image segmentation;Merging;Remote sensing;Training;Accuracy;Data mining;Feature extraction;Deep learning;Artificial intelligence;Training data;Deep learning;image segmentation;region adjacency graph (RAG);region merging;scale parameter interpretability},
  doi={10.1109/TGRS.2025.3544549},
  ISSN={1558-0644},
  month={},}@ARTICLE{10845081,
  author={Gu, Feida and Sang, Hongrui and Zhou, Yanmin and Ma, Jiajun and Jiang, Rong and Wang, Zhipeng and He, Bin},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Learning Graph Dynamics With Interaction Effects Propagation for Deformable Linear Objects Shape Control}, 
  year={2025},
  volume={22},
  number={},
  pages={10881-10892},
  abstract={Robotic manipulation of deformable linear objects (DLOs) has broad application prospects, e.g., manufacturing and medical surgery. To achieve such tasks, a critical challenge is the precise control of the DLOs’ shapes, which requires an accurate dynamics model for deformation prediction. However, due to the infinite dimensionality of the DLOs and the complexity of their deformation mechanism, dynamics models are hard to theoretically calculate. In this paper, for representing the DLO, we use multiple particles being uniformly distributed along the DLO. For learning the dynamics model, we adopt Graph Neural Network (GNN) to learn local interaction effects between neighboring particles, and use the attention mechanism to aggregate the effects of these interactions for the purpose of effect propagation along the DLO (called GA-Net). For manipulation, the Model Predictive Control (MPC) coupled with the learned dynamics model is used to calculate the optimal robot movements, which can also generalize to unseen DLOs. Simulation and real-world experiments demonstrate that GA-Net shows better accuracy than existing methods, and the proposed control framework is effective for different DLOs. Specifically, for model prediction (150 steps), the prediction performance of GA-Net is 14.14% better than the strong baseline (IN-BiLSTM). Videos are available at https://parkergu.github.io/work_dlo/. Note to Practitioners—This paper was motivated by the problem of shape control of DLOs (e.g., ropes, cables) but it also applies to other deformable objects. Robotic manipulation of DLOs has broad application prospects across various industries, including medical surgeries and manufacturing. Existing approaches to manipulate DLOs, such as reinforcement learning, suffer from sample inefficiency and challenges in generalization. To alleviate these issues, we propose a model-based framework. We adopt GNN and attention mechanism to learn DLOs’ dynamics. Then we use MPC coupled with the learned dynamics model for manipulation of DLOs. The framework is sample-efficient for manipulation, and can generalize to unseen DLOs. Previous works on GNN-based dynamics model do not consider instantaneous propagation of interaction effects, which leads to a false prediction. To alleviate this issue, we adopt GNN to learn interaction effects between neighboring particles, and use the attention mechanism to propagate local interaction effects along the DLO. Simulation and real-world experiments demonstrate that our dynamics model shows better accuracy than existing methods, and also demonstrate the effectiveness of the proposed control framework.},
  keywords={Shape control;Deformable models;Predictive models;Robots;Dynamics;Analytical models;Shape;Deformation;Computational modeling;Graph neural networks;Dynamics model learning;shape control of deformable linear objects;robotic manipulation;graph neural network},
  doi={10.1109/TASE.2025.3530957},
  ISSN={1558-3783},
  month={},}@ARTICLE{11089932,
  author={Guei, Hung and Ju, Yan-Ru and Chen, Wei-Yu and Wu, Ti-Rong},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Demystifying MuZero Planning: Interpreting the Learned Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={MuZero has achieved superhuman performance in various games by using a dynamics network to predict the environment dynamics for planning, without relying on simulators. However, the latent states learned by the dynamics network make its planning process opaque. This paper aims to demystify MuZero’s model by interpreting the learned latent states. We incorporate observation reconstruction and state consistency into MuZero training and conduct an in-depth analysis to evaluate latent states across two board games: 9x9 Go and Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our findings reveal that while the dynamics network becomes less accurate over longer simulations, MuZero still performs effectively by using planning to correct errors. Our experiments also show that the dynamics network learns better latent states in board games than in Atari games. These insights contribute to a better understanding of MuZero and offer directions for future research to improve the performance, robustness, and interpretability of the MuZero algorithm. The code and data are available at https://rlg.iis.sinica.edu.tw/papers/demystifying-muzero-planning.},
  keywords={Games;Planning;Decoding;Training;Artificial intelligence;Heuristic algorithms;Optimization;Accuracy;Robustness;Reinforcement learning;Interpretability;Monte Carlo tree search;MuZero;Planning;Reinforcement learning},
  doi={10.1109/TAI.2025.3591082},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10011651,
  author={Wu, Yunlong and Li, Jinghua and Jin, Haoxiang and Zhang, Jiexin and Wang, Yanzhen},
  booktitle={2022 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={RBT-HCI: A Reliable Behavior Tree Planning Method with Human-Computer Interaction}, 
  year={2022},
  volume={},
  number={},
  pages={1637-1642},
  abstract={In this paper, we propose RBT-HCI, a reliable behavior tree (BT) planning method with human-computer interaction, aiming at generating an interpretable and human-acceptable BT. Compared with other BT generation methods, RBT-HCI can reliably plan a BT based on the knowledge base. When an available BT cannot be planned automatically, instead of terminating or relaxing the rules, RBT-HCI provides a new idea, which is to make decisions through human-computer interaction, thereby enhancing the reliability and robustness of the method. The effectiveness of RBT-HCI is verified by an example of robot grasping objects, showing that a reliable and robust planning result can be obtained through knowledge-based automatic planning and human-computer interaction.},
  keywords={Human computer interaction;Knowledge based systems;Grasping;Reliability engineering;Search problems;Robustness;Planning},
  doi={10.1109/ROBIO55434.2022.10011651},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10431590,
  author={Ji, Anli and Aydin, Berkay},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Active Region-Based Flare Forecasting with Sliding Window Multivariate Time Series Forest Classifiers}, 
  year={2023},
  volume={},
  number={},
  pages={196-203},
  abstract={Over the past few decades, many applications of physics-based simulations and data-driven techniques (including machine learning and deep learning) have emerged to analyze and predict solar flares. These approaches are pivotal in understanding the dynamics of solar flares, primarily aiming to forecast these events and minimize potential risks they may pose to Earth. Although current methods have made significant progress, there are still limitations to these data-driven approaches. One prominent drawback is the lack of consideration for the temporal evolution characteristics in the active regions from which these flares originate. This oversight hinders the ability of these meth-ods to grasp the relationships between high-dimensional active region features, thereby limiting their usability in operations. This study centers on the development of interpretable classifiers for multivariate time series and the demonstration of a novel feature ranking method with sliding window-based sub-interval ranking. The primary contribution of our work is to bridge the gap between complex, less understandable black-box models used for high-dimensional data and the exploration of relevant sub-intervals from multivariate time series, specifically in the context of solar flare forecasting. Our findings demonstrate that our sliding-window time series forest classifier performs effectively in solar flare prediction (with a True Skill Statistic of over 85%) while also pinpointing the most crucial features and sub-intervals for a given learning task.},
  keywords={Time series analysis;Forestry;Predictive models;Forecasting;Usability;Task analysis;Machine intelligence;Multivariate Time Series Classification;Solar Flare Prediction;Interval-based Classification},
  doi={10.1109/CogMI58952.2023.00036},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10967868,
  author={Lalitha, R. and V, Dhinavallesan P and R, Edwin Raj and Ponugoti, Sreelekha},
  booktitle={2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)}, 
  title={A Comprehensive Survey on NLP-based Approaches for Summarizing Lengthy Research Papers}, 
  year={2025},
  volume={},
  number={},
  pages={1501-1507},
  abstract={This work reviews recent advances in NLP-based methods for automatic text summarization, with a focus on how they might be used to summarize lengthy research publications. In light of the exponential rise of textual material, systems that can generate succinct and insightful summaries must be developed to enhance information retrieval and lessen the strain of manual reading. It will review techniques that include extractive summary, in which key phrases are removed from the source text, and abstractive summarizing, where the main concepts are formed into new sentences. It contains some excellent techniques, including graph-based approaches, transformer models (BERT, GPT, and T5), recurrent neural networks (RNNs), and hybrid models. Managing domain-specific terminology, maintaining coherence for longer articles, and obtaining computationally effective summarization are some special challenges Metrics of evaluation comprise ROUGE, BLEU, and F1 score. This survey intends to provide a more comprehensive review of present approaches, identify research gaps, and outline possible directions towards the future in order to accelerate the field of artificial text summarization},
  keywords={Surveys;Reviews;Terminology;Computational modeling;Redundancy;Text summarization;Coherence;Reinforcement learning;Transformers;Strain;Text Summarization;NLP;GA-GNN;HAESum;Transformers;Research Papers;Long Document Summarization},
  doi={10.1109/ICMLAS64557.2025.10967868},
  ISSN={},
  month={March},}@INPROCEEDINGS{10641601,
  author={Sun, Yao and Wang, Yi and Eineder, Michael},
  booktitle={IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Post-Earthquake SAR-Optical Dataset for Quick Damaged-Building Detection}, 
  year={2024},
  volume={},
  number={},
  pages={3787-3790},
  abstract={This work introduces a dataset for automated earthquake-damaged building detection from post-event satellite imagery. Using very high-resolution Synthetic Aperture Radar (SAR) and optical data from the 2023 Turkey-Syria earthquakes, the dataset includes over four thousand co-registered building footprints and patches. The task is framed as a binary image classification problem, serving as a reference for researchers to expedite algorithm development for rapid damaged building detection in future events. The dataset and codes together with detailed explanations will be made publicly available at https://github.com/ya0-sun/PostEQ-SARopt-BuildingDamage.},
  keywords={Buildings;Urban areas;Optical imaging;Adaptive optics;Radar polarimetry;Satellite images;Classification algorithms;building damage detection;convolutional neural network (CNN);very high resolution (VHR);remote sensing imagery;synthetic aperture radar (SAR);earthquake;geographic information system (GIS);Open-StreetMap (OSM);large-scale urban areas},
  doi={10.1109/IGARSS53475.2024.10641601},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{11042338,
  author={Moniruzzaman, Mohammad and Ahmed, Ahsan and Aktarujjaman, Md and Uddin, Md Shahab and Sultana, Sheikh Razia and Sayeema, Anika},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={AI-Based Framework for Medical Cost Forecasting and Financial Transaction Monitoring in Healthcare}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The growing digitization of healthcare systems necessitates accurate cost forecasting and robust protection of financial transactions. This paper proposes a novel AI-based framework that combines predictive analytics with cybersecurity techniques to address these dual challenges. Using the Medical Cost Personal Dataset comprising 1,338 records, we developed a Gradient Boosting Regressor that achieved a MAE of 1,873.92, RMSE of 3,912.14, and an R2 score of 0.88, outperforming other baseline models. In parallel, an Isolation Forest model trained on residual errors identified transaction anomalies with a recall of 0.89, demonstrating effective detection of irregular patterns. We also performed adversarial robustness testing, showing that manipulated features like smoker status can cause prediction shifts exceeding $4,000. These results underscore the potential of integrating machine learning and anomaly detection for both forecasting and safeguarding financial operations in healthcare. The proposed framework offers a scalable and efficient solution for building secure, data-driven financial infrastructures in medical systems.},
  keywords={Costs;Accuracy;Medical services;Forestry;Boosting;Forecasting;Computer security;Predictive analytics;Monitoring;Anomaly detection;Medical cost prediction;Financial transaction monitoring;Isolation Forest;Healthcare cybersecurity;Anomaly detection;AI in healthcare;Machine learning},
  doi={10.1109/RMKMATE64874.2025.11042338},
  ISSN={},
  month={May},}@INPROCEEDINGS{10585847,
  author={Zheng, Yi and Majewicz-Fey, Ann},
  booktitle={2024 International Symposium on Medical Robotics (ISMR)}, 
  title={Transformer-Based Automated Skill Assessment and Interpretation in Robot-Assisted Surgery}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Different artificial intelligence approaches have been made to automatically assess skills during robotic surgical training. However, limitations still exist in these studies, including issues related to feature engineering, cross-validation methods, complex model architectures, and interpretability. In response to these limitations, this study introduces a Transformer-based model that processes kinematic data and identifies surgical skill levels. The model performance was rigorously evaluated under the Leave-One-User-Out cross-validation method, resulting in a classification accuracy of 80%. Beyond skill level classification, this study also explores deeper into the interpretability aspect. It includes the extraction of global-attention from the model, providing insights into the significance of each part or gesture within a task during the classification decision-making process. This interpretability holds the potential to help surgeon improve their skill by offering a comprehensive and detailed understanding of their performance.},
  keywords={Training;Accuracy;Medical robotics;Decision making;Surgery;Kinematics;Transformers},
  doi={10.1109/ISMR63436.2024.10585847},
  ISSN={2771-9049},
  month={June},}@INPROCEEDINGS{10021060,
  author={Kan, Xuan and Kong, Yunchuan and Yu, Tianwei and Guo, Ying},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={BraceNet: Graph-Embedded Neural Network For Brain Network Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={4979-4987},
  abstract={Multimodal brain networks extracted from functional magnetic resonance imaging (fMRI) characterize complex connectivities among brain regions from both structural and functional, showing great potential for mental health analysis. Deep neural network models have led a tremendous success in various downstream tasks. However, common property in brain network data, the small number of samples compared with the huge amount of features, hinders the application of deep learning techniques for brain network analysis. This work presents a graph-embedding method by leveraging the unique characteristics of brain networks to unleash the power of deep neural networks and achieve outstanding prediction performance with proper explainability. Experiment results show clear advancements in our proposed braceNet on both real and synthetic datasets.},
  keywords={Deep learning;Network analyzers;Mental health;Functional magnetic resonance imaging;Big Data;Brain modeling;Mathematical models;fMRI analysis;Brain Network;Graph Neural Network},
  doi={10.1109/BigData55660.2022.10021060},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10692306,
  author={Pydala, Bhasha and Bhavana, Bangaru Venkata and Gamyasree, Gorla and Jyotsna, Kambam and Lohitha, Madaparthi and Jyothsna, V.},
  booktitle={2024 2nd World Conference on Communication & Computing (WCONF)}, 
  title={Enhancing Remote Sensing Object Detection Through YOLOV5x6 Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The CA-YOLO (Coordinate Attention- YOLO) model is designed for better object detection addressing precise remote sensing pictures challenges faced by algorithms detecting multiple objects. It improves multi-scale feature extraction and tackles the compromise between detection precision and model complexity. Built on YOLOv5x6, CA-YOLO adds a thin, lightweight coordinate attention module situated in the superficial layer for efficient feature extraction and reducing redundant data. In the deeper layer, a pyramid pooling in space-fast using a tandem construction module is implemented to enhance performance without increasing model parameters. To optimize efficiency, the model reduces parameters, improves inference speed, and refines the anchor box mechanism and loss function for detecting objects of different sizes. Results demonstrate CA-YOLO outperforming the first YOLO in multiple objects detection accuracy, achieving an impressive average inference speed of 125 fps. Importantly, these improvements maintain the same parameters and complexity, making CA-YOLO an excellent choice for various applications.},
  keywords={YOLO;Accuracy;Computational modeling;Clustering algorithms;Interference;Feature extraction;Inference algorithms;Complexity theory;Remote sensing;Genetic algorithms;Attention mechanism;object detection;coordinate attention;SPPF;SIoU loss},
  doi={10.1109/WCONF61366.2024.10692306},
  ISSN={},
  month={July},}@INPROCEEDINGS{9995471,
  author={Pecka, Caleb and Bastola, Dhundy},
  booktitle={2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Investigating stagnant clinical outcomes after fecal microbiome transplant in autism spectrum disorder}, 
  year={2022},
  volume={},
  number={},
  pages={3287-3294},
  abstract={The impact of fecal microbiome transplant (FMT) on autism spectrum disorder (ASD) symptom recovery has been previously investigated with widely varying success rates. The goal of this study is to determine criteria for reliable assessment of FMT recovery and investigate possible explanations for stagnant ASD FMT recovery outcomes. The results from this study show evidence of decreased bacterial diversity in a subset of patients with poor clinical outcomes, even after FMT. These patients display differential profiles for Akkermansia, a gut microbe associated with mucin degradation, as well as differential levels of metabolites including tryptophan derivatives and pyroxidal, a vagus nerve afferant polarizer. These results are expected to help explain gut-brain axis mechanisms associated with FMT success in ASD.},
  keywords={Optical fiber polarization;Measurement;Autism;Microorganisms;Neurotransmitters;Reflection;Optical fiber theory;autism;ASD;microbiome;fecal microbiome transplant;FMT;metabolite;dysbiosis;gut-brain axis},
  doi={10.1109/BIBM55620.2022.9995471},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10498208,
  author={Qing, Wu and Junyang, Wang and Kang, Zhou and Bowen, Wei and Huiping, Wu and Haifeng, Wang},
  booktitle={2024 International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Long Short-Term Memory Based Trust Security Protection in Edge Computing Environment}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The security and privacy are the significant anxieties connected to Edge Computing, as it is an open-access as well as self-organized network. Through the combination of the Internet of Things (IoT), and 5G-class large networks, traditional enterprise Cloud Computing (CC) systems are not appropriate process with enormous data produced through integrating with network edge electronic devices. So as to efficiently address this difficult issue, Edge Computing (EC) comes into existence. So, this research proposed the hybrid learning approach of Long Short-Term Memory (LSTM) for security approach along with a trust model was developed to manage the EC network from familiar as well as unfamiliar attacks, while reduced a False Detection Rate (FDR). The effectiveness of the proposed method attains good results and it is estimated by various evaluation indices such as accuracy, False Positive Rate (FPR), F1-score and Packet Loss Rate (PLR) of values about 99%, 75%, 0.9727 and 0.08 respectively when compared to the existing methods like Generative Adversarial Network (GAN) and UAV-Trust based Task Offloading (UAV-TTO).},
  keywords={Privacy;Packet loss;Generative adversarial networks;Security;Internet of Things;Hybrid learning;Protection;Edge Computing;Internet of Things;Long Short-Term Memory;Trust;Privacy Preserving},
  doi={10.1109/ICICACS60521.2024.10498208},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11065269,
  author={Kang, Rui and Bin, Ziyan and Miao, Shihan and Qin, Siyao and Li, Man},
  booktitle={2025 5th International Symposium on Computer Technology and Information Science (ISCTIS)}, 
  title={Intelligent fault diagnosis method for railway locomotive main transformer based on oil physicochemical association rule mining}, 
  year={2025},
  volume={},
  number={},
  pages={133-138},
  abstract={Fault diagnosis of railway locomotive main transformer is crucial to ensure railway transportation safety. Aiming at the dimensionality disaster and category imbalance problems existing in existing methods when processing highdimensional heterogeneous data, this paper proposes a fault diagnosis method based on multi-index and association rule mining, combining the improved ML-kNN algorithm (MLk’sNN.EC) and Apriori association rule mining algorithm to achieve multi-dimensional data fusion and accurate fault location.The ML-k’sNN.EC model introduces a dynamic k value optimization mechanism, and uses the BLX- $\alpha$ genetic algorithm to adaptively adjust the number of nearest neighbors to improve classification performance;the Apriori algorithm mines strong association rules between monitoring indicators to enhance model interpretability. Taking the maintenance records and alarm records of the main transformer of HXD3 locomotive as the data set, the experiment shows that this method can effectively identify key fault features such as low breakdown voltage and high moisture content in the analysis of oil physicochemical and gas indicators, with a confidence level of more than 0.9. Compared with the classic multi-label model, the proposed method performs better in indicators such as average accuracy, providing reliable decision support for the condition maintenance of railway locomotive main transformer.},
  keywords={Fault diagnosis;Heuristic algorithms;Oils;Oil insulation;Transformers;Rail transportation;Association rule learning;Classification algorithms;Maintenance;Genetic algorithms;Railway locomotive main transformer;fault diagnosis;association rule mining;oil physics and chemistry},
  doi={10.1109/ISCTIS65944.2025.11065269},
  ISSN={},
  month={May},}@INPROCEEDINGS{10939723,
  author={Birajdar, Sphurti and Gajdhane, Amol and Agnihotri, Kuldeep and Havale, Dhanashri Sanadkumar and Sagvekar, Vijaya and T, Thulasimani},
  booktitle={2024 International Conference on Integration of Emerging Technologies for the Digital World (ICIETDW)}, 
  title={Predicting E-commerce Sales Forecasting and Inventory Management Based on Fuzzy LIM-CNN Technique}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Online shopping's share of the market has grown over the last decade, even if retail as a whole has slowed. Logistical costs for EC are higher than for other retail models due to a variety of problems with inventory management. Even though EC makes inventory management more difficult, it works well with EC because consumers can easily compare prices, which is important because goods demand is very price sensitive. Three stages, including preprocessing, feature selection, and model training, make up this suggested approach. The term "data preprocessing" refers to the steps used to remove any anomalies or noise from the chosen data. Using feature selection, we may sift through different datasets and extract the most unnecessary and superfluous information. A Fuzzy LIM-CNN was employed for the purpose of training the model. The proposed approach outperforms CNN and Fuzzy LIM with an average accuracy of 91.67%.},
  keywords={Training;Costs;Accuracy;Warehousing;Noise;Data preprocessing;Inventory management;Feature extraction;Electronic commerce;Forecasting;Sales Forecasting;Fuzzy Local Information Means Algorithm (FLIM);E-Commerce},
  doi={10.1109/ICIETDW61607.2024.10939723},
  ISSN={},
  month={Sep.},}@ARTICLE{9514447,
  author={Zhu, Feng and Wang, Yan and Zhou, Jun and Chen, Chaochao and Li, Longfei and Liu, Guanfeng},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Unified Framework for Cross-Domain and Cross-System Recommendations}, 
  year={2023},
  volume={35},
  number={2},
  pages={1171-1184},
  abstract={Cross-Domain Recommendation (CDR) and Cross-System Recommendation (CSR) have been proposed to improve the recommendation accuracy in a target dataset (domain/system) with the help of a source one with relatively richer information. However, most existing CDR and CSR approaches are single-target, namely, there is a single target dataset, which can only help the target dataset and thus cannot benefit the source dataset. In this paper, we focus on three new scenarios, i.e., Dual-Target CDR (DTCDR), Multi-Target CDR (MTCDR), and CDR+CSR, and aim to improve the recommendation accuracy in all datasets simultaneously for all scenarios. To do this, we propose a unified framework, called GA (based on Graph embedding and Attention techniques), for all three scenarios. In GA, we first construct separate heterogeneous graphs to generate more representative user and item embeddings. Then, we propose an element-wise attention mechanism to effectively combine the embeddings of common entities (users/items) learned from different datasets. Moreover, to avoid negative transfer, we further propose a Personalized training strategy to minimize the embedding difference of common entities between a richer dataset and a sparser dataset, deriving three new models, i.e., GA-DTCDR-P, GA-MTCDR-P, and GA-CDR+CSR-P, for the three scenarios respectively. Extensive experiments conducted on four real-world datasets demonstrate that our proposed GA models significantly outperform the state-of-the-art approaches.},
  keywords={Motion pictures;Social networking (online);Transfer learning;Training;Recommender systems;Collaborative filtering;Business process re-engineering;Recommender systems;cross-domain recommendation;cross-system recommendation},
  doi={10.1109/TKDE.2021.3104873},
  ISSN={1558-2191},
  month={Feb},}@INPROCEEDINGS{10197142,
  author={Upama, Paramita Basak and Kolli, Anushka and Kolli, Hansika and Alam, Subarna and Syam, Mohammad and Shahriar, Hossain and Ahamed, Sheikh Iqbal},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Quantum Machine Learning in Disease Detection and Prediction: a survey of applications and future possibilities}, 
  year={2023},
  volume={},
  number={},
  pages={1545-1551},
  abstract={Quantum machine learning (QML) in the field of disease detection and prediction use quantum computing techniques and algorithms to analyze and classify large datasets of medical information, by identifying subtle patterns and predict the occurrence or progression of diseases. It involves applying machine learning techniques to data from biological and medical research, such as-genomic and proteomic data, medical imaging, electronic health records, and clinical trial data, using quantum computing algorithms and architectures to perform these analyses more efficiently and accurately than classical computing methods. This approach has the potential to provide new insights into complex biological systems and facilitate the development of more effective treatments and personalized medicine. In this paper, a systematic review of the use of QML algorithms has been conducted, which focuses on the detection and prediction of diseases among patients. The current essence of the field along with the challenges and limitations of current works have also been discussed. After evaluating the implemented and proposed methods of data analysis, algorithm development, usefulness and efficiency of the system in various disease detection and prediction, a recommendation was made on the open research scopes in this field at the end of the paper.},
  keywords={Surveys;Quantum computing;Machine learning algorithms;Systematics;Machine learning;Proteomics;Prediction algorithms;quantum machine learning (QML);disease detection;disease prediction;classical machine learning;quantum computing;healthcare},
  doi={10.1109/COMPSAC57700.2023.00238},
  ISSN={0730-3157},
  month={June},}@ARTICLE{9782433,
  author={Benkert, Ryan and Aribido, Oluwaseun Joseph and AlRegib, Ghassan},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Example Forgetting: A Novel Approach to Explain and Interpret Deep Neural Networks in Seismic Interpretation}, 
  year={2022},
  volume={60},
  number={},
  pages={1-12},
  abstract={In recent years, deep neural networks have significantly impacted the seismic interpretation process. Due to the simple implementation and low interpretation costs, deep neural networks are an attractive component for the common interpretation pipeline. However, neural networks are frequently met with distrust due to their property of producing semantically incorrect outputs when exposed to sections the model was not trained on. We address this issue by explaining model behavior and improving generalization properties through example forgetting. First, we introduce a method that effectively relates semantically malfunctioned predictions to their respectful positions within the neural network representation manifold. More concrete, our method tracks how models “forget” seismic reflections during training and establishes a connection to the decision boundary proximity of the target class. Second, we use our analysis technique to identify frequently forgotten regions within the training volume and augment the training set with state-of-the-art style transfer techniques from computer vision. We show that our method improves the segmentation performance on underrepresented classes while significantly reducing the forgotten regions in the F3 volume in The Netherlands.},
  keywords={Training;Computational modeling;Heating systems;Neural networks;Deep learning;Predictive models;Feature extraction;Deep learning;example forgetting;seismic interpretation;semantic segmentation},
  doi={10.1109/TGRS.2022.3178112},
  ISSN={1558-0644},
  month={},}@ARTICLE{10766377,
  author={Zhong, Jie and Zhang, Heng and Miao, Qiang},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={A Novel Altitude Measurement Channel Reconstruction Method Based on Symbolic Regression and Information Fusion}, 
  year={2025},
  volume={74},
  number={},
  pages={1-12},
  abstract={Accurate altitude data are imperative for precise aircraft flight control, navigation planning, and air traffic management, especially in global positioning system (GPS)-denied environments. While deep learning methods offer promising solutions for altitude prediction through complex predictive models, their inherent lack of interpretability raises safety concerns, particularly in safety-critical aviation contexts. This article introduces a novel symbolic regression (SR)-based approach to altitude prediction. Initially, raw data undergo random projection (RP) to a feature space, addressing challenges associated with feature extraction in SR. Subsequently, altitude-related information is discerned from the inertial navigation system (INS) and atmospheric system (AS), employing genetic programming (GP) to formulate fully interpretable altitude prediction equations. To enhance robustness, information fusion (IF) technology integrates the prediction equations with vertical velocity, establishing a resilient virtual altitude channel. In scenarios where the GPS is entirely unavailable, our proposed method undergoes effective validation across diverse aircraft types and under various flight conditions. Furthermore, the robustness of our fusion algorithm is verified across different noise levels, underscoring its reliability in challenging conditions.},
  keywords={Aircraft;Satellites;Mathematical models;Global Positioning System;Accuracy;Aircraft navigation;Atmospheric modeling;Predictive models;Feature extraction;Computational modeling;Altitude prediction;information fusion (IF);interpretable;symbolic regression (SR)},
  doi={10.1109/TIM.2024.3502815},
  ISSN={1557-9662},
  month={},}@ARTICLE{10494393,
  author={Bi, Xia-An and Yang, Zicheng and Huang, Yangjun and Xing, Zhaoxu and Xu, Luyun and Wu, Zihao and Liu, Zhengliang and Li, Xiang and Liu, Tianming},
  journal={IEEE Transactions on Medical Imaging}, 
  title={CE-GAN: Community Evolutionary Generative Adversarial Network for Alzheimer’s Disease Risk Prediction}, 
  year={2024},
  volume={43},
  number={11},
  pages={3663-3675},
  abstract={In the studies of neurodegenerative diseases such as Alzheimer’s Disease (AD), researchers often focus on the associations among multi-omics pathogeny based on imaging genetics data. However, current studies overlook the communities in brain networks, leading to inaccurate models of disease development. This paper explores the developmental patterns of AD from the perspective of community evolution. We first establish a mathematical model to describe functional degeneration in the brain as the community evolution driven by entropy information propagation. Next, we propose an interpretable Community Evolutionary Generative Adversarial Network (CE-GAN) to predict disease risk. In the generator of CE-GAN, community evolutionary convolutions are designed to capture the evolutionary patterns of AD. The experiments are conducted using functional magnetic resonance imaging (fMRI) data and single nucleotide polymorphism (SNP) data. CE-GAN achieves 91.67% accuracy and 91.83% area under curve (AUC) in AD risk prediction tasks, surpassing advanced methods on the same dataset. In addition, we validated the effectiveness of CE-GAN for pathogeny extraction. The source code of this work is available at https://github.com/fmri123456/CE-GAN.},
  keywords={Diseases;Generative adversarial networks;Imaging;Genetics;Community networks;Mathematical models;Generators;Generative adversarial networks;imaging genetics;community evolutionary convolution;disease risk prediction;pathogeny extraction;Alzheimer’s disease},
  doi={10.1109/TMI.2024.3385756},
  ISSN={1558-254X},
  month={Nov},}@INPROCEEDINGS{10063369,
  author={Bagave, Prachi and Westberg, Marcus and Dobbe, Roel and Janssen, Marijn and Ding, Aaron Yi},
  booktitle={2022 IEEE 4th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={Accountable AI for Healthcare IoT Systems}, 
  year={2022},
  volume={},
  number={},
  pages={20-28},
  abstract={Various AI systems have taken a unique space in our daily lives, helping us in decision-making in critical as well as non-critical scenarios. Although these systems are widely adopted across different sectors, they have not been used to their full potential in critical domains such as the healthcare sector enabled by the Internet of Things (IoT). One of the important hindering factors for adoption is the implication for accountability of decisions and outcomes affected by an AI system, where the term accountability is understood as a means to ensure the performance of a system. However, this term is often interpreted differently in various sectors. Since the EU GDPR regulations and the US congress have emphasised the importance of enabling accountability in AI systems, there is a strong demand to understand and conceptualise this term. It is crucial to address various aspects integrated with accountability and understand how it affects the adoption of AI systems. In this paper, we conceptualise these factors affecting accountability and how it contributes to a trustworthy healthcare AI system. By focusing on healthcare IoT systems, our conceptual mapping will help the readers understand what system aspects those factors are contributing to and how they affect the system trustworthiness. Besides illustrating accountability in detail, we also share our vision towards causal interpretability as a means to enhance accountability for healthcare AI systems. The insights of this paper shall contribute to the knowledge of academic research on accountability, and benefit AI developers and practitioners in the healthcare sector.},
  keywords={Privacy;Decision making;Focusing;Medical services;Regulation;Internet of Things;Security;Accountability;Trustworthiness;Healthcare AI;Internet of Things (IoT)},
  doi={10.1109/TPS-ISA56441.2022.00013},
  ISSN={},
  month={Dec},}@ARTICLE{10507080,
  author={Wang, Dandan and Zhang, Junhui and Liu, Shihao and Lyu, Fei and Huang, Weidi and Xu, Bing},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={KD-ViT: A Lightweight Method for Online Wear State Recognition of Key Friction Pairs in Axial Piston Pump}, 
  year={2024},
  volume={20},
  number={7},
  pages={9621-9632},
  abstract={Online wear state recognition of key friction pairs in the axial piston pump is of great significance for stable operation and predictive maintenance of the whole hydraulic system. Edge computing (EC) meets the real-time and low-cost requirements of online wear state recognition whereas two challenges limit its application. One is that current fault diagnosis methods only focus on local fault information, causing inaccuracy and poor generalization ability in different working conditions. The other is that the computing power and storage of EC devices are limited. Therefore, a lightweight knowledge-distilled vision transformer (ViT) is proposed for online wear state recognition. A novel time-frequency domain stacked and channel-weighted pooling structure is proposed to directly process raw time series. To realize high accuracy and high generalization ability, a ViT-based teacher model is pretrained to learn local and global information. To narrow model capacity gap and adapt to the limited resource of the edge node, a novel student model with a simplified self-attention mechanism is proposed to mimic the structure of the ViT and learn from the pretrained teacher model through knowledge distillation. An edge node with functions of signal acquisition, data preprocessing, and wear state recognition is designed and the distilled student model is deployed into it. Comparison with other state-of-the-art methods, ablation experiment, and online verification experiment demonstrate that the proposed method trades off wear state recognition performance and hardware limitations.},
  keywords={Computational modeling;Pistons;Time series analysis;Transformers;Friction;Fault diagnosis;Time-frequency analysis;Axial piston pump;edge computing (EC);knowledge distillation (KD);vision transformer (ViT);wear state recognition},
  doi={10.1109/TII.2024.3384610},
  ISSN={1941-0050},
  month={July},}@INPROCEEDINGS{10893146,
  author={Gopi, Sreekanth and Sreekanth, Devananda and Dehbozorgi, Nasrin},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing Engineering Education Through LLM-Driven Adaptive Quiz Generation: A RAG-Based Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice study aims to develop an Artificial Intelligence (AI) MCQ generation system for engineering students, with a focus on adaptive learning, educational technology, and innovative assessment tools, to enhance personalized learning. Engineering education faces significant academic performance challenges, with first-year retention rates in STEM fields ranging between 27% to 46%, largely due to poor academic achievements. Multiple Choice Questions (MCQs) identify misconceptions, reinforce knowledge retention, and offer efficient assessment methods for engineering education. This interactive method improves attention and memory retention, reinforces knowledge, and improves comprehension. In this context, the emergence of Large Language Models (LLMs) such as GPT-4 has marked a significant advancement. Our literature review method employed a systematic approach, analyzing peer-reviewed articles, conference papers, and authoritative reports to uncover the trends and challenges in AI-driven quiz generation. The notable gap identified in our literature review is the lack of LLM-based adaptive quiz generation methods specifically for engineering education. Our methodology involved sourcing relevant structured datasets, data pre-processing, embedding generation, vector database storage, hybrid-search retrieval, LLM query results feed, prompt engineering, and context-based response. In this research, we adopted Vectara as a vector database tool for its automatic data ingestion capabilities and seamless integration with generative AI applications. Prompt engineering involves a dual-prompt approach, where the Contextual Question Prompt formulates questions based on user topics and chat history, while the Answer Question Prompt manages MCQ responses with explanations, ensuring relevant and contextually accurate interactions. Evaluation includes topic relevancy, answer relevancy, and a contextual relevancy score. Preliminary results indicate promising results for the generation of accurate and contextually appropriate questions with minimal hallucinations. The quiz generation system was deployed using Streamlit cloud-based architecture to showcase the functionality. Looking forward, we aim to expand the dataset to include more diverse engineering disciplines and to refine the retrieval algorithms to better handle complex diagrams and mathematical expressions commonly found in engineering texts.},
  keywords={Accuracy;Systematics;Databases;Learning (artificial intelligence);Market research;Vectors;Mathematical models;Prompt engineering;Systematic literature review;STEM;AI quiz generation;engineering education;personalized learning;Large Language Models;GPT-4;RAG;Vec-tara;prompt engineering;LLM evaluation},
  doi={10.1109/FIE61694.2024.10893146},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10302622,
  author={Guidetti, Veronica and Dolci, Giovanni and Franceschini, Erica and Bacca, Erica and Burastero, Giulia Jole and Ferrari, Davide and Serra, Valentina and Di Benedetto, Fabrizio and Mussini, Cristina and Mandreoli, Federica},
  booktitle={2023 IEEE 10th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Death After Liver Transplantation: Mining Interpretable Risk Factors for Survival Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={This study introduces a novel approach to mine risk factors for short-term death after liver transplantation (LT). The method outputs intelligible survival models by combining Cox’s regression with a genetic programming technique known as multi-objective symbolic regression (MOSR). We consider 485 Electronic Health Records (EHRs) of patients who underwent LT, containing information on hospitalization and preoperative conditions, with a focus on infections and colonizations by multi-resistant Gram-negative bacteria. We evaluate MOSR outcomes against several performance metrics and demonstrate that they are well-calibrated, predictive, safe, and parsimonious. Finally, we select the most promising post-LT early survival risk score based on information criteria, performance, and out-of-distribution safety. Validating this technique at a multicenter level could improve service pipeline logistics through a trustworthy machine-learning method.},
  keywords={Measurement;Analytical models;Microorganisms;Pipelines;Liver;Machine learning;Data models;Multi-Objective Symbolic Regression;Cox’s model;Liver Transplant;Survival analysis},
  doi={10.1109/DSAA60987.2023.10302622},
  ISSN={},
  month={Oct},}@ARTICLE{10975844,
  author={Zhang, Zihan and Gorbunova, Alina and Rhew, Keunho and Shi, Jianjun},
  journal={IEEE Transactions on Reliability}, 
  title={A Review of Prognostics Methods for Electronic Packages: From a Structure-Aware System-Level Perspective}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Prognostics for electronic packages is an evolving field critical to predicting the reliability and lifespan of electronic systems. This article proposes a novel “structure-aware system-level (SASL)” approach, addressing the limitations of traditional methods that treat components or subsystems as isolated black boxes. SASL examines how individual component degradation propagates, interacts within the package structure, and collectively determines the system's lifetime. The article reviews three key areas: component-level prognostics, package structure, and system-level analysis, offering guidance for future research. It advocates interdisciplinary collaboration to develop practical and interpretable prognostics methods, driving innovation in industries reliant on complex electronic systems.},
  keywords={Reliability;Reviews;Failure analysis;Degradation;Fatigue;Prognostics and health management;Plastics;Predictive models;Accuracy;Maintenance;Degradation;electronic packages;lifetime prediction;prognostics;structure;system level},
  doi={10.1109/TR.2025.3558449},
  ISSN={1558-1721},
  month={},}@ARTICLE{9440853,
  author={Shi, Chenghui and Xu, Xiaogang and Ji, Shouling and Bu, Kai and Chen, Jianhai and Beyah, Raheem and Wang, Ting},
  journal={IEEE Transactions on Cybernetics}, 
  title={Adversarial CAPTCHAs}, 
  year={2022},
  volume={52},
  number={7},
  pages={6095-6108},
  abstract={Following the principle of to set one’s own spear against one’s own shield, we study how to design adversarial completely automated public turing test to tell computers and humans apart (CAPTCHA) in this article. We first identify the similarity and difference between adversarial CAPTCHA generation and existing hot adversarial example (image) generation research. Then, we propose a framework for text-based and image-based adversarial CAPTCHA generation on top of state-of-the-art adversarial image generation techniques. Finally, we design and implement an adversarial CAPTCHA generation and evaluation system, called aCAPTCHA, which integrates 12 image preprocessing techniques, nine CAPTCHA attacks, four baseline adversarial CAPTCHA generation methods, and eight new adversarial CAPTCHA generation methods. To examine the performance of aCAPTCHA, extensive security and usability evaluations are conducted. The results demonstrate that the generated adversarial CAPTCHAs can significantly improve the security of normal CAPTCHAs while maintaining similar usability. To facilitate the CAPTCHA security research, we also open source the aCAPTCHA system, including the source code, trained models, datasets, and the usability evaluation interfaces.},
  keywords={CAPTCHAs;Security;Usability;Image synthesis;Electronic mail;Computers;Resilience;Adversarial image;completely automated public turing test to tell computers and humans apart (CAPTCHA);deep learning;usable security},
  doi={10.1109/TCYB.2021.3071395},
  ISSN={2168-2275},
  month={July},}@ARTICLE{9976038,
  author={Yan, Qingyun and Chen, Yuhan and Jin, Shuanggen and Liu, Shuci and Jia, Yan and Zhen, Yinqing and Chen, Tiexi and Huang, Weimin},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Inland Water Mapping Based on GA-LinkNet From CyGNSS Data}, 
  year={2023},
  volume={20},
  number={},
  pages={1-5},
  abstract={The sensitivity of Cyclone Global Navigation Satellite System (CyGNSS) data to inland water bodies was well documented, however, its advantage over other sensors has seldom been reported. In this work, a semantic segmentation method is adopted for detecting inland water bodies using the CyGNSS data. The widely used LinkNet with the global attention mechanism (GAM) and atrous spatial pyramid pooling (ASPP), namely GA-LinkNet, is equipped to better extract water distributions. The performance comparison with an existing method and other deep networks proved the accuracy and effectiveness of this approach. Satisfactory agreement between the derived and referenced water masks was achieved, with the overall accuracy being 0.959 and 0.976, the mean intersection over union being 0.785 and 0.641, and the F1 scores being 0.879 and 0.781 for the Amazon and Congo regions, respectively. Furthermore, underestimation of water by the reference data was shown during evaluation, which proves the usefulness of the CyGNSS-derived water mask for improving the existing water mask products.},
  keywords={Spatial resolution;Semantic segmentation;Optical sensors;Water resources;Rivers;Remote sensing;Data mining;Cyclone Global Navigation Satellite System (CyGNSS);Global Navigation Satellite System-Reflectometry (GNSS-R);inland water mapping;LinkNet;soil moisture (SM)},
  doi={10.1109/LGRS.2022.3227596},
  ISSN={1558-0571},
  month={},}@ARTICLE{10499869,
  author={Bearfield, Cindy Xiong and van Weelden, Lisanne and Waytz, Adam and Franconeri, Steven},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Same Data, Diverging Perspectives: The Power of Visualizations to Elicit Competing Interpretations}, 
  year={2024},
  volume={30},
  number={6},
  pages={2995-3007},
  abstract={People routinely rely on data to make decisions, but the process can be riddled with biases. We show that patterns in data might be noticed first or more strongly, depending on how the data is visually represented or what the viewer finds salient. We also demonstrate that viewer interpretation of data is similar to that of ‘ambiguous figures’ such that two people looking at the same data can come to different decisions. In our studies, participants read visualizations depicting competitions between two entities, where one has a historical lead (A) but the other has been gaining momentum (B) and predicted a winner, across two chart types and three annotation approaches. They either saw the historical lead as salient and predicted that A would win, or saw the increasing momentum as salient and predicted B to win. These results suggest that decisions can be influenced by both how data are presented and what patterns people find visually salient.},
  keywords={Data visualization;Visualization;Annotations;Market research;Bars;Image color analysis;Data mining;Affordances;annotations;bar chart;decisions;line chart;predictions;table;visual saliency;visualization design},
  doi={10.1109/TVCG.2024.3388515},
  ISSN={1941-0506},
  month={June},}@ARTICLE{9551763,
  author={Li, Changjiang and Ji, Shouling and Weng, Haiqin and Li, Bo and Shi, Jie and Beyah, Raheem and Guo, Shanqing and Wang, Zonghui and Wang, Ting},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Towards Certifying the Asymmetric Robustness for Neural Networks: Quantification and Applications}, 
  year={2022},
  volume={19},
  number={6},
  pages={3987-4001},
  abstract={One intriguing property of deep neural networks (DNNs) is their vulnerability to adversarial examples – those maliciously crafted inputs that deceive target DNNs. While a plethora of defenses have been proposed to mitigate the threats of adversarial examples, they are often penetrated or circumvented by even stronger attacks. To end the constant arms race between attackers and defenders, significant efforts have been devoted to providing certifiable robustness bounds for DNNs, which ensures that for a given input its vicinity does not admit any adversarial instances. Yet, most prior works focus on the case of symmetric vicinities (e.g., a hyperrectangle centered at a given input), while ignoring the inherent heterogeneity of perturbation direction (e.g., the input is more vulnerable along a particular perturbation direction). To bridge the gap, in this article, we propose the concept of asymmetric robustness to account for the inherent heterogeneity of perturbation directions, and present Amoeba1, an efficient certification framework for asymmetric robustness. Through extensive empirical evaluation on state-of-the-art DNNs and benchmark datasets, we show that compared with its symmetric counterpart, the asymmetric robustness bound of a given input describes its local geometric properties in a more precise manner, which enables use cases including (i) modeling stronger adversarial threats, (ii) interpreting DNN predictions, and makes it a more practical definition of certifiable robustness for security-sensitive domains.},
  keywords={Robustness;Perturbation methods;Optimization;Neural networks;Computational modeling;Training;Deep learning;Robustness certification;deep learning security;adversarial example},
  doi={10.1109/TDSC.2021.3116105},
  ISSN={1941-0018},
  month={Nov},}@ARTICLE{10586989,
  author={Jafar, Abbas and Lee, Myungho},
  journal={IEEE Access}, 
  title={High Accuracy COVID-19 Prediction Using Optimized Union Ensemble Feature Selection Approach}, 
  year={2024},
  volume={12},
  number={},
  pages={122942-122958},
  abstract={Recently, the world has been dealing with a severe outbreak of COVID-19. The rapid transmission of the virus causes mild to severe cases of cough, fever, body aches, organ failures, and death. An increasing number of patients, fewer diagnostic options, and extended waiting periods for test results all put pressure on healthcare systems, increasing the virus’s spread. A concise and accurate automatic diagnosis is crucial to identify infected patients in the early stage. This paper proposes a machine learning-based predictive framework to identify COVID-19 cases from clinical data using an optimized union ensemble feature selection (OUEFS) approach. The OUEFS is based on the union ensemble of the feature subsets obtained through a rigorous feature selection (FS) process. It also involves a performance optimization of the ML classifiers. Initially the OUEFS identified key features from the publicly accessible COVID-19 dataset using FS methods such as Mutual Information Feature Selection (MIFS), Recursive Feature Elimination (RFE), and the RidgeCV. The most important features were selected using Top-k thresholding technique. Then selected subsets of features were integrated using a union ensemble approach where an optimal combination of features with enhanced predictive power is derived. This composite feature set was subsequently utilized for model training and evaluation. The classification was conducted using machine learning algorithms such as linear SVM, gradient boosting (GB), logistic regression (LR), and Adaboost to compare their effectiveness on individual and combined feature subsets. We also conducted a Genetic Algorithm (GA) based hyperparameter optimization (HPO) which further refined our training process and enhanced the accuracy of our proposed approach. Experimental results show that the union ensemble of MIFS and RidgeCV FS techniques and the Adaboost classifier and GA HPO achieved 96.30% accuracy. Our optimized union ensemble approach demonstrated superior performance over previous ensemble-based approaches to predict COVID-19 disease, thus offering a robust tool for early and efficient diagnosis without requiring hospital visits.},
  keywords={COVID-19;Feature extraction;Radio frequency;Support vector machines;Accuracy;Prediction algorithms;Machine learning;Ensemble learning;Hyperparameter optimization;Machine learning;feature selection;COVID-19 classification;ensemble learning;hyper-parameter optimization},
  doi={10.1109/ACCESS.2024.3424231},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10765959,
  author={Potteiger, Nicholas and Samaddar, Ankita and Bergstrom, Hunter and Koutsoukos, Xenofon},
  booktitle={2024 International Conference on Assured Autonomy (ICAA)}, 
  title={Designing Robust Cyber-Defense Agents with Evolving Behavior Trees}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Modern network defense can benefit from the use of autonomous systems, offloading tedious and time-consuming work to agents with standard and learning-enabled components. These agents, operating on critical network infrastructure, need to be robust and trustworthy to ensure defense against adaptive cyber-attackers and, simultaneously, provide explanations for their actions and network activity. However, learning-enabled components typically use models, such as deep neural networks, that are not transparent in their high-level decision-making leading to assurance challenges. Additionally, cyber-defense agents must execute complex long-term defense tasks in a reactive manner that involve coordination of multiple interdependent subtasks. Behavior trees are known to be successful in modelling interpretable, reactive, and modular agent policies with learning-enabled components. In this paper, we develop an approach to design autonomous cyber defense agents using behavior trees with learning-enabled components, which we refer to as Evolving Behavior Trees (EBTs). We learn the structure of an EBT with a novel abstract cyber environment and optimize learning-enabled components for deployment. The learning-enabled components are optimized for adapting to various cyber-attacks and deploying security mechanisms. The learned EBT structure is evaluated in a simulated cyber environment, where it effectively mitigates threats and enhances network visibility. For deployment, we develop a software architecture for evaluating EBT-based agents in computer network defense scenarios. Our results demonstrate that the EBT-based agent is robust to adaptive cyber-attacks and provides high-level explanations for interpreting its decisions and actions.},
  keywords={Adaptive systems;Software architecture;Autonomous systems;Decision making;Artificial neural networks;Programming;Computer networks;Security;Cyberattack;Standards;Cybersecurity;Autonomous Systems;Behavior Tree;Reinforcement Learning;Machine Learning;Genetic Programming},
  doi={10.1109/ICAA64256.2024.00011},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10385869,
  author={Wei, Yaonai and Ma, Chong and Zhong, Tianyang and Du, Lei and Zhang, Tuo and Zhang, Songyao and Yang, Li and Liu, Tianming and Zhang, Han and He, Zhibin and Shang, Muheng and Han, Junwei},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={FMRI-Guided Time-Symmetric Joint Model for Visual Attention Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={3212-3217},
  abstract={Visual attention prediction is linked to brain activity, cognition, and behavior. Despite the availability of brain activity features, previous studies have not fully utilized them, resulting in saliency maps predicted by models primarily based on image features that do not accurately reflect visual attention in the human brain. This inspires us to use functional Magnetic Resonance Imaging (fMRI) signals as a "brain observer" to supervise the training of developing models that integrate top-down image attention-dependent cues and supervise information from saliency maps generated from gaze movement patterns under natural stimuli. Hence, this paper presents an FMRI-Guided Time-Symmetric Joint Model to predict saliency maps from movie clips, which captures the dynamic aspects of human brain cognition and attention, enabling the combination of image features with brain features. Furthermore, we generalize the model to the MS-COCO challenge, evaluating its performance on non-movie data. Our model outperforms other brain-feature-free methods in focusing on visual attention regions of humans in both movie and non-movie datasets. Additionally, incorporating brain features improves model performance, indicating their ability to bridge the semantic gap between human cognition and visual images, allowing for more accurate capture of visual attention regions.},
  keywords={Bridges;Training;Visualization;Semantics;Predictive models;Functional magnetic resonance imaging;Observers;saliency detection;fMRI;gaze map},
  doi={10.1109/BIBM58861.2023.10385869},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{9898314,
  author={Ma, Qingyun and Liu, Haiou and Liu, QiQiang},
  booktitle={2022 Global Conference on Robotics, Artificial Intelligence and Information Technology (GCRAIT)}, 
  title={The study of intelligent poetry writing robots}, 
  year={2022},
  volume={},
  number={},
  pages={36-39},
  abstract={In order to solve the problem that the content of the poem is inconsistent with the writing intention of the poem at this stage and is not enough to express the author's mood and mood, the Encoder-Decoder model, Transformer, python programming language, and the pycharm development tool are used to realize a poetry writing robot system, and the automatic writing of the poetry writing robot is completed, and only one line needs to be entered to automatically generate a poem that is neat and tidy, and the function of a good mood is automatically generated. The central idea and theme of the written poems are more clear, the content and creative mood expressed in the story are more unified, and the poetry writing system designed to protect traditional culture in the literary industry and promote the development of cultural treasures - ancient poetry has been widely used.},
  keywords={Industries;Mood;Service robots;Writing;Transformers;Cultural differences;Information technology;Intelligent poetry;Transformer;Writing poetry},
  doi={10.1109/GCRAIT55928.2022.00017},
  ISSN={},
  month={July},}@ARTICLE{10507744,
  author={Zhang, Ling and Jiang, Li and Gao, Ge},
  journal={IEEE Transactions on Plasma Science}, 
  title={Stability and Reliability Analysis of High-Power Magnet Power Supply Based on Long Pulse Operation of CRAFT}, 
  year={2024},
  volume={52},
  number={9},
  pages={3478-3486},
  abstract={High-power converter power supply system is built to meet the requirements of continuous improvement of long pulse parameters. In order to maintain the stability of high-power power supply system under long pulse operation, based on the Comprehensive Research Facility for Fusion Technology (CRAFT) magnet power supply system, this article proposes optimized control strategy to promise the reliability and safety. To further enhance the control strategy, this article employs a genetic algorithm (GA) for tuning the proportional-integral-derivative (PID) parameters. GA is utilized as an optimization technique to fine-tune the proportional, integral, and derivative parameters, aiming to achieve optimal performance and stability in the power supply system. In addition, this article analyzes the three parallel operation modes in detail, including the basic principle explanation under each operation mode, the trigger angle range, control strategy analysis, and current ripple analysis are given. This comprehensive approach not only contributes to the understanding of operation of the power supply system but also integrates advanced optimization techniques, ensuring efficient and stable performance during extended pulse operations.},
  keywords={Power supplies;Thyristors;Superconducting magnets;Genetic algorithms;Power system stability;Magnetic analysis;Tuning;Control strategy;high-power magnet power supply;long pulse;stability and reliability analysis},
  doi={10.1109/TPS.2024.3385532},
  ISSN={1939-9375},
  month={Sep.},}@ARTICLE{11015269,
  author={Riek, Nathan T. and Akcakaya, Murat and Bouzid, Zeineb and Gokhale, Tanmay and Helman, Stephanie and Kraevsky-Philips, Karina and Ji, Rui Qi and Sejdic, Ervin and Zègre-Hemsey, Jessica K. and Martin-Gill, Christian and Callaway, Clifton W. and Saba, Samir and Al-Zaiti, Salah},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of Occlusion Myocardial Infarction}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Objective: In this paper we develop and evaluate ECG-SMART-NET for occlusion myocardial infarction (OMI) identification. OMI is a severe form of heart attack characterized by complete blockage of one or more coronary arteries requiring immediate referral for cardiac catheterization to restore blood flow to the heart. Two thirds of OMI cases are difficult to visually identify from a 12-lead electrocardiogram (ECG) and can be potentially fatal if not identified quickly. Previous works on this topic are scarce, and current state-of-the-art evidence suggests both feature-based random forests and convolutional neural networks (CNNs) are promising approaches to improve ECG detection of OMI. Methods: While the ResNet architecture has been adapted for use with ECG recordings, it is not ideally suited to capture informative temporal features within each lead and the spatial concordance or discordance across leads. We propose a clinically informed modification of the ResNet-18 architecture. The model first learns temporal features through temporal convolutional layers with 1xk kernels followed by a spatial convolutional layer, after the residual blocks, with 12x1 kernels to learn spatial features. Results: ECG-SMART-NET was benchmarked against the original ResNet-18 and other state-of-the-art models on a multisite real-word clinical dataset that consists of 10,393 ECGs from 7,397 unique patients (rate of OMI = 7.2%). ECG-SMART-NET outperformed other models in the classification of OMI with a test AUC of 0.953 [0.921, 0.978]. Conclusion and Significance: ECG-SMART-NET can outperform the state-of-the-art random forest for OMI prediction and is better suited for this task than the original ResNet-18 architecture.},
  keywords={Electrocardiography;Lead;Kernel;Data models;Computer architecture;Random forests;Myocardium;Training;Convolutional neural networks;Medical diagnostic imaging;Convolutional Neural Network;Electrocardiogram;Occlusion Myocardial Infarction;Residual Network},
  doi={10.1109/TBME.2025.3573581},
  ISSN={1558-2531},
  month={},}@INPROCEEDINGS{10612108,
  author={Kuo, En-Chun and Su, Yea-Huey},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Assembling Fragmented Domain Knowledge: A LLM-Powered QA System for Taiwan Cinema}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research introduces the development of a specialized Question Answering (QA) system, designed to tackle the challenges posed by dispersed domain knowledge. Specifically tailored for the Taiwanese movie industry, this system utilizes advancements in Natural Language Processing (NLP) and incorporates large language models via open-source platforms like LangChain. Our aim is to facilitate industry professionals in swiftly locating and extracting pertinent information from extensive data resources. A key focus is on mitigating the risk of data leakage, which is often associated with uploading documents to general-purpose chatbots. We have conducted a comprehensive evaluation of our Large Language Model (LLM)-powered QA system, showcasing its efficacy and accuracy in response. Ultimately, this research strives to illuminate the complexities of aggregating scattered expertise, aiding those who seek to delve deeply into domain-specific knowledge.},
  keywords={Industries;Technological innovation;Accuracy;Large language models;Motion pictures;Information retrieval;Question answering (information retrieval);Generative AI;LangChain;Domain Knowledge;Question Answering System;Taiwan Movie Industry},
  doi={10.1109/CEC60901.2024.10612108},
  ISSN={},
  month={June},}@INPROCEEDINGS{10497437,
  author={Dharani, M. and Radhakrishnan, C.},
  booktitle={2024 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Optimizing Breast Cancer Prediction: A Multimodal Dataset Apporach with XGBOOST}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost, a state-of-the-art machine learning algorithm, an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently, the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data, providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images, demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced, accurate, and efficient breast cancer diagnosis, holding promise for improving early detection rates and patient outcomes in clinical settings.},
  keywords={Radio frequency;Recurrent neural networks;Neurons;Feature extraction;Breast cancer;Mammography;Mathematical models;Breast Cancer Detection;Mammogram Images;XGBoost;Genetic Algorithm;Temporal dependencies and RNN-RBN},
  doi={10.1109/ESCI59607.2024.10497437},
  ISSN={},
  month={March},}@INPROCEEDINGS{9861151,
  author={Yuan, Yue and Han, Yafang and Xue, JingYi and Guo, Yibo},
  booktitle={2022 23rd IEEE International Conference on Mobile Data Management (MDM)}, 
  title={A Dynamic Dispatching Method in the Unmanned Airport Baggage Transportation System}, 
  year={2022},
  volume={},
  number={},
  pages={500-505},
  abstract={Baggage transportation system with unmanned electric vehicles is one of the emerging research topic of the civil aviation airport. However, the battery capacity of electric delivery vehicles limits the distance and load capacity during driving, which has an influence on the decision of vehicles scheduling. To address the above problems, this paper propose a dynamic scheduling model of unmanned electric baggage transportation vehicles in airport containing both load capacity and battery capacity constraints. We also design a dynamic scheduling algorithm to process updating of flights massages in real time using the GCN-CNN-GRU neural network framework to determine the real-time driving condition of vehicles. The experiments under simulated scenarios have proved the performance of our method.},
  keywords={Heuristic algorithms;Atmospheric modeling;Neural networks;Transportation;Airports;Prediction algorithms;Dynamic scheduling;baggage tranportation;vehicles scheduling;DVRP;genetic algorithm;machine learning},
  doi={10.1109/MDM55031.2022.00106},
  ISSN={2375-0324},
  month={June},}@INPROCEEDINGS{10935232,
  author={HUANG, YUTING and PENG, DUNLU and WANG, DEBBY D.},
  booktitle={2024 International Conference on Machine Learning and Cybernetics (ICMLC)}, 
  title={Learning of Molecular Graphs in Toxicity Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={232-238},
  abstract={In-silico toxicity prediction plays a key role in the health industry and research. Machine learning has been widely rewarded for its high efficiency in this field, but the methods are mostly expertise driven and with limited growth. After mitigating many practical problems smartly, deep learning has also been entrusted with high expectations in toxicity prediction. In this work, we attempted to predict compound toxicity by leveraging a graph representation of the compounds and a neat graph-learning framework. Key atomic and bond features were captured by the graph representations, and different graph-learning techniques in the framework were investigated. As evaluated on the Tox21 data, the graph-learning framework possesses a good potential in attaining state-of-the-art performances and handling imbalanced data in toxicity prediction tasks.},
  keywords={Deep learning;Industries;Toxicology;Biological system modeling;Predictive models;Benchmark testing;Data models;Biochemistry;Compounds;Cybernetics;Toxicity prediction;Molecular graph;Deep learning;Attention mechanism},
  doi={10.1109/ICMLC63072.2024.10935232},
  ISSN={2160-1348},
  month={Sep.},}@INPROCEEDINGS{10160701,
  author={Guo, Rui and Liu, Xi and Wang, Ziheng and Jarc, Anthony},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Multiple Surgical Instruments Tracking-By-Prediction With Graph Hierarchy}, 
  year={2023},
  volume={},
  number={},
  pages={2683-2689},
  abstract={Current research strive has tremendously changed the horizon of computer vision tasks in multiple agents tracking. Nevertheless, in the research of robotic assisted surgery, reliable surgical instrument tracking imposes challenge due to the high complexity in state modeling for the hierarchical structure of the instrument versus de-coupling the spatial-temporal correlations naturally embedded in the task. In this paper, we present a new tracking paradigm integrating the trajectory prediction to reduce the data association error that is propagated from the false detection. As a key component in the system, a proposed predictor disentangles the hierarchical modeling and agent kinematic learning by introducing inductive attention mechanism in spatial-temporal graph network. Experiments on real anatomical datasets show that our tracking-by-prediction scheme improves overall localization accuracy over the frames by up to 81%, in comparison to the generic pipelines of tracking, even with transductive graph representation learning, with a large margin of gain in terms of precise localization.},
  keywords={Representation learning;Location awareness;Instruments;Pipelines;Surgery;Kinematics;Predictive models},
  doi={10.1109/ICRA48891.2023.10160701},
  ISSN={},
  month={May},}@INPROCEEDINGS{10896005,
  author={Dubey, Aditya and Sharma, Ramnaresh and Bisen, Dhananjay and Venu, Nookala and Jaiswal, Varshali and Raghuwanshi, Bhagat Singh and Shakywar, Khemchand},
  booktitle={2024 IEEE International Conference on Intelligent Signal Processing and Effective Communication Technologies (INSPECT)}, 
  title={Stock Market Prediction Using Machine Learning Based Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Many methods have been used to forecast stock market trends in the big data age, including real numbers, fuzzy time series data, fuzzy sets design, and conventional time series data. The control of semantic value data is made possible by the use of fuzzy time series data in stock market prediction, which makes accurate value predictions possible. These techniques are mostly used to forecast dynamic, non-linear datasets in a variety of industries, such as stock markets and cryptocurrencies. In order to predict stock prices, artificial intelligence (AI) methods such as neural networks (NN) have become increasingly important. Many methods have been developed to validate parametric and non-parametric theories for predicting trends and gains in the stock market using the feed-forward (FF) NN technique. A variety of soft computing techniques have been investigated in order to provide ways for decision-making based on profit and loss criteria without relying on artificial intelligence. This paper's main goal is to perform a comprehensive examination of the different prediction techniques used to estimate price and return in the stock market. The study includes a comparative review of several approaches as well as a variety of stock market forecasting strategies.},
  keywords={Computational modeling;Time series analysis;Signal processing algorithms;Predictive models;Prediction algorithms;Market research;Vectors;Stock markets;Forecasting;Investment;Neural Network;fuzzy rules;Long Short-Term Memory;Support Vector Regression;Genetic Algorithm},
  doi={10.1109/INSPECT63485.2024.10896005},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10593888,
  author={Nishant, Neerav and Magadum, Alkawati and Pandey, Vivekanand and Suganthi, D and Unni, Manu Vasudevan and Anusuya, S},
  booktitle={2024 International Conference on Electronics, Computing, Communication and Control Technology (ICECCC)}, 
  title={Enhancing Student Placement Predictions with a Trans-CLSTM Based Recommendation System}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Enhancing students' employability poses a major hurdle for educational institutions in the present day, considering the intricate nature of educational entities. Institutions are finding ways to leverage technology in order to improve their administrative processes and decision-making capabilities. Providing comprehensive insights into educational processes and entities through advanced data analytics is crucial for a successful strategy. This study emphasises three crucial components: data preprocessing, feature selection, and model training. Data preprocessing is crucial for ensuring that the dataset is well-prepared for analysis. Various feature selection techniques are used to determine the most relevant features for training purposes. The proposed Trans-CLSTM models surpass traditional algorithms like LSTM and CNN, showcasing substantial enhancements in accuracy, achieving an impressive accuracy rate of 98.22%. This research adds to the ongoing efforts to improve educational quality and student outcomes using data-driven approaches.},
  keywords={Training;Accuracy;Data preprocessing;Employment;Decision making;Prediction algorithms;Feature extraction;Placement Prediction;Genetic Algorithm;Long Short-Term Memory (LSTM)},
  doi={10.1109/ICECCC61767.2024.10593888},
  ISSN={},
  month={May},}@ARTICLE{10021887,
  author={Zhang, Juping and Zheng, Gan and Zhang, Yangyishi and Krikidis, Ioannis and Wong, Kai-Kit},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Deep Learning Based Predictive Beamforming Design}, 
  year={2023},
  volume={72},
  number={6},
  pages={8122-8127},
  abstract={This paper investigates deep learning techniques to predict transmit beamforming based on only historical channel data without current channel information in the multiuser multiple-input-single-output downlink. This will significantly reduce the channel estimation overhead and improve the spectrum efficiency especially in high-mobility vehicular communications. Specifically, we propose a joint learning framework that incorporates channel prediction and power optimization, and produces prediction for transmit beamforming directly. In addition, we propose to use the attention mechanism in the Long Short-Term Memory Recurrent Neural Networks to improve the accuracy of channel prediction. Simulation results using both a simple autoregressive process model and the more realistic 3GPP spatial channel model verify that our proposed predictive beamforming scheme can significantly improve the effective spectrum efficiency compared to traditional channel estimation and the method that separately predicts channel and then optimizes beamforming.},
  keywords={Array signal processing;Channel estimation;Deep learning;Predictive models;Optimization;Logic gates;Estimation;Channel prediction;beamforming;deep learning},
  doi={10.1109/TVT.2023.3238108},
  ISSN={1939-9359},
  month={June},}@INPROCEEDINGS{10099376,
  author={Nguyen, Son Minh and Le, Duc Viet and Havinga, Paul J. M.},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={Learning the world from its words: Anchor-agnostic Transformers for Fingerprint-based Indoor Localization}, 
  year={2023},
  volume={},
  number={},
  pages={150-159},
  abstract={In this paper, we propose Anchor-agnostic Transformers (AaTs) that can exploit the attention mechanism for Received Signal Strength (RSS) based fingerprinting localization. In real-world applications, the RSS modality is inherently well-known for its extreme sensitivity to dynamic environments. Since most machine learning algorithms applied to the RSS modality do not possess any attention mechanism, they can only capture superficial representations, yet subtle but distinct ones characterizing specific locations, thereby leading to significant degradation in the testing phase. In contrast, AaTs are enabled to focus exclusively on relevant anchors at every Received Signal Strength (RSS) sequence for these subtle but distinct representations. This also facilitates the model to neglect redundant clues formed by noisy ambient conditions, thus achieving better accuracy in fingerprinting localization. Moreover, explicitly resolving collapse problems at the feature level (i.e., none-informative or homogeneous features) can further invigorate the self-attention process, by which subtle but distinct representations to specific locations are radically captured with ease. To this end, we enhance our proposed model with two sub-constraints, namely covariance and variance losses that are mediated with the main task within the representation learning stage towards a novel multi-task learning manner. To evaluate our AaTs, we compare the models with the state-of-the-art (SoTA) methods on three benchmark indoor localization datasets. The experimental results confirm our hypothesis and show that our proposed models could provide much higher accuracy.},
  keywords={Location awareness;Representation learning;Pervasive computing;Sensitivity;Fingerprint recognition;Transformers;Multitasking;Transformer;Self-Attention;CNNs;Indoor Localization;Indoor positioning;Deep Learning},
  doi={10.1109/PERCOM56429.2023.10099376},
  ISSN={2474-249X},
  month={March},}@INPROCEEDINGS{10356522,
  author={Xu, Shuting and Wang, Ruochen},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={OdinDTA: Combining Mutual Attention and Pre-training for Drug-target Affinity Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={680-687},
  abstract={Accurate and effective Drug Target binding Affinity (DTA) prediction can significantly shorten the drug development lifecycle and reduce the cost. Although many deep learning-based methods have been developed for DTA prediction, most do not model complex drug-target interaction process and have poor interpretability. In addition, these models depend on large-scale labelled data. To address these problems, we designed a new DTA prediction model called OdinDTA. We use drug sequences and graphs to extract drug features in this model. To meet the challenge of labelled data scarcity, our studies adopted self-supervised pre-training tasks to learn information of amino acid sequences of proteins. Finally, we utilize the mutual attention mechanism to fuse the representations of drugs and proteins. We evaluate the performance of our method on two benchmark datasets, KIBA and Davis. Experimental results show that our model outperforms the current state-of-the-art methods on two independent datasets.},
  keywords={Drugs;Proteins;Learning systems;Costs;Fuses;Neural networks;Predictive models;Drug target interactions;Mutual attention;Pretraining task;Graph neural network},
  doi={10.1109/ICTAI59109.2023.00106},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11011187,
  author={Wen, Sijie},
  booktitle={2025 2nd International Conference on Algorithms, Software Engineering and Network Security (ASENS)}, 
  title={GRU Networks with improved Local Attention for Nonlinear Time Series Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={119-123},
  abstract={This research explores a novel computational approach for time series analysis based on LSTM’s lightweight variant GRU, combined with local attention mechanisms. The proposed model integrates innovative feature selection techniques and evolutionary algorithms to optimize model performance, addressing complex nonlinear problems in sequential data processing. Experimental results on financial datasets show that the optimized model improves prediction accuracy and generalization capability, offering important application value in data-driven decision-making and risk management. The model achieves a 0.9% improvement in R2, 5.0% reduction in MAE, and 9.4% decrease in MSE compared to standard baseline models, with potential applications for various time-dependent forecasting tasks.},
  keywords={Machine learning algorithms;Computational modeling;Time series analysis;Software algorithms;Predictive models;Network security;Data models;Risk management;Standards;Software engineering;Local attention;Nonlinear time series analysis;Computational Intelligence Approach;machine learning},
  doi={10.1109/ASENS64990.2025.11011187},
  ISSN={},
  month={March},}@INPROCEEDINGS{11068521,
  author={Lightholder, Jack and Hardgrove, Craig},
  booktitle={2025 IEEE Aerospace Conference}, 
  title={Onboard Estimation of Physical Parameters in Active Neutron Spectroscopy Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Neutron instruments, such as the Dynamic Albedo of Neutrons (DAN) instrument on the Mars Science Laboratory Curiosity rover, measure the abundance and energies of neutrons after they have undergone interactions with the environment around them. Active neutron spectrometers include a pulsed neutron generator to increase the signal of these measurements. Neutron counts across multiple energy ranges are measured and binned after the time of each pulse and integrated into neutron die away curves. Retrievals performed on neutron die away curves estimate geochemical parameters of the soil such as water equivalent hydrogen and bulk neutron absorption cross section. Parameter estimation must be completed quickly for operations teams to assess the physical parameters at a given location and make tactical follow-on decisions. Past work has reduced the time required to compute physical parameters, but still requires hours and supercomputing scale resources. Here we demonstrate a rapid approach for parameter retrieval using machine learning capable of estimating physical parameters with computational resources available in an embedded environment onboard the spacecraft. A genetic algorithm approach was used to jointly optimize model hyperparameters and perform feature selection for six machine learning model types. Models are then evaluated against the results from the traditional Bayesian retrieval process to characterize model variance from the baseline Bayesian approach. Top models achieve 0.2 wt. % mean absolute error retrieving the water equivalent hydrogen parameter, and 0.0005 cm2/g mean absolute error retrieving the bulk neutron absorption cross section parameter. We assess feature importance and model selection to reason about the driving characteristics of neutron die away curves that enable this approach. Finally, we benchmark runtime and memory footprint of the top models on a Snapdragon 855 processor to demonstrate their path to flight on a representative compute platform. Rapid parameter estimation can be leveraged in the mission planning cycle to generate ‘quick look’ estimates useful for tactical decision making. Embedded deployment of such models can also be utilized onboard future instruments to make in-situ estimates of parameters. This work demonstrates data treatments to support future onboard science instrument autonomy efforts for neutron spectrometers. This is particularly important for applications where active neutron and gamma-ray spectrometers can be used to make rapid, first order geochemical assessments to prioritize follow-on observations without the need for contact science instruments.},
  keywords={Space vehicles;Parameter estimation;Absorption;Computational modeling;Instruments;Hydrogen;Estimation;Machine learning;Neutrons;Bayes methods},
  doi={10.1109/AERO63441.2025.11068521},
  ISSN={2996-2358},
  month={March},}@INPROCEEDINGS{10960067,
  author={Alijoyo, Franciskus Antonius and Muzafer, Syed Shaheem and Bhasin, Narinder Kumar and Chattopadhyay, Dipanwita and Das, Bijit and Raj, I Infant},
  booktitle={2024 IEEE 1st International Conference on Green Industrial Electronics and Sustainable Technologies (GIEST)}, 
  title={Optimizing Climate Impact Assessment: Sloth-Inspired Optimization with Ridge Regression for Socio-economic Policy Insights}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Global socio-economic systems are facing serious problems as a result of climate change, making it necessary for the development of reliable approaches for evaluating its effects and guiding policy decisions. When processing complicated climatic and financial statistics, traditional strategies often have accuracy and interpretability problems. The goal of this research is to optimize the evaluation of climate impact with the aid of integrating the Sloth-inspired Optimization algorithm (SIOA) with Ridge Regression (RR). This technique provides a novel framework for optimizing selecting features and enhancing the reliability of predictions in socio-economic modelling. This integration seeks to address the shortcomings of traditional strategies by using enhancing model interpretability and performance in weather effect assessment. The financial outcomes of weather alternate are then expected by way of integrating a subset of characteristics right into a Ridge Regression version, with an emphasis on growing model interpretability and decreasing prediction mistakes. A climate observe dataset employed to the included architecture produced effective outcomes. Ridge Regression's prediction accuracy become stepped forward, and metrics for mean Squared error (MSE) and mean Absolute errors (MAE) were reduced, owing to SIOA's a success identification of vital weather variability. The potential to capture elaborate linkages amongst climatic factors and economic repercussions became shown to be superior when compared to traditional techniques of study. This paradigm is beneficial for making plans sustainable development and making knowledgeable decisions because it now not most effective increases prediction abilities but also fosters a higher expertise of the dynamic interplay between climatic factors and financial outcomes.},
  keywords={Measurement;Industrial electronics;Accuracy;Predictive models;Prediction algorithms;Reliability;Socioeconomics;Sustainable development;Optimization;Meteorology;Climate change;Climate Impact Assessment;Sloth-Inspired Optimization Algorithm (SIOA);Ridge Regression (RR);Socioeconomic Modeling;Predictive Accuracy},
  doi={10.1109/GIEST62955.2024.10960067},
  ISSN={},
  month={Oct},}
