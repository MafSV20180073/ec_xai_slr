@ARTICLE{10210581,
  author={Lele, Ashwin Sanjay and Chang, Muya and Spetalnick, Samuel D. and Crafton, Brian and Konno, Shota and Wan, Zishen and Bhat, Ashwin and Khwa, Win-San and Chih, Yu-Der and Chang, Meng-Fan and Raychowdhury, Arijit},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={A Heterogeneous RRAM In-Memory and SRAM Near-Memory SoC for Fused Frame and Event-Based Target Identification and Tracking}, 
  year={2024},
  volume={59},
  number={1},
  pages={52-64},
  abstract={Accurate identification of the target and tracking it at high speeds using drone-mounted cameras and compute hardware finds military and commercial applications. Conventional frame-based cameras and convolutional neural networks (CNNs) extract detailed spatial information to show high accuracy but suffer from lower throughput caused by large models. Alternatively, event cameras capture the motion information as an asynchronous event stream with high temporal resolution. Spiking neural networks (SNNs) can be used to process these data at high speed, but the sparse sensing and difficulty in training SNN limit the accuracy. Fusing the complementary spatial and temporal advantages of the frame and event-based pipelines allows high-speed identification and tracking while preserving accuracy. The SNN processes the event stream continuously to provide high-speed target estimates with lower accuracy, while periodic anchors provided by the reliable CNN restore the accuracy. In this work, we present a heterogeneous programmable ARM Cortex-based system-on-a-chip (SoC) in 40-nm Taiwan Semiconductor Manufacturing Company (TSMC) ultra low power (ULP) technology with power-efficient RRAM compute-in-memory (CIM) for CNN and high-speed SRAM compute-near-memory (CNM) for SNN for the modality-matched acceleration of the hybrid vision. Our SoC incorporates: 1) two levels of power gating to save 91.8% of total chip power with non-volatile RRAM-CIM; 2) embedded triple error correction (TEC) within RRAM CIM macro to suppress the raw bit errors in reading by >5 orders of magnitude; and 3) parallelly operating CNN and SNN modules to provide >100 outputs/s. Such cross-layer hybrid approaches can mitigate fundamental tradeoffs in sensing and processing.},
  keywords={Cameras;Target tracking;Random access memory;Neurons;Convolutional neural networks;Sensors;In-memory computing;Nonvolatile memory;System-on-chip;Spiking neural networks;Aerial target tracking;compute-in-memory (CIM);event-based vision;heterogeneous processing;non-volatile memory},
  doi={10.1109/JSSC.2023.3297411},
  ISSN={1558-173X},
  month={Jan},}@INPROCEEDINGS{10640715,
  author={Montero, David and Mahecha, Miguel D. and Martinuzzi, Francesco and Aybar, César and Klosterhalfen, Anne and Knohl, Alexander and Koebsch, Franziska and Anaya, Jesús and Wieneke, Sebastian},
  booktitle={IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Recurrent Neural Networks for Modelling Gross Primary Production}, 
  year={2024},
  volume={},
  number={},
  pages={4214-4217},
  abstract={Accurate quantification of Gross Primary Production (GPP) is crucial for understanding terrestrial carbon dynamics. It represents the largest atmosphere-to-land CO2 flux, especially significant for forests. Eddy Covariance (EC) measurements are widely used for ecosystem-scale GPP quantification but are globally sparse. In areas lacking local EC measurements, remote sensing (RS) data are typically utilised to estimate GPP after statistically relating them to in-situ data. Deep learning offers novel perspectives, and the potential of recurrent neural network architectures for estimating daily GPP remains underexplored. This study presents a comparative analysis of three architectures: Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs), and Long-Short Term Memory (LSTMs). Our findings reveal comparable performance across all models for full-year and growing season predictions. Notably, LSTMs outperform in predicting climate-induced GPP extremes. Furthermore, our analysis highlights the importance of incorporating radiation and RS inputs (optical, temperature, and radar) for accurate GPP predictions, particularly during climate extremes.},
  keywords={Radar remote sensing;Recurrent neural networks;Laser radar;Atmospheric measurements;Ultraviolet sources;Biological system modeling;Production;Gross Primary Production;Recurrent Neural Networks;Remote Sensing;XAI;Climate Extremes},
  doi={10.1109/IGARSS53475.2024.10640715},
  ISSN={2153-7003},
  month={July},}@ARTICLE{10879028,
  author={Li, Rourou and Xia, Tangbin and Jiang, Yimin and Wu, Jianhua and Fang, Xiaolei and Gebraeel, Nagi and Xi, Lifeng},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Deep Complex Wavelet Denoising Network for Interpretable Fault Diagnosis of Industrial Robots With Noise Interference and Imbalanced Data}, 
  year={2025},
  volume={74},
  number={},
  pages={1-11},
  abstract={Fault diagnosis (FD) of industrial robots (IRs) plays an increasingly indispensable role in modern manufacturing. Fault-related component obscurity by strong noise, feature exploitation insufficiency with scarce fault samples, and limited physical interpretation hinder existing diagnostic models’ application to IRs. A deep, complex wavelet denoising network (DCWDN) is, thus, proposed to achieve high-performance and interpretable FD with robustness against noise and class-imbalanced data. Hereinto, a dual-tree cascade autoencoder with trainable convolutional filters is constructed. Significantly, complex wavelet conditions such as orthogonality, approximate analyticity, and sparsity are imposed on the filters to structure their optimization. Meanwhile, shrinkage-based denoising with learnable thresholds is integrated to suppress noise-related components. The proposed DCWDN organically combines the data adaptivity of deep learning (DL) and wavelets’ time-frequency representation ability. Its interpretability is embodied through the explainable structure, learned scientifically meaningful filters, and extracted coefficients with explicit fault indications. Case studies on real IR datasets and experimental drivetrain benchmarks are conducted to demonstrate the effectiveness and superiority of the proposed method.},
  keywords={Wavelet transforms;Filters;Feature extraction;Industrial robots;Noise reduction;Convolution;Noise;Discrete wavelet transforms;Adaptation models;Wavelet analysis;Class-imbalanced data;complex wavelets;fault diagnosis (FD);industrial robot (IR);interpretable neural network;noise interference},
  doi={10.1109/TIM.2025.3540131},
  ISSN={1557-9662},
  month={},}@ARTICLE{9805655,
  author={Dhebar, Yashesh and Deb, Kalyanmoy and Nageshrao, Subramanya and Zhu, Ling and Filev, Dimitar},
  journal={IEEE Transactions on Cybernetics}, 
  title={Toward Interpretable-AI Policies Using Evolutionary Nonlinear Decision Trees for Discrete-Action Systems}, 
  year={2024},
  volume={54},
  number={1},
  pages={50-62},
  abstract={Black-box artificial intelligence (AI) induction methods such as deep reinforcement learning (DRL) are increasingly being used to find optimal policies for a given control task. Although policies represented using a black-box AI are capable of efficiently executing the underlying control task and achieving optimal closed-loop performance—controlling the agent from the initial time step until the successful termination of an episode, the developed control rules are often complex and neither interpretable nor explainable. In this article, we use a recently proposed nonlinear decision-tree (NLDT) approach to find a hierarchical set of control rules in an attempt to maximize the open-loop performance for approximating and explaining the pretrained black-box DRL (oracle) agent using the labeled state–action dataset. Recent advances in nonlinear optimization approaches using evolutionary computation facilitate finding a hierarchical set of nonlinear control rules as a function of state variables using a computationally fast bilevel optimization procedure at each node of the proposed NLDT. In addition, we propose a reoptimization procedure for enhancing the closed-loop performance of an already derived NLDT. We evaluate our proposed methodologies (open- and closed-loop NLDTs) on different control problems having multiple discrete actions. In all these problems, our proposed approach is able to find relatively simple and interpretable rules involving one to four nonlinear terms per rule, while simultaneously achieving on par closed-loop performance when compared to a trained black-box DRL agent. A postprocessing approach for simplifying the NLDT is also suggested. The obtained results are inspiring as they suggest the replacement of complicated black-box DRL policies involving thousands of parameters (making them noninterpretable) with relatively simple interpretable policies. The results are encouraging and motivating to pursue further applications of proposed approach in solving more complex control tasks.},
  keywords={Artificial intelligence;Task analysis;Optimization;Automobiles;Training;Reinforcement learning;Boolean functions;Nonlinear systems;Decision trees;Bilevel;interpretable;nonlinear decision tree (NLDT);reinforcement learning (RL)},
  doi={10.1109/TCYB.2022.3180664},
  ISSN={2168-2275},
  month={Jan},}@ARTICLE{9940593,
  author={He, Ziyan and Ma, Xiaoli},
  journal={IEEE Signal Processing Letters}, 
  title={Improving Radio Tomographic Imaging Accuracy by Attention Augmented Optimization Technique}, 
  year={2022},
  volume={29},
  number={},
  pages={2323-2327},
  abstract={Radio tomographic imaging (RTI) has become a popular approach to reconstruct spatial loss fields (SLFs) in an area covered by a wireless network based on received signal strength (RSS) measurements. SLF images quantify the attenuation rate of the radio-frequency waves at each location in the network. The attenuation for the propagation path can be modeled as the 2-dimensional integral of SLF scaled by a weight function, which is the foundation of RTI techniques and makes the SLF reconstruction possible. In recent years, many methods, including machine-learning-based schemes, have been proposed to achieve more accurate SLF estimates. In this letter, we develop an attention neural network-augmented optimization SLF estimation scheme by taking advantage of deep learning and the traditional RTI technique. Our proposed method achieves the best reconstruction performance among the existing approaches.},
  keywords={Radio frequency;Image reconstruction;Wireless networks;Transceivers;Shadow mapping;Optimization;Estimation;Radio tomographic imaging;image refinement;attention mechanism;deep learning;wireless networks},
  doi={10.1109/LSP.2022.3220149},
  ISSN={1558-2361},
  month={},}@ARTICLE{10677437,
  author={Jun Yook, Hyun and Min Hong, Pyo and Hyun Kang, So and San Jhun, Ga and Eun Seo, Jae and Lee, Youn Kyu},
  journal={IEEE Access}, 
  title={Attention Map Is All We Need for Lightweight Fingerprint Liveness Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={130031-130041},
  abstract={To counter the security threats posed by presentation attacks on fingerprint authentication systems, various deep learning-based fingerprint liveness detection methods have been proposed. However, existing methods typically require significant computing resources or lengthy detection times to achieve high accuracy, which can limit their use in resource-constrained environments such as on-device applications. In this paper, we propose a novel fingerprint liveness detection method that utilizes a Multi-head Self-Attention mechanism. By focusing on important regions of fingerprint images, our proposed method maximizes detection accuracy while simultaneously minimizing both model size and detection time. Our evaluation on real-world datasets demonstrates that our proposed method achieves detection accuracy comparable to state-of-the-art methods while requiring the smallest model size and the least detection time, confirming that our proposed method is the most efficient liveness detection method available.},
  keywords={Fingerprint recognition;Feature extraction;Image matching;Accuracy;Training;Convolutional neural networks;Authentication;Fingerprint liveness detection;lightweight method;multi-head self-attention;fingerprint authentication;presentation attacks},
  doi={10.1109/ACCESS.2024.3458908},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10304551,
  author={Zhang, Weishan and Wang, Yue and Chen, Xiang and Tian, Zhi},
  booktitle={2023 IEEE 24th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)}, 
  title={Spectrum Transformer: Wideband Spectrum Sensing using Multi-Head Self-Attention}, 
  year={2023},
  volume={},
  number={},
  pages={101-105},
  abstract={Data-driven machine learning techniques have been advocated to detect the existence of target signals in complex wireless environments. However, wideband spectrum sensing has to deal with special challenges, including enlarged data dimensionality, insufficient training data, and implicit inter-band dependencies. Facing these issues, conventional deep models unfortunately suffer from high model complexity, inferior sensing accuracy, and notorious over-fitting issues due to ignorance of domain knowledge on spectrum occupancy patterns given limited training data. All these factors lead to ineffective learning model design in the most current literature. To fill this gap, this paper proposes a novel multi-task learning solution for wideband spectrum sensing. Empowered by the multi-head self-attention mechanism, we design an efficient Spectrum Transformer architecture to effectively learn both the inter-band spectrum occupancy correlations and the inner-band spectrum features of the wideband spectrum. Spectrum Transformer outperforms the existing methods based on convolutional neural networks especially in small-data regimes, by achieving higher sensing accuracy with 89% reduction in model complexity.},
  keywords={Wireless communication;Training;Wireless sensor networks;Training data;Signal processing;Transformers;Data models;Spectrum Transformer;wideband spectrum sensing;cognitive radio;neural network;multi-head self-attention mechanism},
  doi={10.1109/SPAWC53906.2023.10304551},
  ISSN={1948-3252},
  month={Sep.},}@ARTICLE{10597653,
  author={Gao, Shiwei and Li, Tianzhen and Dong, Xiaohui and Dang, Xiaochao},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Semi-Supervised Soft Sensor Modeling Based on Ensemble Learning With Pseudolabel Optimization}, 
  year={2024},
  volume={73},
  number={},
  pages={1-18},
  abstract={Key quality variables are critical in the industrial production process. The soft sensor technology, which predicts key quality variables by establishing mathematical models, has gradually become a research hotspot. However, due to the difficulty in obtaining labeled data in industrial fields, a substantial quantity of unlabeled data is not reasonably utilized, which challenges the reliability and accuracy of conventional soft sensor models. Therefore, a semi-supervised model based on the voting ensemble learning is proposed, which combines the outcomes of multiple models’ predictions and utilizes a genetic optimization algorithm to iteratively optimize the generated pseudolabels, improving the accuracy of pseudolabels. By using the channel attention mechanism and multiscale feature fusion method, the feature extraction ability of the model is further improved, thus enhancing the prediction accuracy of the model. Finally, experiments were carried out on industrial debutanizer and industrial steam volume datasets to validate the superior predictive performance of the proposed method.},
  keywords={Predictive models;Soft sensors;Data models;Accuracy;Mathematical models;Optimization;Ensemble learning;Attention mechanism;ensemble learning;pseudolabel optimization;semi-supervised learning;soft sensor},
  doi={10.1109/TIM.2024.3427786},
  ISSN={1557-9662},
  month={},}@ARTICLE{9729234,
  author={Panizo-Lledot, Angel and Pedemonte, Martín and Bello-Orgaz, Gema and Camacho, David},
  journal={IEEE Access}, 
  title={Addressing Evolutionary-Based Dynamic Problems: A New Methodology for Evaluating Immigrants Strategies in MOGAs}, 
  year={2022},
  volume={10},
  number={},
  pages={27611-27629},
  abstract={Multi-Objective Genetic Algorithms (MOGAs) have been successfully used to address dynamic problems in a wide variety of domains. In these domains, data changes over time, so a non-static analysis is required to obtain feasible solutions. In this type of environments, MOGAs are often time-consuming and require special adaptation to work properly. A number of different techniques have been proposed to adapt MOGAs to dynamic environments for tackling the previous problems such as hypermutation, memory and immigrant schemes or multi-population methods, among others. In particular, immigrant strategies are one of the most commonly used methods, for that reason, this work proposes a new methodology that allows to make a detailed evaluation of their performance when these strategies are used. The proposed methodology works on two levels, a coarse-grain one and a fine-grain one. In the former, an overall evaluation of the different immigrant strategies is made based on three different dimensions: Quality, Stability and Speed. In the latter, a detailed study of the status of the immigrant individuals during the evolution of the algorithm is carried out. This is a very relevant aspect to take into account in order to evaluate whether an immigrant strategy is working properly or not. To deploy this methodology, a new visualization technique for population mixing analysis is proposed in this work. In order to validate the proposed methodology, a test case in the context of the Dynamic Community Detection problem (DCD) has been selected using a MOGA that applies several different immigrant schemes, showing both how the methodology works and how it could be employed in a particular dynamic problem.},
  keywords={Statistics;Sociology;Heuristic algorithms;Genetic algorithms;Optimization;Europe;Convergence;Dynamic problems;immigrant strategies;multi-objective genetic algorithms;dynamic community detection;social network analysis},
  doi={10.1109/ACCESS.2022.3156944},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10313520,
  author={Mazumder, Badhan and Tripathy, Deepan Krishna and Yeates, Keith Owen and Beauchamp, Miriam H. and Craig, William and Doan, Quynh and Freedman, Stephen B. and Lebel, Catherine and Zemek, Roger and Ware, Ashley L. and Hye Ye, Dong},
  booktitle={2023 IEEE EMBS International Conference on Biomedical and Health Informatics (BHI)}, 
  title={Multimodal Deep Learning for Pediatric Mild Traumatic Brain Injury Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Despite its prevalence, little is known about the pathophysiology of mild traumatic brain injury (mTBI). This makes it difficult for clinicians to accurately diagnose mTBI and to predict outcomes in affected children, thereby highlighting the urgent need to identify novel and efficacious biomarkers of pediatric mTBI. To address this important knowledge gap, this study introduced a multimodal magnetic resonance imaging (MRI) based deep learning approach toward the classification of mTBI as compared with mild orthopedic injury (OI) by considering both structural MRI (sMRI) and diffusion tensor imaging (DTI). Firstly, convolutional features were extracted by employing a pre-trained DenseNet to capture the morphological features of both modalities. Next, by employing Deep Canonical Correlation Analysis (DCCA), distinct features obtained from the sMRI and DTI data were integrated into a multi-modal embedding. The obtained DCCA fused compact multimodal features were then fed to a random forest (RF) classifier that was used to classify mTBI versus mild OI. Additionally, to visualize the intra-individually heterogeneous brain regions that DenseNet most heavily relied upon for making classification, Gradient-weighted Class Activation Mapping (Grad-CAM) was applied to the DenseNet outcomes for both modalities. According to the experimental outcomes on the clinical dataset, the introduced multimodal deep learning strategy improved the classification accuracy by 8.6% (from 75.8% to 84.4%) and 7.8% (from 76.6% to 84.4%) when compared to the unimodal morphological features, as generated from sMRI and DTI.},
  keywords={Deep learning;Pediatrics;Correlation;Data visualization;Biomarkers;Feature extraction;Robustness;Mild Traumatic Brain Injury;Deep Learning;Transfer Learning;Multi-modal;Explainable AI},
  doi={10.1109/BHI58575.2023.10313520},
  ISSN={2641-3604},
  month={Oct},}@INPROCEEDINGS{10540875,
  author={de Reus, Nico and Schadd, Maarten P.D. and Maaiveld, Thomas M. and Nieuwenhuis Nyegaard, Damian Domela and van den Broek, Captain Artiom A. and van der Waa, Jasper and Trantas, Athanasios},
  booktitle={2024 International Conference on Military Communication and Information Systems (ICMCIS)}, 
  title={Generating Explainable Military Courses of Action}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Course Of Action (COA) generation is an important step in the military decision making process. In land operations it is a manual, creative process throughout which a commander and his staff take many factors into account, such as mission, terrain and weather, doctrine, threat capabilities and own capabilities. Disadvantages of this manual process are the inability of taking into account too many factors, the number of staff involved and the difficulty in evaluating COAs. New (AI-based) technologies can overcome these disadvantages and when implemented could serve as Tactical Decision Aids. This paper presents the results of research in which a step towards an automated tactical decision support tool for land operations was made. For a single SEIZE task at company level, based on doctrinal templates, COAs are selected and optimized using Genetic Algorithms based on simulated effects. An initial step in elucidating the generated COAs is undertaken by linking individual outcomes of simulation runs during the (GA) optimization process to tactical features of the terrain.11This paper was originally presented at the NATO Science and Technology Organization Symposium (ICMCIS) organized by the Information Systems Technology (IST) Panel, IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23–24 April 2024.},
  keywords={Military communication;Decision making;Manuals;Mathematical models;Planning;Task analysis;Optimization;military;course of action;simulations;machine learning;explainable AI},
  doi={10.1109/ICMCIS61231.2024.10540875},
  ISSN={},
  month={April},}@ARTICLE{9772386,
  author={Liu, Peng and Wu, Yizhong and She, Chengqi and Wang, Zhenpo and Zhang, Zhaosheng},
  journal={IEEE Transactions on Power Electronics}, 
  title={Comparative Study of Incremental Capacity Curve Determination Methods for Lithium-Ion Batteries Considering the Real-World Situation}, 
  year={2022},
  volume={37},
  number={10},
  pages={12563-12576},
  abstract={The incremental capacity analysis (ICA) method is a promising method in battery state of health (SOH) estimation studies. The incremental capacity (IC) curve determination is one of the critical parts of the ICA method. However, the uncertain and incomplete charging conditions of real-world electric vehicles (EVs) significantly limit the IC curve determination. This article provides a thorough analysis of the practicality and limitations of four IC curve determination methods based on the datasets collected from real-world operating EVs with a comprehensive comparison scheme. The Lorentz function fitting method is improved by the differential evolution algorithm, breaking the limitation of fixed parameter boundary constraints. A novel PCHIP method is further proposed to determine the IC curve, with higher robustness to realistic uncertain and incomplete charging conditions. The proposed method is validated by real-world data from 40 EVs with low sampling frequency. The results show the extracted features from the IC curves, determined by the proposed method have a stronger correlation with the SOH, allowing the accurate SOH estimation with a 2% error. With less computational resources and sampling frequency requirements, this method shows great potential for the realistic battery management system implementation.},
  keywords={Integrated circuit modeling;Voltage;Feature extraction;Estimation;Data models;Cleaning;State of charge;Incremental capacity analysis (ICA);lithium-ion battery;real-world data;state of health (SOH)},
  doi={10.1109/TPEL.2022.3173464},
  ISSN={1941-0107},
  month={Oct},}@ARTICLE{10355051,
  author={Wu, Jiehong and Zhang, Jingchuan and Sun, Ya'nan and Li, Xianwei and Gao, Lijun and Han, Guangjie},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Multi-UAV Collaborative Dynamic Task Allocation Method Based on ISOM and Attention Mechanism}, 
  year={2024},
  volume={73},
  number={5},
  pages={6225-6235},
  abstract={The problem of task allocation of Unmanned aerial vehicle (UAV) systems is a hot issue in scientific research. Aiming at overcome the shortcomings of existing algorithms in terms of load balancing and execution efficiency, an algorithm Improved Self-Organizing Mapping (ISOM) is proposed in this paper. Firstly, considering the two factors of the UAV flight distance and the mission execution time, the load balance of the UAV is designed. The sum of the track lengths of multiple UAVs and the total time required by multiple UAVs to complete all the tasks in the task area are used to evaluate the quality of cooperative task assignment of multiple UAVs. Secondly, the learning rate and neighborhood function of nonlinear change are designed to ensure the stability and accelerate its convergence. With the increase of the number of iterations, the radius of the neighborhood gradually decreases, and the renewal range of the superior neighborhood is determined by the nonlinear function. Finally, in order to solve the problem of new tasks of UAV and UAV failure, the attention mechanism based on the ISOM algorithm is introduced. Different attention is allocated by the distance between the UAV and the mission points to ensure the missions can be fully executed. Compared with algorithms PSO-GA, Gurobi and ORTools, the time to complete the task is effectively reduced, respectively. At the same time, the algorithm is verified in a large task environment. When the number of tasks is 200 and the number of UAVs is 8, in the TSPLIB task set, the simulation results demonstrate the high efficiency and flexibility of the proposed algorithm.},
  keywords={Autonomous aerial vehicles;Resource management;Robots;Optimization;Vehicle dynamics;Task analysis;Self-organizing networks;Emergency services;Unmanned aerial vehicle (UAV) system;multiple task allocation;Improved Self-OrganizingMapping (ISOM);emergencies;attention mechanism},
  doi={10.1109/TVT.2023.3341878},
  ISSN={1939-9359},
  month={May},}@ARTICLE{10250856,
  author={Ma, Chong and Zhao, Lin and Chen, Yuzhong and Guo, Lei and Zhang, Tuo and Hu, Xintao and Shen, Dinggang and Jiang, Xi and Liu, Tianming},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Rectify ViT Shortcut Learning by Visual Saliency}, 
  year={2024},
  volume={35},
  number={12},
  pages={18013-18025},
  abstract={Shortcut learning in deep learning models occurs when unintended features are prioritized, resulting in degenerated feature representations and reduced generalizability and interpretability. However, shortcut learning in the widely used vision transformer (ViT) framework is largely unknown. Meanwhile, introducing domain-specific knowledge is a major approach to rectifying the shortcuts that are predominated by background-related factors. For example, eye-gaze data from radiologists are effective human visual prior knowledge that has the great potential to guide the deep learning models to focus on meaningful foreground regions. However, obtaining eye-gaze data can still sometimes be time-consuming, labor-intensive, and even impractical. In this work, we propose a novel and effective saliency-guided ViT (SGT) model to rectify shortcut learning in ViT with the absence of eye-gaze data. Specifically, a computational visual saliency model (either pretrained or fine-tuned) is adopted to predict saliency maps for input image samples. Then, the saliency maps are used to filter the most informative image patches. Considering that this filter operation may lead to global information loss, we further introduce a residual connection that calculates the self-attention across all the image patches. The experiment results on natural and medical image datasets show that our SGT framework can effectively learn and leverage human prior knowledge without eye-gaze data and achieves much better performance than baselines. Meanwhile, it successfully rectifies the harmful shortcut learning and significantly improves the interpretability of the ViT model, demonstrating the promise of transferring human prior knowledge derived visual saliency in rectifying shortcut learning.},
  keywords={Data models;Medical diagnostic imaging;Task analysis;Predictive models;Visualization;Deep learning;Training;Interpretability;saliency;shortcut learning;vision transformer (ViT)},
  doi={10.1109/TNNLS.2023.3310531},
  ISSN={2162-2388},
  month={Dec},}@INPROCEEDINGS{10393635,
  author={M, Prem Kumar and Logesh Babu, R. and Sunil, G and Sampathkumar, J. and Chakraborty, Subhra},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Attention-Based Deep Learning Algorithm in Natural Language Processing for Optical Character Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Optical Character Recognition (OCR) is commonly referred as text recognition which poses a substantial issue in the computer vision tasks. Conventional optical character recognition systems frequently suffer in handwritten document recognition. To solve this, Deep Learning (DL) models have emerged as a powerful and advanced solution for character recognition. The present research offers a unique CNN-RNN model with an Attention Mechanism (CNN-RNN-AM) for English image character recognition. The process comprised many important phases, beginning with image collection from a user-defined dataset, then image pre-processesing includes grayscale conversion and noise reduction. For effective character recognition, the proposed approach integrates the segmentation process at multiple levels, including line segmentation, word segmentation, and character segmentation. Finally, the CNN-RNN with an attention mechanism is deployed for character recognition. The experimental findings demonstrated the remarkable efficacy of the suggested CNN-RNN-AM model. It outperformed other compared models by attaining an excellent character recognition accuracy of 99.89%.},
  keywords={Deep learning;Training;Optical filters;Image segmentation;Text recognition;Computational modeling;Optical character recognition;Attention Mechanism;Computer Vision;Deep Learning;Grayscale Conversion and Optical Character Recognition},
  doi={10.1109/EASCT59475.2023.10393635},
  ISSN={},
  month={Oct},}@ARTICLE{10906524,
  author={Ye, Te and Zhang, Zizhen and Zhang, Qingfu and Chen, Jinbiao and Wang, Jiahai},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Solving Multiobjective Combinatorial Optimization via Learning to Improve Method}, 
  year={2025},
  volume={9},
  number={3},
  pages={2122-2136},
  abstract={Recently, neural combinatorial optimization (NCO) methods have been prevailing for solving multiobjective combinatorial optimization problems (MOCOPs). Most NCO methods are based on the “Learning to Construct” (L2C) paradigm, where the trained model(s) can directly generate a set of approximate Pareto optimal solutions. However, these methods still suffer from insufficient proximity and poor diversity towards the true Pareto front. In this paper, following the “Learning to Improve” (L2I) paradigm, we propose weight-related policy network (WRPN), a learning-based improvement method for solving MOCOPs. WRPN is incorporated into multiobjective evolutionary algorithm (MOEA) frameworks to effectively guide the search direction. A shared baseline for proximal policy optimization is presented to reduce variance in model training. A quality enhancement mechanism is designed to further refine the Pareto set during model inference. Computational experiments conducted on two classic MOCOPs, i.e., multiobjective traveling salesman problem and multiobjective vehicle routing problem, indicate that our method achieves remarkable results. Notably, our WRPN module can be easily integrated into various MOEA frameworks such as NSGA-II, MOEA/D and MOGLS, providing versatility and applicability across different problem domains.},
  keywords={Vectors;Optimization;Vehicle routing;Training;Pareto optimization;Decoding;Computational modeling;Traveling salesman problems;Modulation;Heuristic algorithms;Multi-objective combinatorial optimization;neural heuristic;learning to optimize;deep reinforcement learning},
  doi={10.1109/TETCI.2025.3540424},
  ISSN={2471-285X},
  month={June},}@INPROCEEDINGS{10386591,
  author={Jin, Ling and Xu, Xiaodan and Wang, Yuhan and Sadabadi, Kaveh Farokhi and Lazar, Alina and Don, Duleep Rathgamage and Needell, Zachary and Spurlock, C Anna and Amirgholy, Mahyar and Asudegi, Mona},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Leveraging Probe Data and Machine Learning to Derive and Interpret Macroscopic Fundamental Diagrams Across U.S. Cities}, 
  year={2023},
  volume={},
  number={},
  pages={2606-2615},
  abstract={Macroscopic fundamental diagram (MFD) captures an orderly relationship among traffic flow, density, and speed at the network level. Understanding network-wide traffic through MFDs can optimally allocate demand to existing networks, improving performance by maximizing network production and avoiding congestion. However, due to historical data limitations, empirically derived MFD models are sparse in the literature, especially for the U.S. cities. Leveraging a large-scale and granular census-tract-level flow and density derived from vehicle probe data, this research is the first to develop a machine learning approach to both derive MFD models and interpret their underlying difference among urban networks across the entire United States. Among the four machine learning methods tested here XGBoost is found to deliver the best performance to predict the network traffic flow for given vehicular density and location attributes. Interaction Shapley Additive explanation (SHAP) values are used to interpret the factors, such as land use, transportation infrastructure, and network topology, that influence the flow-density relationships among locations. The analysis framework developed in this work can generate datadriven MFDs and a deeper understanding of their shape dependence on network, infrastructure, and land use characteristics, which can be used by transportation authorities to derive and optimize location-specific MFDs facilitating more informed management and planning decisions at the network level.},
  keywords={Analytical models;Shape;Network topology;Urban areas;Transportation;Machine learning;Telecommunication traffic;macroscopic fundamental diagram;United States;vehicle probe data;machine learning models;TreeExplainer;Interaction Shapley values},
  doi={10.1109/BigData59044.2023.10386591},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10548655,
  author={Fu, Rongxiang and Li, Jinwang},
  booktitle={2024 7th International Conference on Advanced Algorithms and Control Engineering (ICAACE)}, 
  title={A High-Density Electrical Inversion Model Coupled with Neural Network Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={193-197},
  abstract={The high-density electrical method technology holds significant importance in the exploration of geological hazards in coal mines. In recent years, a nonlinear inversion method exemplified by the BP (Backpropagation) neural network has gained widespread prevalence in the inversion of high-density electrical methods. Addressing issues such as susceptibility to local minima, slow convergence, and subpar inversion accuracy encountered in high-density electrical inversion using the BP neural network method, this study integrates the GA (Genetic Algorithm) with the BP neural network for the nonlinear inversion of high-density electrical methods. This algorithm initially establishes the structure of the neural network, randomly generates the initial weights and thresholds of the neural network to create a population of chromosomes, and then carries out chromosome replication, crossover, and mutation. The optimal value yielded by the genetic algorithm is employed as the initial weight and threshold of the BP neural network, thereby improving its performance in the inversion of high-density electrical data. Through the inversion calculations of two sets of models, it becomes evidently clear that the GA-BP algorithm demonstrates superiority and feasibility in the two-dimensional nonlinear inversion of high- density electrical methods.},
  keywords={Backpropagation;Geology;Neural networks;Sociology;Hazards;Coal mining;Statistics;High density electrical method;Nonlinear inversion;Genetic algorithm;BP neural network;Intelligent interpretation},
  doi={10.1109/ICAACE61206.2024.10548655},
  ISSN={},
  month={March},}@INPROCEEDINGS{9892483,
  author={Friess, Stephen and Tiňo, Peter and Menzel, Stefan and Xu, Zhao and Sendhoff, Bernhard and Yao, Xin},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Spatio-Temporal Activity Recognition for Evolutionary Search Behavior Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Traditional methods for solving problems within computer science rely mostly upon the application of handcrafted algorithms. As however manual engineering of them can be considered to be a tedious process, it is interesting to consider how far internal mechanisms can be directly learned in an end-to-end manner instead. This is especially tempting to consider for metaheuristic and evolutionary optimization routines which inherently rely upon creating abundant amounts of data during run-time. To implement such an approach for these types of algorithms, it effectively requires a pipeline to first acquire deran-domized algorithm components in a domain-dependent manner and secondly a mapping to select them based upon characteristic features which unveil the black box character of an optimization problem. While in principle, within our prior work we proposed methods for extracting spatial features from metadata, these unfortunately fail to acknowledge the time-dependent nature of it. Thus, fail in scenarios when the inputs generated from initial iterations are not expressive enough. For this reason we specifically develop within this work architectures for spatio-temporal data processing. Particularly, we find that our proposed GCN-GRU and LSTM architectures, which take inspiration from CNN-LSTMs originally proposed for activity recognition in multimedia data-streams, demonstrate high efficiency and most consistent performance on time series of variable length. Further, we can also demonstrate that the class activation map (CAM) for interpretable learning with time series data helps to understand and reflects problem-dependent properties of the search behavior of an optimization algorithm.},
  keywords={Time series analysis;Pipelines;Neural networks;Metaheuristics;Computer architecture;Activity recognition;Feature extraction;Representation Learning;Algorithm Selection;Graph Neural Networks;Activity Recognition;Time Series Classification},
  doi={10.1109/IJCNN55064.2022.9892483},
  ISSN={2161-4407},
  month={July},}@ARTICLE{9912397,
  author={Saum, Narith and Sugiura, Satoshi and Piantanakulchai, Mongkut},
  journal={IEEE Access}, 
  title={Hyperparameter Optimization Using Iterative Decision Tree (IDT)}, 
  year={2022},
  volume={10},
  number={},
  pages={106812-106827},
  abstract={Machine learning and deep learning have gained a lot of attention from researchers because of their promising predictive performance and the availability of extensive high-dimensional data and high-performance computational hardware. However, the performance of these algorithms is susceptible to the choice of hyperparameters, while optimizing these hyperparameters is usually computationally expensive. For this reason, this study proposed a novel sequential search algorithm using decision tree regression as the surrogate function. In each iteration of this algorithm, several new combinations of hyperparameters were selected from a few best-performed leaves of the decision tree, called Iterative Decision Tree (IDT). Our approach could reduce the computational time from repetitive training the surrogate function compared to conventional sequential search algorithms and enable parallel computing. To confirm the effectiveness of the proposed algorithm, it was compared with six popular benchmark optimization algorithms, including Grid Search, Random Search, Bayesian Optimization, Random Forest, Tree-Structured Parzen Estimation, and Genetic Algorithm. The comparison was examined by optimizing three benchmark nonconvex functions, and hyperparameter tuning of two machine learning algorithms (Support Vector Machine and Random Forest) and two deep learning models (Autoencoder and Convolutional Neural Networks). As a result, the proposed algorithm achieved competitive performance with high stability in addition to the feature importance metrics.},
  keywords={Optimization;Machine learning algorithms;Linear programming;Training;Genetic algorithms;Deep learning;Search problems;Decision tree;deep learning;feature importance;hyperparameter optimization;machine learning},
  doi={10.1109/ACCESS.2022.3212387},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10873595,
  author={Afroze, Nashrah and Padovani, Andrea and Choi, Jihoon and Ravikumar, Priyankka Gundlapudi and Kuo, Yu-Hsin and Zhang, Chengyang and Song, Taeyoung and Tian, Mengkun and Sarkar, Eknath and Noor, Manifa and Ravindran, Prasanna Venkatesan and Aabrar, Khandker Akif and Yildiz, Bilge and Mahapatra, Souvik and Kummel, Andrew and Cho, Kyeongjae and Yu, Shimeng and Datta, Suman and Lee, Jun Hee and Larcher, Luca and Thareja, Gaurav and Khan, Asif},
  booktitle={2024 IEEE International Electron Devices Meeting (IEDM)}, 
  title={Self-Healing Ferroelectric Capacitors with ∼ 1000x Endurance Improvement at High Temperatures (85–125°C)}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={For the first time, we demonstrate that introducing an interfacial WO3 layer in ultra-thin ferroelectric Hf0.5Zr0.5O2 (HZO) capacitors improves endurance by 1000× at 125°C. It dramatically slows the degradation of write endurance with increasing temperature, leading to record-high endurance in a 5 nm HZO capacitor at elevated temperatures: 109 cycles at 85°C and 108 cycles at 125°C as well as >1012 cycles at 25°C -all for complete polarization switching $\left(2 P_r \approx 40 \mu \mathrm{C} / \text{cm}^2\right)$. Trap densities extracted from temperature- and cycling-dependent leakage currents show that the Oxygen vacancy (Vo) generation in HZO with cycling is significantly reduced in the presence of the WO3 layer. This is due to Oxygen (O) ion migration into HZO from WO3 during write pulses, which is favored by the asymmetric HZO/ WO3 diffusion barrier (as calculated by Density Functional Theory-based models). Since this prevents back diffusion of O ions from HZO into WO3, there is a net migration of O ions into HZO with continued cycling, partially healing cycling-induced Vo generation. This is a thermally activated self-healing process that becomes more efficient at elevated temperatures, thereby explaining our experimental observations. This concept can be useful for ferroelectric memories (FE-RAMs and -FETs) in emerging 3-D memory-on-logic architectures, where rising temperatures with increasing number of stacked dies is a major challenge.},
  keywords={Degradation;Oxygen;Three-dimensional displays;Capacitors;Memory architecture;Switches;Ions;Leakage currents;Electron devices},
  doi={10.1109/IEDM50854.2024.10873595},
  ISSN={2156-017X},
  month={Dec},}@INPROCEEDINGS{10611921,
  author={Bermejo, Enrique and Cordón, Oscar and Irurita, Javier and Alemán, Inmaculada and Salvador, Ángel Rubio},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Age-at-Death Estimation based on Symbolic Regression Ensemble Learning from Multiple Annotations}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={The present study addresses the problem of semiautomatic age-at-death estimation from pubic symphysis, a crucial yet complex task in forensic anthropology. Its accuracy directly depends on the quality of the pubic bone trait labeling developed by the forensic practitioners, affected by an inherent uncertainty in their definition. As interpretability is a mandatory requirement, we propose an approach where the model design is based on evolutionary learning, considering genetic programming to frame the problem as a symbolic regression task. Additionally, ensemble learning is considered to address the challenges posed by noise, uncertainty, and conflicting annotations inherent in data collected from multiple subjects. Ensemble learning provides an effective approach to navigate these challenges by facilitating consensus-building through decision making and information fusion. Hence, observer committees are formed, comprising multiple forensic specialists with different skills and expertise which provide alternative annotations. Several ensemble configurations combining different weak learners and aggregation operators are tested to assess their effectiveness in improving accuracy and reliability in age-at-death predictions. Their performance is compared against models trained on single annotations, revealing an improvement in predictive accuracy. The obtained results also highlight the benefits of incorporating diverse perspectives to address the complexities associated with human variability and anatomical assessments.},
  keywords={Uncertainty;Accuracy;Annotations;Forensics;Decision making;Predictive models;Mathematical models;Age-at-death estimation;Ensemble learning;Symbolic regression;Genetic programming},
  doi={10.1109/CEC60901.2024.10611921},
  ISSN={},
  month={June},}@ARTICLE{11072478,
  author={Tang, Hongyu and Xu, Chenggang and Huang, Xiaoyun and Zhu, Yuxuan and Li, Yunlong and Gao, Dawei and Ma, Yitao and Xu, Kai},
  journal={IEEE Electron Device Letters}, 
  title={Efficient LDMOS Design via Transferable Surrogate Models and Multi-Objective Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Optimizing LDMOS performance requires balancing breakdown voltage (BV) and specific on-resistance (Ron,sp) under silicon-limit constraints. Conventional technology computer-aided design (TCAD)-based device design is time-consuming and inefficient for large parameter spaces. This work presents a machine learning (ML)-assisted framework that combines initial and fine-tuned deep neural network (DNN) surrogate models with multi-objective particle swarm optimization (MOPSO). The fine-tuned DNN adapts to a non-overlapping extended design space using only a small dataset, while the two surrogates are selectively applied during MOPSO to evaluate candidate designs, enabling significantly faster design evaluation compared to TCAD. SHAP analysis reveals consistent feature importance that aligns with the underlying device physics. The framework constructs diverse Pareto-optimal fronts, offering a scalable solution for automated LDMOS optimization under complex performance trade-offs.},
  keywords={Adaptation models;Optimization;Computational modeling;Training;Artificial neural networks;Performance evaluation;Physics;Doping;Transfer learning;Electron devices;Machine learning (ML);multi-objective optimization (MOO);LDMOS;TCAD},
  doi={10.1109/LED.2025.3586707},
  ISSN={1558-0563},
  month={},}@INPROCEEDINGS{10347141,
  author={Marcílio Júnior, Wilson E. and Eler, Danilo Medeiros and Breve, Fabrício},
  booktitle={2023 36th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)}, 
  title={Model-Agnostic Interpretation via Feature Perturbation Visualization}, 
  year={2023},
  volume={},
  number={},
  pages={19-24},
  abstract={As machine learning algorithms increasingly replace traditional approaches, ensuring their reliability becomes crucial in applications where incorrect decisions can lead to serious consequences. This work proposes a novel model-agnostic in-terpretation approach using feature perturbations, along with a validated visualization tool. The approach enables better understanding of model decisions by domain experts, facilitating effective decision-making in real-world applications.},
  keywords={Visualization;Machine learning algorithms;Perturbation methods;Decision making;Machine learning;Classification algorithms;Reliability},
  doi={10.1109/SIBGRAPI59091.2023.10347141},
  ISSN={2377-5416},
  month={Nov},}@INPROCEEDINGS{10436014,
  author={Zhong, Changqing and Xia, Hongbing and He, Huanli},
  booktitle={2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC)}, 
  title={Genetic Algorithm in Fault Diagnosis System of Construction Machinery}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={With the continuous progress of the times, the speed of economic development is also gradually accelerating. In various industries, construction machinery plays a very important role. However, due to the improvement of scientific and technological level and the continuous improvement of people's quality requirements, the difficulty of construction has also increased accordingly. Therefore, there are enormous difficulties in solving these problems. In response to this issue, this article analyzed and compared the commonly used traditional methods and testing techniques, and draws conclusions. At the same time, the performance of the engineering machinery fault diagnosis system was tested. The test results showed that the diagnostic accuracy was above 94%, and the diagnostic time was within 0.4 ms; the work efficiency was above 0.84; the robustness of genetic algorithm was above 0.04; the interpretability of the system was above 50%. Among them, genetic algorithm was applied to the field of fault diagnosis in construction machinery, and the goal of improving work efficiency was achieved by selecting appropriate methods under different conditions. Genetic algorithms can automatically extract effective features and reduce the need for manual intervention. By optimizing feature weights or selecting the optimal feature subset, the algorithm can effectively reduce the interference of redundant features, extract important features related to faults, and provide a more reliable basis for fault diagnosis.},
  keywords={Fault diagnosis;Wireless communication;Manuals;Feature extraction;Machinery;Genetic algorithms;Testing;Construction Machinery;Fault Diagnosis;Genetic Algorithm;Engineering Faults},
  doi={10.1109/ICMNWC60182.2023.10436014},
  ISSN={},
  month={Dec},}@ARTICLE{10901973,
  author={Zhao, Shu-Li and Wu, Jian-Fei and Song, Yang and Chen, Le-Dong and Xiao, Zhi-Tao},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={A Deep-Learning-Based Modeling Method for Phase-Free Near-Field Scanning Measurement}, 
  year={2025},
  volume={73},
  number={6},
  pages={3547-3559},
  abstract={This study presents a deep-learning-based method for the precise inversion of electromagnetic (EM) radiation sources, utilizing amplitude data from multichannel near-field scans to infer equivalent dipole array parameters. Unlike traditional heuristic search methods or interpolation-based artificial neural networks (ANNs), the proposed model combines residual networks with channel attention mechanisms to effectively capture the intrinsic nonlinear relationships among multidirectional near-field data and their correlations with dipole parameters, thereby streamlining the inverse mapping process from near-field measurements to dipole parameters. Comprehensive simulations and experimental results, including scenarios with patch antennas at varying heights and microcontroller unit (MCU) chips, validate the robustness and accuracy of the proposed model.},
  keywords={Electromagnetic interference;Integrated circuit modeling;Accuracy;Magnetic field measurement;Magnetic fields;Heuristic algorithms;Mathematical models;Data models;Neural networks;Magnetic shielding;Channel attention mechanism;deep learning;electromagnetic (EM) radiation;near-field scans;residual networks},
  doi={10.1109/TAP.2025.3542600},
  ISSN={1558-2221},
  month={June},}@INPROCEEDINGS{10862386,
  author={Yin, Weiwei and Ji, Xiu and Li, Rui and Lu, Chengxiang and Hou, Tianyuan and Xie, Beimin},
  booktitle={2024 8th International Conference on Electrical, Mechanical and Computer Engineering (ICEMCE)}, 
  title={Prediction of transmission line temperature based on improved genetic neural network}, 
  year={2024},
  volume={},
  number={},
  pages={606-609},
  abstract={Transmission lines play an important role in social production and development, so it is very important to detect the safety of transmission lines. In this paper, GANN and attentional mechanism is introduced to predict the temperature of transmission lines. simulation data containing characteristics such as ambient temperature, humidity and solar radiation are generated, and the temperature of the transmission line is calculated. the data is preprocessed using standardization techniques and feature selection is performed using LassoCV. In order to optimize the structure and hyperparameters of the neural network, genetic algorithm is introduced to optimize the neural network model generation by generation through the steps of population initialization, fitness calculation, selection, crossover and variation. In the neural network, an attention mechanism is added to enable the model to automatically focus on the features that are most important to the prediction. In the prediction stage, the individual with the best fitness is selected as the final model, and the model is evaluated by MSE, $R^{2}$ and MAE. The experimental results show that the improved genetic neural network model combined with the attention mechanism can predict the temperature of the transmission line more effectively, with higher accuracy and stability.},
  keywords={Temperature distribution;Power transmission lines;Attention mechanisms;Neural networks;Standardization;Predictive models;Feature extraction;Genetics;Data models;Thermal stability;Transmission lines;GANN;Temperature prediction},
  doi={10.1109/ICEMCE64157.2024.10862386},
  ISSN={},
  month={Oct},}@ARTICLE{11008568,
  author={Mahmoud, Mahmoud Badee Rokaya and Hemdan, Dalia Ismaeil Ibrahim and Alajmani, Samah Hazzaa and Alyami, Raneem Yousif and Elmarhomy, Ghada and Hashim, Hassan and Atlam, El-Sayed},
  journal={IEEE Access}, 
  title={Optimized AI and IoT-Driven Framework for Intelligent Water Resource Management}, 
  year={2025},
  volume={13},
  number={},
  pages={97628-97646},
  abstract={The scheme of water resources management is necessary for reducing water scarcity in arid areas and improving water availability in general. However, water leak detection and irrigation scheduling traditional AI models are often computationally intensive and require complex hyperparameter tuning, making them less scalable. This study presents an artificial intelligence-based optimization framework that improves forecasting accuracy, computational speed, and real-time adaptability. The architecture combines the ensemble-learning algorithms (XGBoost, LightGBM), hybrid AIs (XGBoost + Autoencoder), and metaheuristic feature selection (GA, PSO, SA) for making intelligent decisions. Moreover, ontology-based feature structuring enhances interpretability, while hyperparameter tuning (GridSearchCV, Bayesian Optimization) and model compression techniques (pruning, quantization, knowledge distillation) ensure computational efficiency. A large number of experiments on real-world IoT sensor data testify to the effectiveness of the framework. It achieves 0.992 AUC-ROC scores for leak detection, an RMSE of 0.227 hours for irrigation scheduling, and an overall accuracy of 94.8%. Additional performance measures comprise precision (89.0%), recall (95.2%), F1-score (0.92), and inference speed (0.003 ms/sample). Although quantization has reduced the computational overhead, we still see a 13.02% increase in the model size as seen in Experiment 6, leading to a trade-off that needs to be optimized further. This study offers a deployable AI-based model for sustainable water management by tackling the issues of scalability, computational cost, and limitations in benchmark evaluation. By virtue of the empirical validation and comparative analysis of the framework, it has been shown to perform better than the regular methods, proving that the methodology can act as a step forward in the field of real-time, AI-assisted irrigation and leak detection systems.},
  keywords={Artificial intelligence;Water resources;Computational modeling;Optimization;Real-time systems;Adaptation models;Irrigation;Quantization (signal);Accuracy;Leak detection;AI-driven optimization;IoT sensor data;sustainable water management;ensemble learning;irrigation scheduling;leak detection;hybrid AI models;metaheuristic feature selection;Bayesian optimization;model quantization;real-time inference;edge-cloud computing},
  doi={10.1109/ACCESS.2025.3572067},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10356408,
  author={Panagoulias, Dimitrios P. and Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Tailored Explainability in Medical Artificial Intelligence-empowered Applications: Personalisation via the Technology Acceptance Model}, 
  year={2023},
  volume={},
  number={},
  pages={486-490},
  abstract={The great momentum of Artificial Intelligence-empowered applications makes the requirement for detailed and tailored explainability frameworks more crucial. This is particularly evident in the medical domain, where validation of methodologies and outcomes is very important to the adoption of such systems. The depth and the level of understanding of Artificial Intelligence-related concepts is a significant design parameter and necessitates a systemic approach to ensure that a proper level of transparency is incorporated in an Artificial Intelligence-empowered application. In this paper, we propose a novel and generalised approach for the analysis of user requirements and abilities in relation to Artificial Intelligence-empowered applications. Specifically, we use the Technology Acceptance Model (TAM), as a technical methodology to measure the user perception of usefulness and usability of a technology and, subsequently, identify the corresponding depths of explainablity requirements. As a result, we design a layered and personalised explainability framework that may increase adoption rates of domain-specific Artificial Intelligence-empowered technologies.},
  keywords={Technology acceptance model;Software;Usability;Artificial intelligence;AI-empowered software engineering;biomarkers;explainability;technology acceptance model},
  doi={10.1109/ICTAI59109.2023.00077},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10500073,
  author={Couder, Juan Ortiz and Gomez, Dawson and Ochoa, Omar},
  booktitle={SoutheastCon 2024}, 
  title={Requirements Verification Through the Analysis of Source Code by Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={75-80},
  abstract={In the most recent years, Large Language Models (LLMs) have gained popularity and have been accepted and used in different domains due to their ability to understand and generate written language. LLMs allow us to analyze large amounts of data in a few moments, yet they are also extremely simple to use, making them a very powerful assistive tool that can aid in a wide range of tasks; from planning a family trip, to aid during the development process of a huge system. For software developers, LLMs have been mostly used for code generation, explanation, or optimization. Software verification is a crucial part of software development as it is the process of ensuring that a system meets specific requirements. Requirements specifications play a pivotal role in software verification as they define what a system should do. In this paper we propose the use of LLMs for code verification through the analysis of requirements specifications. We prove that LLMs, such as GPT-3.5, can verify a list of requirements through a given code and evaluate why the requirements have or have not been met.},
  keywords={Codes;Software design;Source coding;Software;Mathematical models;Robustness;Planning;Verification;Software Engineering;Software Requirements;ChatGPT;Large Language Model;GPT-3.5},
  doi={10.1109/SoutheastCon52093.2024.10500073},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10941803,
  author={Shang, Wenli and Yang, Xiaojun and Gu, Zhaojun and Wang, Shuang and Ding, Lei},
  booktitle={2024 10th International Conference on Computer and Communications (ICCC)}, 
  title={An Intrusion Detection System for the Internet of Vehicles Based on Multi-Level Hybrid Feature Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1976-1981},
  abstract={The rapid advancement of Internet of Vehicles (IoV) technology has increasingly automated and intelligentized modern vehicles. The connection between vehicle networks and external networks has become much closer, significantly increasing the risks of intrusions and threats, making vehicle network security more critical. This paper propose an intrusion detection model based on multi-level hybrid feature analysis to identify intrusions and threats in the IoV. The model utilizes parallel Long Short-Term Memory (LSTM), and One-Dimensional Convolution (Conv1D) to extract global and local features from input data separately and then merges these features to provide comprehensive and integrated hybrid features. It employs a multi-head attention mechanism to extract relationships at different positions in the sequence from multiple perspectives, and an improved emporal Convolutional Network (TCN) to further capture long-distance dependencies in the sequence, thereby extending the model's awareness of long-term dependencies. Finally, malicious traffic is identified through multi-classification. The proposed model was evaluated on two publicly available IoV security datasets, CICIoV2024 and CICIDS2017, achieving accuracy rates of 100% and 99.821 %, respectively. These findings underscore the effectiveness of our proposed model.},
  keywords={Analytical models;Attention mechanisms;Accuracy;Computational modeling;Intrusion detection;Network security;Feature extraction;Data models;Long short term memory;Internet of Vehicles;Internet of Vehicles;Intrusion Detection System;Conv1D;TCN;LSTM;PSO;Attention Mechanism},
  doi={10.1109/ICCC62609.2024.10941803},
  ISSN={2837-7109},
  month={Dec},}@INPROCEEDINGS{10059682,
  author={Challur, Geetesh and Tammana, Pradhan Babu and Ramesh, Solasa Venkata Naga and Dattathreya, Kanigiri Guru},
  booktitle={2022 Fourth International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT)}, 
  title={Evaluating the effectiveness of the Burden fairness metric}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Burden fairness metrics are numeric representations of the weights given to tasks. The greatest obstacle in introducing fairness metrics is it does not really measure what we intend for it to do. This can be seen with the “burden fairness apparency” metric, which states if a task is balanced in terms of restriction on size but the workload change that results from that restriction leads to a discrepant disparity between tasks. Fairness metric is determined by the system's calculation of the ratio and type of mistakes it does intrinsically. Several firms develop fair engines because calculating fairness is considered a profit losing activity, meaning that the payback period for this project has to be comparably lower than traditional setups if it wants to succeed in an open market. In this paper, the effectiveness of the burden fairness metric is evaluated with an ML-based approach.},
  keywords={Measurement;Computer science;Computational modeling;Evolutionary computation;Computational efficiency;Task analysis;Engines;Fairness metrics;Burden;Statistical parity;Decision boundary;Sensitive attributes;Unprivileged groups;Classification},
  doi={10.1109/ICERECT56837.2022.10059682},
  ISSN={},
  month={Dec},}@ARTICLE{11009173,
  author={Wang, Yunhe and Du, Zhengyu and Li, Xiaomin and Xiao, Wenyuan and Liu, Hongpu and Yang, Liang},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Evolving Dual-directional Multiobjective Feature Selection for High-dimensional Gene Expression Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={High-dimensional gene expression data has gained considerable attention in diverse medical fields such as disease diagnosis, with the challenges of the dimensionality curse and exponentially growing computation. To analyze the data, feature selection is an essential step by reducing the dimensionality. However, most feature selection algorithms for high-dimensional gene expression data still suffer from low classification and poor generalization ability. An evolutionary algorithm is an effective paradigm for enhancing global search capability in feature selection. Inspired by the evolutionary algorithm Competitive Swarm Optimization, we propose a Multiobjective Dual-directional Competitive Swarm Optimization (MODCSO) method for feature selection from high-dimensional gene expression data. First, we design a competitive swarm optimization algorithm framework based on multi-objective optimization to evolve three objective functions simultaneously. Then, we introduce a dual-directional learning strategy that trains particles within the loser group using two distinct learning strategies. To assess the effectiveness and efficiency of the suggested algorithm, we evaluate MODCSO through extensive experiments on twenty high-dimensional gene expression datasets and three real-world biological datasets. Compared to various leading feature selection algorithms, our proposed algorithm MODCSO exhibits superior competitiveness for the high-dimensional feature selection task. Moreover, we provide other extensive analyses to demonstrate further the robustness and biological interpretability of MODCSO in handling high-dimensional gene expression data.},
  keywords={Feature extraction;Optimization;Gene expression;Particle swarm optimization;Linear programming;Classification algorithms;Bioinformatics;Heuristic algorithms;Convergence;Accuracy;feature selection;high-dimensional gene expression data;competitive swarm optimization},
  doi={10.1109/JBHI.2025.3572310},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{9871548,
  author={Ellis, Charles A. and Sendi, Mohammad S.E. and Miller, Robyn L. and Calhoun, Vince D.},
  booktitle={2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={An Unsupervised Feature Learning Approach for Elucidating Hidden Dynamics in rs-fMRI Functional Network Connectivity}, 
  year={2022},
  volume={},
  number={},
  pages={4449-4452},
  abstract={Dynamic functional network connectivity (dFNC) data extracted from resting state functional magnetic resonance imaging (rs-fMRI) recordings has played a significant role in characterizing the role that brain network interactions play in a variety of brain disorders and cognitive functions. dFNC analyses frequently use clustering methods to identify states of network activity. However, it is possible that these states are dominated by a few highly influential networks or nodes, which could obscure condition-related insights that might be gained from networks or nodes less influential to the clustering. In this study, we propose a novel feature learning-based approach that could contribute to the identification of condition-related activity in formerly less influential networks or nodes. We demonstrate the viability of our approach within the context of schizophrenia (SZ), applying our approach to a dataset consisting of 151 participants with SZ and 160 controls (HCs). We find that the removal of some connectivity pairs significantly affects the underlying states and magnifies the differences between participants with SZ and HCs in each state. Given our findings, we hope that our approach will contribute to the characterization and improved diagnosis of a variety of neurological conditions and functions. Clinical Relevance— Our approach could contribute to the characterization and diagnosis of many neurological conditions},
  keywords={Representation learning;Neurological diseases;Mental disorders;Heuristic algorithms;Clustering methods;Clustering algorithms;Functional magnetic resonance imaging},
  doi={10.1109/EMBC48229.2022.9871548},
  ISSN={2694-0604},
  month={July},}@ARTICLE{10379612,
  author={Aljebreen, Mohammed and Mengash, Hanan Abdullah and Alamgeer, Mohammad and Alotaibi, Saud S. and Salama, Ahmed S. and Hamza, Manar Ahmed},
  journal={IEEE Access}, 
  title={Land Use and Land Cover Classification Using River Formation Dynamics Algorithm With Deep Learning on Remote Sensing Images}, 
  year={2024},
  volume={12},
  number={},
  pages={11147-11156},
  abstract={Currently, remote sensing images (RSIs) are often exploited in the explanation of urban and rural areas, change recognition, and other domains. As the majority of RSI is high-resolution and contains wide and varied data, proper interpretation of RSIs is most important. Land use and land cover (LULC) classification utilizing deep learning (DL) is a common and efficient manner in remote sensing and geospatial study. It is very important in land planning, environmental monitoring, mapping, and land management. But, one of the recent approaches is problems like vulnerability to noise interference, low classification accuracy, and worse generalization ability. DL approaches, mostly Convolutional Neural Networks (CNNs) revealed impressive performance in image recognition tasks, making them appropriate for LULC classification in RSIs. Therefore, this study introduces a novel Land Use and Land Cover Classification employing the River Formation Dynamics Algorithm with Deep Learning (LULCC-RFDADL) technique on RSIs. The main objective of the LULCC-RFDADL methodology is to recognize the diverse types of LC on RSIs. In the presented LULCC-RFDADL technique, the dense EfficientNet approach is applied for feature extraction. Furthermore, the hyperparameter tuning of the Dense EfficientNet method was implemented using the RFDA technique. For the classification process, the LULCC-RFDADL technique uses the Multi-Scale Convolutional Autoencoder (MSCAE) model. At last, the seeker optimization algorithm (SOA) has been exploited for the parameter choice of the MSCAE system. The achieved outcomes of the LULCC-RFDADL algorithm were examined on benchmark databases. The simulation values show the better result of the LULCC-RFDADL methods with other approaches in terms of different metrics.},
  keywords={Feature extraction;Classification algorithms;Heuristic algorithms;Remote sensing;Deep learning;Satellite images;Land use planning;Metaheuristics;Remote sensing images;land use classification;land cover;deep learning;metaheuristics},
  doi={10.1109/ACCESS.2023.3349285},
  ISSN={2169-3536},
  month={},}@ARTICLE{10559590,
  author={Yoshida, Masatomo and Namura, Haruto and Okuda, Masahiro},
  journal={IEEE Access}, 
  title={Adversarial Examples for Image Cropping: Gradient-Based and Bayesian-Optimized Approaches for Effective Adversarial Attack}, 
  year={2024},
  volume={12},
  number={},
  pages={86541-86552},
  abstract={In this study, we propose novel approaches for generating adversarial examples targeting machine learning-based image cropping systems. Image cropping is crucial for meeting display space restrictions and highlighting content’s interest areas. However, existing image cropping systems often miss user-intended areas, have necessities to remove inherent biases in light of AI fairness, or might expose users to legal risks. To address these issues, our paper introduces approaches for effectively creating adversarial examples in both black-box and white-box settings. In the white-box approach, we utilize gradient-based perturbations focusing on the model’s blurring layer and targeting effective areas. For the black-box approach, even for models where gradient information is unavailable, we levered pixel attacks with Bayesian optimization and patch attacks to effectively narrow the search space. We also introduce a novel quantitative evaluation method for image cropping by measuring shifts in gaze saliency map peak values, reflecting a typical scenario with social network services. Our results suggest that our approaches not only outperform existing methods but also exhibit the potential to be an effective solution to the problems even with models on actual platforms.},
  keywords={Glass box;Computational modeling;Perturbation methods;Predictive models;Closed box;Gaussian noise;Data models;Adversarial machine learning;Object detection;Social networking (online);Adversarial examples;image cropping;object detection;saliency map;Twitter},
  doi={10.1109/ACCESS.2024.3415356},
  ISSN={2169-3536},
  month={},}@ARTICLE{10752958,
  author={Nwobodo, Onyeka Josephine and Wereszczyński, Kamil and Kuaban, Godlove Suila and Skurowski, Przemysław and Cyran, Krzysztof Adam},
  journal={IEEE Access}, 
  title={An Adaptation of Fitts’ Law for Performance Evaluation and Optimization of Augmented Reality (AR) Interfaces}, 
  year={2024},
  volume={12},
  number={},
  pages={169614-169627},
  abstract={There is growing widespread adoption of augmented reality in tech-driven industries and sectors of society, such as medicine, gaming, flight simulation, education, interior design and modelling, entertainment, construction, tourism, repair and maintenance, public safety, agriculture, and quantum computing. However, ensuring smooth and intuitive interactions with augmented objects is challenging, requiring practical performance evaluation and optimization models to assess and improve users’ experiences with AR-enhanced systems. In this paper, we apply Fitts’ Law to model and predict interaction task difficulty with objects distributed across four spatial quadrants. We use genetic optimization algorithms to fine-tune Fitts’ Law parameters, achieving a model that significantly enhances predictive accuracy. Our optimized model demonstrates an approximately 40% reduction in interaction task difficulty across all quadrants, leading to a more ergonomic and intuitive user interface. This study contributes to the Human-Computer Interaction (HCI) field by offering a refined metric for evaluating and optimizing AR interfaces and addressing the unique challenges of three-dimensional interaction environments. Therefore, we propose a practical framework for the performance evaluations and optimization of augmented reality and other user interfaces.},
  keywords={Performance evaluation;Solid modeling;Adaptation models;Ergonomics;Computational modeling;Predictive models;Brain modeling;Optimization;Augmented reality;Load modeling;Augmented reality;SLAM;Fitts’ law;level of difficulty;ergonomics in AR;user engagement},
  doi={10.1109/ACCESS.2024.3498444},
  ISSN={2169-3536},
  month={},}@ARTICLE{10891791,
  author={Chhotray, Santosh Kumar and Mishra, Debahuti and Pati, Sarada Prasanna and Mishra, Sashikala},
  journal={IEEE Access}, 
  title={An Optimized Cascaded CNN Approach for Feature Extraction From Brain MRIs for Tumor Classification}, 
  year={2025},
  volume={13},
  number={},
  pages={32681-32705},
  abstract={This study enhances brain tumor classification by leveraging pre-trained models and attention mechanisms, ultimately improving accuracy and reliability in medical imaging diagnostics through feature extraction. A generative adversarial network (GAN) is employed for artifact removal, and images are resized to  $224\times 224$  pixels. Four pre-trained models—VGG16, ResNet50, NASNet, and DenseNet121—capture distinct features, and a Custom-CNN integrates these models with the convolutional block attention module (CBAM). The bald eagle optimization (BEO) algorithm is used to optimize the hyperparameters while balancing exploration and exploitation. The proposed Custom-CNN outperformed all pre-trained models in classifying brain tumor data across three datasets (Br35H, FIGSHARE, and SARTAJ), achieving a highest accuracy of 0.9722, sensitivity of 0.9689, precision of 0.9721, and an F-score of 0.9708 for the Br35H dataset. The incorporation of CBAM (Custom-CNN-CBAM) resulted in consistent performance improvements, with accuracy increasing from 0.9433 to 0.9572 for the Br35H dataset and from 0.9336 to 0.9501 for the FIGSHARE dataset, achieving the highest F-score of 0.9598. The enhanced version of the Custom-CNN-CBAM model utilizing the BEO, referred to as Custom-CNN-CBAM-BEO, demonstrated superior convergence speed and accuracy compared to models optimized with genetic algorithm (GA) and particle swarm optimization (PSO), highlighting the effectiveness of the BEO optimization approach. The evaluation of various Custom-CNN models incorporating attention mechanisms and optimization techniques revealed that the Custom-CNN-CBAM-BEO model achieved the best average rank of 5.68 in the Friedman test, with the Bonferroni-Dunn test confirming its superiority.},
  keywords={Feature extraction;Brain modeling;Accuracy;Computational modeling;Brain tumors;Computer architecture;Adaptation models;Medical diagnostic imaging;Optimization;Magnetic resonance imaging;Squeeze-and-excitation block (SEB);spatial attention block (SAB);convolutional block attention module (CBAM);attention-based feature extraction;bald eagle optimization (BEO)},
  doi={10.1109/ACCESS.2025.3543214},
  ISSN={2169-3536},
  month={},}@ARTICLE{10360809,
  author={Hu, Yun-Zhang and Wang, Hui},
  journal={IEEE Access}, 
  title={TATune: A RocksDB Knob Tuning System Based on Transformer}, 
  year={2023},
  volume={11},
  number={},
  pages={143589-143600},
  abstract={RocksDB is a powerful database engine that offers a wide range of adjustable knobs, which greatly influence its performance. However, configuring RocksDB manually for optimal performance is challenging due to the large number of available knobs and their complex settings. To address this issue, we propose Transformer Adaptive Gentic Algorithm Tune(TATune), an auto-tuning system for RocksDB knobs. In TATune, knob configuration files for RocksDB are randomly generated and executed at different preset workloads first. Subsequently, the correlation between the knob and RocksDB performance is learned by the prediction model based on Transformer. Finally, an adaptive genetic algorithm that utilizes the prediction model as a fitness function to recommend the RocksDB knob setting. Additionally, a novel optimization metric is also proposed to evaluate the performance of the auto-tuning RocksDB knob system. TATune is compared with other approaches to configure RockDB knobs on six distinct workloads. The results indicate that TATune is effective and achieves significant performance improvement across various target workloads. The final average optimization performance is 26% better than K2vTune and 72% better than RTune.},
  keywords={Predictive models;Adaptation models;Statistics;Sociology;Merging;Genetic algorithms;Compaction;Transformers;Database systems;RocksDB;auto-tuning;knob configuration;transformer;adaptive genetic algorithm},
  doi={10.1109/ACCESS.2023.3343455},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10165918,
  author={Xu, Tao and Xu, Kai and Zhang, Jiangming and Yang, Sijie and Huang, Junjie},
  booktitle={2023 6th International Conference on Energy, Electrical and Power Engineering (CEEPE)}, 
  title={Quality Inspection Scheduling Problem Based on Reinforcement Learning Environment}, 
  year={2023},
  volume={},
  number={},
  pages={837-843},
  abstract={Quantity inspection plays an important role in power metering. With the development of the digital construction of the quality inspection laboratory, the scheduling algorithm of quality inspection tasks requires higher scheduling efficiency and accuracy to meet the diverse needs of practical applications. Different from the traditional job-shop scheduling problem (JSP), there is no fixed corresponding relationship between samples and tasks in the quality inspection task scheduling problem (QISP), which means a higher degree of freedom of scheduling. At the same time, quality inspection tasks have more complex constraints such as serial, parallel, and mutual exclusion, which makes the existing scheduling algorithms cannot be directly applied. This paper builds a reinforcement learning (RL) based method for QISP. A new scheduling feature representation method is proposed to fully describe the state of quality inspection tasks and sample-device utilization. Aiming to solve the problem of sparse rewards, we present a reward function to integrate scheduling environment utilization rate and empty time. Considering the non-repetitive and complex constraints of quality inspection tasks, a set of action selection rules is proposed to replace the agent's direct learning of action decisions. Heuristic decide is used to improve the convergence speed of the algorithm and enhance the interpretability of the model's action selection. Compared with the traditional MWKR, GA, PSO algorithms, the RL-based method in this paper shows great advantages in solution quality and efficiency on the real data-set of a quality inspection laboratory of a state grid corporation.},
  keywords={Power engineering;Scheduling algorithms;Heuristic algorithms;Laboratories;Metaheuristics;Reinforcement learning;Inspection;quality inspection scheduling problem;reinforcement learning;scheduling algorithm},
  doi={10.1109/CEEPE58418.2023.10165918},
  ISSN={},
  month={May},}@ARTICLE{10310193,
  author={Jiao, Bowen and Wang, Yulin and Wang, Peng and Wang, Hongchang and Yu, Yixuan},
  journal={IEEE Access}, 
  title={GA-Stereo: A Real-Time Stereo Network Based on the Gradient Flow Shunting Strategy and the Atrous Pyramid Network}, 
  year={2023},
  volume={11},
  number={},
  pages={126052-126065},
  abstract={While stereo matching methods have great progress in recent years, they still face several formidable challenges. These challenges mainly include how to fully utilize global context and depth semantic information for depth feature extraction while maintaining low computational cost, and how to accurately predict disparity in object details and ill-posed regions of stereo images. In this paper, we propose GA-Stereo, an end-to-end stereo network aiming at fast and more accurate disparity regression from rectified stereo images. Firstly, we propose GA-Net, a depth feature extraction network for stereo networks; it utilizes a gradient flow shunting strategy and aggregated residual transformation to calculate the matching cost of stereo images. Secondly, we propose an Atrous Pyramid Network, which implements convolution kernels adaptive sampling to assist the initial disparity map optimize, on the basis of more feature information and larger receptive field. Finally, we propose a collaborative supervised learning strategy. By using the collaborative supervised learning strategy during training stage, our GA-Stereo can not only calculate loss from the Ground Truth, but also calculate the loss from perceptual reconstruction loss and edge-loss smoothing loss to obtain better training results and more accurate predicted disparity map than other stereo networks. Our GA-Stereo achieve highly competitive results in matching accuracy and computational efficiency on stereo benchmarks, including SceneFlow, KITTI2012, and KITTI2015. This advancement represents a significant step forward in real-time stereo matching methods.},
  keywords={Feature extraction;Costs;Computational efficiency;Three-dimensional displays;Optimization;Semantics;Estimation;Computer vision;Deep learning;Stereo image processing;Gradient methods;Shunts (electrical);Computer vision;deep learning;stereo matching;gradient flow shunting strategy;aggregated residual transformation;atrous pyramid network;soft attention mechanism;perceptual reconstruction loss;edge-aware smoothing loss},
  doi={10.1109/ACCESS.2023.3330830},
  ISSN={2169-3536},
  month={},}@ARTICLE{10143418,
  author={Wong, W. K. and Juwono, Filbert H. and Nuwara, Yohanes and Kong, Jeffery T. H.},
  journal={IEEE Sensors Journal}, 
  title={Synthesizing Missing Travel Time of P-Wave and S-Wave: A Two-Stage Evolutionary Modeling Approach}, 
  year={2023},
  volume={23},
  number={14},
  pages={15867-15877},
  abstract={Acquiring sonic waves is an essential part of oil and gas exploration as they give critical information about the well’s data and lithography at each well depth progression. However, these measurements are not always accessible, making analysis challenging. As computational power has improved, machine learning methods may now be used to predict these values from other data. Nonetheless, one shortcoming of existing models is that most of them are not transparent (i.e., black-box models). As a result, although promising great performance, they do not offer much insight to petrophysicists and geologists. This research aims to generate mathematical models for predicting compressional wave (P-wave) and shear wave (S-wave) readings using a multistage evolutionary modeling approach. In particular, a multistage equation modeling approach using tree-based genetic programming (GP) and adaptive differential evolution (ADE) is proposed. The obtained best mathematical models yield  ${R}^{{2}}$  of 0.745 and 0.9066 for P-wave and S-wave regression on normalized data, respectively. The average performance of models is  ${R}^{{2}}={0}.{90}$  (P-Wave) and  ${R}^{{2}}={0}.{75}$  (S-Wave). The performance of these mathematical models is comparable with other “black-box” models but with more compact mathematical approach in regression, thereby opening opportunities for interpretability and analysis. Finally, the “white-box” models presented in this article can be fine-tuned further as needed.},
  keywords={Mathematical models;Optimization;Stochastic processes;Predictive models;Machine learning;Genetic algorithms;Conductivity;Adaptive differential evolution (ADE);genetic programming (GP);sonic wave prediction},
  doi={10.1109/JSEN.2023.3280708},
  ISSN={1558-1748},
  month={July},}@INPROCEEDINGS{10821914,
  author={Nawaz, M. Zohaib and Nawaz, M. Saqib and Fournier-Viger, Philippe and Tseng, Vincent S.},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={An MDL-Based Genetic Algorithm for Genome Sequence Compression}, 
  year={2024},
  volume={},
  number={},
  pages={6724-6731},
  abstract={The exponential growth of genomic data has posed significant challenges for lossless compression of genome sequences. While recent reference-free genome compressors have shown promising results, they often fail to fully leverage the inherent sequential structure of genome sequences, require substantial computational resources and lack (or have limited) interpretability. This paper presents a novel genome compression method that employs the Minimum Description Length (MDL) principle, which is based on the idea that the best model for a given dataset is the one that provides the shortest description of that dataset. The proposed compressor, called GMG (Genetic algorithm for MDL-based Genome compression), integrates a genetic algorithm to identify optimal k-mers (patterns) in a model to best compress the genome data. Experimental results across various datasets demonstrate that GMG outperforms state-of-the-art genome compressors in terms of bits-per-base compression and computational efficiency. Furthermore, it is demonstrated that the optimal patterns identified by GMG for compression can also be utilized for genome classification, offering a multifunctional advantage over previous compressors. GMG is freely available at github.com/MuhammadzohaibNawaz/GMG},
  keywords={Metagenomics;Multithreading;Computational modeling;Scalability;Genomics;Graphics processing units;Compressors;Data models;Bioinformatics;Genetic algorithms;Genome sequences;MDL;GA;Crossover;Mutation},
  doi={10.1109/BIBM62325.2024.10821914},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{10387318,
  author={Kavarakuntla, Tulasi and Han, Liangxiu and Lloyd, Huw and Latham, Annabel and Kleerekoper, Anthony and Akintoye, Samson B.},
  journal={IEEE Access}, 
  title={A Generic Performance Model for Deep Learning in a Distributed Environment}, 
  year={2024},
  volume={12},
  number={},
  pages={8207-8219},
  abstract={Performance modelling of a deep learning application is essential to improve and quantify the efficiency of the model framework. However, existing performance models are mostly case-specific, with limited capability for the new deep learning frameworks/applications. In this paper, we propose a generic performance model of an application in a distributed environment with a generic expression of the application execution time that considers the influence of both intrinsic factors/operations (e.g. algorithmic parameters/internal operations) and extrinsic scaling factors (e.g. the number of processors, data chunks and batch size). We formulate it as a global optimisation problem and solve it using regularisation on a cost function and differential evolution algorithm to find the best-fit values of the constants in the generic expression to match the experimentally determined computation time. We have evaluated the proposed model on three deep learning frameworks (i.e., TensorFlow, MXnet, and Pytorch). The experimental results show that the proposed model can provide accurate performance predictions and interpretability. In addition, the proposed work can be applied to any distributed deep neural network without instrumenting the code and provides insight into the factors affecting performance and scalability.},
  keywords={Analytical models;Predictive models;Deep learning;Computational modeling;Training;Mathematical models;Graphics processing units;Deep learning;analytical modeling;empirical modeling;optimization;differential evolution},
  doi={10.1109/ACCESS.2024.3352017},
  ISSN={2169-3536},
  month={},}@ARTICLE{11048519,
  author={Hu, Bin and Zhao, Liying},
  journal={IEEE Access}, 
  title={DRL-ED-TSPP: A Deep Reinforcement Learning Model With Encoder-Decoder for Solving the Traveling Salesman Problem With Profits}, 
  year={2025},
  volume={13},
  number={},
  pages={111372-111391},
  abstract={The rapid growth of smart cultural tourism necessitates intelligent path planning solutions that harmonize diverse stakeholder interests, including tourist satisfaction, attraction utilization, and guide efficiency. Traditional approaches, however, struggle to address the nonlinear optimization objectives inherent in balancing cultural value density against spatiotemporal costs. This paper proposes DRL-ED-TSPP, a deep reinforcement learning (DRL) model with an Encoder-Decoder architecture, to solve the Traveling Salesman Problem with Profits (TSPP) for sustainable cultural tourism planning. The model addresses the critical challenge of designing closed-loop tours that maximize cultural value per unit time while minimizing travel costs, a problem exacerbated by the NP-hard nature of TSPP and the inefficiencies of existing heuristic or metaheuristic methods. Our solution integrates a Transformer-based encoder with a Composite Feature Embedding (CFE) layer to fuse heterogeneous inputs—spatial coordinates, travel costs, and cultural value matrices—into a unified semantic space, enabling robust representation of nonlinear relationships. The encoder employs stacked self-attention layers to capture spatial-temporal dependencies and thematic continuity, while the decoder leverages a two-stage attention mechanism combining multi-head global context modeling and single-head cultural value prioritization. A dynamic masking strategy ensures Hamiltonian cycle constraints, and dual exploration-exploitation strategies (stochastic sampling for training, greedy search for inference) enhance solution diversity and decision efficiency. Evaluations on synthetic datasets (SyntheticGrid-20, RealCluster-50, MixedCity-100) and real-world cultural sites (Hangzhou West Lake, Xi’an Qin-Han-Tang Zone) demonstrate that DRL-ED-TSPP outperforms state-of-the-art baselines, achieving 4.6–7.0% improvement in cost-to-value ratio, 2.5–7.5% higher cultural value accumulation, and 9–15% faster inference times.},
  keywords={Cultural differences;Costs;Planning;Traveling salesman problems;Mathematical models;Deep reinforcement learning;Routing;Path planning;Metaheuristics;Decoding;TSPP;encoder-decoder structure;deep learning;travel planning},
  doi={10.1109/ACCESS.2025.3582025},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10408209,
  author={Loper, Margaret and Sitterle, Valerie},
  booktitle={2023 Winter Simulation Conference (WSC)}, 
  title={Evolving Lvc To Include Evaluation Of Human-Ai Teaming Dynamics}, 
  year={2023},
  volume={},
  number={},
  pages={2506-2517},
  abstract={There are significant differences between using systems as human-controlled tools to accomplish a specific task and using systems designed to "cooperate and partner" with humans to achieve capabilities beyond either side acting alone. The live, virtual, constructive (LVC) paradigm increasingly emphasized by the DoD has wide acceptance and is congruent with how the military thinks about training, evaluation, and mission rehearsal. Consequently, it may help address these challenges. This paper aims to overview the current LVC construct, challenges associated with human-AI teaming and intentional design of these dynamics to achieve new capabilities, and the resulting need to evolve the LVC construct to improve our pursuit of understanding and evaluation that leads to effective fielding.},
  keywords={Training;Heuristic algorithms;Mashups;Mathematics;US Department of Defense;Artificial intelligence;Task analysis},
  doi={10.1109/WSC60868.2023.10408209},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10742769,
  author={Singh, Bhavpreet and Batth, Jaspreet Singh and Goel, Paurav},
  booktitle={2024 First International Conference on Technological Innovations and Advance Computing (TIACOMP)}, 
  title={Enhancing Meta-Heuristic Algorithms by Dynamically Changing Exploration and Exploitation}, 
  year={2024},
  volume={},
  number={},
  pages={53-58},
  abstract={This paper attempts to provide a new technique in this research that builds on the meta-heuristic approaches already in use to tackle optimization problems in various disciplines. Our suggested framework aims to advance optimization methods, taking cues from the Evolutionary Rao Algorithm (ERA) and its counterparts. Although meta-heuristic algorithms have demonstrated efficacy across several domains, they frequently display constraints in catering to all issue scenarios. Our approach aims to get over these limitations by improving upon the fundamentals of ERA and adding creative design improvements. We seek to prove the superiority and efficacy of our method by thorough experimentation and comparative analysis. The paper opens with a summary of ERA and its evolutionary forerunners, then delves into a thorough explanation of our methodology with a focus on improvements designed to lessen ERA's drawbacks. Next, we demonstrate the experimental configuration and assessment standards that were employed to evaluate our suggested algorithm's performance in comparison to other methods. Our research aims to develop more robust and dependable optimization tools by improving the capabilities of existing algorithms, which will stimulate innovation in a variety of industries.},
  keywords={Industries;Technological innovation;Reviews;Heuristic algorithms;Instruments;Metaheuristics;Optimization methods;Search problems;Optimization;Standards;Meta-heuristics;Optimization;Evolution;Exploration},
  doi={10.1109/TIACOMP64125.2024.00019},
  ISSN={},
  month={June},}@INPROCEEDINGS{10546186,
  author={Liu, Ruohuan and Wang, Bin and Yang, Yazhi and Zhang, Xingpeng},
  booktitle={2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT)}, 
  title={Prediction of Cement Slurry Formulation Based on RMAPCN}, 
  year={2024},
  volume={},
  number={},
  pages={1401-1405},
  abstract={Cement slurry formulation design is a very important process in cementing operations, and the performance of the formula will directly affect the quality of cementing. In traditional cementing operations, professionals perform experiments based on information from adjacent Wells to obtain fuzzy cement formulas, and then constantly adjust the final cement formula in the actual operation. This operation can cost a lot of labor and time, which is not good for real-time operation. To solve the above problems, a new forecasting model RMAPCN (IndRNN with Multi-Head Attention Mechanism and PSO-CNN) is proposed in this paper for the prediction of cement slurry formulation. The model can quickly obtain the cement slurry formulation with higher accuracy and better timeliness by mining the characteristics of the existing data information and using the well information. The comparison between the RMAPCN model and the baseline model shows that the RMAPCN model has obvious advantages in each performance index, and can be used to guide the actual cement slurry formulation design.},
  keywords={Costs;Recurrent neural networks;Cement industry;Stability criteria;Predictive models;Feature extraction;Data models;Cementing Operation;Cement Slurry Formulation;Multi-head Attention Mechanism;Independently Recurrent Neural Network},
  doi={10.1109/ICCECT60629.2024.10546186},
  ISSN={},
  month={April},}@INPROCEEDINGS{11047679,
  author={Hu, Zhou and Wang, Yingbo and Xu, Bin},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={Research on Powder Formulation Design Based on Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={2085-2088},
  abstract={In this study, the machine learning technology was used to establish the propellant performance prediction model, and the propellant force, explosion temperature and explosion heat were predicted respectively. Then, based on the established propellant performance prediction model, combined with evolutionary algorithm, a propellant formulation optimization method with energy as the goal is proposed. Compared with the standard propellant M30, the detonation temperature of the optimized propellant formulation is reduced by 100K without reducing the propellant force. This study provides a new idea for the design of propellant formula, and is expected to improve the efficiency of propellant formula design.},
  keywords={Powders;Weapons;Force;Optimization methods;Machine learning;Propulsion;Predictive models;Explosions;Nitrogen;Standards;gun propellant;powder formulation;machine learning;propellant performance prediction;nitroguanidine propellant},
  doi={10.1109/AIITA65135.2025.11047679},
  ISSN={},
  month={March},}@INPROCEEDINGS{10669875,
  author={Cabrera, Christian and Paleyes, Andrei and Lawrence, Neil D.},
  booktitle={2024 IEEE/ACM International Workshop New Trends in Software Architecture (SATrends)}, 
  title={Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation}, 
  year={2024},
  volume={},
  number={},
  pages={5-9},
  abstract={Software systems impact society at different levels as they pervasively solve real-world problems. Modern software systems are often so sophisticated that their complexity exceeds the limits of human comprehension. These systems must respond to changing goals, dynamic data, unexpected failures, and security threats, among other variable factors in real-world environments. Systems’ complexity challenges their interpretability and requires autonomous responses to dynamic changes. Two main research areas explore autonomous systems’ responses: evolutionary computing and autonomic computing. Evolutionary computing focuses on software improvement based on iterative modifications to the source code. Autonomic computing focuses on optimising systems’ performance by changing their structure, behaviour, or environment variables. Approaches from both areas rely on feedback loops that accumulate knowledge from the system interactions to inform autonomous decision-making. However, this knowledge is often limited, constraining the systems’ interpretability and adaptability. This paper proposes a new concept for interpretable and adaptable software systems: self-sustaining software systems (S4). S4 builds knowledge loops between all available knowledge sources that define modern software systems to improve their interpretability and adaptability. This paper introduces and discusses the S4 concept.CCS CONCEPTS• Software and its engineering → Designing software; Automatic programming; Software evolution.},
  keywords={Software architecture;Source coding;Natural languages;Prototypes;Software systems;Market research;Complexity theory;Autonomous Systems;Software Engineering;Knowledge Graphs;Data-Oriented Architectures;Large Language Models},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10164113,
  author={Wang, Xiaohui and Xia, Mengchen and Deng, Weiwei},
  journal={IEEE Access}, 
  title={MSRN-Informer: Time Series Prediction Model Based on Multi-Scale Residual Network}, 
  year={2023},
  volume={11},
  number={},
  pages={65059-65065},
  abstract={Time series is a huge quantity of data related to time sequence in real life and its forecast remains challenging. In this paper, a deep learning model, which is called MSRN-Informer (Multi-scale Residual Network Improved Informer) model, is proposed to enhance the precision of time series forecast. A multi-scale structure is added in Informer model to extract data features of different scales, and a residual network is applied to reduce data loss, which can reduce the waste of significant resources and overfitting caused by increasing the depth of the network in traditional improvement methods. To prove the effectiveness of the presented MSRN-Informer model, it is compared with Informer, Informer + and ARIMA methods on four datasets. The results show that MSRN-Informer has a better prediction ability and show a reduced error. The research findings of this paper can be potentially used as reliable reference and basis for effective time series prediction.},
  keywords={Predictive models;Convolutional neural networks;Feature extraction;Transformers;Time series analysis;Residual neural networks;Time series;informer;1D-CNN;multi-scale;residual network},
  doi={10.1109/ACCESS.2023.3289824},
  ISSN={2169-3536},
  month={},}@ARTICLE{10962264,
  author={Bai, Tianyou and Peng, Dandan and Tian, Jinpeng},
  journal={IEEE Transactions on Transportation Electrification}, 
  title={Wavelet Transformer-Based Multi-Channel and Multi-Resolution Information Perceptron for Lithium-ion Battery State of Health Estimation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In the application of Lithium-ion battery, indicators like state of health (SOH) are widely adopted in the battery monitoring system. However, it is hard for SOH estimation to be directly obtained from measurement, and it can be interrupted by frequent disturbances and unknown noises. Therefore, in order to accurately predict SOH values, this paper proposes a wavelet convolutional encoded deformable Transformer (WCED-Trans). WCED-Trans aims to extract frequency battery features in expanded scales and guide the study of model for key information with high relevance, thus increasing the estimation accuracy and alleviating the impact of noises. This model first processes battery signals with multiple discrete wavelet transforms and 1-demensional convolutional neural networks, where the frequency features are encoded and transmitted in a multi-channel and multi-resolution pattern. Then, the encoded data representations are perceived by a deformable self-attention-based Transformer encoder. Unlike traditional Transformer, this encoder introduces a set of offset networks to the self-attention module. The offset groups can refine the study of model by changing the shape of the receptive field with deformed points. The model was experimented on NASA and CALCE dataset, from which the effectiveness and efficiency of this model were proved.},
  keywords={Wavelet transforms;Transformers;Estimation;Noise;Integrated circuit modeling;Transforms;Feature extraction;Lithium-ion batteries;Convolutional neural networks;Computational modeling;Lithium-ion battery;State of health;Transformer;Wavelet transform;Convolutional neural network},
  doi={10.1109/TTE.2025.3559538},
  ISSN={2332-7782},
  month={},}@ARTICLE{11000447,
  author={Fuertes, Daniel and del-Blanco, Carlos R. and Jaureguizar, Fernando and García, Narciso},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={TOP-Former: A Multi-Agent Transformer Approach for the Team Orienteering Problem}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Route planning for a fleet of vehicles is an important task in applications such as package delivery, surveillance, or transportation, often integrated within larger Intelligent Transportation Systems (ITS). This problem is commonly formulated as a Vehicle Routing Problem (VRP) known as the Team Orienteering Problem (TOP). Existing solvers for this problem primarily rely on either linear programming, which provides accurate solutions but requires computation times that grow with the size of the problem, or heuristic methods, which typically find suboptimal solutions in a shorter time. In this paper, we introduce TOP-Former, a multi-agent route planning neural network designed to efficiently and accurately solve the Team Orienteering Problem. The proposed algorithm is based on a centralized Transformer neural network capable of learning to encode the scenario (modeled as a graph) and analyze the complete context of all agents to deliver fast, precise, and collaborative solutions. Unlike other neural network-based approaches that adopt a more local perspective, TOP-Former is trained to understand the global situation of the vehicle fleet and generate solutions that maximize long-term expected returns. Extensive experiments demonstrate that the presented system outperforms most state-of-the-art methods in terms of both accuracy and computation speed.},
  keywords={Transformers;Routing;Accuracy;Linear programming;Real-time systems;Planning;Transportation;Natural language processing;Faces;Costs;Team orienteering problem;multi-agent;vehicle routing problem;deep reinforcement learning;transformer},
  doi={10.1109/TITS.2025.3566157},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10917357,
  author={Divya, J. and Jaison, B.},
  booktitle={2024 4th International Conference on Soft Computing for Security Applications (ICSCSA)}, 
  title={Enhancing Air Quality Prediction with Hybrid Deep Learning Techniques: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={330-336},
  abstract={Nowadays, air pollution is among the significant and crucial areas of concern to policymakers and environmental and public health experts internationally. It has been considered that bad air can badly affect human health, ecosystems, and climate change. This air pollution, or poor air quality, has been proven to have negatively life-threatening and serious impacts. Accurate and timely adaption of air quality for various impacts is critical to avert the adverse impacts. The paper aims to provide an in-depth review of recent advances in air quality prediction using hybrid deep learning techniques. Mostly, the current methods of predicting the quality of air face challenges, like the inability to reproduce the complex and non-linear characteristics of air pollution. To tackle the existing challenges that bedevil traditional approaches, deep learning, being part of artificial intelligence with the capacity to bolster the efficiency and accuracy of the projections, has been adopted. Hybrid deep learning models, in association with physical or statistical models, offer promising approaches to enhance air quality prediction. This paper introduces the state-of-the-art review of the major concepts and methodologies applied to air quality prediction with hybrid deep learning techniques, showing benefits and limits of such models, the summary of recent studies, and discussions on future research trends in this fast-growing and interesting field.},
  keywords={Air pollution;Air quality;Predictive models;Deep learning;Artificial intelligence;Environmental monitoring;Public healthcare;Deep learning;Climate change;Air Pollution;Air Quality Prediction;Hybrid Deep Learning;Artificial Intelligence;Environmental Health;Public Health;Deep Learning Models},
  doi={10.1109/ICSCSA64454.2024.00059},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10662130,
  author={Yang, Mingzhe and Zhou, Yuan and Wang, Haiyang and Li, Shuoshi},
  booktitle={2024 43rd Chinese Control Conference (CCC)}, 
  title={Neural Network Design Based on Differentiable Attention Module Search}, 
  year={2024},
  volume={},
  number={},
  pages={8643-8648},
  abstract={Attention mechanisms constitute vital techniques in deep learning, where neural network architectures based on these mechanisms proficiently mine essential information from data and demonstrate robust feature extraction capabilities. The utilization of various attention mechanisms within convolutional neural networks to design more efficient architectures represents a significant research area in the field of deep learning. To address this issue, this paper proposes a neural network design based on differentiable attention module search. Firstly, this paper analyzes existing attention mechanisms and designs a multi-attention search space. Subsequently, a differentiable search strategy is employed to identify attention modules within this multi-attention search space. Finally, the proposed search algorithm is applied to fine-grained image classification tasks to verify the effectiveness of the proposed method. The experimental results show that the searched network models can fully leverage the advantages of different attention mechanisms and exhibit excellent performance on various datasets. On the CUB-200-2011, Stanford Cars, and FGVC-Aircraft fine-grained classification datasets, the proposed method achieved classification accuracies of 87.4%, 92.8%, and 94.0%, respectively.},
  keywords={Deep learning;Attention mechanisms;Neural networks;Feature extraction;Search problems;Image categorization;Classification algorithms;Deep learning;Attention mechanism;Differentiable;Neural architecture search;Fine-grained classification},
  doi={10.23919/CCC63176.2024.10662130},
  ISSN={1934-1768},
  month={July},}@ARTICLE{9568704,
  author={Chai, Yidong and Zhou, Yonghang and Li, Weifeng and Jiang, Yuanchun},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={An Explainable Multi-Modal Hierarchical Attention Model for Developing Phishing Threat Intelligence}, 
  year={2022},
  volume={19},
  number={2},
  pages={790-803},
  abstract={Phishing website attack, as one of the most persistent forms of cyber threats, evolves and remains a major cyber threat. Various detection methods (e.g., lookup systems, fraud cue-based methods) have been proposed to identify phishing websites. The limitations of lookup systems (e.g., failing to address newly created attacks) and the fraud cue-based methods (e.g., relying on feature engineering) motivated the development of deep representation-based methods capable of learning deep fraud cues for enhanced anti-phishing capacity. Focusing mostly on URLs, these methods fail to analyze other two important modalities of website content: textual information and visual design. Moreover, the interpretability of these deep learning based methods is limited, reducing model trustworthiness and preventing relevant and actionable intelligence. As such, we propose a multi-modal hierarchical attention model (MMHAM) which jointly learns the deep fraud cues from the three major modalities of website content for phishing website detection. Specifically, MMHAM features an innovative shared dictionary learning approach for aligning representations from different modalities in the attention mechanism. In our evaluation experiments, the proposed MMHAM not only learned improved deep cues for enhanced phishing detection, but provided a hierarchical interpretability system from which we could develop phishing threat intelligence to inform phishing websites detection at different levels.},
  keywords={Phishing;Navigation;Visualization;Uniform resource locators;Deep learning;Protocols;Blacklisting;Antiphishing;machine learning;multimodal systems;security and protection},
  doi={10.1109/TDSC.2021.3119323},
  ISSN={1941-0018},
  month={March},}@ARTICLE{10077581,
  author={Liu, Wenjun and Liu, Shuangyin and Hassan, Shahbaz Gul and Cao, Yingying and Xu, Longqin and Feng, Dachun and Cao, Liang and Chen, Weijun and Chen, Yaocong and Guo, Jianjun and Liu, Tonglai and Zhang, Hang},
  journal={IEEE Access}, 
  title={A Novel Hybrid Model to Predict Dissolved Oxygen for Efficient Water Quality in Intensive Aquaculture}, 
  year={2023},
  volume={11},
  number={},
  pages={29162-29174},
  abstract={Dissolved oxygen content is a key indicator of water quality in aquaculture environment. Because of its nonlinearity, dynamics, and complexity, which makes traditional methods face challenges in the accuracy and speed of dissolved oxygen content prediction. As a solution to these issues, this study introduces a hybrid model consisting of the Light Gradient Boosting Machine (LightGBM) and the Bidirectional Simple Recurrent Unit (BiSRU). Firstly, Linear interpolation and smoothing were used to identify significant parameters. LightGBM algorithm then determines the significance of dissolved oxygen by eliminating irrelevant variables and predicting dissolved oxygen in intensive aquaculture. Finally, the attention method was implemented to map the weighting and learning parameter matrices, so enabling the BiSRU’s hidden states to be assigned different weights. The findings shown that the presented prediction model can accurately anticipate the fluctuating trend of dissolved oxygen over a 10-day period in just 122 seconds, and the accuracy rate reached 96.28%. Comparing the model effects of LightGBM-BiSRU, LightGBM - GRU, LightGBM-LSTM, and BiSRU - Attention takes the least time. Its higher prediction accuracy can provide an essential reference for intensive aquaculture water quality regulation.},
  keywords={Predictive models;Aquaculture;Water quality;Technological innovation;Data models;Computational modeling;Market research;Non-linear;LightGBM;BiSRU;attention mechanism},
  doi={10.1109/ACCESS.2023.3260089},
  ISSN={2169-3536},
  month={},}@ARTICLE{10774177,
  author={Liu, Jiaqi and Hang, Peng and Na, Xiaoxiang and Huang, Chao and Sun, Jian},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Cooperative Decision-Making for CAVs at Unsignalized Intersections: A MARL Approach With Attention and Hierarchical Game Priors}, 
  year={2025},
  volume={26},
  number={1},
  pages={443-456},
  abstract={The development of autonomous vehicles has shown great potential to enhance the efficiency and safety of transportation systems. However, the decision-making issue in complex human-machine mixed traffic scenarios, such as unsignalized intersections, remains a challenge for autonomous vehicles. While reinforcement learning (RL) has been used to solve complex decision-making problems, existing RL methods still have limitations in dealing with cooperative decision-making of multiple connected autonomous vehicles (CAVs), ensuring safety during exploration, and simulating realistic human driver behaviors. In this paper, a novel and efficient algorithm, Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient (MA-GA-DDPG), is proposed to address these limitations. Our proposed algorithm formulates the decision-making problem of CAVs at unsignalized intersections as a decentralized multi-agent reinforcement learning problem and incorporates an attention mechanism to capture interaction dependencies between ego CAV and other agents. The attention weights between the ego vehicle and other agents are then used to screen interaction objects and obtain prior hierarchical game relations, based on which a safety inspector module is designed to improve the traffic safety. Furthermore, both simulation and hardware-in-the-loop experiments were conducted, demonstrating that our method outperforms other baseline approaches in terms of driving safety, efficiency, and comfort.},
  keywords={Decision making;Safety;Autonomous vehicles;Games;Attention mechanisms;Reinforcement learning;Vehicles;Human-machine systems;Reliability;Heuristic algorithms;Multi-agent reinforcement learning;connected autonomous vehicles;decision-making;attention mechanism;unsignalized intersections},
  doi={10.1109/TITS.2024.3503092},
  ISSN={1558-0016},
  month={Jan},}@ARTICLE{10896673,
  author={Dogan, Yahya},
  journal={IEEE Access}, 
  title={AutoEffFusionNet: A New Approach for Cervical Cancer Diagnosis Using ResNet-Based Autoencoder With Attention Mechanism and Genetic Feature Selection}, 
  year={2025},
  volume={13},
  number={},
  pages={44107-44122},
  abstract={Cervical cancer poses a significant global health challenge, necessitating accurate and efficient diagnostic solutions. This study introduces a novel hybrid framework, AutoEffFusionNet, that integrates unsupervised feature learning through ResNet-based autoencoders with attention mechanisms and supervised learning via transfer learning models. By leveraging the complementary strengths of these approaches, the proposed method achieves enhanced diagnostic accuracy in cervical cancer classification. Genetic algorithms optimize the feature selection process, retaining only the most relevant attributes, thereby addressing feature redundancy and improving computational efficiency. The selected features are then classified using a Support Vector Machine, effectively combining deep learning’s feature extraction capabilities with machine learning’s robust classification strengths. Additionally, Grad-CAM visualizations are incorporated to highlight critical regions influencing the classification decisions, enhancing interpretability and transparency. The framework was rigorously evaluated on two benchmark datasets, SIPaKMeD, and Mendeley LBC, achieving remarkable accuracies of 99.26% and 100%, respectively. These results demonstrate the effectiveness of the proposed model in addressing key challenges in cervical cancer diagnosis and its potential for deployment in clinical applications.},
  keywords={Feature extraction;Cervical cancer;Accuracy;Cancer;Transfer learning;Solid modeling;Support vector machines;Autoencoders;Computational modeling;Robustness;Cervical cancer diagnosis;autoencoder;transfer learning;genetic algorithm;CMAB;support vector machine},
  doi={10.1109/ACCESS.2025.3543850},
  ISSN={2169-3536},
  month={},}@ARTICLE{11062720,
  author={Rafiei, Alireza and Motie-Shirazi, Mohsen and Sameni, Reza and Clifford, Gari D. and Katebi, Nasim},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Next-Generation Fetal Heart Monitoring: Leveraging Neural Sequential Modeling for Ultrasound Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Objective: Fetal heart rate (FHR) and its variability are crucial indicators of fetal well-being. One-dimensional Doppler ultrasound (DUS) has become a widely used tool for this monitoring purpose, particularly in low-resource settings, due to its affordability, portability, and simplicity. Yet, its potential remains underexplored, with existing methods relying on rigid, non-adaptive algorithms that struggle to capture beat-to-beat variations. This study aims to bridge the gap by delivering reliable estimates through sequential modeling of regions of interest. Methods: We introduce AutoFHR, a novel interpretable neural temporal model based on dilated causal convolutions and attention mechanisms, designed to automatically estimate heartbeat locations within DUS signals. AutoFHR utilizes an innovative learning objective that minimizes generation error while uniquely incorporating a spectral fidelity term to retain the natural rhythm of fetal cardiac activity. Results: Cross-population, subject-independent evaluations demonstrate AutoFHR's proficiency in heartbeat localization, significantly outperforming conventional methods in FHR estimation while improving FHR variability analysis. AutoFHR achieves a root mean square error (RMSE) of 2.2 beats per minute (bpm) and 2.8 bpm, a maximum limit of agreement of 4.5 and 5.6 bpm, and an estimated bias of 0.3 and 0.1 bpm on the development and external validation datasets, respectively. Conclusions: Our findings indicate a strong correspondence between estimated and reference fetal electrocardiogram-derived heartbeats and highlight the model's generalizability and robustness over time. Significance: This work advances the clinical utility of DUS-based fetal monitoring by improving FHR analysis, supporting earlier detection of distress and expanding access to quality prenatal care in clinical and remote settings.},
  keywords={Fetal heart rate;Heart rate variability;Monitoring;Ultrasonic imaging;Doppler effect;Estimation;Biomedical engineering;Hospitals;Electrocardiography;Pediatrics;Deep learning;Doppler ultrasound (DUS);fetal heart rate (FHR) estimation;fetal health monitoring;generative modeling;variability analysis},
  doi={10.1109/TBME.2025.3585461},
  ISSN={1558-2531},
  month={},}@INPROCEEDINGS{11048016,
  author={Gao, Qiang and Yang, Yuntai and Lin, Sidi and Cao, Zhe and Li, Zhengkui and Niu, Wenwei and Chen, Jianning and Wang, Wencai},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={Stability Control of Moisture Content at the Outlet of Drying Machine Based on WOA and Stacking Strategy}, 
  year={2025},
  volume={},
  number={},
  pages={214-222},
  abstract={The moisture stability control of tobacco leaves is a crucial task in tobacco processing workshop. The commonly used PID control method faces issues such as regulation delay and low accuracy. Moisture stability control using modern machine learning methods also requires further improvement. To address these challenges, we proposed a method for stabilizing the outlet moisture content by combining an improved Fast Whale Optimization Algorithm (FWOA) with a tobacco moisture prediction module named S-LSTM-AT. The S-LSTM-AT module employs a stacking framework, which integrates base-learners and a meta-learner to achieve a more accurate prediction of outlet moisture content. The FWOA algorithm then utilizes the moisture predictions of S-LSTM-AT to iteratively search for the optimal combination of parameters that will stabilize the moisture content at the drying stage of the tobacco production. Experimental results demonstrate that, compared to present methods, our improved stable control method reduces the average deviation of outlet moisture content from 0.1301 to 0.0838, which is a decrease of approximately 35.6%. This effectively enhances the control accuracy and overall production quality in the tobacco workshop.},
  keywords={Accuracy;PI control;Stacking;Moisture;Process control;Production;Prediction algorithms;Whale optimization algorithms;Stability analysis;PD control;tobacco;outlet moisture content;ensemble learning;LSTM;attention mechanism;whale optimization algorithm;automated control},
  doi={10.1109/AIITA65135.2025.11048016},
  ISSN={},
  month={March},}@ARTICLE{10682967,
  author={Wan, Zishen and Liu, Che-Kai and Yang, Hanchen and Raj, Ritik and Li, Chaojian and You, Haoran and Fu, Yonggan and Wan, Cheng and Li, Sixu and Kim, Youbin and Samajdar, Ananda and Lin, Yingyan and Ibrahim, Mohamed and Rabaey, Jan M. and Krishna, Tushar and Raychowdhury, Arijit},
  journal={IEEE Transactions on Circuits and Systems for Artificial Intelligence}, 
  title={Towards Efficient Neuro-Symbolic AI: From Workload Characterization to Hardware Architecture}, 
  year={2024},
  volume={1},
  number={1},
  pages={53-68},
  abstract={The remarkable advancements in artificial intelligence (AI), primarily driven by deep neural networks, are facing challenges surrounding unsustainable computational trajectories, limited robustness, and a lack of explainability. To develop next-generation cognitive AI systems, neuro-symbolic AI emerges as a promising paradigm, fusing neural and symbolic approaches to enhance interpretability, robustness, and trustworthiness, while facilitating learning from much less data. Recent neuro-symbolic systems have demonstrated great potential in collaborative human-AI scenarios with reasoning and cognitive capabilities. In this paper, we aim to understand the workload characteristics and potential architectures for neuro-symbolic AI. We first systematically categorize neuro-symbolic AI algorithms, and then experimentally evaluate and analyze them in terms of runtime, memory, computational operators, sparsity, and system characteristics on CPUs, GPUs, and edge SoCs. Our studies reveal that neuro-symbolic models suffer from inefficiencies on off-the-shelf hardware, due to the memory-bound nature of vector-symbolic and logical operations, complex flow control, data dependencies, sparsity variations, and limited scalability. Based on profiling insights, we suggest cross-layer optimization solutions and present a hardware acceleration case study for vector-symbolic architecture to improve the performance, efficiency, and scalability of neuro-symbolic computing. Finally, we discuss the challenges and potential future directions of neuro-symbolic AI from both system and architectural perspectives.},
  keywords={Artificial intelligence;Artificial neural networks;Vectors;Computer architecture;Computational modeling;Hardware;Performance analysis;Cognitive AI;neuro-symbolic AI;workload characterization;performance analysis;domain-specific architecture},
  doi={10.1109/TCASAI.2024.3462692},
  ISSN={2996-6647},
  month={Sep.},}@ARTICLE{10786197,
  author={Wu, Hang and Zhu, Yuanda and Shi, Wenqi and Tong, Li and Wang, May D},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Fairness Artificial Intelligence in Clinical Decision Support: Mitigating Effect of Health Disparity}, 
  year={2025},
  volume={29},
  number={2},
  pages={815-823},
  abstract={The United States, as well as the global community, experiences health disparities among socially disadvantaged populations. These disparities often manifest in the data utilized for AI model training. Without appropriate de-biasing strategies, models trained to optimize predictive performance may inadvertently capture and perpetuate these inherent biases. The utilization of biased models in clinical decision-making can inflict harm upon patients from disadvantaged groups and exacerbate disparities when these decisions are documented and employed to train subsequent AI models. Unlike conventional correlation-based methods, we aim to mitigate the negative impacts of health disparity by answering a causal inference question for fairness: would the clinical decision support system make a different decision if the patient had a different sensitive attribute (e.g., race)? Recognizing the high computational complexity of developing causal models, we propose a flexible and efficient causal-model-free algorithm, CFReg, which provides causal fairness for supervised machine learning models. In addition, CFReg also develops a novel evaluation metric to quantify fairness within clinical settings. We first validate CFReg using a healthcare dataset of 48,784 patients focused on care management, then generalize to another four benchmark datasets with racial and ethnic disparity, including law school admission, adult income, criminal recidivism, and violent crime prediction. Experimental results demonstrate that CFReg outperforms baseline approaches in both fairness and accuracy, achieving a good trade-off between model fairness and supervised classification performance.},
  keywords={Data models;Computational modeling;Prediction algorithms;Machine learning algorithms;Machine learning;Predictive models;Mathematical models;Medical services;Training;Supervised learning;Causal inference;fairness;health disparity;clinical decision support},
  doi={10.1109/JBHI.2024.3513398},
  ISSN={2168-2208},
  month={Feb},}@INPROCEEDINGS{10611989,
  author={Batista, João Eduardo and Pindur, Adam Kotaro and Iba, Hitoshi and Silva, Sara},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Measuring Structural Complexity of GP Models for Feature Engineering over the Generations}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Feature engineering is a necessary step in the machine learning pipeline. Together with other preprocessing methods, it allows the conversion of raw data into a dataset containing only the necessary features to solve the task at hand, reducing the computational complexity of inducing models and creating models that are potentially simpler, more robust, and more interpretable. We use M3GP, a wrapper-based feature engineering algorithm, to induce a set of features that are adapted in number and in shape to several classifiers with different levels of predictive power, from decision trees with depth 3 to random forests with 100 estimators and no depth limit. Intuition tells us that classifiers that are restricted in the number of features should compensate for this restriction by using features with a high degree of correlation with the target objective. By opposition, the principle behind the boosting algorithm tells us that we can create a strong classifier using a large set of weak features. This indicates that classifiers with no restrictions should prefer many but weaker features. Our results confirm this hypothesis while also revealing that M3GP induces unnecessarily complex features. We measure complexity using several structural complexity metrics found in the literature and show that, although our pipeline consistently obtains good results, the structural complexity of the induced models varies drastically across runs. Additionally, while the test performance peaks in the early stages of the evolution, the complexity of the feature engineering models continues to grow, with little to no return in test performance. This work promotes using several complexity metrics to measure model interpretability and identifies issues related to model complexity in M3GP, proposing solutions to improve the computational cost of inducing models and the complexity of the final models.},
  keywords={Measurement;Analytical models;Computational modeling;Pipelines;Predictive models;Prediction algorithms;Complexity theory;Genetic Programming;Model Complexity;Feature Engineering;Model Interpretability;Classification},
  doi={10.1109/CEC60901.2024.10611989},
  ISSN={},
  month={June},}@INPROCEEDINGS{10254100,
  author={Hua, Minh and Sheppard, John W.},
  booktitle={2023 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Evolving Intertask Mappings for Transfer in Reinforcement Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Recently, there has been a focus on using transfer learning to reduce the sample complexity in reinforcement learning. One component that enables transfer is an intertask mapping that relates a pair of tasks. Automatic methods attempt to learn task relationships either by evaluating all possible mappings in a brute force manner, or by using techniques such as neural networks to represent the mapping. However, brute force methods do not scale well in problems since there is an exponential number of possible mappings, and automatic methods that use complex representations generate mappings that are not always interpretable. In this paper, we describe a population-based algorithm that generates intertask mappings in a tractable amount of time. The idea is to use an explicit representation of an intertask mapping, and to combine an evolutionary algorithm with an offline evaluation scheme to search for the optimal mapping. Experiments on two transfer learning problems show that our approach is capable of finding highly-fit mappings and searching a space that is infeasible for a brute force approach. Furthermore, agents that learn using the mappings found by our approach are able to reach a performance target faster than agents that learn without transfer.},
  keywords={Transfer learning;Force;Games;Reinforcement learning;Evolutionary computation;Search problems;Space exploration},
  doi={10.1109/CEC53210.2023.10254100},
  ISSN={},
  month={July},}@INPROCEEDINGS{10617708,
  author={Zuo, Wangge and Sun, WenZhao and Lan, Bijian and Wan, Jing},
  booktitle={2024 2nd International Symposium of Electronics Design Automation (ISEDA)}, 
  title={RLCkt II: Deep Reinforcement Learning via Attention-Aware Sampling for Analog Integrated Circuit Transistor Sizing Automation}, 
  year={2024},
  volume={},
  number={},
  pages={177-181},
  abstract={The sizing of circuit transistors that meet design specifications in analog integrated circuit (IC) traditionally relies on the intuition and experience of human experts, posing challenges that are labor-intensive and time-consuming, particularly as circuit complexity increases. Compared to mainstream optimization algorithms that exhibit slow optimization speeds and unstable solutions when dealing with large-scale analog IC, this study introduces RLCktII, a breakthrough improvement built upon the advanced RLCkt. For the first time, it incorporates an attention mechanism combined with deep reinforcement learning into the domain of automated analog integrated circuit transistor sizing. Through the attention mechanism, it dynamically discerns the most distinctive input data, enhancing the deep reinforcement learning model's capability to handle complex tasks. RLCkt II was evaluated on two industrial-scale analog integrated circuits: LDO and R2R. After one and a half days of training, our RLCkt II agent achieved an average improvement of 28.71 % and 7.94% in convergence accuracy over the state-of-the-art RLCkt. In the same design tasks, RLCkt II demonstrated a speed advantage nearly a hundred times faster than the Genetic Algorithm (GA) while also ensuring greater design precision.},
  keywords={Training;Attention mechanisms;Design automation;Deep reinforcement learning;Transistors;Task analysis;Integrated circuit modeling;Transistor Sizing;Attention Mechanism;Reinforcement Learning;Automation of Analog Design},
  doi={10.1109/ISEDA62518.2024.10617708},
  ISSN={},
  month={May},}@ARTICLE{10587240,
  author={Y, Nguyen Tan and Lam, Pham Duc and Tinh, Vo Phuc and Le, Duy-Dong and Nam, Nguyen Hoang and Khoa, Tran Anh},
  journal={IEEE Access}, 
  title={Joint Federated Learning Using Deep Segmentation and the Gaussian Mixture Model for Breast Cancer Tumors}, 
  year={2024},
  volume={12},
  number={},
  pages={94231-94249},
  abstract={Medical image segmentation is crucial for deep learning (DL) applications in clinical settings. Ensuring accurate segmentation is challenging due to diverse image sources and significant data sharing and privacy concerns in centralized learning setups. To address these challenges, we introduce a novel federated learning (FL) framework tailored for breast cancer. First, we use random regions of interest (ROIs) and bilinear interpolation to determine pixel color intensity based on neighboring pixels, addressing data inconsistencies from heterogeneous distribution parameters and increasing dataset size. We then employ the UNet model with a deep convolutional backbone (Visual Geometry Group [VGG]) to train the augmented data, enhancing recognition during training and testing. Second, we apply the Gaussian Mixture Model (GMM) to improve segmentation quality. This approach effectively manages distinct data distributions across hospitals and highlights images with a higher likelihood of tumor presence. Compared to other segmentation algorithms, GMM enhances the salience of valuable images, improving tumor detection. Finally, extensive experiments in two scenarios, federated averaging (FedAvg) and federated batch normalization (FedBN), demonstrate that our method outperforms several state-of-the-art segmentation methods on five public breast cancer datasets. These findings validate the effectiveness of our proposed framework, promising significant benefits for the community and society.},
  keywords={Breast cancer;Image segmentation;Tumors;Biomedical imaging;Breast cancer;Medical diagnostic imaging;Hospitals;Federated learning;Gaussian mixture model;Federated learning;meta-global;Gaussian mixture model;segmentation;breast tumor},
  doi={10.1109/ACCESS.2024.3424569},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10256879,
  author={Chang, Zheng and Liu, Jie and Li, Bingyu and Du, Xuhao and Cai, Ziwen and Zhu, Le},
  booktitle={2023 3rd International Conference on Energy Engineering and Power Systems (EEPS)}, 
  title={Health State Estimation of Lithium-ion Batteries Based on APDE-Bi-GRU-Attention Model}, 
  year={2023},
  volume={},
  number={},
  pages={496-503},
  abstract={To maintain safe and dependable battery operation and lower battery system maintenance costs, state of health (SOH) estimate, one of the primary BMS tasks for electric vehicles, is essential. In order to improve the SOH prediction accuracy of lithium battery, a SOH prediction method based on the improved differential evolution algorithm (APDE) and the bi-directional gated recurrent unit network (Bi-GRU-attention) combined with the attention mechanism is proposed. Firstly, the feature factors related to battery capacity are extracted from battery charging data and correlation analysis is performed, and the four with high correlation are selected as inputs of model. Then, the Attention mechanism is applied to the Bi-GRU network to form the Bi-GRU-attention network, and the key parameters of the network parameters are optimally searched by the improved differential evolution algorithm (APDE) to build the final prediction model. Experiments are conducted on NASA dataset, and the results show that the APDE-Bi-GRU-attention method has higher prediction accuracy and fit, which verifies the feasibility of the prediction method.},
  keywords={Lithium-ion batteries;Correlation;Predictive models;Logic gates;Prediction algorithms;Feature extraction;Electric vehicles;State of Health Estimate;Lithium Battery;Bi-directional gated recurrent unit network;Differential evolution algorithm;Attention mechanism},
  doi={10.1109/EEPS58791.2023.10256879},
  ISSN={},
  month={July},}@INPROCEEDINGS{10669832,
  author={Alshahwan, Nadia and Harman, Mark and Harper, Inna and Marginean, Alexandru and Sengupta, Shubho and Wang, Eddy},
  booktitle={2024 IEEE/ACM 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering (InteNSE)}, 
  title={Assured LLM-Based Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={7-12},
  abstract={In this paper we address the following question: How can we use Large Language Models (LLMs) to improve code independently of a human, while ensuring that the improved code(1)does not regress the properties of the original code ?(2)improves the original in a verifiable and measurable way ?To address this question, we advocate Assured LLM-Based Software Engineering; a generate-and-test approach, inspired by Genetic Improvement. Assured LLMSE applies a series of semantic filters that discard code that fails to meet these twin guarantees. This overcomes the potential problem of LLM’s propensity to hallucinate. It allows us to generate code using LLMs, independently of any human. The human plays the role only of final code reviewer, as they would do with code generated by other human engineers.This paper is an outline of the content of the keynote by Mark Harman at the International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, Monday 15th April 2024, Lisbon, Portugal.},
  keywords={Codes;Filters;Large language models;Conferences;Semantics;Benchmark testing;Genetics;Large Language Models (LLMs);Genetic Improvement (GI);Search Based Software Engineering (SBSE);Llama;CodeLlama;Automated Code Generation},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10219777,
  author={Jiang, Jiawei and Chen, Jiacheng and Xu, Honghui and Feng, Yuchao and Zheng, Jianwei},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={GA-HQS: MRI reconstruction via a generically accelerated unfolding approach}, 
  year={2023},
  volume={},
  number={},
  pages={186-191},
  abstract={Deep unfolding networks (DUNs) are the foremost methods in the realm of compressed sensing MRI, as they can employ learnable networks to facilitate interpretable forward-inference operators. However, several daunting issues still exist, including the heavy dependency on first-order optimization algorithms, the insufficient information fusion mechanisms, and the limitation of capturing long-range relationships. To address the issues, we propose a Generically Accelerated Half-Quadratic Splitting (GA-HQS) algorithm that incorporates second-order gradient information and pyramid attention modules for the delicate fusion of inputs at the pixel level. Moreover, a multi-scale split transformer is also designed to enhance the global feature representation. Comprehensive experiments demonstrate that our method surpasses previous ones on single-coil MRI acceleration tasks.},
  keywords={Magnetic resonance imaging;Noise reduction;Transformers;Task analysis;Compressed sensing;Optimization;Compressed sensing MRI;accelerated unfolding;half-quadratic splitting;information fusion},
  doi={10.1109/ICME55011.2023.00040},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{9871150,
  author={Bi, Yuda and Abrol, Anees and Fu, Zening and Calhoun, Vince},
  booktitle={2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Deep Learning Prediction and Visualization of Gender Related Brain Changes from Longitudinal Structural MRI Data in the ABCD Study}, 
  year={2022},
  volume={},
  number={},
  pages={3814-3817},
  abstract={Deep learning algorithms for predicting from neuroimaging data have shown considerable promise. Deep learning models that take advantage of the data's $3D$ structure have been proven to outperform ordinary machine learning on a number of learning tasks[1]. The majority of past research in this area, however, has focused on data from adults. Within the Adolescent Brain and Cognitive Development (ABCD) dataset, a major longitudinal development research, we examine the use of structural MRI data to predict gender and to identify gender related changes in brain structure. The results demonstrate that gender prediction accuracy is extremely high (>94%), and that this accuracy increases with age. Brain regions identified as the most discriminative in the task under study include predominantly frontal regions in addition to temporal lobe. When evaluating gender predictive changes specific to a two year increase in age, a broader set of visual, cingulate, and insular regions are revealed. Overall, our findings show a robust pattern of gender related structural brain changes, even over a small age range. This suggests the potential for evaluating the relationship of these changes to various behavioral and environmental factors to further study how the brain develops during adolescence. Clinical relevance— These results are not focused on clinical relevance currently, but in the future may be useful to characterize interactions between gender and potentially clinically relevant measures in adolescents.},
  keywords={Deep learning;Brain;Visualization;Three-dimensional displays;Biometrics (access control);Magnetic resonance imaging;Data visualization},
  doi={10.1109/EMBC48229.2022.9871150},
  ISSN={2694-0604},
  month={July},}@ARTICLE{10858452,
  author={Park, Dongho and An, Jimin and Lee, Dawit and Kang, Inseung and Young, Aaron J.},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Human-in-the-Loop Optimization of Hip Exoskeleton Assistance During Stair Climbing}, 
  year={2025},
  volume={72},
  number={7},
  pages={2147-2156},
  abstract={Objective: This study applies human-in-the-loop optimization to identify optimal hip exoskeleton assistance patterns for stair climbing. Methods: Ten participants underwent optimization to individualize hip flexion and extension assistance, followed by a validation comparing optimized assistance (OPT) to biological hip moment-based assistance (BIO), no assistance (No-Assist), and no exoskeleton (No-Exo) conditions. Results: OPT reduced metabolic cost by 4.5% compared to No-Exo, 11.44% compared to No-Assist, and 5.02% compared to BIO, demonstrating the effectiveness of the optimization approach. Statistical analysis revealed distinct characteristics in optimal assistance timing and magnitude that deviated systematically from biological hip moment patterns. Compared to BIO, OPT exhibited later peak flexion timing (76.4 $\pm$ 3.7% vs 65.0%), shorter flexion duration (29.2 $\pm$ 3.6% vs 40.0%), later peak extension timing (26.7 $\pm$ 3.8% vs 20.0% of gait cycle), and higher peak flexion magnitude (11.1 $\pm$ 1.5 Nm vs 10.0 Nm). While individual optimal assistance profiles varied across participants, comparison between individually optimized parameters and the best subject-independent parameters identified through post-hoc analysis showed consistency. On average, metabolic rate convergence was achieved after 18 iterations, while most exoskeleton control parameters did not reach our convergence criteria within 20 iterations. Conclusion: These findings demonstrate that human-in-the-loop optimization can effectively identify task-specific assistance patterns for stair climbing, while the consistency between individual and subject-independent parameters suggests the potential for developing generalized assistance strategies. The systematic differences between optimized and biological moment-based assistance underscore the fundamental distinctions between biological torque-based control and optimal control for exoskeleton assistance.},
  keywords={Exoskeletons;Stairs;Optimization;Hip;Legged locomotion;Torque;Costs;Flexible printed circuits;Pelvis;Timing;Bayesian optimization;hip exoskeleton;human-in-the-loop optimization;metabolic cost;personalized assistance;stair climbing},
  doi={10.1109/TBME.2025.3536516},
  ISSN={1558-2531},
  month={July},}@INPROCEEDINGS{9870317,
  author={Saletta, Martina and Ferretti, Claudio},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A Grammar-based Evolutionary Approach for Assessing Deep Neural Source Code Classifiers}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Neural networks for source code processing have proven to be effective for solving multiple tasks, such as locating bugs or detecting vulnerabilities. In this paper, we propose an evolutionary approach for probing the behaviour of a deep neural source code classifier by generating instances that sample its input space. First, we apply a grammar-based genetic algorithm for evolving Python functions that minimise or maximise the probability of a function to be in a certain class, and we also produce programs that yield an output near to the classification threshold, namely for which the network does not express a clear classification preference. We then use such sets of evolved programs as initial popu-lations for an evolution strategy approach in which we apply, by following different policies, constrained small mutations to the individuals, so to both explore the decision boundary of the network and to identify the features that most contribute to a particular prediction. We furtherly point out how our approach can be effectively used for several tasks in the scope of the interpretable machine learning, such as for producing adversarial examples able to deceive a network, for identifying the most salient features, and further for characterising the abstract concepts learned by a neural model.},
  keywords={Codes;Computational modeling;Neural networks;Computer bugs;Machine learning;Evolutionary computation;Task analysis;structured grammatical evolution;evolution strategy;decision boundaries;deep neural networks;source code classifiers},
  doi={10.1109/CEC55065.2022.9870317},
  ISSN={},
  month={July},}@INPROCEEDINGS{9980163,
  author={Xu, Xin and Zhang, Jiaxing},
  booktitle={2022 15th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={An Identification Recognition Method Based on the Optimization Mechanism of Emotional EEG Module}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={With the rapid development of informati on society, people's demand for personal privacy a nd property protection has become stronger and st ronger. At present, the traditional biometric techno logy has been difficult to meet the needs of social de velopment. Electroencephalography (EEG), as a un ique biometric feature of individuals, has received wide attention from a large number of researchers. In order to solve the problems of difficult to apply in practice and low recognition accuracy due to the induction of specific situations and differences in i ndividual characteristics in EEG data acquisition, a PSO-Attention-RNN (PARNN) recognition mode 1 is proposed in this paper. Firstly, the energy entro py of five rhythms, a-wave, ß-wave, δ-wave, θ-wave and γ-wave, in EEG signals are extracted as featur e vectors by using wavelet packet transform. These features are then input into the PARNN optimized recognition model, and the EEG temporal frequen cy bands corresponding to different emotional mod ules are filtered using particle swarm optimization (PSO), which can lead to the highest recognition ac curacy for the subjects. The whole process was vali dated in a self-collected emotional EEG database. T he results show that the average recognition accura cy of the algorithm in this paper can reach 90.99%, and the recognition accuracy of the positive emotio n module reaches 93.72%.},
  keywords={Emotion recognition;Privacy;Biometrics (access control);Signal processing algorithms;Signal processing;Brain modeling;Electroencephalography;Emotional module;identification;PARNN model;wavelet packet decomposition},
  doi={10.1109/CISP-BMEI56279.2022.9980163},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10822209,
  author={Wang, Hanmo},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Q-TetoFormer: A New Gene Regulatory Network Prediction Method Based on Quantum Computing and Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={471-474},
  abstract={Quantum computing has enabled precise simulation in gene regulatory network (GRN) prediction by capturing regulatory relationships at a microscopic level. However, current quantum approaches face significant limitations due to high noise levels and prohibitive training costs, making them challenging to implement effectively. To address these issues, we introduce Q-TetoFormer (Quantum-Tuned Extraction and Transformation Orchestrator Former), a novel framework that merges quantum computing with Transformer architecture to enhance GRN prediction accuracy and efficiency.Q-TetoFormer begins by preprocessing gene data, feeding it through a neural network-embedded quantum circuit. The circuit’s output then flows into TetoFormer, a Transformer-based module that leverages attention mechanisms to reduce quantum noise and enrich feature extraction. The output from TetoFormer subsequently optimizes the quantum circuit, creating a feedback loop that improves model performance iteratively. Extensive experiments on five GRN prediction benchmarks demonstrate that Q-TetoFormer not only achieves superior prediction accuracy over state-of-the-art methods but also significantly reduces training overhead, enhancing its practical utility.},
  keywords={Training;Quantum computing;Accuracy;Costs;Qubit;Prediction methods;Transformers;Feature extraction;Quantum circuit;Optimization;Transformer;Quantum computing;GRN prediction;Hybrid quantum-deep learning},
  doi={10.1109/BIBM62325.2024.10822209},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10294588,
  author={Yang, Shangshang and Zhen, Cheng and Tian, Ye and Ma, Haiping and Liu, Yuanchao and Zhang, Panpan and Zhang, Xingyi},
  booktitle={2023 5th International Conference on Data-driven Optimization of Complex Systems (DOCS)}, 
  title={Evolutionary Multi-Objective Neural Architecture Search for Generalized Cognitive Diagnosis Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={Cognitive diagnosis models (CDMs) with high generalization are essential for intelligent education systems to reveal students' knowledge states in multiple datasets. However, existing CDMs' architectures are designed dependent on researcher expertise and experience from observing and summarizing partial students' learning behaviors, which makes handcrafted models not cover all learning behaviors well and thus limits their generalization. To develop generalized CDMs, this paper proposes an evolutionary neural architecture search to design CDMs' architectures effective on multiple datasets automatically. Specifically, we first formulate the search task as a multi-objective optimization problem (MOP), which maximizes model performance on multiple datasets containing learning behaviors as many as possible to ensure model generalization. Then, an expressive search space is devised to contain as many potential architectures as possible, where each architecture is denoted by a unified form, taking three given inputs and integrating them in a linear or no-linear manner for prediction. Finally, an evolutionary algorithm with a tailored deduplication strategy is employed to solve the MOP, where each architecture is further represented by a single-root computation tree for easy optimization. Experiments on multiple datasets demonstrate the generalization and effectiveness of the best architecture searched by the proposed approach, and the searched architecture also holds as good interpretability as handcrafted architectures.},
  keywords={Computational modeling;Education;Computer architecture;Evolutionary computation;Search problems;Genetics;Behavioral sciences;Cognitive diagnosis;neural architecture search;evolutionary algorithm;multi-objective optimization},
  doi={10.1109/DOCS60977.2023.10294588},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10688331,
  author={Akshat, Abhi and Tripathi, Kritika and Raj, Gaurav and Sar, Ayan and Choudhury, Tanupriya and Choudhury, Tanupriya and Saraf, Santosh and Dewangan, Bhupesh Kumar},
  booktitle={2024 OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 4.0}, 
  title={A Comparative Study Between Chat GPT, T5 and LSTM for Machine Language Translation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the most fundamental uses of machine learning is Machine Language Translation. There has been a lot of compelling research in this field. With the increase in the popularity of Large Language Models (LLMs) and their ever-increasing use cases, their application in machine language translation is immense. With the advancement in science and technology, the power of a Large Language model is growing to a point where it can actually replace humans at certain tasks. LLMs like Chat GPT are one the most powerful tools that exist. This paper provides a comparative study between Chat GPT and models like LSTM and T5 for Machine Language Translation. This paper focuses on English to Hindi translation. The primary idea is to fine-tune the Chat GPT model, 3.5-turbo, and compare its performance against other algorithms. A dataset from IIT Bombay would be used to fine-tune Chat GPT and other models.},
  keywords={Technological innovation;Machine learning algorithms;Accuracy;Large language models;Computational modeling;Machine learning;Fourth Industrial Revolution;Large Language Model;Machine Language Translation;Chat GPT;LSTM;T5},
  doi={10.1109/OTCON60325.2024.10688331},
  ISSN={},
  month={June},}@INPROCEEDINGS{10612084,
  author={Miyandoab, Sevil Zanjani and Rahnamayan, Shahryar and Bidgoli, Azam Asilian and Ebrahimi, Sevda and Makrehchi, Masoud},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Enhancing Diversity in Multi-Objective Feature Selection}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Feature selection plays a pivotal role in the data preprocessing and model-building pipeline, significantly en-hancing model performance, interpretability, and resource efficiency across diverse domains. In population-based optimization methods, the generation of diverse individuals holds utmost importance for adequately exploring the problem landscape, particularly in highly multi-modal multi-objective optimization problems. Our study reveals that, in line with findings from sev-eral prior research papers, commonly employed crossover and mutation operations lack the capability to generate high-quality diverse individuals and tend to become confined to limited areas around various local optima. This paper introduces an augmen-tation to the diversity of the population in the well-established multi-objective scheme of the genetic algorithm, NSGA-II. This enhancement is achieved through two key components: the genuine initialization method and the substitution of the worst individuals with new randomly generated individuals as a re-initialization approach in each generation. The proposed multi-objective feature selection method undergoes testing on twelve real-world classification problems, with the number of features ranging from 2,400 to nearly 50,000. The results demonstrate that replacing the last front of the population with an equivalent number of new random individuals generated using the genuine initialization method and featuring a limited number of features substantially improves the population's quality and, consequently, enhances the performance of the multi-objective algorithm.},
  keywords={Sociology;Pipelines;Optimization methods;Evolutionary computation;Feature extraction;Data models;Distance measurement},
  doi={10.1109/CEC60901.2024.10612084},
  ISSN={},
  month={June},}@INPROCEEDINGS{10635474,
  author={Hannan, Darryl and Nesbit, Steven C. and Wen, Ximing and Smith, Glen and Zhang, Qiao and Goffi, Alberto and Chan, Vincent and Morris, Michael J. and Hunninghake, John C. and Villalobos, Nicholas E. and Kim, Edward and Weber, Rosina O. and MacLellan, Christopher J.},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)}, 
  title={Interpretable Models for Detecting and Monitoring Elevated Intracranial Pressure}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Detecting elevated intracranial pressure (ICP) is crucial in diagnosing and managing various neurological conditions. These fluctuations in pressure are transmitted to the optic nerve sheath (ONS), resulting in changes to its diameter, which can then be detected using ultrasound imaging devices. However, interpreting sonographic images of the ONS can be challenging. In this work, we propose two systems that actively monitor the ONS diameter throughout an ultrasound video and make a final prediction as to whether ICP is elevated. To construct our systems, we leverage subject matter expert (SME) guidance, structuring our processing pipeline according to their collection procedure, while also prioritizing interpretability and computational efficiency. We conduct a number of experiments, demonstrating that our proposed systems are able to outperform various baselines. One of our SMEs then manually validates our top system’s performance, lending further credibility to our approach while demonstrating its potential utility in a clinical setting.},
  keywords={Ultrasonic imaging;Ultrasonic variables measurement;Subject matter experts;Pipelines;Predictive models;Optical imaging;Pressure measurement;Machine Learning;Computer Vision;Biomedical Imaging},
  doi={10.1109/ISBI56570.2024.10635474},
  ISSN={1945-8452},
  month={May},}@ARTICLE{10933532,
  author={Zhang, Ziqi and Yu, Guanqing and Deng, Zhaohong and Luo, Chenxi and Cai, Cheng and Zhang, Wei and Hu, Fuping and Choi, Kup-Sze and Wei, Zhisheng and Wang, Lei and Wu, Jing},
  journal={IEEE Transactions on Computational Biology and Bioinformatics}, 
  title={SEFP: Structure-Based Enzyme Function Prediction}, 
  year={2025},
  volume={22},
  number={3},
  pages={1211-1221},
  abstract={Traditional biological experimental methods to determine enzyme properties are time-consuming and costly, leading to an increasing interest in computational models for enzyme function prediction. However, the existing computational methods are insufficient and inefficient to exploit enzyme structure. In this work, we introduce SEFP, a novel method leveraging enzyme point clouds for enzyme function prediction. The structure encoder of SEFP uses a tailored enzyme point cloud network to analyze the three-dimensional arrangement of atoms within the enzyme, integrating hierarchical residue global features through a residue feature adapter to extract detailed enzyme point features. Additionally, the Bio-BCS residue feature encoder extracts enzyme residue features with channel and spatial weights using a specially designed attention mechanism. Finally, SEFP fuses point and residue features to generate the final prediction results. Comparative evaluations show that SEFP outperforms various recent computational methods, demonstrating superior performance. On the RSCB enzyme structure dataset, SEFP achieves an f1-score of 95.85, outperforming two representative structure-based methods, EnzyNet and DeepFri. On the HECNet dataset, SEFP maintains its superiority over all comparison sequence-based methods, yielding an f1-score of 94.29. Ablation studies are conducted to confirm the effectiveness of individual modules within SEFP. These findings underscore the potential of SEFP for reliable and precise enzyme function prediction, offering advancements in bioinformatics and computational biology.},
  keywords={Enzymes;Feature extraction;Point cloud compression;Training;Amino acids;Databases;Annotations;Predictive models;Bioinformatics;Three-dimensional displays;Enzyme function prediction;point cloud;structural feature learning;attention mechanism},
  doi={10.1109/TCBBIO.2025.3552846},
  ISSN={2998-4165},
  month={May},}@INPROCEEDINGS{10990084,
  author={Suzuki, Yasuhiro and Shimada, Kaoru},
  booktitle={2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE)}, 
  title={Instance-Based Discovery of ItemSBs Leveraging Individuality Through Discretization}, 
  year={2024},
  volume={},
  number={},
  pages={92-97},
  abstract={This study proposes a novel instance-based method for discovering itemsets with statistically distinctive backgrounds (ItemSBs) by discretizing continuous attribute values. Instead of discretizing an entire dataset, in this method, each instance's continuous attributes are discretized individually using Standard Deviation-Based Discretization and Segmented Distance-Order-Based Discretization techniques, capturing the instance-specific characteristics of ItemSBs. The proposed method enables the discovery of explainable ItemSBs and forecasting by leveraging the machine rule mining method GNMiner. Experiments performed on a music dataset demonstrated the effectiveness of the proposed approach in improving the discovery of ItemSBs and the associated forecasting accuracy compared with conventional methods that overlook individuality.},
  keywords={Knowledge engineering;Accuracy;Itemsets;Evolutionary computation;Predictive models;Forecasting;Standards;rule discovery;instance based;discretization;itemset;evolutionary computation},
  doi={10.1109/AIxDKE63520.2024.00024},
  ISSN={2831-7203},
  month={Dec},}@INPROCEEDINGS{10709089,
  author={Jiang, Wangqian},
  booktitle={2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={A Study on Momentum Evaluation of Tennis Matches Based on EWM-Topsis Model and LightGBM Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1909-1914},
  abstract={With the continuous development of tennis, the existence or otherwise of momentum, a kind of energy that can change the situation, has always been a doubt in people's mind. In order to better reflect the impact caused by momentum in tennis matches, this paper digs deeper into the characteristics of momentum hidden behind the tennis game based on the 2023 Wimbledon match dataset. In this paper, the importance of different indicators in players' momentum is derived by establishing the EWM-Topsis model, then the turning point of players' momentum is extracted by using the CUSUM algorithm, and the fluctuation of the tournament is predicted based on the LightGBM algorithm, and finally the objective planning function for maximizing the momentum is solved by the genetic algorithm, and optimization of the players' strategies is proposed. By predicting the player's momentum changes in the future matches, coaches can adjust the match tactics in time to win the matches.},
  keywords={Potential energy;Measurement;Games;Predictive models;Turning;Prediction algorithms;Market research;Planning;Sports;Genetic algorithms;momentum;EWM-TOPSIS;randomness test;LightGBM},
  doi={10.1109/ICIPCA61593.2024.10709089},
  ISSN={},
  month={June},}@INPROCEEDINGS{10859638,
  author={Wang, Yang},
  booktitle={2024 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Educational Big Data Mining and Analysis Based on Support Vector Machine Performance Prediction Rate}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In this era, educational data has generated data-driven insights, especially with the application of machine learning models to predict the student performance. Even though previous researchers suggested various robust machines learning techniques still there are several challenges such as data complexity, privacy concerns, and the varied formats of educational data for efficient data processing and analysis. This study focuses on developing a robust model for predicting student performance by employing advanced machine learning methods tailored for educational data. This paper proposes a novel approach namely GIWRF-SVM utilizing Gini Impurity based Weighted Random Forest (GIWRF) with Support Vector Machine (SVM) performance prediction rate. Initially, the data is collected from Academic Performance Dataset (xAPI-Edu-Data) i.e. XAPI dataset. Then, the collected data is processed using various techniques such as discretization and resampling. Further, the processed data is fed as input to Gini Impurity based Weighted Random Forest (GIWRF) for feature selection. In the end, SVM is used for prediction of academic warning for college student's has acquired greater results with Mean Absolute Error (MAE) of 9.24, Root Mean Square Error (RMSE) of 4.28 and Root Absolute Error (RAE) of 4.76 when compared with Genetic Algorithm with Decision Tree Regression.},
  keywords={Support vector machines;Impurities;Optimization models;Predictive models;Big Data;Data models;Root mean square;Random forests;Regression tree analysis;Genetic algorithms;education big data mining;gini impurity based weighted random forest;machine learning;prediction rate and support vector machine},
  doi={10.1109/ICIICS63763.2024.10859638},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10612035,
  author={Guha, Ritam and Deb, Kalyanmoy},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Scalable Polynomial RegEM(a)O for Multi-lMany-objective Platform-based Design Optimization Problems}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The goal of a generic evolutionary multi- or many-objective algorithm is to explore a search space and find the trade-off optimal solutions for two or more conflicting objectives. In platform-based practical design optimization problems, it is not sufficient to just find a set of trade-off optimal solutions, certain regularity properties are expected in the entire fleet of trade-off solutions. For this purpose, we propose a scalable regularity-based optimization framework - RegEM(a)O - which automatically extracts polynomial regularity principles from the resulting Pareto-optimal front of multi- or many-objective problems. Thereafter, it attempts to search for a regular front of trade-off solutions following a similar form of polynomial regularity principles. Despite being slightly worse than the true Pareto-optimal solutions, regular solutions possess simple properties among them, making them easily interpretable, their inventory easily maintainable, and easily scalable. In this paper, we apply RegEM(a)O to a number of small and large-scale real-world engineering design problems to demonstrate its practical advantage.},
  keywords={Evolutionary computation;Search problems;Polynomials;Space exploration;Optimization;Design optimization;Regularity;Platform-based Design;Multi- Many-objective Optimization;Pareto Front;Bi-Ievel Search},
  doi={10.1109/CEC60901.2024.10612035},
  ISSN={},
  month={June},}@ARTICLE{9354957,
  author={Xu, Xueyuan and Wu, Xia and Wei, Fulin and Zhong, Wei and Nie, Feiping},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A General Framework for Feature Selection Under Orthogonal Regression With Global Redundancy Minimization}, 
  year={2022},
  volume={34},
  number={11},
  pages={5056-5069},
  abstract={Feature selection has attracted a lot of attention in obtaining discriminative and non-redundant features from high-dimension data. Compared with traditional filter and wrapper methods, embedded methods can obtain a more informative feature subset by fully considering the importance of features in the classification tasks. However, the existing embedded methods emphasize the above importance of features and mostly ignore the correlation between the features, which leads to retain the correlated and redundant features with similar scores in the feature subset. To solve the problem, we propose a novel supervised embedded feature selection framework, called feature selection under global redundancy minimization in orthogonal regression (GRMOR). The proposed framework can effectively recognize redundant features from a global view of redundancy among the features. We also incorporate the large margin constraint into GRMOR for robust multi-class classification. Compared with the traditional embedded methods based on least square regression, the proposed framework utilizes orthogonal regression to preserve more discriminative information in the subspace, which can help accurately rank the importance of features in the classification tasks. Experimental results on twelve public datasets demonstrate that the proposed framework can obtain superior classification performance and redundancy removal performance than twelve other feature selection methods.},
  keywords={Feature extraction;Redundancy;Task analysis;Minimization;Computational modeling;Radio frequency;Data models;Feature selection;orthogonal regression;global redundancy minimization;feature weighting;large margin;embedded methods},
  doi={10.1109/TKDE.2021.3059523},
  ISSN={1558-2191},
  month={Nov},}@INPROCEEDINGS{9971660,
  author={Yang, Meng and Li, Ruichen and Wang, Bei and Zhang, Tao},
  booktitle={2022 7th International Conference on Intelligent Informatics and Biomedical Science (ICIIBMS)}, 
  title={Automatic Sleep Staging Method Based on EEG Signal and its Optimized Feature Space}, 
  year={2022},
  volume={7},
  number={},
  pages={208-212},
  abstract={Sleep is essential for physical and mental health. One's overnight sleep is usually evaluated into different sleep stages consisting of several sleep cycles. Computerized sleep staging would be an efficient tool but the performance is still required to be developed. In this study, an automatic sleep staging method is realized based on EEG signal and its optimized feature space. Several characteristic features are extracted from sleep EEG as an original feature space. A non-negative matrix factorization method based on kernel function and sparse improvement is developed to optimize the feature space for sleep staging. A classification model is constructed based on BP neural network and the parameters are estimated by PSO algorithm. Totally 10 overnight sleep recordings were tested. The proposed method achieved an average classification accuracy of 81% which is rather satisfactory as an assistant tool for application.},
  keywords={Sleep;Feature extraction;Brain modeling;Electroencephalography;Skeleton;Recording;Classification algorithms;BP neural network;EEG;Non-negative matrix factorization;PSO;Sleep staging},
  doi={10.1109/ICIIBMS55689.2022.9971660},
  ISSN={2189-8723},
  month={Nov},}@INPROCEEDINGS{10863618,
  author={Timmerman, Mark and Apperloo, Edser and Ben Aziza, Syrine},
  booktitle={2024 IEEE PES Innovative Smart Grid Technologies Europe (ISGT EUROPE)}, 
  title={Analyzing Parameter Estimation Methods for RC Models in the Modelling of Heat Dynamics of Residential Buildings}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The growing use of heat pumps contributes significantly to energy consumption and is thus a suitable focus for flexibility solutions. Maximizing the flexibility of a single heat pump requires an accurate model of a building’s heat dynamics, ensuring that the heat pumps can be controlled appropriately. These dynamics are unique to each building and continuously evolve as a result of a variety of factors such as weather, home remodelling, and building usage. Resistor-capacitor (RC) models are a proven way to model such dynamics, but require parameters to be tuned to the building represented by the model. Training algorithms can be applied to learn these parameters based on observational data. This paper qualitatively compares three such algorithms: a genetic algorithm, a neural network and a sequential Monte Carlo algorithm. The quality of the learning algorithms is assessed on the accuracy, its adaptability, explainability, and the amount of time and data required to converge. This serves as the foundation regarding the practical usability of such an algorithm in a real-world environment.},
  keywords={Training;Adaptation models;Accuracy;Parameter estimation;Monte Carlo methods;Heat pumps;Heuristic algorithms;Buildings;Tuning;Genetic algorithms;digital twins;machine learning;heat pump;genetic algorithms},
  doi={10.1109/ISGTEUROPE62998.2024.10863618},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9812046,
  author={Wathieu, Adam and Groechel, Thomas R. and Lee, Haemin Jenny and Kuo, Chloe and Matarić, Maja J.},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={RE:BT-Espresso: Improving Interpretability and Expressivity of Behavior Trees Learned from Robot Demonstrations}, 
  year={2022},
  volume={},
  number={},
  pages={11518-11524},
  abstract={Behavior trees (BTs) are hierarchical agent control architectures popular for robot task-level planning that can be autonomously learned from robot demonstrations via decision tree (DT) intermediaries, making them accessible to non-expert users. Conversion algorithms from DTs to BTs, such as the BT-Espresso algorithm, focus on replicating DT logic in a BT format but do not exploit the strengths of the BT architecture. We introduce the Representation Exploitation of BT-Espresso (RE:BT-Espresso) algorithm, which builds on BT-Espresso and improves the learned BT's interpretability and expressivity. RE:BT-Espresso improves interpretability by removing logical redundancies in the generated BTs and improves expressivity by exploiting desired BT structures, such as adding Inverter nodes, Repeater sequences, and Parallel Selector Action nodes that gives the user a choice of actions for state spaces that did not resolve to a concise action in the DT. The RE:BT-Espresso algorithm was evaluated against BT-Espresso using demonstration data synthesized by BTs. When compared to the synthesized BTs using graph edit distance (GED), RE:BT-Espresso outscored BT-Espresso on 54 subtrees, tied on 178, and lost on 2. Further, the proposed reduction strategies reduced the number of nodes in a generated tree by a median of 7.82%. The results validate improved interpretability and expressivity of learned RE:BT-Espresso task-level BT policies from robot demonstration.},
  keywords={Automation;Redundancy;Repeaters;Inverters;Behavioral sciences;Planning;Decision trees},
  doi={10.1109/ICRA46639.2022.9812046},
  ISSN={},
  month={May},}@INPROCEEDINGS{9980684,
  author={Bayomie, Dina and Revoredo, Kate and Di Ciccio, Claudio and Mendling, Jan},
  booktitle={2022 4th International Conference on Process Mining (ICPM)}, 
  title={Improving Accuracy and Explainability in Event-Case Correlation via Rule Mining}, 
  year={2022},
  volume={},
  number={},
  pages={24-31},
  abstract={Process mining analyzes business processes’ behavior and performance using event logs. An essential requirement is that events are grouped in cases representing the execution of process instances. However, logs extracted from different systems or non-process-aware information systems do not map events with unique case identifiers (case IDs). In such settings, the event log needs to be pre-processed to group events into cases – an operation known as event correlation. Existing techniques for correlating events work with different assumptions: some assume the generating processes are acyclic, others require extra domain knowledge such as the relation between the events and event attributes, or heuristic information about the activities’ execution time behavior. However, the domain knowledge is not always available or easy to acquire, compromising the quality of the correlated event log. In this paper, we propose a new technique called EC-SA-RM, which correlates the events using a simulated annealing technique and iteratively learns the domain knowledge as a set of association rules. The technique requires a sequence of timestamped events (i.e., the log without case IDs) and a process model describing the underlying business process. At each iteration of the simulated annealing, a possible correlated log is generated. Then, EC-SA-RM uses this correlated log to learn a set of association rules that represent the relationship between the events and the changing behavior over the events’ attributes in an understandable way. These rules enrich the input and improve the event correlation process for the next iteration. EC-SA-RM returns an event log in which events are grouped in cases and a set of association rules that explain the correlation over the events. We evaluate our approach using four real-life datasets.},
  keywords={Correlation;Simulated annealing;Behavioral sciences;Data mining;Business;Information systems;Event correlation;Association rule mining;Simulated annealing;Explainability},
  doi={10.1109/ICPM57379.2022.9980684},
  ISSN={},
  month={Oct},}@ARTICLE{10596098,
  author={Li, Zhi and Zheng, Ke and Li, Jiaxin and Li, Chengrui and Gao, Lianru},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Cross-Semantic Heterogeneous Modeling Network for Hyperspectral Image Classification}, 
  year={2024},
  volume={62},
  number={},
  pages={1-16},
  abstract={The adequate and finer spectral information in hyperspectral images (HSIs) are benefit for various downstream applications like smart agriculture and environmental monitoring. In HSI classification, dual-stream convolutional networks have gained much attention and have been widely used. In patch-based hyperspectral classification tasks, however, merely using center-labeled patches could lead to an increased unlabeled noise in the data. Moreover, in the application of dual-stream network structures, heterogeneity existed in both the data and feature semantic levels to capture more representative features. To tackle these challenges, we have devised a framework called cross-semantic heterogeneous modeling network (CreatingNet), which aligns more closely with the design principles of dual-stream networks by adjusting the input size. This framework introduces a distance metric attention mechanism (DMAM) based on spectral and spatial distances to strengthen the influence of the center pixel on the entire patch. Additionally, we present a fusion module named CrossViT, which combines features with diverse structures and characteristics, leveraging their complementarity. The proposed multiscale heterogeneous fusion module allows for more effective integration of spatial and spectral features in the images. Extensive experiments on four well-known HSI datasets (Indian Pines, Pavia University, Salinas, and Houston 2013) demonstrate the superior classification performance of the proposed CreatingNet to several state-of-the-art methods. The effectiveness of the proposed model is further validated through ablation studies.},
  keywords={Feature extraction;Transformers;Noise;Hyperspectral imaging;Data mining;Convolutional neural networks;Three-dimensional displays;Attention mechanism;fusion;hyperspectral imagery (HSI);image classification;spectral–spatial feature extraction},
  doi={10.1109/TGRS.2024.3426358},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10731312,
  author={Latif, Ehsan and Parasuraman, Ramviyas and Zhai, Xiaoming},
  booktitle={2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)}, 
  title={PhysicsAssistant: An LLM-Powered Interactive Learning Robot for Physics Lab Investigations}, 
  year={2024},
  volume={},
  number={},
  pages={864-871},
  abstract={Robot systems in education can leverage Large language models’ (LLMs) natural language understanding capabilities to provide assistance and facilitate learning. This paper proposes a multimodal interactive robot (PhysicsAssistant) built on YOLOv8 object detection, cameras, speech recognition, and chatbot using LLM to provide assistance to students’ physics labs. We conduct a user study on ten 8th-grade students to empirically evaluate the performance of PhysicsAssistant with a human expert. The Expert rates the assistants’ responses to student queries on a 0-4 scale based on Bloom’s taxonomy to provide educational support. We have compared the performance of PhysicsAssistant (YOLOv8+GPT-3.5-turbo) with GPT-4 and found that the human expert rating of both systems for factual understanding is same. However, the rating of GPT-4 for conceptual and procedural knowledge (3 and 3.2 vs 2.2 and 2.6, respectively) is significantly higher than PhysicsAssistant (p < 0.05). However, the response time of GPT-4 is significantly higher than PhysicsAssistant (3.54 vs 1.64 sec, p < 0.05). Hence, despite the relatively lower response quality of PhysicsAssistant than GPT-4, it has shown potential for being used as a real-time lab assistant to provide timely responses and can offload teachers’ labor to assist with repetitive tasks. To the best of our knowledge, this is the first attempt to build such an interactive multimodal robotic assistant for K-12 science (physics) education.},
  keywords={Taxonomy;Education;Robot vision systems;Object detection;Speech recognition;Real-time systems;Cognition;Physics education;Time factors;Robots;Large Language Model;Human-Robot Interaction;Object Detection;Physics Assistant;Bloom’s Taxonomy},
  doi={10.1109/RO-MAN60168.2024.10731312},
  ISSN={1944-9437},
  month={Aug},}@ARTICLE{9869631,
  author={Etemadyrad, Negar and Gao, Yuyang and Li, Qingzhe and Guo, Xiaojie and Krueger, Frank and Lin, Qixiang and Qiu, Deqiang and Zhao, Liang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Functional Connectivity Prediction With Deep Learning for Graph Transformation}, 
  year={2024},
  volume={35},
  number={4},
  pages={4862-4875},
  abstract={Inferring resting-state functional connectivity (FC) from anatomical brain wiring, known as structural connectivity (SC), is of enormous significance in neuroscience for understanding biological neuronal networks and treating mental diseases. Both SC and FC are networks where the nodes are brain regions, and in SC, the edges are the physical fiber nerves among the nodes, while in FC, the edges are the nodes’ coactivation relations. Despite the importance of SC and FC, until very recently, the rapidly growing research body on this topic has generally focused on either linear models or computational models that rely heavily on heuristics and simple assumptions regarding the mapping between FC and SC. However, the relationship between FC and SC is actually highly nonlinear and complex and contains considerable randomness; additional factors, such as the subject’s age and health, can also significantly impact the SC-FC relationship and hence cannot be ignored. To address these challenges, here, we develop a novel SC-to-FC generative adversarial network (SF-GAN) framework for mapping SC to FC, along with additional metafeatures based on a newly proposed graph neural network-based generative model that is capable of learning the stochasticity. Specifically, a new graph-based conditional generative adversarial nets model is proposed, where edge convolution layers are leveraged to encode the graph patterns in the SC in the form of a graph representation. New edge deconvolution layers are then utilized to decode the representation back to FC. Additional metafeatures of subjects’ profile information are integrated into the graph representation with newly designed sparse-regularized layers that can automatically select features that impact FC. Finally, we have also proposed new post hoc explainer of our SF-GAN, which can identify which subgraphs in SC strongly influence which subgraphs in FC by a new multilevel edge-correlation-guided graph clustering problem. The results of experiments conducted to test the new model confirm that it significantly outperforms existing state-of-the-art methods, with additional interpretability for identifying important metafeatures and subgraphs.},
  keywords={Correlation;Generative adversarial networks;Deep learning;Deconvolution;Convolutional neural networks;Neural networks;Brain modeling;Convolutional neural network;deep learning;functional connectivity (FC);interpretable graph neural networks;metafeatures;structural connectivity (SC);subgraph mining},
  doi={10.1109/TNNLS.2022.3197337},
  ISSN={2162-2388},
  month={April},}@INPROCEEDINGS{10385933,
  author={Wei, Yaonai and Zhang, Tuo and Zhang, Han and Zhong, Tianyang and Zhao, Lin and Liu, Zhengliang and Ma, Chong and Zhang, Songyao and Shang, Muheng and Du, Lei and Li, Xiao and Liu, Tianming and Han, Junwei},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain Activation Maps}, 
  year={2023},
  volume={},
  number={},
  pages={1523-1530},
  abstract={Over decades, neuroscience has accumulated a wealth of research results in the text modality that can be used to explore cognitive processes. Meta-analysis is a typical method that successfully establishes a link from text queries to brain activation maps using these research results, but it still relies on an ideal query environment. In practical applications, text queries used for meta-analyses may encounter issues such as semantic redundancy and ambiguity, resulting in an inaccurate mapping to brain images. On the other hand, large language models (LLMs) like ChatGPT have shown great potential in tasks such as context understanding and reasoning, displaying a high degree of consistency with human natural language. Hence, LLMs could improve the connection between text modality and neuroscience, resolving existing challenges of meta-analyses. In this study, we propose a method called Chat2Brain that combines LLMs to basic text-2-image model, known as Text2Brain, to map open-ended semantic queries to brain activation maps in data-scarce and complex query environments. By utilizing the understanding and reasoning capabilities of LLMs, the performance of the mapping model is optimized by transferring text queries to semantic queries. We demonstrate that Chat2Brain can synthesize anatomically plausible neural activation patterns for more complex tasks of text queries.},
  keywords={Training;Neuroscience;Biological system modeling;Semantics;Redundancy;Natural languages;Brain modeling;meta-analysis;large language model;image generation},
  doi={10.1109/BIBM58861.2023.10385933},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10347726,
  author={Hu, Yunzhang and Wang, Hui},
  booktitle={2023 8th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)}, 
  title={Research on Rockdb knob Configuration based on LightGBM and NSGA2}, 
  year={2023},
  volume={8},
  number={},
  pages={361-366},
  abstract={RocksDB is an exemplary database engine in terms of performance. However, its performance optimization necessitates manual adjustment of numerous intricate knob configuration, which poses challenges for database users. In order to address this predicament, this paper proposes an automated method for tuning RocksDB knob configuration. Firstly, we employ a neural network algorithm to extract pivotal features of the knob configuration. These features are acquired through profound analysis and learning from RocksDB, enabling precise capture of the parameters' impact on performance. Subsequently, we introduce the Non-dominated Sorting Genetic Algorithm II (NSGA2), a multi-objective evolutionary algorithm, to optimize the rotary configurations and select the most promising configuration scheme based on the maximized fitness values. This algorithm adeptly balances multiple performance metrics, thus discovering the optimal knob configuration scheme. Lastly, we construct an adaptive function model based on Light Gradient Boosting Machine (LightGBM) to evaluate and select the knob configuration schemes. To validate the efficacy of our approach, we conducted comparative experimental studies between our proposed method and three alternative approaches under six different workloads. The experimental results demonstrate the ability of our method to enhance performance across various workload scenarios. Through this research, we present an automated method for tuning RocksDB knob configuration, which bestows convenience and efficiency upon database users.},
  keywords={Measurement;Databases;Neural networks;Manuals;Predictive models;Feature extraction;Informatics;RocksDB;Knob Configuration;NSGA2;LightGBM},
  doi={10.1109/ICIIBMS60103.2023.10347726},
  ISSN={2189-8723},
  month={Nov},}@INPROCEEDINGS{10386908,
  author={Ji, Anli and Aydin, Berkay},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Interpretable Solar Flare Prediction with Sliding Window Multivariate Time Series Forests}, 
  year={2023},
  volume={},
  number={},
  pages={1519-1524},
  abstract={Recently, the synergy of physics-based feature engineering and data-intensive methods, including machine learning and deep learning, has ushered in a new era in the analysis and prediction of space weather forecasting, specifically for solar flare prediction. These sophisticated approaches play a pivotal role in understanding the complex mechanisms leading to solar flares, with a primary focus on forecasting these events and mitigating potential risks they pose to our planet. While current methodologies have made substantial advancements, they are not without limitations, and one particularly glaring limitation is the neglect of temporal evolution characteristics within the active regions from which solar flares originate. This oversight impairs the capacity of these methods to capture the intricate relationships among high-dimensional features of these active regions, thereby constraining their practical utility. Our study focuses on two key objectives: the development of interpretable classifiers for multivariate time series data and the introduction of an innovative feature ranking method using sliding window-based sub-interval ranking. The central contribution of our work lies in bridging the gap between complex, less interpretable “black-box” models typically employed for high-dimensional data and the exploration of pertinent sub-intervals within multivariate time series data, with a specific emphasis on solar flare forecasting. Our findings underscore the efficacy of our sliding-window time series forest classifier in solar flare prediction, achieving a True Skill Statistic of over 85%. Our approach is capable of pinpointing the most critical features and sub-intervals relevant to any given learning task. These results indicate significant progress toward improving the interpretability and accuracy of flare prediction models, further advancing our understanding of these impactful events.},
  keywords={Deep learning;Planets;Time series analysis;Weather forecasting;Closed box;Forestry;Predictive models;Multivariate Time Series Classification;Solar Flare Prediction;Interval-based Classification},
  doi={10.1109/BigData59044.2023.10386908},
  ISSN={},
  month={Dec},}@ARTICLE{10153334,
  author={Bruns, Ralf and Dunkel, Jürgen and Seremet, Serif},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Learning Ship Activity Patterns in Maritime Data Streams: Enhancing CEP Rule Learning by Temporal and Spatial Relations and Domain-Specific Functions}, 
  year={2023},
  volume={24},
  number={10},
  pages={11384-11395},
  abstract={Maritime surveillance systems are of particular importance for the smooth and safe operation of maritime traffic. Such systems must efficiently analyze the continuous stream of incoming ship movement data to provide an up-to-date picture of the situation at sea. Complex Event Processing (CEP) is a software technology dedicated to the analysis of data streams in real time and seems to be promising for maritime surveillance as well. CEP is based on rules that usually have to be formulated manually by domain experts. Recently, several approaches of learning CEP rules have been proposed. However, all these approaches are limited to standard CEP rule languages which are not well suited for describing maritime situations. In this paper, we extend Bat4CEP, an innovative bat-inspired approach to automatic CEP rule learning, to meet the specific needs of the maritime domain. In particular, we extend the rule language of Bat4CEP to include temporal-spatial operators and domain-specific functions. This extended rule language makes it possible to express complex maritime facts in a simple and understandable form. Furthermore, it is shown how the proposed rule language extensions can be integrated into the Bat4CEP learning approach. The effectiveness of the approach is demonstrated through extensive experiments with real maritime data streams.},
  keywords={Marine vehicles;Artificial intelligence;Surveillance;Metaheuristics;Seaports;Real-time systems;Standards;Maritime transportation;maritime data analytics;metaheuristics;machine learning;complex event processing;interpretable AI},
  doi={10.1109/TITS.2023.3282246},
  ISSN={1558-0016},
  month={Oct},}@INPROCEEDINGS{10619870,
  author={Liu, Wei and Li, Kaiwen and Li, Wenhua and Wang, Rui and Zhang, Tao},
  booktitle={2024 IEEE 18th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={Multi-Agent Deep Reinforcement Learning for Multi-Modal Orienteering Problem}, 
  year={2024},
  volume={},
  number={},
  pages={000169-000174},
  abstract={The multi-modal orienteering problem (MM-OP) is common in real life and is to plan diverse tours that can visit as many nodes as possible with limited resources. Researchers used to adopt group intelligence algorithms such as evolutionary algorithms to solve MM-OP, however, show difficulty in designing complex operators and dealing with large-scale cases in real-time. This study first proposes a multi-agent deep reinforcement learning (MA-DRL) method for MM-OP. Our model deploys multiple agents, each trained to independently explore and exploit the solution space, thereby discovering diverse optimal paths. This diversity is critical in multi-modal optimization and is achieved through a unique reward-sharing mechanism implemented within the MA-DRL framework. Empirical evaluation of our model against traditional evolutionary algorithms on various test instances demonstrates its superior optimization accuracy and efficiency, particularly in larger problem sizes. Additionally, the robustness across different instance sizes underscores its great generalization ability.},
  keywords={Training;Adaptation models;Navigation;Computational modeling;Evolutionary computation;Deep reinforcement learning;Real-time systems;Orienteering Problem;Multi-modal Optimization;Multi-agent;Deep Reinforcement Learning},
  doi={10.1109/SACI60582.2024.10619870},
  ISSN={2765-818X},
  month={May},}@INPROCEEDINGS{10859943,
  author={Yang, Qiuyu},
  booktitle={2024 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Financial Risk Warning Based on Bayesian Neural Networks and Variational Auto Encoders}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent days, predicting financial risk warnings is essential for protecting economic stability, and enabling practical actions against credit defaults, market crises, and systemic risks. Previous researchers suggested various traditional models but still, because of the complexity of and high-dimensional financial data there are challenges such as; noise, temporal dependencies, and macroeconomic factors and thus ensuring model interpretability for stakeholders, and computing uncertainty to enhance trust in predictions. This paper suggests a novel approach by incorporating ensemble methods such as Bayesian Neural Network (BNN), Long Short-Term Memory (LSTM) and Variational Auto Encoders (VAE) for effective and early financial risk prediction. Initially, the data is collected from a large dataset embedded into the Exploratory Factor Analysis (EFA) model for categorizing the data into factors. Further, the data is fed into the prediction model which is integrated using BNN, LSTM, and VAE for effective prediction of financial risk. Hence, the proposed BNN-LSTM-VAE has acquired greater results with Mean Absolute Error (MAE) of 0.07843, Mean Absolute Percentage Error (MAPE) of 3.947, and Mean Square Error (MSE) of 0.00851 respectively when compared with existing model integrated using Factor Analysis (FA), Particle Swarm Optimizer and LSTM namely FA-PSO-LSTM.},
  keywords={Analytical models;Uncertainty;Biological system modeling;Computational modeling;Neural networks;Predictive models;Data models;Bayes methods;Stakeholders;Long short term memory;bayesian neural network;exploratory factor analysis;financial risk;long short-term memory;variational auto encoders},
  doi={10.1109/ICIICS63763.2024.10859943},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11006244,
  author={Esmaeili, Mobina and Hasheminejad, Seyed Mohammad Hossein and Sabeti, Vajiheh},
  booktitle={2025 11th International Conference on Web Research (ICWR)}, 
  title={A Multimodal Approach for Persian Speech Emotion Recognition with Evolutionary Feature Selection}, 
  year={2025},
  volume={},
  number={},
  pages={346-351},
  abstract={Understanding emotions in speech is fundamental to natural human-computer interaction, yet accurately capturing these emotions remains a challenge, especially in low-resource languages like Persian. Linguistic complexity and limited labeled datasets hinder the performance of conventional Speech Emotion Recognition (SER) models. To address these challenges, this study introduces a multimodal SER system that integrates acoustic and textual features for improved emotion classification. The model employs Whisper ASR (Automatic Speech Recognition) for speech-to-text conversion and a Modified Differential Evolution (MDE) algorithm for optimized speech feature selection. Extracted features are fused using a self-attention mechanism before being processed by a deep learning-based classification model. Evaluations on the ShEMO (Sharif Speech Emotion) dataset demonstrate that the proposed approach achieves significant improvements over existing methods. Results highlight the impact of multimodal integration and evolutionary optimization in refining SER performance, particularly in handling complex emotional expressions. This research advances emotion recognition technology for applications in virtual assistants, mental health monitoring, and customer service automation.},
  keywords={Emotion recognition;Virtual assistants;Transfer learning;Refining;Speech recognition;Feature extraction;Acoustics;Classification algorithms;Speech processing;Speech to text;Differential Evolution Algorithm;Speech Processing;Speech Emotion Recognition;Multimodal Model},
  doi={10.1109/ICWR65219.2025.11006244},
  ISSN={2837-8296},
  month={April},}@INPROCEEDINGS{10709033,
  author={Yan, Hanjun},
  booktitle={2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Bearing Fault Image Recognition Method Based on Decision Fusion and Optimization Deep Learning Framework}, 
  year={2024},
  volume={},
  number={},
  pages={949-955},
  abstract={Classical algorithms in data mining have been widely studied and applied in industrial equipment condition monitoring. However, the traditional deep learning models are not yet accurate in identifying the bearing status, and most of them rely on manual experience for identification, which leads to certain errors. This study proposes a hyperparameter optimization method using a swarm optimization algorithm for CNN architecture. At the beginning, the primary vibration signal is converted into a two-dimensional time-frequency map to construct a dataset. Second, the network noise immunity is tested and the optimal network framework is determined. Then, the parameter search is optimized using the swarm optimization algorithm and the fitness function is designed. Finally, the interpretability and stability of the network are improved by visualization and decision fusion. After the verification of Case Western Reserve University bearing dataset, the method introduced in this research paper displays noteworthy accuracy in fault diagnosis and holds substantial significance for engineering applications.},
  keywords={Deep learning;Vibrations;Training;Time-frequency analysis;Image recognition;Accuracy;Stability analysis;Robustness;Particle swarm optimization;Optimization;bearing failure;hyperparameter optimization;decision fusion;convolutional neural network},
  doi={10.1109/ICIPCA61593.2024.10709033},
  ISSN={},
  month={June},}
