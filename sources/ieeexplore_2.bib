@INPROCEEDINGS{10356243,
  author={Stodt, Jan and Reich, Christoph and Clarke, Nathan},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={A Novel Metric for XAI Evaluation Incorporating Pixel Analysis and Distance Measurement}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Explainable Artificial Intelligence (XAI) seeks to enhance transparency and trust in AI systems. Evaluating the quality of XAI explanation methods remains challenging due to limitations in existing metrics. To address these issues, we propose a novel metric called Explanation Significance Assessment (ESA) and its extension, the Weighted Explanation Significance Assessment (WESA). These metrics offer a comprehensive evaluation of XAI explanations, considering spatial precision, focus overlap, and relevance accuracy. In this paper, we demonstrate the applicability of ESA and WESA on medical data. These metrics quantify the understandability and reliability of XAI explanations, assisting practitioners in interpreting AI-based decisions and promoting informed choices in critical domains like healthcare. Moreover, ESA and WESA can play a crucial role in AI certification, ensuring both accuracy and explainability. By evaluating the performance of XAI methods and underlying AI models, these metrics contribute to trustworthy AI systems. Incorporating ESA and WESA in AI certification efforts advances the field of XAI and bridges the gap between accuracy and interpretability. In summary, ESA and WESA provide comprehensive metrics to evaluate XAI explanations, benefiting research, critical domains, and AI certification, thereby enabling trustworthy and interpretable AI systems.},
  keywords={Measurement;Bridges;Decision making;Medical services;Distance measurement;Reliability;Artificial intelligence;XAI;XAI evaluation;evaluation metric;explainability;understandability},
  doi={10.1109/ICTAI59109.2023.00009},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{10955158,
  author={Chen, Liang and Sun, Leming and Zhong, Caiming},
  journal={IEEE Access}, 
  title={Interpretability-Oriented Adjustment of K-Means: A Multiple-Objective Particle Swarm Optimization Framework}, 
  year={2025},
  volume={13},
  number={},
  pages={68084-68096},
  abstract={Clustering is an unsupervised machine learning technique used to partition unlabeled data into different groups. However, traditional clustering methods only provide a set of results without any explanations. While numerous methods in the literature attempt to explain clustering results, the explanation rules provided by these models are fixed and sacrificing clustering quality for the sake of making the rules easier to understand. To address this, this paper proposes a feature selection model to balance the interpretability and clustering quality. The model consists of two stages. In the first stage, the concept of explanatory radius is defined, and the explanatory radius of each cluster in the initial clustering results is calculated. In the second stage, a feature subspace is selected, and the dataset is re-clustered in this subspace using a proposed formula to obtain a new clustering result. Three objective functions are designed to evaluate the performance of the new clustering results in terms of cluster quality and interpretability. Subsequently, the model utilizes a multi-objective optimization framework to optimize the three objective functions in the solution space formed by different feature subspaces, resulting in a set of Pareto solutions. Each solution in the Pareto set represents a trade-off between clustering quality and interpretability. Finally, the contribution of features during the generation process of each cluster is used to represent the interpretability of each cluster’s result. The proposed method is validated on both artificial datasets and real-world datasets, and comparative analyses are conducted with the latest explainable clustering algorithms in the literature. The analysis results demonstrate the effectiveness of the proposed method.},
  keywords={Clustering algorithms;Optimization;Linear programming;Machine learning algorithms;Decision trees;Prediction algorithms;Particle swarm optimization;Vectors;Prototypes;Feature extraction;Feature selection;interpretability;K-means clustering},
  doi={10.1109/ACCESS.2025.3558716},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10532888,
  author={Ileri, Kadir},
  booktitle={2024 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET)}, 
  title={LightGBM: Predicting Average Localization Error Through Particle Swarm Optimization in Wireless Sensor Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Localization of nodes represents a significant concern within Wireless Sensor Networks (WSNs). Predicting localization error accurately offers several advantages such as improved network performance, optimized resource allocation, and cost reduction. This paper presents a comprehensive investigation into the estimation of average localization error (ALE) in WSNs. The study employs the LightGBM algorithm, incorporating a particle swarm optimization (PSO) methodology to enhance predictive accuracy. The performance of the proposed model is assessed through comparison with various alternative machine learning methods, employing the R2 and MSE evaluation metrics. The proposed LightGBM-PSO model outperforms the other methods with the R2 value of 0.9043 and the MSE value of 0.1217. Moreover, feature importance analysis has been achieved. The number of iterations shows the greatest influence on the estimation of ALE, whereas the transmission range demonstrates the least impact.},
  keywords={Location awareness;Measurement;Wireless communication;Wireless sensor networks;Machine learning algorithms;Signal processing algorithms;Estimation;LightGBM;particle swarm optimization;MLP;DT;wireless sensor networks},
  doi={10.1109/WiSPNET61464.2024.10532888},
  ISSN={},
  month={March},}@INPROCEEDINGS{11009247,
  author={Li, Jingjing and Tao, Yizheng and Jin, Bin},
  booktitle={2025 7th International Conference on Software Engineering and Computer Science (CSECS)}, 
  title={A Software Defect Prediction Model Enhanced by Self-Attention Mechanism and Particle Swarm Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Software defect prediction is a key aspect of software quality assurance that involves the use of historical data and a variety of analytical techniques to estimate which parts of the code are most likely to contain errors. Not only can software defects lead to system failure, but they can also have serious economic and social consequences. Most of the current methods rely on a single type of feature and fail to explore the multiple information in the code fully. Meanwhile, manually tuning hyperparameters is both time-consuming and difficult to achieve optimal results. Based on the encoder architecture, this research proposes an enhanced software defect prediction model, which combines the self-attention mechanism and particle swarm optimization (PSO-BiEncoders-SelfAttn). This model achieves efficient feature extraction, dynamic adjustment of feature fusion weights, and automated optimization of hyperparameters. This study trained and tested the model on five different publicly available datasets and evaluated it using metrics including precision, recall, and F-measure. The proposed PSO-BiEncoders-SelfAttn model improves the state-of-art, achieving an average F-measure improvement of 7.92% according to the experimental result.},
  keywords={Measurement;Codes;Computational modeling;Software quality;Predictive models;Feature extraction;Particle swarm optimization;Tuning;Optimization;Software engineering;software defect prediction;self-attention mechanism;particle swarm optimization;encoder;deep learning},
  doi={10.1109/CSECS64665.2025.11009247},
  ISSN={},
  month={March},}@INPROCEEDINGS{10612158,
  author={Pang, Junwei and Mei, Yi and Zhang, Mengjie},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Multi-Objective Genetic-Programming Hyper-Heuristic for Evolving Interpretable Flexible Job Shop Scheduling Rules}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={The job shop scheduling problem is an important combinatorial optimisation problem in the real world. Genetic programming hyper-heuristic has been successfully applied to automatically evolve effective dispatching rules to make a schedule in real time without much domain knowledge. However, the interpretability of GP-evolved rules has been largely neglected, which could lead to the lack of reliability and trustworthiness of the evolved rules in practice. Current work related to interpretable genetic programming algorithms primarily uses the model size as the interpretability metric. This could not fully reflect the interpretability of evolved rules. To overcome the limitation, we employ structural complexity and dimension gap as more comprehensive interpretability measures. In addition, a new multi-objective genetic programming algorithm, which applies the a non-dominated sorting method to solve the objective selection bias issue, is proposed to optimise the makespan (scheduling objective), structural complexity and dimension gap simultaneously. A variety of experiments demonstrates the competitive performance of our proposed algorithm based on effectiveness, convergence and diversity. Furthermore, the semantics of evolved dispatching rules are analysed to show their better interpretability.},
  keywords={Schedules;Job shop scheduling;Heuristic algorithms;Semantics;Genetic programming;Size measurement;Dispatching;multi-objective genetic programming;interpretability;flexible job shop scheduling},
  doi={10.1109/CEC60901.2024.10612158},
  ISSN={},
  month={June},}@ARTICLE{10697262,
  author={Schneider, Ethan and Wu, Daniel and Das, Devleena and Chernova, Sonia},
  journal={IEEE Robotics and Automation Letters}, 
  title={CE-MRS: Contrastive Explanations for Multi-Robot Systems}, 
  year={2024},
  volume={9},
  number={11},
  pages={10121-10128},
  abstract={As the complexity of multi-robot systems grows to incorporate a greater number of robots, more complex tasks, and longer time horizons, the solutions to such problems often become too complex to be fully intelligible to human users. In this work, we introduce an approach for generating natural language explanations that justify the validity of the system's solution to the user, or else aid the user in correcting any errors that led to a suboptimal system solution. Toward this goal, we first contribute a generalizable formalism of contrastive explanations for multi-robot systems, and then introduce a holistic approach to generating contrastive explanations for multi-robot scenarios that selectively incorporates data from multi-robot task allocation, scheduling, and motion-planning to explain system behavior. Through user studies with human operators we demonstrate that our integrated contrastive explanation approach leads to significant improvements in user ability to identify and solve system errors, leading to significant improvements in overall multi-robot team performance.},
  keywords={Resource management;Multi-robot systems;Schedules;Explainable AI;Decision making;Visualization;Taxonomy;Natural languages;Human factors;Human in the loop;Design and human factors;human factors and human-in-the-loop;multi-robot systems},
  doi={10.1109/LRA.2024.3469786},
  ISSN={2377-3766},
  month={Nov},}@INPROCEEDINGS{10487744,
  author={Shekhar, Shashank and Salim, Asif and Jinturkar, Vivaswan and Nayak, Anirudha and Bansode, Adesh},
  booktitle={2023 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)}, 
  title={A PSO Based Method to Generate Actionable Counterfactuals for High Dimensional Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Counterfactual explanations (CFE) are methods that explain a machine learning model by giving an alternate class prediction of a data point with some minimal changes in its features. It helps the users to identify their data attributes that caused an undesirable prediction like a loan or credit card rejection. We describe an efficient, and an actionable counterfactual (CF) generation method based on particle swarm optimization (PSO). We propose a simple objective function for the optimization of instance-centric CF generation problem. The PSO brings in a lot of flexibility in terms of carrying out multi-objective optimization in large dimensions, capability for multiple CF generation, and setting box constraints or immutability of data attributes. An algorithm is proposed that incorporates these features and it enables greater control over the proximity and sparsity properties over the generated CFs. The proposed algorithm is evaluated with a set of action-ability metrics in real-world datasets, and the results were superior compared to that of the state-of-the-arts.},
  keywords={Measurement;Computer science;Machine learning;Predictive models;Linear programming;Data engineering;Credit cards;Expainable AI (XAI);Counterfactual Explanations;Particle Swarm Optimization},
  doi={10.1109/CSDE59766.2023.10487744},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10691196,
  author={Wang, Shiqi and Chen, Yining},
  booktitle={2024 IEEE International Symposium on the Physical and Failure Analysis of Integrated Circuits (IPFA)}, 
  title={Improved Yield Prediction and Failure Analysis in Semiconductor Manufacturing with XGBoost and Shapley Additive exPlanations Models}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={In the domain of semiconductor manufacturing, the accurate prediction of wafer yield and subsequent failure analysis (FA) are of critical importance with respect to the assurance of product quality and the optimization of production processes. However, traditional methods frequently exhibit a high dependency on engineering expertise, modest accuracy, and an inability to adapt swiftly to manufacturing environment changes. To address these issues, this study introduces an advanced machine learning (ML) model that combines Particle Swarm Optimization (PSO) with XGBoost. This innovative approach is adept at capturing the complex non-linear relationships between wafer acceptance test (WAT) data and wafer yield. The integration of PSO enables effective WAT feature selection while fine-tuning the hyperparameters of the XGBoost, thereby resulting in a significant improvement in model performance. The proposed PSO-XGBoost model exhibits remarkable accuracy (96.4%), AUC-score (91.4%), F1-measure (97.9%), precision (97.2%), and recall (98.6%). Moreover, the integration of the Shapley Additive exPlanations (SHAP) method facilitates the interpretability of the model, elucidating the critical WAT parameters that influence yield on both global and local scales. This study not only provides a cost-effective methodology that reduces reliance on human expertise but also paves the way for the expanded role of artificial intelligence (AI) in enhancing semiconductor manufacturing processes. This represents a new era in the field of smart manufacturing and quality assurance.},
  keywords={Semiconductor device modeling;Analytical models;Accuracy;Additives;Failure analysis;Production;Semiconductor device manufacture;Wafer yield prediction;failure analysis;XGBoost;particle swarm optimization;SHAP method},
  doi={10.1109/IPFA61654.2024.10691196},
  ISSN={1946-1550},
  month={July},}@INPROCEEDINGS{10181829,
  author={Bhat, Ashwin and Raychowdhury, Arijit},
  booktitle={2023 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Non-Uniform Interpolation in Integrated Gradients for Low-Latency Explainable-AI}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={There has been a surge in Explainable-AI (XAI) methods that provide insights into the workings of Deep Neural Network (DNN) models. Integrated Gradients (IG) is a popular XAI algorithm that attributes relevance scores to input features commensurate with their contribution to the model's output. However, it requires multiple forward & backward passes through the model. Thus, compared to a single forward-pass inference, there is a significant computational overhead to generate the explanation which hinders real-time XAI. This work addresses the aforementioned issue by accelerating IG with a hardware-aware algorithm optimization. We propose a novel non-uniform interpolation scheme to compute the IG attribution scores which replaces the baseline uniform interpolation. Our algorithm significantly reduces the total interpolation steps required without adversely impacting convergence. Experiments on the ImageNet dataset using a pre-trained InceptionV3 model demonstrate 2.6-3.6×performance speedup on GPU systems for iso-convergence. This includes the minimal 0.2-3.2% latency overhead introduced by the pre-processing stage of computing the non-uniform interpolation step-sizes.},
  keywords={Interpolation;Computational modeling;Graphics processing units;Artificial neural networks;Inference algorithms;Real-time systems;Classification algorithms;Explainable AI (XAI);Deep Neural Networks (DNN);Hardware-Aware Algorithm Design;GPU systems},
  doi={10.1109/ISCAS46773.2023.10181829},
  ISSN={2158-1525},
  month={May},}@INPROCEEDINGS{11044613,
  author={Reska, Daniel and Jurczuk, Krzysztof and Kretowski, Marek},
  booktitle={2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)}, 
  title={Combining GPU and Apache Spark for Evolving Explainable Decision Trees on Large-Scale Data}, 
  year={2025},
  volume={},
  number={},
  pages={194-197},
  abstract={Decision trees (DTs) belong to explainable machine learning techniques applicable for classification and regression problems. Traditionally, DTs are built through a top-down greedy search, which is usually fast but may result in sub-optimal solutions. One of the alternatives is the use of evolutionary algorithms (EAs), allowing for more global exploration that can yield simpler and accurate DTs. However, the EA-based DT induction is computationally expensive, especially for large-scale data. Therefore, different parallel and distributed accelerators are continuously explored to alleviate its high computing requirements. In this paper, we propose a hybrid Spark+GPU supported solution on commodity hardware. The Spark-based component distributes the computations over a cluster, while inside each cluster node, they are further parallelized on a GPU. Experimental validation on various datasets shows that the hybrid solution significantly accelerates the EA-based DT induction and scales well by simply adding more commodity nodes. Moreover, it is much more price-effective than a multi-GPU supported one running on costly HPC servers.},
  keywords={File systems;Scalability;Graphics processing units;Machine learning;Evolutionary computation;Cluster computing;Hardware;Sparks;Servers;Regression tree analysis;evolutionary algorithms;decision tree;Apache Spark;GPGPU;explainable machine learning},
  doi={10.1109/CCGridW65158.2025.00035},
  ISSN={},
  month={May},}@INPROCEEDINGS{10195062,
  author={Arabikhan, Farzad and Gegov, Alexander and Kaymak, Uzay and Akbari, Negar},
  booktitle={2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Fuzzy Networks for Explainable Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={199-200},
  abstract={Advanced machine learning techniques are very powerful in predictive tasks. However, they are mostly weak in explaining the inference process and they are mostly treated as black-box models. Fuzzy Network (FN) is powerful white-box technique which is capable of dealing with complexity and linguistic uncertainty. In this paper, a method is introduced to optimise Rule Based Networks using Fuzzy C-Means (FCM) for rule reduction, Genetic Algorithms to tune the membership functions and Backward Selection to reduce the inputs and network branches. A case study in transport and telecommuting is used to illustrate the performance of the proposed method. The results show the FN ability to explain the internal process of decision making and its capabilities in transparency and interpretability as an Explainable AI method.},
  keywords={Uncertainty;Decision making;Merging;Machine learning;Linguistics;Remote working;Telecommunication network reliability;Fuzzy Rule Based Network;Fuzzy Network Optimization;White-Box Model;Explainable AI},
  doi={10.1109/CAI54212.2023.00094},
  ISSN={},
  month={June},}@INPROCEEDINGS{10409470,
  author={Kopte, Gabriel Anunciação and Lacerda, Marcelo Gomes Pereira de and Neto, Fernando Buarque de Lima},
  booktitle={2023 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={Improving Transferability of Population-Based Learning-to-Optimize Algorithms Through Imitation Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The process of algorithm development is iterative and requires a meticulous evaluation of the existing problem. In recent years, Learning to optimize (L2O) models have transformed this task by using machine learning to generate efficient optimization methods. However, transferring knowledge effectively to problems divergent from the original training context remains a challenge encountered by most L2O approaches. This paper introduces a method that enhances transferability of population-based L2O algorithms through imitation learning. Our method adopts a two-step learning process involving imitation and reinforcement learning to train L2O policies. Experimental results demonstrate that our proposed model, incorporating Particle Swarm optimization (PSO) as the teacher algorithm, outperforms the baseline model in key scenarios. This validates the potential of imitation learning in catalyzing the progress of populations-based L2O models.},
  keywords={Training;Machine learning algorithms;Metaheuristics;Optimization methods;Reinforcement learning;Task analysis;Particle swarm optimization;Population-based optimization;Learn to Optimize (L2O);Meta-learning},
  doi={10.1109/LA-CCI58595.2023.10409470},
  ISSN={2769-7622},
  month={Oct},}@INPROCEEDINGS{10987044,
  author={Zhu, Shibang and Huang, Binhong and He, Zhuo and Yang, Jingqi},
  booktitle={2025 IEEE International Conference on Electronics, Energy Systems and Power Engineering (EESPE)}, 
  title={Crop Planting Optimization Based on Simulated Annealing Algorithm and Genetic Algorithm}, 
  year={2025},
  volume={},
  number={},
  pages={1104-1110},
  abstract={Based on simulated annealing algorithm and genetic algorithm, this study aims to provide an effective planting strategy to improve the efficiency of crop production in a village in the mountainous area. Firstly, a multi-objective optimization model is established for the agricultural production characteristics of this countryside, and the Nondominated Sorting Genetic Algorithm II (NSGA-II) is used for global search and combined with the Simulated Annealing Algorithm for local optimization. Secondly, in order to cope with various uncertainties, this paper introduces genetic algorithm (GA) to simulate the biological evolution process and combines with particle swarm optimization algorithm (PSO) to accelerate the convergence and seek for the planting combination that maximizes the profit. Finally, considering the substitutability and complementarity of crops, the study designed a set of comprehensive optimization models, using Spearman's correlation analysis and Kendall's tau-b correlation analysis, to establish a multi-scenario optimization strategy to adapt to market demand and climate change.},
  keywords={Uncertainty;Correlation;Optimization models;Crops;Simulated annealing;Production;Particle swarm optimization;Optimization;Genetic algorithms;Sorting;Climate change;Simulated annealing;NSGA-II;Simulated Annealing;Genetic Algorithm;Particle Swarm Optimization;Spearman Correlation Analysis},
  doi={10.1109/EESPE63401.2025.10987044},
  ISSN={},
  month={March},}@INPROCEEDINGS{10801000,
  author={Raguraman, P. and Kumaresan, M. and Ramesh, S.},
  booktitle={2024 8th International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={A Comprehensive Survey of AI-Driven Biomedical Image Processing for Intracerebral Hemorrhage Detection and Classification: Current Trends, Challenges, and Future Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1649-1653},
  abstract={Amongst many life-threatening conditions, a fatal condition is the Intracerebral hemorrhage (ICH). It may result in death if not treated immediately and hence necessitates the need for accurate diagnosis for effective treatment. In recent times, concepts of Artificial intelligence (AI), have emerged as a transformative tool in medical image processing, offering faster and more reliable ICH detection and classification. This research study reviews the current advancements in AI-driven biomedical image processing for ICH, exploring various state-of-the-art models involving Convolutional Neural Networks (CNNs), variants of CNN with more efficient feature extraction procedures, Long Short-Term Memory (LSTM) networks, and optimization methods like Genetic Algorithms (GA), Ant Colony Model (ACO), rParticle Swarm Optimization (PSO). Additionally, challenges such as data scarcity, model interpretability, and generalization across diverse populations are discussed. The paper highlights future research directions, including the need for explainable AI, multimodal data integration, and real-time, low-cost AI solutions for resourceconstrained environments. By addressing these challenges, AI has the potential to revolutionize ICH detection and improve patient outcomes globally.},
  keywords={Explainable AI;Computational modeling;Biological system modeling;Data models;Real-time systems;Biomedical image processing;Convolutional neural networks;Hemorrhaging;Long short term memory;Genetic algorithms;Intracerebral Hemorrhage;Artificial Intelligence;MRI;Feature Engineering;Optimization Techniques},
  doi={10.1109/ICECA63461.2024.10801000},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10291869,
  author={Gao, Xiang and Guo, Shuai and Song, Weiqiong},
  booktitle={2023 IEEE 7th Information Technology and Mechatronics Engineering Conference (ITOEC)}, 
  title={Series arc fault detection and identification based on improved residual network by PSO}, 
  year={2023},
  volume={7},
  number={},
  pages={231-236},
  abstract={With the development of industrialization, the requirements for power safety are getting higher and higher. Low voltage series arc fault is the main cause of electrical fire, and it has high concealment because it is directly connected to the circuit and the current is lower than the loop current. Aiming at the problems of difficult feature extraction and poor recognition accuracy in low voltage series arc fault detection and recognition method, this paper proposes a low voltage series arc fault recognition method based on improved residual network. The improvement of the traditional residual network includes the following three aspects : First, the particle swarm optimization ( PSO ) algorithm is used to optimize the residual network, so as to quickly and accurately fit the fault arc characteristic quantity ; secondly, the dual attention network module ( DANET ) is added to the convolutional neural network detection algorithm model. Finally, the RELU activation function of the traditional ResNet network is replaced by the RELU-Softsign activation function to improve the convergence speed of the network and strengthen batch standardization. Through comparative experiments, the results show that the recognition accuracy of the improved residual network is 98 %, and the recognition accuracy and convergence speed are better than other models.},
  keywords={Low voltage;Correlation;Fault detection;Standardization;Predictive models;Mathematical models;Safety;arc fault;residual network;deep learning;convolution attention;particle swarm optimization(PSO) algorithm},
  doi={10.1109/ITOEC57671.2023.10291869},
  ISSN={2693-289X},
  month={Sep.},}@ARTICLE{10684706,
  author={Xia, Zhixin and He, Siyuan and Liu, Changwei and Liu, Yongshan and Yang, Xiaolei and Bu, Huifeng},
  journal={IEEE Access}, 
  title={PSO-GA Hyperparameter Optimized ResNet-BiGRU-Based Intrusion Detection Method}, 
  year={2024},
  volume={12},
  number={},
  pages={135535-135550},
  abstract={Intrusion detection systems (IDS) identify network intrusions by detecting abnormal traffic data, thereby ensuring network security. However, intrusion detection data can vary with changes in the network and attack environment, resulting in poor performance and portability of intrusion detection algorithms. Therefore, an intrusion detection method based on PSO-GA hyperparameter optimized ResNet-BiGRU is proposed. The two-layer bidirectional gated recurrent unit (BiGRU) is connected to the fully connected layer of the residual neural network (ResNet). Firstly, ResNet is used to extract parallel local features, and BiGRU is used to extract long-distance-dependent features from the parallel local features, and the attention mechanism is added after the BIGRU to utilize correlation between the features to assign weights to the extracted features, so as to more comprehensively capture the important features of network intrusion and improve the detection performance. At the same time, the parameters of the basic particle swarm optimization (PSO) are dynamically optimized and combined with the genetic algorithm (GA) to perform a mutation operation when the iterative process falls into a local optimal solution, adding a random perturbation to the current velocity and position of the particles, so that the particles are able to explore new regions in the space in order to jump out of the local optimal solution, and ultimately achieve automatic optimization of the hyperparameters of the ResNet-BiGRU model to achieve a model with better generalization performance. Finally, the proposed method is validated by using the variant NSL-KDD dataset, which achieves an accuracy of 98.46% and average precision, average recall and average False Alarm Rate(FAR) of 91.84%, 95.99% and 0.31%, and achieved high accuracy on three datasets KDD99, UNSW-NB15, and CIC-IDS 2017. The method is proved to have a strong intrusion detection capability by comparison experiments with other algorithms.},
  keywords={Feature extraction;Intrusion detection;Optimization;Deep learning;Accuracy;Convolutional neural networks;Adaptation models;Bidirectional control;Particle swarm optimization;Residual neural networks;Bidirectional gated recurrent unit;intrusion detection;particle swarm optimization algorithm;residual neural network},
  doi={10.1109/ACCESS.2024.3464529},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10958341,
  author={Arukonda, Srinivas and Voddelli, SriLakshmi},
  booktitle={2024 IEEE 21st India Council International Conference (INDICON)}, 
  title={Enhanced Disease Diagnosis Through Adaptive Ensemble Optimization and Hybrid Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Ensemble learning becomes a backbone in disease diagnosis using several classifiers to ensure improved prediction accuracy and also model reliability. However, conventional ensemble techniques often suffer some critical challenges, like poor diversity among base models, less efficient convergence, and sometimes high computational costs. That is why addressing these matters is essential to make further strides in ensemble-based diagnostic frameworks. This study introduces the Adaptive Ensemble Optimization with Hybrid Learning (AE HL) as an Novel Bagging Approach with Teaching-Learning-Based Optimization (BA-TLBO). The AE-HL framework encompasses a new fitness function that uses a new diversity metric with the Hamming distance to optimize both accuracy and classifier diversity effectively. To counteract inefficiencies in convergence, AE-HL uses adaptive optimization strategy that learns to balance exploration and exploitation during the learning phase. A multi-phase An optimization technique is employed, that limits the amount of computation by successively refining the best promising configurations; dynamic bag size adaptations improve the trade-off between variance and bias and, hence generalization over different datasets. Furthermore, the approach is integrated with a lightweight Explainable AI (XAI) module in order to support interpretability without an increase in complexity. The method is tested on several benchmark datasets for disease diagnosis where it is shown that AE-HL outperformed best among several ensemble optimization techniques. In summary, the proposed method obtained the highest accuracy with explainability and diversity in comparison with advanced metrics and statistical analysis. These results confirm the robustness, efficiency, and transparency of the AE-HL as a solution for enhancing systems for disease diagnosis.},
  keywords={Measurement;Accuracy;Explainable AI;Computational modeling;Diversity reception;Medical diagnosis;Hybrid learning;Hamming distances;Ensemble learning;Optimization;Bagging;Computational Efficiency;Differential Evaluation;Disease Diagnosis;Ensemble Learning;Explainable AI;Hamming Distance;Meta-Heuristic Algorithms},
  doi={10.1109/INDICON63790.2024.10958341},
  ISSN={2325-9418},
  month={Dec},}@ARTICLE{10363639,
  author={Almaraashi, Majid and Abdulrahim, Mahmoud and Hagras, Hani},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={A Life-Long Learning XAI Metaheuristic-Based Type-2 Fuzzy System for Solar Radiation Modeling}, 
  year={2024},
  volume={32},
  number={4},
  pages={2102-2115},
  abstract={Solar photovoltaic (PV) power generation is one of the most important sources for renewable energy. However, PV power generation is entirely dependent on the amount of downward solar radiation reaching the solar cells. This is determined by uncertain and uncontrollable meteorological factors such as temperature, humidity, wind speed, and direction, as well as other factors such as topographical characteristics. Good solar radiation prediction models can increase energy output while decreasing the operation costs of PV power generation. For example, in some provinces in China, PV stations are required to upload short-term online power forecast information to power dispatching agencies. Numerous AI, statistical, and numerical weather prediction models have been used in many real-world renewable energy applications, with a focus on modeling accuracy. However, there is a need for explainable AI models that could be easily understood, analyzed, and augmented by the stakeholders. In this article, we present a compact, explainable, and lifelong learning metaheuristic-based interval type-2 fuzzy logic system for solar radiation modeling. The generated model will be composed of a small number of short IF-Then rules that have been optimized via simulated annealing to produce models with high prediction accuracy. These models are updated through a life-long learning approach to maximize their accuracy and maintain interpretability. In the process of lifelong learning, the proposed method transferred the model's knowledge to new geographical locations with minimal forgetting. The proposed method achieved good prediction accuracy and outperformed on new geographical locations other transparent and black-box models by 13.2% as well as maintaining excellent generalization ability. The resulting models have been evaluated and accepted by experts, and thanks to the generated transparency, the experts were able to augment the models with their expertise, which increased the models' accuracy.},
  keywords={Predictive models;Solar radiation;Numerical models;Analytical models;Artificial intelligence;Meteorology;Costs;Explainable AI (XAI);solar energy;type-2 fuzzy systems},
  doi={10.1109/TFUZZ.2023.3343955},
  ISSN={1941-0034},
  month={April},}@INPROCEEDINGS{10894829,
  author={Sanjana, S. and Kiruthika, C. Sri and Kanimozhi, M.},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Biologically Inspired Image Processing Techniques for Improved Resolution in FMRI Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Functional Magnetic Resonance Imaging (fMRI) is a popular neuro-imaging technology that detects brain activity by monitoring blood oxygenation levels. However, fMRI suffers from limitations in temporal resolution due to the slow hemodynamic response, leading to challenges in accurately capturing rapid neural processes. To address this issue, this work proposed the use of Particle Swarm Optimization (PSO) method to enhance temporal resolution in fMRI data analysis. PSO is a nature-inspired optimization algorithm that efficiently explores high-dimensional search spaces to find optimal solutions. This approach refines the temporal resolution by identifying optimal time points and reducing noise, which enhances the interpretability of neural dynamics. Experimental results demonstrate that PSO-based temporal resolution enhancement improves the detection of cognitive and motor-related brain activity compared to conventional methods. This approach provides a significant step forward in fMRI analysis, offering better insights into fast neural events and opening avenues for more accurate brain-computer interfaces and clinical diagnostics.},
  keywords={Neuroimaging;Brain;Data analysis;Refining;Noise;Functional magnetic resonance imaging;Brain-computer interfaces;Hemodynamics;Particle swarm optimization;Optimization;Image Processing;Temporal Resolution;fMRI;Particle Swarm Optimization (PSO)},
  doi={10.1109/ICERCS63125.2024.10894829},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10961720,
  author={Viveka, M. and Priya, N. Shanmuga},
  booktitle={2025 International Conference on Visual Analytics and Data Visualization (ICVADV)}, 
  title={Hybrid Fuzzy Logic-based Explainable Models for Assessing Student Academic Outcomes}, 
  year={2025},
  volume={},
  number={},
  pages={1214-1219},
  abstract={In this study, a unique method for predicting students' grades by combining Fuzzy Logic with Particle Swarm Optimization (PSO) is presented. The Student Performance dataset is employed by the algorithm to forecast the final grade (G3) based on the previous grades (G1, G2). The effectiveness of the proposed system is demonstrated through a comprehensive model evaluation that employs significant metrics, including R-squared, Mean Absolute Error, Root Mean Squared Error, and Mean Squared Error. In contrast to conventional regression methodologies, the hybrid model exhibits superior performance, with MSE values of 0.345, RMSE values of 0.588, MAE values of 0.482, and R2 values of 0.944. These findings indicate that Fuzzy Logic and PSO have the potential to improve regression models that predict the performance of students in the classroom. The proposed method is a reliable for educational data analytics due to its superior predictive accuracy compared to linear regression and other baseline models.},
  keywords={Fuzzy logic;Measurement;Analytical models;Accuracy;Visual analytics;Predictive models;Prediction algorithms;Data models;Reliability;Particle swarm optimization;Student Performance Prediction;Fuzzy Logic;Particle Swarm Optimization;Regression;mutual information-based feature selection},
  doi={10.1109/ICVADV63329.2025.10961720},
  ISSN={},
  month={March},}@INPROCEEDINGS{10017521,
  author={Hakkoum, Hajar and Abnane, Ibtissam and Idri, Ali},
  booktitle={2022 IEEE/ACS 19th International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Evaluating Interpretability of Multilayer Perceptron and Support Vector Machines for Breast Cancer Classification}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The best-performing machine learning (ML) models suffer from a lack of interpretability. This study conducted an empirical evaluation of two interpretability techniques, global surrogate and local interpretable model-agnostic explanations (LIME). Experiments on two black boxes, a multilayer perceptron, and support vector machines were carried out on two breast cancer tabular datasets. The results show that local interpretability can work along the global one to provide insights into the model. Quantitative evaluations show that the global surrogate slightly outperforms LIME. Interpretability techniques have the potential to fix the interpretability trade-off for opaque models.},
  keywords={Support vector machines;Computational modeling;Machine learning;Multilayer perceptrons;Breast cancer;Interpretability;XAI;explainability;black box;LIME;medicine},
  doi={10.1109/AICCSA56895.2022.10017521},
  ISSN={2161-5330},
  month={Dec},}@ARTICLE{10555129,
  author={Prabhushankar, Mohit and AlRegib, Ghassan},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={VOICE: Variance of Induced Contrastive Explanations to Quantify Uncertainty in Neural Network Interpretability}, 
  year={2025},
  volume={19},
  number={1},
  pages={19-31},
  abstract={In this paper, we visualize and quantify the predictive uncertainty of gradient-based post hoc visual explanations for neural networks. Predictive uncertainty refers to the variability in the network predictions under perturbations to the input. Visual post hoc explainability techniques highlight features within an image to justify a network's prediction. We theoretically show that existing evaluation strategies of visual explanatory techniques partially reduce the predictive uncertainty of neural networks. This analysis allows us to construct a plug in approach to visualize and quantify the remaining predictive uncertainty of any gradient-based explanatory technique. We show that every image, network, prediction, and explanatory technique has a unique uncertainty. The proposed uncertainty visualization and quantification yields two key observations. Firstly, oftentimes under incorrect predictions, explanatory techniques are uncertain about the same features that they are attributing the predictions to, thereby reducing the trustworthiness of the explanation. Secondly, objective metrics of an explanation's uncertainty, empirically behave similarly to epistemic uncertainty. We support these observations on two datasets, four explanatory techniques, and six neural network architectures.},
  keywords={Uncertainty;Visualization;Neural networks;Transformers;Perturbation methods;Training;Deep learning;Predictive uncertainty;gradients;contrastive explanations;counterfactual explanations;neural networks;deep learning},
  doi={10.1109/JSTSP.2024.3413536},
  ISSN={1941-0484},
  month={Jan},}@INPROCEEDINGS{10851107,
  author={Boulesnane, Abdennour and Souilah, Abdelhakim},
  booktitle={2024 1st International Conference on Electrical, Computer, Telecommunication and Energy Technologies (ECTE-Tech)}, 
  title={An Evolutionary Large Language Model for Hallucination Mitigation}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The emergence of LLMs, like ChatGPT and Gemini, has marked the modern era of artificial intelligence applications characterized by high-impact applications generating text, images, and videos. However, these models usually ensue with one critical challenge called hallucination: confident presentation of inaccurate or fabricated information. This problem attracts serious concern when these models are applied to specialized domains, including healthcare and law, where the accuracy and preciseness of information are absolute conditions. In this paper, we propose EvoLLMs, an innovative framework inspired by Evolutionary Computation, which automates the generation of high-quality Question-answering (QA) datasets while minimizing hallucinations. EvoLLMs employs genetic algorithms, mimicking evolutionary processes like selection, variation, and mutation, to guide LLMs in generating accurate, contextually relevant question-answer pairs. Comparative analysis shows that EvoLLMs consistently outperforms human-generated datasets in key metrics such as Depth, Relevance, and Coverage, while nearly matching human performance in mitigating hallucinations. These results highlight EvoLLMs as a robust and efficient solution for QA dataset generation, significantly reducing the time and resources required for manual curation.},
  keywords={Measurement;Accuracy;Large language models;Prevention and mitigation;Computational modeling;Medical services;Manuals;Evolutionary computation;Videos;Genetic algorithms;Large Language Model (LLM);Evolutionary Computation;Optimization Problem;Genetic Algorithm;Prompt Engineering;Hallucination},
  doi={10.1109/ECTE-Tech62477.2024.10851107},
  ISSN={},
  month={Dec},}@ARTICLE{10973053,
  author={Rani Palakayala, Anitha and Kuppusamy, P. and Kothandaraman, D. and Archana, Gunakala and Gera, Jaideep},
  journal={IEEE Access}, 
  title={HAMF: A Novel Hierarchical Attention-Based Multi-Modal Fusion Model for Parkinson’s Disease Classification and Severity Prediction}, 
  year={2025},
  volume={13},
  number={},
  pages={81252-81278},
  abstract={Parkinson’s Disease (PD) is a neurodegenerative disorder that requires correct diagnosis and continuous monitoring of the disease severity. The state-of-the-art methods tend to be unimodal or lack robustness in generalizing between modalities, and hence cannot be applied clinically in diverse populations. A comprehensive approach is a multi-modal framework that overcomes these limitations by integration of brain Magnetic Resonance Imaging (MRI) data, gait analysis, and speech signals for enhanced classification and severity estimation of PD. A Hierarchical Attention-based Multi-modal Fusion (HAMF) model is developed in this paper to employ hierarchical attention mechanism at feature and decision levels to help the model learn representations at various levels. This leads to richer feature extraction, besides fusing different data modalities with accurate integration. Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) methods are used in optimizing the model, by which the convergence speed raised by 15–20 %. An accuracy of 94.2 % was achieved, thus improving by 4–5 %, compared to the existing methodologies. Temporal Convolutional Network (TCN) which can capture long-range temporal dependencies, was used in the longitudinal severity estimation task, achieving a Mean Squared Error (MSE) of 0.12 in disease progression forecasting. Beyond this, Domain-Adversarial Neural Network (DANN) enables improved cross-domain generalization and maintains a consistent classification accuracy of 90-93% on diversified datasets. Finally, SHapley Additive exPlanations - Class Activation Maps (SHAP-CAM) further enhanced the model explainability. During the conduct of this work, 85% of all cases provided clinically interpretable insights that allowed clinicians to conduct personalized treatment planning in a more robust and interpretable way. This work substantially extends current multi-modal diagnosis and analysis of PD progression by offering a robust and interpretable tool to clinicians for personalized treatment planning.},
  keywords={Brain modeling;Diseases;Predictive models;Data models;Accuracy;Magnetic resonance imaging;Attention mechanisms;Adaptation models;Genetic algorithms;Data integration;Attention;genetic algorithm;explainable AI;multi-modal data fusion;neurodegeneration;Parkinson’s disease;particle swarm optimization},
  doi={10.1109/ACCESS.2025.3563177},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10957940,
  author={He, Yinghan and Chen, Chao},
  booktitle={2024 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)}, 
  title={Fault Prediction Study of MOSFET Device Based on Optimized Neural Network on Spark Platform}, 
  year={2024},
  volume={},
  number={},
  pages={1400-1405},
  abstract={Accurately predicting the aging failure time of MOSFET (Metal-Oxide-Semiconductor Field-Effect Transistor) devices is of great significance to the health management of electronic components. In order to solve the problems of declining prediction accuracy and long algorithm running time during long-term prediction of MOSFET devices, this paper uses particle swarm optimization (PSO) algorithm to optimize the neural network of bidirectional gated recurrent unit combined with self-attention mechanism, and builds a Spark platform for data processing and parallel computing. The MOSFET thermal aging dataset disclosed by NASA Research Center is used for experiments to compare the model proposed in this paper with other models, and the experiments prove that the algorithm optimized by particle swarm has higher fitting superiority and prediction accuracy, and the relative errors of different prediction starting points are all less than 3%, and the parallel performance study of different cluster nodes is carried out in the Yarn environment, which verifies the advantages of the parallel computing performance of Spark. Parallel computing performance advantage, the method proposed in this paper can realize the long-term prediction of the failure of MOSFET devices with effectiveness.},
  keywords={Semiconductor device modeling;Performance evaluation;MOSFET;Machine learning algorithms;Neural networks;Parallel processing;Predictive models;Prediction algorithms;Sparks;Particle swarm optimization;spark parallel computing;particle swarm optimization algorithm;neural networks;MOSFET devices;aging failure prediction},
  doi={10.1109/ICICML63543.2024.10957940},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11081977,
  author={Li, Xinyue and Zhang, Yu and Hu, Wang and Wang, Renchao},
  booktitle={2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Multitask Genetic Programming Based on Shapley Additive Explanation and Seismic Building Vulnerability Assessment Case}, 
  year={2025},
  volume={},
  number={},
  pages={255-258},
  abstract={In traditional multitask genetic programming (MTGP), expressions for each task are selected independently based on certain criteria from the population. However, valuable knowledge embedded in expressions may be lost by disregarding those with lower accuracy. Inspired by Shapley additive explanation (SHAP) analysis, a SHAP analysis-aided MTGP algorithm, termed SHMTGP, is proposed to integrate valuable knowledge dispersed within the population. Specifically, a SHAP-guided selection method is designed as the core composition of SHMTGP, aiming to extract valuable knowledge from the population of each task. Experimental results on three groups of test functions demonstrate the superiority of SHMTGP over state-of-the-art methods. Additionally, a case study on seismic building vulnerability assessment further evidences the superiority of SHMTGP.},
  keywords={Additives;Accuracy;Scalability;Buildings;Genetic programming;Big Data;Artificial intelligence;symbolic regression;SHAP analysis;multitask genetic programming},
  doi={10.1109/ICAIBD64986.2025.11081977},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{10847359,
  author={Guo, Yali and Wu, Peng and Guo, Haoping},
  booktitle={2024 IEEE 16th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Optimization and Construction of AI Systems Using Artificial Intelligence Technology}, 
  year={2024},
  volume={},
  number={},
  pages={1131-1135},
  abstract={In this article, artificial intelligence technology is applied to optimize the construction of artificial intelligence (AI) system. Traditional artificial intelligence technology has some problems such as data limitation, expert knowledge dependence and lack of interpretability. In view of the above problems, this project intends to use particle swarm optimization (PSO) to process and analyze the data so as to realize intelligent service. The aim of this article is to improve the performance and effect of artificial intelligence system and provide better user experience for users. First of all, how to use genetic algorithm to make automatic decision and optimization, and its application in practice are discussed. On this basis, intelligent algorithms and models are proposed to improve the system performance. On this basis, this project proposes an intelligent autonomous intelligent system based on PSO to achieve the fastest speed of 105 milliseconds per project. The system has the characteristics of high efficiency, high intelligence and high reliability, and can play a better role in different industries.},
  keywords={System performance;Decision making;User experience;Reliability;Security;Artificial intelligence;Particle swarm optimization;Intelligent systems;Optimization;Genetic algorithms;AI System;Particle Swarm Optimization;System Optimization;System Construction},
  doi={10.1109/CICN63059.2024.10847359},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{9867807,
  author={Remman, Sindre Benjamin and Strümke, Inga and Lekkas, Anastasios M.},
  booktitle={2022 American Control Conference (ACC)}, 
  title={Causal versus Marginal Shapley Values for Robotic Lever Manipulation Controlled using Deep Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={2683-2690},
  abstract={We investigate the effect of including application knowledge about a robotic system states’ causal relations when generating explanations of deep neural network policies. To this end, we compare two methods from explainable artificial intelligence, KernelSHAP, and causal SHAP, on a deep neural network trained using deep reinforcement learning on the task of controlling a lever using a robotic manipulator. A primary disadvantage of KernelSHAP is that its explanations represent only the features’ direct effects on a model’s output, not considering the indirect effects a feature can have on the output by affecting other features. Causal SHAP uses a partial causal ordering to alter KernelSHAP’s sampling procedure to incorporate these indirect effects. This partial causal ordering defines the causal relations between the features, and we specify this using application knowledge about the lever control task. We show that enabling an explanation method to account for indirect effects and incorporating some application knowledge can lead to explanations that better agree with human intuition. This is especially favorable for a real-world robotics task, where there is considerable causality at play, and in addition, the required application knowledge is often handily available.},
  keywords={Deep learning;Knowledge engineering;Analytical models;Data analysis;Neural networks;Reinforcement learning;Manipulators;Deep reinforcement learning;robotics;explainable artificial intelligence;Shapley additive explanations;causal SHAP},
  doi={10.23919/ACC53348.2022.9867807},
  ISSN={2378-5861},
  month={June},}@INPROCEEDINGS{10191746,
  author={Morales, Giorgio and Sheppard, John},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Counterfactual Explanations of Neural Network-Generated Response Curves}, 
  year={2023},
  volume={},
  number={},
  pages={01-08},
  abstract={Response curves exhibit the magnitude of the response of a sensitive system to a varying stimulus. However, response of such systems may be sensitive to multiple stimuli (i.e., input features) that are not necessarily independent. As a consequence, the shape of response curves generated for a selected input feature (referred to as “active feature”) might depend on the values of the other input features (referred to as “passive features”). In this work we consider the case of systems whose response is approximated using regression neural networks. We propose to use counterfactual explanations (CFEs) for the identification of the features with the highest relevance on the shape of response curves generated by neural network black boxes. CFEs are generated by a genetic algorithm-based approach that solves a multi-objective optimization problem. In particular, given a response curve generated for an active feature, a CFE finds the minimum combination of passive features that need to be modified to alter the shape of the response curve. We tested our method on a synthetic dataset with 1-D inputs and two crop yield prediction datasets with 2-D inputs. The relevance ranking of features and feature combinations obtained on the synthetic dataset coincided with the analysis of the equation that was used to generate the problem. Results obtained on the yield prediction datasets revealed that the impact on fertilizer responsivity of passive features depends on the terrain characteristics of each field.},
  keywords={Shape;Neural networks;Crops;Training data;Production;Machine learning;Mathematical models;Counterfactual explanations;response curves;deep regression;explainable machine learning},
  doi={10.1109/IJCNN54540.2023.10191746},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10097126,
  author={Mahmood, Usman and Fu, Zening and Calhoun, Vince and Plis, Sergey},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Glacier: Glass-Box Transformer for Interpretable Dynamic Neuroimaging}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Deep learning models can perform as well or better than humans in many tasks, especially vision related. Almost exclusively, these models are used to perform classification or prediction. However, deep learning models are usually of black-box nature, and it is often difficult to interpret the model or the features. The lack of interpretability causes a restrain from applying deep learning to fields such as neuroimaging, where the results must be transparent, and interpretable. Therefore, we present a ’glass-box’ deep learning model and apply it to the field of neuroimaging. Our model mixes spatial and temporal dimensions in succession to estimate dynamic connectivity between the brain’s intrinsic networks. The interpretable connectivity matrices produced by our model result in beating state-of-the-art models on many tasks using multiple functional MRI datasets. More importantly, our model estimates task-based flexible connectivity matrices, unlike static methods such as Pearson’s correlation coefficients.},
  keywords={Neuroimaging;Deep learning;Magnetic resonance imaging;Signal processing;Predictive models;Brain modeling;Transformers;Interpretable DL;neuroimaging;fMRI},
  doi={10.1109/ICASSP49357.2023.10097126},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10411549,
  author={Lin, Mingqian and Shang, Lin and Gao, Xiaoying},
  booktitle={2023 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Enhancing Interpretability in AI-Generated Image Detection with Genetic Programming}, 
  year={2023},
  volume={},
  number={},
  pages={371-378},
  abstract={IGC can produce realistic AI-generated images that challenge human perception. Detecting AI-generated content is critical, which has prompted the technology to tell apart real images from the generated ones. However, the existing methods, such as CNND, LGrad, lack interpretability. Unlike traditional image classification, it is crucial to know why the image can be considered as AI-generated. We introduce a novel AI-generated image detector based on genetic programming (GP), prioritizing both interpretability and classification accuracy. This application of GP in this context emphasizes the need for interpretability in AI-generated content identification. Our GP-based approach not only achieves competitive classification accuracy but also provides transparent decision-making processes, bridging the interpretability gap. This method enhances trust and understanding in the AI-generated image detection process. Through extensive experiments, we highlight the potential of GP-based detectors for this unique task. This research contributes to improving the transparency and reliability of AI-generated image detection, holding implications for computer vision and image forensics. Our work emphasizes the pivotal role of interpretability in distinguishing AI-generated content and offers insights into the inner workings of such models and also achieves a good generation ability.},
  keywords={Image forensics;Decision making;Genetic programming;Detectors;Reliability;Task analysis;Image classification;AI-generated image detection;Genetic Programming;Interpretability;Transparency},
  doi={10.1109/ICDMW60847.2023.00053},
  ISSN={2375-9259},
  month={Dec},}@INPROCEEDINGS{10611751,
  author={Rajwar, Kanchan and Deep, Kusum},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Q-Learning-Driven Framework for High-Dimensional Optimization Problems}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={High-dimensional optimization problems present a significant challenge in various scientific and engineering domains due to their complexity and the exponential increase in the search space. Traditional optimization algorithms often struggle to balance exploration and exploitation efficiently in such settings. To address this challenge, Reinforcement Learning (RL) is integrated with metaheuristic algorithms in this paper. The proposed framework dynamically selects among Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evolution (DE), and Artificial Bee Colony (ABC) algorithms based on their performance history. The RL agent is trained via a Q- Learning algorithm with dynamically allocated rewards to ensure a fair evaluation of the improvements in objective values. It determines the most suitable algorithm to apply in each iteration, adapting its strategy as the optimization progresses. QL-H(GDPA) is evaluated on five widely recognized high-dimensional benchmark functions using statistical analyses such as the Friedman test and the Nemenyi post hoc test. The experimental results demonstrate the superior performance of QL-H(GDPA) over individual algorithms, highlighting its effectiveness in high-dimensional optimization. The adaptive nature of the algorithm selection process allows for more effective navigation through complex solution spaces, particularly in high-dimensional contexts. The study underscores the potential of RL in improving optimization strategies and opens avenues for more intelligent and adaptable optimization frameworks in high-dimensional scenarios.},
  keywords={Statistical analysis;Navigation;Heuristic algorithms;Metaheuristics;Reinforcement learning;Search problems;History;Adaptive Algorithm Selection;Evolutionary Computation Techniques;High-Dimensional Optimization;Hybrid Algorithms;Q-Learning;Reinforcement Learning},
  doi={10.1109/CEC60901.2024.10611751},
  ISSN={},
  month={June},}@ARTICLE{10538270,
  author={Chadaga, Krishnaraj and Prabhu, Srikanth and Sampathila, Niranjana and Chadaga, Rajagopala and Umakanth, Shashikiran},
  journal={IEEE Access}, 
  title={An Explainable Decision Support Framework for Differential Diagnosis Between Mild COVID-19 and Other Similar Influenzas}, 
  year={2024},
  volume={12},
  number={},
  pages={75010-75033},
  abstract={It is tough to clinically differentiate between mild COVID-19 and other similar influenzas due to their comparable transmission traits and symptoms. The Real-time reverse transcriptase-polymerase chain reaction (RT-PCR) test is utilized regularly to diagnose severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) despite being prone to false-negative results. In recent years, intelligent support systems have been developed for patient triage and disease diagnosis. Thus, this research utilizes machine learning to diagnose COVID-19 from routine biomarkers. Twelve feature selection techniques, which include nature-inspired techniques, have been compared to extract the essential features. Multiple classifiers, including stacking, voting and deep learning, are trained to predict the patient diagnosis. The maximum accuracy obtained by the classifiers was 95% in this retrospective study. The diagnostic predictions were further interpreted using five explainable artificial intelligence methods. Biomarkers such as albumin, protein, eosinophil and total white blood cells were crucial. Thus, automated diagnostic systems can be supportive in the accurate and timely detection of COVID-19 and similar influenza infections.},
  keywords={COVID-19;Machine learning;Influenza;Blood;Feature extraction;Machine learning algorithms;Biomarkers;Explainable AI;Bio-inspired computing;Algorithm design and analysis;Biomarkers;explainable artificial intelligence;Mild COVID-19;nature-inspired algorithms;non-COVID-19 influenza},
  doi={10.1109/ACCESS.2024.3405071},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10730587,
  author={Naka, Edjola},
  booktitle={2024 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={A Feature Importance Method based on Cosine Similarity and Metaheuristic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={18-23},
  abstract={Currently, there is a frequent generation of high-dimensional data in various domains. This study aims to present a novel way of lowering the number of features in datasets with large dimensionality, and not only. The analysis suggests a two-stage approach for selecting the most relevant features. Firstly, it will use cosine similarity in a pre-processing step to identify the most significant features ranking them according to the most important ones. Next, a hybrid metaheuristic, a combination of binary Volleyball Premier League and Antlion optimizer will be employed to reselect the most significant features detected in the initial phase. Various extracted features are utilized on selected datasets of Parkinson Disease to compare their results with the scenario when the hybrid metaheuristic employs all the features. The findings demonstrated notable advantages in terms of decreasing the time required for execution, with improvements ranging from 40.37% to a maximum of 91.57%. Additionally, there was a reduction in the number of features by 9.28% to 73.85%, while impacting the accuracy by a maximum of 4.47% in approximately 80% of the datasets.},
  keywords={Accuracy;Metaheuristics;Predictive models;Feature extraction;Distance measurement;Complexity theory;Artificial intelligence;Diseases;cosine similarity;feature importance;hybrid metaheuristic;feature selection;high-dimensional dataset},
  doi={10.1109/IICAIET62352.2024.10730587},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10356434,
  author={Duell, Jamie and Seisenberger, Monika and Zhong, Tianlong and Fu, Hsuan and Fan, Xiuyi},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={A Formal Introduction to Batch-Integrated Gradients for Temporal Explanations}, 
  year={2023},
  volume={},
  number={},
  pages={452-459},
  abstract={eXplainable Artificial Intelligence (XAI) is at the forefront of Artificial Intelligence research. Little attention, however, has been paid to the development of XAI methods for temporal data. Current state-of-the-art methods treat instances as independent and do not utilise the time dimension. Critical fields such as Healthcare and Finance often take a temporal form, leaving a prominent gap in XAI research. To this end, we propose the utilisation and optimisation of path based methods to use the temporal nature of data for explanations. In this work we (1) Extrapolate on a new technique for explainability forming a formal introduction, based on Integrated Gradients, a technique not designed for temporal data, (2) introduce new properties for time-based explainers and give an overview of the state-of-the-art methods and their adherence to these properties, (3) provide a theoretical and empirical analysis of path based methods, (4) demonstrate explanations on real world case studies. From this, we identify the proposed method best adheres to both the proposed properties and existing properties. Similarly, we demonstrate how the introduced method outperforms state-of the-art methods in the demonstrated areas},
  keywords={Interpolation;Finance;Production;Medical services;Computational efficiency;Artificial intelligence;Optimization;Explainability;Interpretability;Temporal;Integrated Gradients},
  doi={10.1109/ICTAI59109.2023.00072},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10925776,
  author={Kumar, Sanjay and Kharkwal, Harendra Singh and Verma, Atul and Singh, Amit Kumar and Srivastava, Meenakhi},
  booktitle={2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM)}, 
  title={Hybrid TFT-GRU Time Series Models Optimized by PSO: An Advanced Approach for Financial Data Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Accurate financial time series prediction is a key challenge in modern quantitative finance, directly influencing decision-making and strategy development. In reply to this challenge, researchers recommend an innovative hybrid model that cartels the strengths of the Temporal Fusion Transformer (TFT) and Gated Recurrent Unit (GRU) models for financial data prediction. The TFT is created for interpretable multi-horizon forecasting and can capture both short- and long-term relationships in time series data, while GRU excels in efficiently handling sequential data with lower computational complexity associated to more traditional recurrent models like LSTMs. This hybrid method influences the unique advantages of both TFT and GRU to build a more robust and flexible predictive model.To advance the precision and efficiency of the hybrid TFT-GRU model, we employ Particle Swarm Optimization (PSO) for hyperparameter tuning. PSO, a nature-inspired optimization algorithm, is used to optimize key parameters such as learning rate and batch size, which directly impact the performance of the model. The PSO algorithm efficiently searches the hyperparameter space by simulating the social behavior of particles in a swarm, leading to faster convergence on optimal solutions. This integration of PSO ensures that the hybrid model is both highly accurate and computationally efficient.The TFT-GRU-PSO hybrid model is tested on actual financial data, which includes datasets of stock prices. Experimental findings demonstrate that our model surpasses conventional approaches in terms of forecasting accuracy, as evaluated by Mean Squared Error (MSE), Mean Absolute Error (MAE), and consistency in prediction. This research introduces an advanced approach to financial time series forecasting, demonstrating that hybrid deep learning models combined with optimization techniques like PSO provide a powerful tool for improving prediction in volatile and complex financial markets.},
  keywords={Accuracy;Computational modeling;Time series analysis;Predictive models;Prediction algorithms;Data models;Thin film transistors;Forecasting;Particle swarm optimization;Optimization;Financial time series prediction;Hybrid model;Temporal Fusion Transformer (TFT);Gated Recurrent Unit (GRU);Particle Swarm Optimization (PSO);Prediction accuracy},
  doi={10.1109/IIPEM62726.2024.10925776},
  ISSN={},
  month={Nov},}@ARTICLE{10065588,
  author={Zhang, Fangfang and Mei, Yi and Nguyen, Su and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Survey on Genetic Programming and Machine Learning Techniques for Heuristic Design in Job Shop Scheduling}, 
  year={2024},
  volume={28},
  number={1},
  pages={147-167},
  abstract={Job shop scheduling (JSS) is a process of optimizing the use of limited resources to improve the production efficiency. JSS has a wide range of applications, such as order picking in the warehouse and vaccine delivery scheduling under a pandemic. In real-world applications, the production environment is often complex due to dynamic events, such as job arrivals over time and machine breakdown. Scheduling heuristics, e.g., dispatching rules, have been popularly used to prioritize the candidates such as machines in manufacturing to make good schedules efficiently. Genetic programming (GP), has shown its superiority in learning scheduling heuristics for JSS automatically due to its flexible representation. This survey first provides comprehensive discussions of recent designs of GP algorithms on different types of JSS. In addition, we notice that in the recent years, a range of machine learning techniques, such as feature selection and multitask learning, have been adapted to improve the effectiveness and efficiency of scheduling heuristic design with GP. However, there is no survey to discuss the strengths and weaknesses of these recent approaches. To fill this gap, this article provides a comprehensive survey on GP and machine learning techniques on automatic scheduling heuristic design for JSS. In addition, current issues and challenges are discussed to identify promising areas for automatic scheduling heuristic design in the future.},
  keywords={Job shop scheduling;Machine learning;Dynamic scheduling;Sequential analysis;Genetic programming;Schedules;Automatic learning;genetic programming (GP);job shop scheduling (JSS);machine learning;scheduling heuristics},
  doi={10.1109/TEVC.2023.3255246},
  ISSN={1941-0026},
  month={Feb},}@INPROCEEDINGS{10770725,
  author={Chartcharnchai, Puttisan and Jewajinda, Yutana and Praditwong, Kata},
  booktitle={2024 28th International Computer Science and Engineering Conference (ICSEC)}, 
  title={A Categorical Particle Swarm Optimization for Hyperparameter Optimization in Low-Resource Transformer-based Machine Translation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a categorical particle swarm optimization (PSO) for hyperparameter optimization of the Transformer-based neural machine translation for low-resource training. The proposed PSO is a set-based PSO representing particles as probability distributions rather than solution values. The experiments on two datasets under various low-resource conditions on the standard dataset of German-English and Thai-English translations validate the proposed PSO. Empirical results demonstrate that our proposed PSO algorithm converges to near optimum solutions and improves the translation quality over the non-optimized Transformer models and manually optimized models under low-resource training.},
  keywords={Training;Computer science;Neural machine translation;Transformers;Hyperparameter optimization;Vectors;Probability distribution;Particle swarm optimization;Standards;Optimization;Neural machine translation;Transformer;Particle swarm optimization;hyperparameter optimization},
  doi={10.1109/ICSEC62781.2024.10770725},
  ISSN={2768-0592},
  month={Nov},}@INPROCEEDINGS{10911244,
  author={Sadhana, U and Singh, Tripty and M, Beena. B.},
  booktitle={2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE)}, 
  title={Swarm-Optimized Deep Convolutional Networks for Precise Detection and Grading of Diabetic Retinopathy}, 
  year={2024},
  volume={},
  number={},
  pages={663-667},
  abstract={Diabetic Retinopathy (DR) is a very critical problem of diabetes that can lead to blindness if not detected and treated in the early stage. This research was conducted on this difficult disease based on image processing and Machine intelligence. In this research, our model detects and classifies the DR using the swarm-optimized deep convolutional networks. The proposed model integrated the convolutional neural networks (CNNs) along with Particle Swarm Optimization (PSO) to enrich the performance of the model execution and results with fine-tuned hyperparameters. This custom-optimized CNN model, designed for image classification, was evaluated on the Kaggle diabetic retinopathy dataset. The swarm-optimized deep CNN model presented balanced performance across all DR classes and achieved a precision of 0.93, recall of 0.97, and F1-score of 0.95 for all classes. The model's overall accuracy reached 0.84 on the selected dataset.},
  keywords={Diabetic retinopathy;Accuracy;Machine learning;Retina;Robustness;Real-time systems;Convolutional neural networks;Particle swarm optimization;Machine intelligence;Image classification;Diabetic Retinopathy;CNN;Particle Swarm Optimization;Machine Learning},
  doi={10.1109/AECE62803.2024.10911244},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10363793,
  author={Lin, Songlu and Yang, Meicheng and Wang, Yuzhe and Wang, Zhihong},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={An Explainable AI Predictor to Improve Clinical Prognosis for Acute Respiratory Distress Syndrome}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={Acute Respiratory Distress Syndrome (ARDS) is a severe respiratory disorder characterized by the failure of the lungs and often associated with elevated death rates. Providing an accurate clinical prognosis for ARDS patients is complex due to the myriad clinical variables involved. In this study, we introduce an Explainable AI Predictor designed to improve the accuracy of prognostic predictions for ARDS. -This work outlines a solution to the challenge of short-term ARDS diagnosis, utilizing an algorithm that leverages a multi-feature fusion approach based on XGBoost learning and Optuna. The proposed algorithm enables ARDS status prediction within a critical 48-hour window, which is vitally important for life-saving interventions in clinical settings. Furthermore, ‐‐ the proposed algorithm incorporates features that enhance interpretability, assisting medical professionals in diagnosis and treatment planning. Experimental results substantiate the efficacy of our proposed method, with the algorithm achieving an overall micro-AUC of 0.832 when applied to the test set. This performance metric underscores the accuracy and predictive strength of our approach. The encouraging results emphasize the algorithm's potential to facilitate healthcare professionals in making timely and precise decisions in managing ARDS.},
  keywords={Acute respiratory distress syndrome;Measurement;Decision making;Lung;Prediction algorithms;Planning;Clinical diagnosis},
  doi={10.22489/CinC.2023.003},
  ISSN={2325-887X},
  month={Oct},}@INPROCEEDINGS{10971687,
  author={AbdelRaouf, Hussien and Abouyoussef, Mahmoud and Fouda, Mostafa M. and Fadlullah, Zubair Md and Ibrahem, Mohamed I.},
  booktitle={SoutheastCon 2025}, 
  title={Emerging Trends in AI-Powered IoT: Innovations, Key Challenges, and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={556-562},
  abstract={This survey provides a comprehensive overview of recent emerging technologies in artificial intelligence (AI) applied to the Internet of Things (IoT), highlighting their significance and applications across various domains. Our study covers key advancements, including Concept Drift, Transformers, TinyML, Explainable AI (XAI), and Federated Learning (FL). Concept Drift addresses changes in data patterns to maintain the accuracy of machine learning models in dynamic environments. Transformers revolutionize Natural language processing (NLP) by efficiently capturing long-range dependencies. TinyML enables smart IoT applications on low-power devices, while XAI promotes transparency in AI decisions. FL facilitates decentralized model training while preserving data privacy. Our discussion also covers challenges, limitations, and future research directions to improve AI and IoT integration.},
  keywords={Surveys;Data privacy;Explainable AI;Tiny machine learning;Concept drift;Transformers;Natural language processing;Data models;Internet of Things;Artificial intelligence;Internet-of-Things;Artificial Intelligence;AI Applications},
  doi={10.1109/SoutheastCon56624.2025.10971687},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10887524,
  author={Faryabi, Sadegh and Afzali, Mahboubeh and Naji, Hamid Reza},
  booktitle={2024 19th Iranian Conference on Intelligent Systems (ICIS)}, 
  title={Optimizing Intrusion Detection with a Dual-Archive Approach Using DAPS-XG}, 
  year={2024},
  volume={},
  number={},
  pages={194-198},
  abstract={Intrusion Detection Systems are essential for protecting industrial networks, critical infrastructure, and corporate environments against deliberate cyber-attacks. Nevertheless, a notable obstacle in contemporary intrusion detection systems is the need to handle extensive, multi-dimensional data effectively while ensuring good detection precision and efficient processing. This paper presents DAPS-XG, a sophisticated intrusion detection model that combines Multi-Objective Particle Swarm Optimization for selecting features with XGBoost for categorization. A prominent characteristic of DAPS-XG is its dual-archive Multi-Objective Particle Swarm Optimization system, which integrates two separate archives: a convergence archive, aimed at optimizing classification accuracy, and a diversity archive, intended to investigate a broad spectrum of feature subsets. This dual-archive system effectively optimizes the trade-off between improving detection performance and minimizing computing complexity. The model underwent evaluation using the NSL-KDD dataset, which is a known benchmark in the field of intrusion detection research. The DAPS-XG algorithm effectively decreased the dimensionality of the dataset from 41 to 18 essential features, resulting in a remarkable F1 score of 99.55%. The model is especially suitable for real-time intrusion detection in industrial settings, where high-speed and precise analysis of substantial amounts of network traffic data is crucial. Through the substantial reduction of processing requirements, while maintaining detection accuracy, DAPS-XG provides a very efficient solution for enhancing IDS performance in intricate, data-intensive settings, rendering it extremely applicable to modern cybersecurity applications.},
  keywords={Accuracy;Computational modeling;Scalability;Intrusion detection;Telecommunication traffic;NSL-KDD;Feature extraction;Real-time systems;Particle swarm optimization;Convergence;Intrusion Detection Systems;Multi-Objective Particle Swarm Optimization;XGBoost;Feature Selection;Dual-Archive System;Real-Time Detection},
  doi={10.1109/ICIS64839.2024.10887524},
  ISSN={},
  month={Oct},}@ARTICLE{10293159,
  author={Aljuhani, Ahamed and Alamri, Abdulelah and Kumar, Prabhat and Jolfaei, Alireza},
  journal={IEEE Internet of Things Journal}, 
  title={An Intelligent and Explainable SaaS-Based Intrusion Detection System for Resource-Constrained IoMT}, 
  year={2024},
  volume={11},
  number={15},
  pages={25454-25463},
  abstract={The Internet of Medical Things (IoMT) has revolutionized healthcare, but its vulnerabilities demand robust security solutions, especially for resource-constrained devices. In this research, we introduce an innovative Software-as-a-Service (SaaS)-based intrusion detection system (IDS) designed specifically for the unique challenges of IoMT, deploying at the edge for enhanced efficiency. Our proposed IDS incorporates a multifaceted approach: first, it leverages the particle swarm optimization (PSO) algorithm for feature engineering, optimizing data representation to reduce computational overhead on resource-constrained devices. Second, a diverse ensemble of machine learning and deep learning models is employed to detect a wide array of intrusion attempts within IoMT networks. Third, interpretation is achieved using Shapley additive explanations (SHAPs), providing transparency and understanding of the decision-making process. By combining intelligence, efficiency, explainability, and deploying as a SaaS solution at the network edge, our IDS not only improves the security of resource-constrained IoMT devices but also empowers healthcare professionals with actionable insights, ensuring patient data privacy and network integrity in this dynamic and critical domain. Finally, the results using a publicly available healthcare data set, namely, WUSTL-EHMS-2020 proves the effectiveness of the proposed IDS over some recent state-of-the-art works.},
  keywords={Medical services;Security;Cyberattack;Servers;Image edge detection;Intrusion detection;Deep learning;Explainable artificial intelligence (AI);Internet of Medical Things (IoMT);intrusion detection system (IDS);particle swarm optimization (PSO);Software as a Service (SaaS)},
  doi={10.1109/JIOT.2023.3327024},
  ISSN={2327-4662},
  month={Aug},}@ARTICLE{10402009,
  author={Elsharkawy, Mohamed and Sharafeldeen, Ahmed and Khalifa, Fahmi and Soliman, Ahmed and Elnakib, Ahmed and Ghazal, Mohammed and Sewelam, Ashraf and Thanos, Aristomenis and Sandhu, Harpal S. and El-Baz, Ayman},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Clinically Explainable AI-Based Grading System for Age-Related Macular Degeneration Using Optical Coherence Tomography}, 
  year={2024},
  volume={28},
  number={4},
  pages={2079-2090},
  abstract={We propose an automated, explainable artificial intelligence (xAI) system for age-related macular degeneration (AMD) diagnosis. Mimicking the physician's perceptions, the proposed xAI system is capable of deriving clinically meaningful features from optical coherence tomography (OCT) B-scan images to differentiate between a normal retina, different grades of AMD (early, intermediate, geographic atrophy (GA), inactive wet or active neovascular disease [exudative or wet AMD]), and non-AMD diseases. Particularly, we extract retinal OCT-based clinical imaging markers that are correlated with the progression of AMD, which include: (i) subretinal tissue, sub-retinal pigment epithelial tissue, intraretinal fluid, subretinal fluid, and choroidal hypertransmission detection using a DeepLabV3+ network; (ii) detection of merged retina layers using a novel convolutional neural network model; (iii) drusen detection based on 2D curvature analysis; (iv) estimation of retinal layers' thickness, and first-order and higher-order reflectivity features. Those clinical features are used to grade a retinal OCT in a hierarchical decision tree process. The first step looks for severe disruption of retinal layers' indicative of advanced AMD. These cases are analyzed further to diagnose GA, inactive wet AMD, active wet AMD, and non-AMD diseases. Less severe cases are analyzed using a different pipeline to identify OCT with AMD-specific pathology, which is graded as intermediate-stage or early-stage AMD. The remainder is classified as either being a normal retina or having other non-AMD pathology. The proposed system in the multi-way classification task, evaluated on 1285 OCT images, achieved 90.82% accuracy. These promising results demonstrated the capability to automatically distinguish between normal eyes and all AMD grades in addition to non-AMD diseases.},
  keywords={Retina;Feature extraction;Convolutional neural networks;Macular degeneration;Explainable AI;Optical coherence tomography;Eye diseases;OCT;AMD;CNN;DeepLabV3+;Dry AMD;Wet AMD},
  doi={10.1109/JBHI.2024.3355329},
  ISSN={2168-2208},
  month={April},}@INPROCEEDINGS{11004741,
  author={S J, Ramanan and R, Akshaya and S R, Janet Inba and T S, Ajai Krishna and I, Krithivarsha and D, Shiloah Elizabeth},
  booktitle={2025 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={EMOTICON: Real-Time Video Feed Emotion Detection Enhanced by Particle Swarm Optimization and GRAD-CAM Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={937-944},
  abstract={In recent years, facial expression-based emotion recognition has attracted a lot of interest, especially for real-time applications in fields like healthcare, security, and human-computer interaction. Image processing plays a critical role in a wide range of applications, offering enhanced capabilities for data analysis and feature extraction across various domains. A significant aspect of this project is emotion detection, where image processing techniques are applied to recognize and classify human emotions from facial expressions. To enhance accuracy and interpretability, we introduce EMOTICON, a novel method for real-time emotion recognition from video feeds that combines Grad-CAM (Gradient-weighted Class Activation Mapping), Particle Swarm Optimization (PSO), and Convolutional Neural Networks (CNN). The objective is to enhance both the accuracy and interpretability of emotion recognition systems. To achieve this, we suggest comparing three distinct emotion detection configurations: (1) CNN-based emotion detection, (2) CNN and PSO for optimization, and (3) CNN integrated with Grad-CAM and PSO for enhanced performance and visual representation of the identified features. In order to improve the model's efficiency and capacity for generalization, PSO optimizes the model's parameters while CNN extracts feature maps from facial images during the training phase. By systematically exploring and applying these techniques, the project provides valuable insights into the multifaceted nature of image processing and its transformative potential in contemporary technological applications. Our tests demonstrate that CNN, PSO, and Grad-CAM collectively contribute to enhanced accuracy, which improves performance and provides interpretable insights about the model's decision-making process. The comparative analysis's findings show how effective it is to incorporate interpretability and optimization strategies into emotion detection systems.},
  keywords={Emotion recognition;Visualization;Accuracy;Streaming media;Feature extraction;Real-time systems;Convolutional neural networks;Feeds;Particle swarm optimization;Optimization;Emotion Detection;Real-Time Video Feed;Convolutional Neural Networks (CNN);Particle Swarm Optimization (PSO);Grad-CAM;Probabilistic Emotion Classification},
  doi={10.1109/ICICT64420.2025.11004741},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10830735,
  author={Van Sy, Ha and Lien, Pham Thi Mai},
  booktitle={2024 International Conference on Platform Technology and Service (PlatCon)}, 
  title={Study of AI Development and Evaluation of New Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={139-148},
  abstract={Artificial intelligence (AI) has advanced significantly in recent years, paving the way for a new era of limitless innovation. This analysis examines the changing landscape of AI developments and delves into the unique strategies that have shaped the field. Beginning with the fundamentals of AI, including classical machine learning and data-driven approaches, the review will go into fundamental AI techniques such as reinforcement learning, generative adversarial networks, transfer learning, and neuroevolution. This study emphasizes the necessity of artificial intelligence, particularly explainability (XAI). Furthermore, the paper dives into the interface of quantum computing and AI, ad-dressing the potential revolutionary effects of quantum technology on AI advancement while emphasizing the hurdles associated with integrating these two domains. AI consideration challenges, such as prejudice, fairness, transparency, and legal frameworks, are being addressed to increase understanding of the fast-growing AI area. Reinforcement learning, generative adversarial networks, and transfer learning are at the forefront of AI research, with substantial advances in transparency. Although neuroevolution and quantum AI have not received much attention, they have enormous promise for future growth.},
  keywords={Ethics;Technological innovation;Explainable AI;Computational modeling;Transfer learning;Reinforcement learning;Transforms;Generative adversarial networks;Complexity theory;Artificial intelligence;Artificial intelligence (AI);consideration challenges;explainable AI (XAI);examination framework;potential revolutionary},
  doi={10.1109/PlatCon63925.2024.10830735},
  ISSN={2766-4198},
  month={Aug},}@INPROCEEDINGS{11077551,
  author={Coffie, Lord and Kim, Jongyeop and Chen, Lei},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Deep Learning for Lung Cancer Prediction: Performance & Explainability Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={354-360},
  abstract={Globally, lung cancer continues to be among the common causes of cancer death; therefore, the importance of early patient survival increases in its detection. This study examines how deep learning can predict lung cancer using structured clinical and lifestyle survey data. A comparison was made between a multi-layer perceptron (MLP) and the random forest, XGBoost, and support vector machine (SVM) methods, as well as logistic regression machine learning models. The results demonstrate that ensemble-based models (Random Forest & XGBoost) outperformed the deep learning model, achieving an accuracy of 99.7 % compared to MLP's 94.7 %. We employed SHAP and LIME explainability techniques to improve model interpretability, identifying allergy, swallowing diffculty, and coughing as the most significant predictors of lung cancer. These results show how important it is to make AI-based medical predictions more interpretable in order to increase their use in clinical settings. While deep learning performed well, traditional machine learning models proved to be more effective for structured survey-based datasets. The study shows that machine learning could be useful for screening for lung cancer. It also stresses the need for more research on data augmentation biases, external validation on real-world clinical datasets, and advanced deep learning architectures to make the models more accurate.},
  keywords={Deep learning;Support vector machines;Surveys;Logistic regression;Accuracy;Atmospheric modeling;Lung cancer;Predictive models;Random forests;Allergies;Lung Cancer Prediction;Deep Learning;Machine Learning;Explainability},
  doi={10.1109/AIRC64931.2025.11077551},
  ISSN={},
  month={May},}@INPROCEEDINGS{10099498,
  author={Sun, Jiayi and Guo, Wenming},
  booktitle={2023 IEEE International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Time Series Prediction Based on Time Attention Mechanism and LSTM Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={As a collection of time observations, time series has attracted extensive attention in artificial intelligence. Time series prediction is one of the important topics to obtain future trends. Therefore, based on the discussion of time series characteristics, temporal attention mechanism and deep learning time series prediction, this paper briefly discusses the open data set, experimental environment and parameter settings, and designs an improved time series PA-LSTM prediction model based on deep learning. Finally, through specific experimental analysis. The results show that the RMSLE and MAE values of the PA-LSTM prediction method designed in this paper are 0.012 and 0.010 respectively. The error is lower than other prediction methods. Therefore, the PA-LSTM prediction method has certain advantages.},
  keywords={Deep learning;Time series analysis;Neural networks;Predictive models;Prediction algorithms;Market research;Data models;deep learning;time series;temporal attention mechanism;neural network},
  doi={10.1109/ICICACS57338.2023.10099498},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10253970,
  author={Shi, Gaofeng and Zhang, Fangfang and Mei, Yi},
  booktitle={2023 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Interpretability-Aware Multi-Objective Genetic Programming for Scheduling Heuristics Learning in Dynamic Flexible Job Shop Scheduling}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Dynamic flexible job shop scheduling (DFJSS) is a critical and challenging combinatorial optimisation problem. Genetic programming (GP) has been widely used to learn scheduling heuristics for DFJSS automatically. Ideally, we prefer to have effective and small scheduling heuristics which tend to be easy to be interpreted. However, the effectiveness and the sizes of scheduling heuristics are conflicting, and reducing the rule sizes tends to worsen the effectiveness of scheduling heuristics. This is a typical multi-objective optimisation problem. However, the existing studies in multi-objective DFJSS consider the effectiveness-related objectives only such as minimising max-flowtime and mean-flowtime rather than interpretability-related objectives such as rule size. To fill this gap, this paper aims to propose an interpretability-aware multi-objective GP to learn a well-distributed Pareto-front of scheduling heuristics for DFJSS. This paper first adopts a multi-objective GP algorithm with α-dominance and archive from a routing problem to DFJSS. Then, we propose to use traditional dominance relation based Pareto front for α and archive updating and an objective normalisation based α-dominance sorting strategy to further improve the performance of the adopted multi-objective GP. The results show that the proposed algorithm can obtain significantly better performance than the state-of-the-art multi-objective GP algorithms in different DFJSS scenarios.},
  keywords={Job shop scheduling;Processor scheduling;Heuristic algorithms;Genetic programming;Evolutionary computation;Dynamic scheduling;Routing;Scheduling heuristics learning;Multi-objective genetic programming;α-dominance;Job shop scheduling},
  doi={10.1109/CEC53210.2023.10253970},
  ISSN={},
  month={July},}@INPROCEEDINGS{10413582,
  author={Das, Protiva and Mitra, Sowmen and Chakraborty, Sovon and Mehedi, Md. Humaion Kabir and Adib, Muhammed Yaseen Morshed and Rasel, Annajiat Alim},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={CNN-GRU Based Fusion Architecture For Bengali License Plate Recognition With Explainable AI}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Because of recent improvements to Bangladesh’s roads and highways, Automatic Number Plate Recognition (ALPR) has become a crucial component. Numerous crimes, including kidnapping, failure to pay tolls, and harassment of women, occur on both public and private transportation. The security forces will be able to locate offenders more quickly with the earlier and more accurate detection of license plates. The authors of this research proposing a deep learning-based fusion model for ALPR that integrates CNN and GRU on the basis of these circumstances. A total of 4753 images from various Bangladeshi roads and highways have been collected for training, validation, and testing purposes. The dataset consists of three classes of data namely Private cars, Public buses, and Trucks where all the images are in RGB format. To get precise and reliable findings, a variety of preprocessing approaches have been applied. After passing the images to the proposed architecture all the necessary parameters have been fine-tuned that causes a lesser amount of trainable parameters and more accuracy. The research demonstrates that the suggested CNN-GRU based fusion architecture, with a 98.97% F1-score, outperforms the leading models. Both static photos and CCTV video material can be used to accomplish ALPR tasks with comparable efficiency. Later, Explainable Artificial Intelligence (XAI) model SHAP has been used in order to interpret the outstanding result with a region of features.},
  keywords={Training;Roads;Transportation;Computer architecture;Task analysis;License plate recognition;Testing;ALPR;fusion;CNN;GRU;SHAP;license-plate;recognition},
  doi={10.1109/ICCCNT56998.2023.10413582},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{10963409,
  author={Maulana, Denny and Roestam, Rusdianto and Ghofir, Abdul},
  booktitle={2024 7th International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)}, 
  title={Combining XGBoost with Particle Swarm Optimization to Improve Phishing Detection}, 
  year={2024},
  volume={},
  number={},
  pages={959-964},
  abstract={An improved phishing detection system, an important tool in cyber security, can help reduce the occurrence of phishing cyber-crimes. Existing phishing detection tools such as machine learning models have shown its capability in detecting phishing attempts, but still face some limitations in detection accuracy due to suboptimal hyperparameters. One of the existing powerful high performance and scalability classification model, such as XGBoost shows great result in phishing detection. By optimizing the hyperparameters using PSO, this paper exploits it to further increase the detection accuracy of the XGBoost model. The result of the proposed method XGBoost-PSO model is compared with the original XGBoost model created based on previous research. The proposed method shows that it is able to improve the detection accuracy from 97.53% to 97.67%, recall increases from 93.31% to 98.84%, and the F1-score improves from 97.8% to 97.93%, making the XGBoost-PSO model more effective at minimizing false negatives and false positives. Although precision slightly decreases from 97.3% to 97.03%, the overall improvement in the F1-score demonstrates the effectiveness of hyperparameter optimization in phishing detection.},
  keywords={Seminars;Accuracy;Phishing;Scalability;Hyperparameter optimization;Particle swarm optimization;Computer crime;Intelligent systems;Information technology;Faces;Phishing Detection;XGBoost;Particle Swarm Optimization (PSO);Hyperparameter Optimization;Cybersecurity},
  doi={10.1109/ISRITI64779.2024.10963409},
  ISSN={2832-1456},
  month={Dec},}@ARTICLE{10798436,
  author={Amjad, Ammar and Tai, Li-Chia and Chang, Hsien-Tsung},
  journal={IEEE Access}, 
  title={Utilizing Enhanced Particle Swarm Optimization for Feature Selection in Gender-Emotion Detection From English Speech Signals}, 
  year={2024},
  volume={12},
  number={},
  pages={189564-189573},
  abstract={Speech emotion recognition (SER) plays a vital role in various applications, enabling machines to decode and analyze emotions conveyed through speech. This study introduces a novel approach, Dynamic Gender-Aware Enhanced Binary Particle Swarm Optimization (DGA-EBPSO), that leverages a gender-specific particle swarm optimization (PSO) technique for feature selection to enhance SER accuracy while promoting interpretability. We extract pitch and acoustic-related statistical features from speech samples and develop separate models for gender prediction and emotion detection. The gender-specific DGA-EBPSO algorithm incorporates a hybrid mutation strategy to improve feature selection efficiency and considers gender-based variations in emotional expression. Notably, our approach prioritizes interpretability by allowing for analysis of the features most influential for gender and emotion classification using the DGA-EBPSO framework. This focus on interpretability aligns with the principles of responsible AI development, ensuring transparency and mitigating potential biases in SER systems. The effectiveness of our method is demonstrated by achieving superior classification performance (accuracy, precision, recall, and F1 score) on benchmark emotional speech datasets like CREMA-D, EmergencyCalls, IEMOCAP, and RAVDESS.},
  keywords={Feature extraction;Emotion recognition;Speech recognition;Accuracy;Particle swarm optimization;Databases;Acoustics;Speech enhancement;Recording;Predictive models;Dynamic gender-aware enhanced binary particle swarm optimization (DGA-EPSO);emotion detection;emotional expression variations;feature selection;gender prediction;hybrid mutation strategy;interpretability;pitch and acoustic features;responsible AI;speech emotion recognition (SER)},
  doi={10.1109/ACCESS.2024.3516790},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10612143,
  author={Tsakiridis, Nikolaos L. and Samarinas, Nikiforos and Kalopesa, Eleni and Theocharis, John B. and Zalidis, George C.},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Enhanced Soil Property Estimations from Earth Observation Data with Differential Evolution-Based Multi-Objective TSK Model}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={This paper introduces a novel approach integrating Differential Evolution (DE) with multi-objective optimization techniques for enhancing Type-1 Takagi-Sugeno-Kang (TSK) fuzzy rule-based systems to attain both fair predictive performance and enhanced interpretability within the context of explainable artificial intelligence. The developed approach encodes the whole knowledge base into one chromosome and endeavors to concurrently optimize the prediction accuracy, the number of rules, and the selection of relevant input features. The methodology was tested on Earth observation data for the estimation of soil health parameters via infrared spectroscopy, and more concretely i) on the 2015 LUCAS topsoil dataset to predict three key soil properties (namely, soil organic carbon, clay content, and pH) from laboratory spectra, and ii) on a set of PRISMA hyperspectral images to predict soil organic carbon in a region of northern Greece. Compared to the classical Random Forest (RF) algorithm, our proposed learning algorithm attains a fair balance between accuracy and interpretability, and is statistically equivalent to RF in terms of accuracy. The findings underscore the potential of the proposed methodology in refining TSK models and its applicability in Earth observation-driven predictions, paving the way for both enhanced modeling accuracy and sparse feature selection.},
  keywords={Earth;Radio frequency;Accuracy;Soil properties;Estimation;Predictive models;Prediction algorithms;Vis-NIR spectroscopy;VNIR-SWIR spectroscopy;XAI;remote sensing},
  doi={10.1109/CEC60901.2024.10612143},
  ISSN={},
  month={June},}@ARTICLE{9520652,
  author={Lensen, Andrew and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Genetic Programming for Manifold Learning: Preserving Local Topology}, 
  year={2022},
  volume={26},
  number={4},
  pages={661-675},
  abstract={Manifold learning (MaL) methods are an invaluable tool in today’s world of increasingly huge datasets. MaL algorithms can discover a much lower-dimensional representation (embedding) of a high-dimensional dataset through nonlinear transformations that preserve the most important structure of the original data. State-of-the-art MaL methods directly optimize an embedding without mapping between the original space and the discovered embedded space. This makes interpretability—a key requirement in exploratory data analysis—nearly impossible. Recently, genetic programming has emerged as a very promising approach to MaL by evolving functional mappings from the original space to an embedding. However, genetic programming-based MaL has struggled to match the performance of other approaches. In this work, we propose a new approach to using genetic programming for MaL, which preserves local topology. This is expected to significantly improve performance on tasks where local neighborhood structure (topology) is paramount. We compare our proposed approach with various baseline MaL methods and find that it often outperforms other methods, including a clear improvement over previous genetic programming approaches. These results are particularly promising, given the potential interpretability and reusability of the evolved mappings.},
  keywords={Topology;Manifold learning;Task analysis;Genetic programming;Manifolds;Computational modeling;Numerical models;Evolutionary learning;feature construction;feature selection;genetic programming (GP);manifold learning (MaL)},
  doi={10.1109/TEVC.2021.3106672},
  ISSN={1941-0026},
  month={Aug},}@INPROCEEDINGS{10022164,
  author={De Souza Abreu, João Victor T. and Martins, Denis Mayr Lima and De Lima Neto, Fernando Buarque},
  booktitle={2022 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Evolving Interpretable Classification Models via Readability-Enhanced Genetic Programming}, 
  year={2022},
  volume={},
  number={},
  pages={1691-1697},
  abstract={As the impact of Machine Learning (ML) on busi-ness and society grows, there is a need for making opaque ML models transparent and interpretable, especially in the light of fairness, bias, and discrimination. Nevertheless, interpreting complex opaque models is not trivial. Current interpretability approaches rely on local explanations or produce long explanations that tend to overload the user's cognitive abilities. In this paper, we address this problem by extracting interpretable, transparent models from opaque ones via a new readability-enhanced multi-objective Genetic Programming approach called REMO-GP. To achieve that, we adapt text readability metrics into model complexity proxies that support evaluating ML interpretability. We demonstrate that our approach can generate global interpretable models that mimic the decisions of complex opaque models over several datasets, while keeping model complexity low.},
  keywords={Adaptation models;Computational modeling;Genetic programming;Machine learning;Readability metrics;Complexity theory;Computational intelligence;Artificial Intelligence;Opaque Models;Genetic Programming;Interpretability;Binary Classification},
  doi={10.1109/SSCI51031.2022.10022164},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10356500,
  author={Hagos, Misgina Tsighe and Belton, Niamh and Curran, Kathleen M. and Namee, Brian Mac},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Distance-Aware eXplanation Based Learning}, 
  year={2023},
  volume={},
  number={},
  pages={279-286},
  abstract={eXplanation Based Learning (XBL) is an interactive learning approach that provides a transparent method of training deep learning models by interacting with their explanations. XBL augments loss functions to penalize a model based on deviation of its explanations from user annotation of image features. The literature on XBL mostly depends on the intersection of visual model explanations and image feature annotations. We present a method to add a distance-aware explanation loss to categorical losses that trains a learner to focus on important regions of a training dataset. Distance is an appropriate approach for calculating explanation loss since visual model explanations such as Gradient-weighted Class Activation Mapping (Grad-CAMs) are not strictly bounded as annotations and their intersections may not provide complete information on the deviation of a model’s focus from relevant image regions. In addition to assessing our model using existing metrics, we propose an interpretability metric for evaluating visual feature-attribution based model explanations that is more informative of the model’s performance than existing metrics. We demonstrate performance of our proposed method on three image classification tasks.},
  keywords={Measurement;Training;Deep learning;Visualization;Annotations;Artificial intelligence;Task analysis;eXplanation Based Learning;Interactive Machine Learning;eXplainable AI},
  doi={10.1109/ICTAI59109.2023.00048},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9858301,
  author={Al Ka'bi, Amin},
  booktitle={2022 IEEE International Black Sea Conference on Communications and Networking (BlackSeaCom)}, 
  title={A Proposed Algorithm for Synthesizing the Radiation Pattern of Antenna Arrays}, 
  year={2022},
  volume={},
  number={},
  pages={112-117},
  abstract={The design of antenna arrays is one of the most challenging optimization problems in recent research work. In this paper a new computational algorithm is proposed for synthesizing the radiation pattern of linear antenna arrays. The proposed computational algorithm is based on parallel processing of streams of binary digits, and hence it can perform well in parallel processing digital systems. The optimization technique used in this algorithm is based on “Characteristics Evolution Optimization” method. In this paper, a 16 - element linear antenna array has been taken into consideration, and the performance of the proposed algorithm for synthesizing the radiation pattern of the array is investigated and compared with other existing techniques, such as Differential Evolution (DE), Particle Swarm Optimization (PSO), and Invasive Weed Optimization (IWO). Other forms of Invasive Weed Optimization are investigated as well. Simulation results show that the proposed algorithm significantly outperforms the other optimization techniques in different aspects.},
  keywords={Digital systems;Simulation;Optimization methods;Parallel processing;Linear antenna arrays;Particle swarm optimization;Optimization;Antenna Arrays;Characteristics Evolution Optimization;Linear Array;Pattern Synthesis;Radiation patterns},
  doi={10.1109/BlackSeaCom54372.2022.9858301},
  ISSN={},
  month={June},}@INPROCEEDINGS{10914211,
  author={Wu, Yong and Sun, Zhen and Qiu, Shikun and Dong, Haiqing and Zhou, Qibin and Chen, Kehan},
  booktitle={2024 4th International Conference on Smart Grid and Energy Internet (SGEI)}, 
  title={Lightning Risk Assessment Method Considering Environmental Factors Based on Artificial Intelligence Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={558-562},
  abstract={With the continuous extension of transmission lines, the risk of lightning strikes on transmission lines has significantly increased, especially in areas with complex terrain. Additionally, as the construction of transmission lines encounters more complex terrain, the influencing factors of lightning strikes have become more diverse. This paper proposes a lightning risk assessment method based on Particle Swarm Optimization and Random Forest (PSO-RF). By utilizing ADTD lightning data and geographical information of the study area, the model evaluates high-risk lightning zones. The results indicate that the PSO-RF model outperforms other machine learning models in terms of accuracy, precision and recall, demonstrating excellent performance on the test set. SHAP value analysis reveals that features such as latitude, longitude, lightning frequency and building height significantly influence lightning risk. This study provides guidance for differentiated lightning protection measures in power system transmission lines.},
  keywords={Training;Radio frequency;Accuracy;Power transmission lines;Power measurement;Lightning;Power system stability;Transmission line measurements;Data models;Risk management;Random Forest;Particle Swarm Optimization;Lightning Risk Assessment;SHAP Values},
  doi={10.1109/SGEI63936.2024.10914211},
  ISSN={},
  month={Dec},}@ARTICLE{10742366,
  author={Ming, Jingwei and Xie, Zhiqiang},
  journal={IEEE Access}, 
  title={Adaptive Particle Swarm Optimization Algorithm and Application Model Based on Diversity-Driven Optimization}, 
  year={2024},
  volume={12},
  number={},
  pages={170707-170720},
  abstract={The rapid development of Internet of Things technologies has led to the continuous increase and complexity of data feature dimensions. Therefore, a diversity-driven optimization-based adaptive particle swarm optimization feature selection algorithm was proposed to improve the accuracy of feature selection for high-dimensional data. The diversity drive of particles was constructed through population diversity. Secondly, the feature space segmentation method of the algorithm was improved. An adaptive population size adjustment mechanism was proposed. In 12 data sets with different dimensions, the proposed method had an advantage over other methods in terms of average accuracy. The average accuracy of these two classifiers increased by an average of 12.71% and 9.89%, respectively. The average time cost of the proposed method running 30 times on 12 data sets was 343.83ms, which was an average reduction of 44.02% compared to the other three algorithms. Therefore, diversity-driven optimization methods can enhance the algorithmic particle optimization speed. The proposed algorithm requires lower computational costs and superior feature selection accuracy for high-dimensional data feature selection. This algorithm has positive application value in high-dimensional data feature selection problems.},
  keywords={Feature extraction;Classification algorithms;Optimization;Heuristic algorithms;Accuracy;Convergence;Computational efficiency;Computer crime;Image segmentation;Prediction algorithms;Diversity-driven optimization;PSO algorithm;adaptive adjustment;feature importance;feature selection;KNN classifier},
  doi={10.1109/ACCESS.2024.3491157},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10675761,
  author={Rad, Jaber and Tennankore, Karthik and Abidi, Samina and Abidi, Syed Sibte Raza},
  booktitle={2024 11th IEEE Swiss Conference on Data Science (SDS)}, 
  title={Extracting Decision Paths via Surrogate Modeling for Explainability of Black Box Classifiers}, 
  year={2024},
  volume={},
  number={},
  pages={213-220},
  abstract={A common challenge in using intricate machine learning (ML) classifiers in critical domains is the lack of transparency in making predictions despite exhibiting high performance. Besides, relying solely on a single ML model may introduce uncertainties due to each algorithm's distinct strengths and weaknesses in classification. In this study, we propose a novel method that collects explanations derived from multiple ML classifiers, and subsequently, through subset optimization, extracts a high-quality explanation represented as a set of rules in disjunctive normal form—referred to as decision paths. Quality check of the shortlisted explanation is done considering accuracy of the underlying ML model, fidelity, confidence, instance coverage, and interpretability. We applied our method to a large and complicated real-life dataset related to kidney transplants, addressing a binary classification problem. The experiments show that our method optimally balances the reliability and coverage of the explanation, while minimizing its complexity.},
  keywords={Uncertainty;Machine learning algorithms;Machine learning;Data science;Prediction algorithms;Data models;Organ transplantation;Explainable AI;Surrogate modelling;Explanation by simplification;Model-agnostic explainability},
  doi={10.1109/SDS60720.2024.00037},
  ISSN={2835-3420},
  month={May},}@INPROCEEDINGS{10263814,
  author={Singh, Tejveer and Kumar, Manoj and Kumar, Santosh},
  booktitle={2023 IEEE World Conference on Applied Intelligence and Computing (AIC)}, 
  title={Enhancing Phishing Website Detection Using Particle Swarm Optimization and Feature Selection Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={977-982},
  abstract={In recent years, Web phishing attacks have evolved, eroding customer trust in online services. Traditional blacklist-based approaches struggle to detect sophisticated phishing websites, including newly deployed ones. Researchers are turning to machine learning techniques for early detection but facing limitations in feature selection and parameter tuning. This paper presents an innovative approach that combines Particle Swarm Optimization (PSO) with feature selection techniques, including correlation and mutual information, and tree-based feature selection. The goal is to accurately differentiate between legitimate and phishing websites by identifying relevant features. A comprehensive dataset of diverse website features is used, and correlation and mutual information methods are used to assess feature importance. A tree-based feature selection algorithm refines the feature set, and PSO optimizes the parameters by exploring the feature space. Thorough experimentation is needed to fine-tune features and parameters for accurate detection. Experimental results show the superiority of the proposed approach, eliminating irrelevant features and improving efficiency and classification performance through PSO optimization. Integrating PSO with feature selection provides a robust framework, addressing tuning challenges and improving accuracy.},
  keywords={Correlation;Phishing;Machine learning;Feature extraction;Turning;Space exploration;Particle swarm optimization;Phishing;Machine Learning;Mendeley Dataset;Particle Swarm Optimization;Feature Selection},
  doi={10.1109/AIC57670.2023.10263814},
  ISSN={},
  month={July},}@ARTICLE{10815941,
  author={He, Yawen and Chen, Jianwen and Wu, Zhiyu and Dun, Yaxin and Du, Guichao and Feng, Mengsen and Lu, Yifan and Dang, Wei},
  journal={IEEE Access}, 
  title={Prediction of High-Pressure Physical Properties of Crude Oil Using Explainable Machine Learning Models}, 
  year={2025},
  volume={13},
  number={},
  pages={4912-4931},
  abstract={High-pressure physical property parameters of formation crude oil are crucial for oilfield exploration, development, and production. Various prediction models have been developed using PVT experimental methods, empirical formulas, regression analysis, and machine learning techniques. However, these models often lack sufficient transparency and clarity in their computational processes, limiting their effectiveness in oil and gas exploration and development. This paper employs the Extreme Gradient Boosting (XGBoost) machine learning algorithm, utilizing experimental data such as formation pressure, formation temperature, surface crude oil density, natural gas relative density, gas-oil ratio, saturation pressure, volume factor, formation crude oil density, and formation crude oil viscosity as the dataset. The machine learning model is trained with these parameters to develop the XGBoost prediction model. Optimal parameters, including gas-oil ratio, saturation pressure, volume factor, formation crude oil density, and formation crude oil viscosity, are selected, and the Particle Swarm Optimization (PSO) algorithm is applied to further optimize the model, resulting in the PSO-XGBoost prediction model. To enhance the understanding of the model’s operation and the influencing factors, Shapley Additive Explanations (SHAP) and Explainable Boosting Machine (EBM) techniques are employed for both local and global interpretations of the machine learning model. This study identifies key factors and their weights in predicting high-pressure physical property parameters of formation crude oil, providing valuable insights for predicting shale oil reservoir parameters and enhancing exploration and development efficiency.},
  keywords={Oils;Predictive models;Reservoirs;Viscosity;Boosting;Artificial neural networks;Data models;Computational modeling;Accuracy;Prediction algorithms;Extreme gradient boosting;particle swarm optimization;model interpretation;machine learning;PVT property},
  doi={10.1109/ACCESS.2024.3522595},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10649965,
  author={Singh, Gaurav and Bali, Kavitesh Kumar},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper explores the seamless integration of Generative AI (GenAI) and Evolutionary Algorithms (EAs) within the domain of large-scale multi-objective optimization. Focusing on the transformative role of Large Language Models (LLMs), our study investigates the potential of LLM-Assisted Inference to automate and enhance decision-making processes. Specifically, we highlight its effectiveness in illuminating key decision variables in evolutionarily optimized solutions while articulating contextual trade-offs. Tailored to address the challenges inherent in inferring complex multi-objective optimization solutions at scale, our approach emphasizes the adaptive nature of LLMs, allowing them to provide nuanced explanations and align their language with diverse stakeholder expertise levels and domain preferences. Empirical studies underscore the practical applicability and impact of LLM-Assisted Inference in real-world decision-making scenarios.},
  keywords={Symbiosis;Generative AI;Large language models;Decision making;Neural networks;Inference algorithms;Planning;Generative Artificial Intelligence;large language models;evolutionary algorithms;multi-objective optimization;LLM-Assisted inference;automated decision making;nuanced explanations},
  doi={10.1109/IJCNN60899.2024.10649965},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10612210,
  author={Liang, Jing and Yang, Zexuan and Zhang, Tuo and Bi, Ying},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A Two-Stage Approach Using Genetic Algorithm and Genetic Programming for Remote Sensing Crop Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Crop classification is an important task in remote sensing image analysis. To effectively classify crops, it is necessary to extract or obtain a set of effective features from raw pixels. However, existing methods have several limitations, including poor interpretability of the learned models and the requirements of sufficient training data and domain expertise. To address this, this paper develops a two-stage approach using Genetic Algorithm (GA) and Genetic Programming (GP) to automatically learn a feature set that can effectively classify crops using remote sensing images. In the first stage of the new approach, a GP method is applied to automatically construct a set of high-level features by evolving tree-based solutions. In the second stage, a GA method is employed to select a small subset of features from the constructed features and the original features by removing redundant ones. The performance of the new approach is evaluated on three datasets in two scenarios, i.e., classifying four main crop types and all crop types, respectively. The results demonstrate that the new approach achieves more accurate crop classification compared with eight competitive methods.},
  keywords={Support vector machines;Precision agriculture;Crops;Genetic programming;Training data;Evolutionary computation;Feature extraction;Genetic Programming;Genetic Algorithm;Feature Construction;Feature Selection;Crop Classification},
  doi={10.1109/CEC60901.2024.10612210},
  ISSN={},
  month={June},}@INPROCEEDINGS{10944743,
  author={Greenlee, Aidan and Palumbo, Neil F.},
  booktitle={2025 59th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Breast Cancer Diagnosis via Swarm-Optimized Adaptive Neuro-Fuzzy Inference System}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper discusses a method for classification of breast cancer imaging data through the application of an adaptive neuro-fuzzy inference system (ANFIS) and particle swarm optimization (PSO) for hyperparameter optimization of the ANFIS system. A robust parameter tuning method is used to select the optimal configuration for the ANFIS and PSO components without expert knowledge of the dataset. Using these methods, high classification accuracies can be achieved for both the original and diagnostic versions of the Wisconsin Breast Cancer Dataset. These results demonstrate the flexibility and potential of a joint ANFIS-PSO system for automated diagnosis while retaining system simplicity and linguistic interpretability to support clinical decision-making.},
  keywords={Training;Adaptive systems;Accuracy;Sensitivity;Linguistics;Breast cancer;Particle swarm optimization;System analysis and design;Tuning;Testing;breast cancer;ANFIS;neuro-fuzzy;particle swarm;optimization},
  doi={10.1109/CISS64860.2025.10944743},
  ISSN={2837-178X},
  month={March},}@INPROCEEDINGS{10708185,
  author={Al Jassim, Rasha S. and Al Mansoory, Shqran and Jetly, Karan and Abdullah AlMaqbali, Hilal Ali and Mohammed Albalushi, Muna},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Enhancing Tourism Performance in Oman: A Case Study Using Correlation-Guided Linear Genetic Programming Decision Tree (C-LGPDT)}, 
  year={2024},
  volume={},
  number={},
  pages={1655-1660},
  abstract={This research examines the optimization of decision tree induction techniques by integrating evolutionary algorithms. It focuses on the Linear Genetic Programming Decision Tree (LGPDT). LGPDT employs a linear program to encode decision trees, achieving an optimal balance between accuracy and interpretability. The study introduces C-LGPDT as an extension of LGPDT, aiming to enhance its efficiency through correlation-based feature selection. This integration reduces dataset dimensionality and eliminates irrelevant or redundant features, resulting in a more accurate and interpretable decision tree model. The performance of C-LGPDT is thoroughly examined, and it is shown that it consistently outperforms older approaches, especially C4.5, and that it is more robust and accurate. A tourism dataset is also used to evaluate the C-LGPDT’s performance, with an emphasis on its stability in recall and precision. Results show that C-LGPDT is effective at solving decision tree induction problems, making it a good candidate for machine learning classification tasks.},
  keywords={Accuracy;Genetic programming;Evolutionary computation;Machine learning;Feature extraction;Stability analysis;Decision trees;Information technology;Optimization;Evolutionary Algorithms;Tourism;Decision Tree;Linear Genetic Programming;Classification},
  doi={10.1109/CoDIT62066.2024.10708185},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{9952335,
  author={Sun, Yang and Hao, Baoxin and Su, Bo and Fan, Qing and Sun, Chengqun},
  booktitle={2022 Asian Conference on Frontiers of Power and Energy (ACFPE)}, 
  title={Fault diagnosis of High Voltage Circuit Breaker using Random Forest and PSo-KELM}, 
  year={2022},
  volume={},
  number={},
  pages={221-225},
  abstract={High voltage circuit breaker (HVCB) is an essential and important device of power grid, while any faults occurred in operation mechanism of HVCB will greatly jeopardize reliability and safety of power system. In order to improve fault diagnosis performance, a new fault diagnosis method using random forest (RF) and kernel extreme learning machine (KELM) is presented in this paper. At first, RF is applied to select the critical features derived from coil current. Then, the selected features are applied as inputs of KEML to establish fault diagnosis model. Next, particle swarm optimization (PSO) is introduced to turn crucial parameters of KELM to enhance diagnosis accuracy. Finally, practical samples are used to assess fault diagnosis performance of the presented method. Experimental results indicates the proposed RF-KELM method is capable of providing higher diagnosis accuracy than conventional approaches, which indicates promising future.},
  keywords={Fault diagnosis;Extreme learning machines;Circuit breakers;High-voltage techniques;Feature extraction;Kernel;Integrated circuit modeling;High voltage circuit breaker;random forest;tripping/closing coil current;kernel extreme learning machine;particle swarm optimization;fault diagnosis},
  doi={10.1109/ACFPE56003.2022.9952335},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10912343,
  author={Aryan, Prakash},
  booktitle={2024 IEEE Conference on Engineering Informatics (ICEI)}, 
  title={LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={This paper introduces DebateBrawl, an innovative AI-powered debate platform that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and Adversarial Search (AS) to create an adaptive and engaging debating experience. DebateBrawl addresses the limitations of traditional LLMs in strategic planning by incorporating evolutionary optimization and game-theoretic techniques. The system demonstrates remarkable performance in generating coherent, contextually relevant arguments while adapting its strategy in real-time. Experimental results involving 23 debates show balanced outcomes between AI and human participants, with the AI system achieving an average score of ${2. 7 2}$ compared to the human average of ${2. 6 7}$ out of 10. User feedback indicates significant improvements in debating skills and a highly satisfactory learning experience, with 85% of users reporting improved debating abilities and ${7 8 \%}$ finding the AI opponent appropriately challenging. The system’s ability to maintain high factual accuracy (92% compared to ${7 8 \%}$ in human-only debates) while generating diverse arguments addresses critical concerns in AI-assisted discourse. DebateBrawl not only serves as an effective educational tool but also contributes to the broader goal of improving public discourse through AI-assisted argumentation. The paper discusses the ethical implications of AI in persuasive contexts and outlines the measures implemented to ensure responsible development and deployment of the system, including robust fact-checking mechanisms and transparency in decision-making processes.},
  keywords={Training;Ethics;Visualization;Large language models;Decision making;Strategic planning;Problem-solving;Artificial intelligence;Research and development;Genetic algorithms;Machine Learning;Deep Learning;Generative AI;Large Language Models;Genetic Algorithms;Adversarial Search},
  doi={10.1109/ICEI64305.2024.10912343},
  ISSN={},
  month={Nov},}@ARTICLE{10750399,
  author={Xue, Xingsi and Wu, Mu-En and Khan, Fazlullah},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Biomedical Information Integration via Adaptive Large Language Model Construction}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Integrating diverse biomedical knowledge information is essential to enhance the accuracy and efficiency of medical diagnoses, facilitate personalized treatment plans, and ultimately improve patient outcomes. However, Biomedical Information Integration (BII) faces significant challenges due to variations in terminology and the complex structure of entity descriptions across different datasets. A critical step in BII is biomedical entity alignment, which involves accurately identifying and matching equivalent entities across diverse datasets to ensure seamless data integration. In recent years, Large Language Model (LLMs), such as Bidirectional Encoder Representations from Transformers (BERTs), have emerged as valuable tools for discerning heterogeneous biomedical data due to their deep contextual embeddings and bidirectionality. However, different LLMs capture various nuances and complexity levels within the biomedical data, and none of them can ensure their effectiveness in all heterogeneous entity matching tasks. To address this issue, we propose a novel Two-Stage LLM construction (TSLLM) framework to adaptively select and combine LLMs for Biomedical Information Integration (BII). First, a Multi-Objective Genetic Programming (MOGP) algorithm is proposed for generating versatile high-level LLMs, and then, a Single-Objective Genetic Algorithm (SOGA) employs a confidence-based strategy is presented to combine the built LLMs, which can further improve the discriminative power of distinguishing heterogeneous entities. The experiment utilizes OAEI's entity matching datasets, i.e., Benchmark and Conference, along with LargeBio, Disease and Phenotype datasets to test the performance of TSLLM. The experimental findings validate the efficiency of TSLLM in adaptively differentiating heterogeneous biomedical entities, which significantly outperforms the leading entity matching techniques.},
  keywords={Bioinformatics;Semantics;Biological system modeling;Accuracy;Complexity theory;Encoding;Bidirectional control;Optimization;Large language models;Terminology;Biomedical Information Integration;Large Language Model;Genetic Programming;Genetic Algorithm},
  doi={10.1109/JBHI.2024.3496495},
  ISSN={2168-2208},
  month={},}@ARTICLE{9475970,
  author={Wang, Shaolin and Mei, Yi and Zhang, Mengjie and Yao, Xin},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Genetic Programming With Niching for Uncertain Capacitated Arc Routing Problem}, 
  year={2022},
  volume={26},
  number={1},
  pages={73-87},
  abstract={The uncertain capacitated arc routing problem is an important optimization problem with many real-world applications. Genetic programming is considered a promising hyper-heuristic technique to automatically evolve routing policies that can make effective real-time decisions in an uncertain environment. Most existing research on genetic programming hyper-heuristic for the uncertain capacitated arc routing problem only focused on the test performance aspect. As a result, the routing policies evolved by genetic programming are usually too large and complex, and hard to comprehend. To evolve effective, smaller, and simpler routing policies, this article proposes a novel genetic programming approach, which simplifies the routing policies during the evolutionary process using a niching technique. The simplified routing policies are stored in an external archive. We also developed new elitism, parent selection, and breeding schemes for generating offspring from the original population and the archive. The experimental results show that the newly proposed approach can achieve significantly better test performance than the current state-of-the-art genetic programming algorithms for the uncertain capacitated arc routing problem. The evolved routing policies are smaller, and thus potentially more interpretable.},
  keywords={Routing;Task analysis;Optimization;Statistics;Sociology;Genetic programming;Vehicle dynamics;Capacitated arc routing;genetic programming;hyper-heuristic;program simplification;stochastic optimization},
  doi={10.1109/TEVC.2021.3095261},
  ISSN={1941-0026},
  month={Feb},}@INPROCEEDINGS{10451203,
  author={Yang, Yan and Li, Dongyang and Chen, Zewang and Ai, Ai and Xiao, Zhicheng and Zhang, Xuetao},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={Air Conditioning Load Forecast Based on LSTM Combining Improved Particle Swarm Algorithm and Attention Mechanism}, 
  year={2023},
  volume={},
  number={},
  pages={723-728},
  abstract={Air-conditioning load forecasting is of great significance for saving building energy consumption and maintaining stable load operation of equipment, so research on air-conditioning load forecasting has high practical significance and social value. The building model is established, the air-conditioning load data is obtained by TRNSYS load simulation software, and the IPSO-AM-LSTM neural network model is established by Python. Use the IPSO algorithm to find the best parameters predicted by its model and make predictions. Several different neural network models were trained and validated on building air conditioning load data. Compared with the traditional LSTM model, the MAE, MAPE, and RMSE of IPSO-AM-LSTM are reduced by 61.9%, 46.4%, and 47.1% respectively.},
  keywords={Load forecasting;Atmospheric modeling;Buildings;Neural networks;Predictive models;Prediction algorithms;Data models;Particle swarm optimization;LSTM model;attention mechanism. predictive control},
  doi={10.1109/CAC59555.2023.10451203},
  ISSN={2688-0938},
  month={Nov},}@ARTICLE{11067951,
  author={AbdelRaouf, Hussien and Abouyoussef, Mahmoud and Ibrahem, Mohamed I.},
  journal={IEEE Internet of Things Journal}, 
  title={Leveraging Multi-Head Attention and Counterfactual Explanations for Precise and Efficient Activity Recognition and Heart Attack Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Heart attack detection (HAD) and human activity recognition (HAR) rely on wearable sensor data to track heart health and physical activity in real-time, facilitating early detection and monitoring of health issues. However, existing solutions for HAR and HAD face challenges in effectively capturing spatial features, long-term dependencies, and diverse sensor data representations. These shortcomings impact recognition accuracy, memory efficiency, and processing speed, while also demanding substantial computational resources due to their complexity. They also lead to performance degradation, increasing the risk of inaccurate diagnoses and potentially jeopardizing patient lives. To overcome these limitations, a novel lightweight hybrid architecture for HAR and HAD is proposed, leveraging convolutional neural networks (CNNs) with gated recurrent units (GRUs) and multi-head attention (MHA). CNNs capture spatial features, GRUs extract long-term dependencies, and MHA computes attention weights across data segments to highlight the most relevant features for health diagnosis, ensuring both improved performance and practicality for real-time health monitoring. Moreover, a magnitude-based weight pruning technique is adapted to reduce the proposed architecture’s complexity, making it suitable in resource-constrained settings without sacrificing accuracy. Furthermore, our methodology integrates an optimized genetic algorithm for counterfactual explanations, recommending minimal health data changes to lower heart attack risk. Experimental results on a real testbed and datasets, including PAMAP2, WISDM, and Cleveland, demonstrate that the proposed method outperforms the state-of-the-art methods, achieving up to 3% improvement in F1-score and accuracy, while reducing inference time, number of parameters, and memory footprint by over 40%, 70%, and 60%, respectively.},
  keywords={Accuracy;Human activity recognition;Feature extraction;Cardiac arrest;Monitoring;Heart;Real-time systems;Support vector machines;Radio frequency;Data mining;Human activity recognition (HAR);heart attack detection (HAD);multi-head attention},
  doi={10.1109/JIOT.2025.3585540},
  ISSN={2327-4662},
  month={},}@INPROCEEDINGS{10729376,
  author={Han, Xiao},
  booktitle={2024 IEEE 2nd International Conference on Sensors, Electronics and Computer Engineering (ICSECE)}, 
  title={Research on Digital System of Human Resource Information Based on Cloud Computing}, 
  year={2024},
  volume={},
  number={},
  pages={775-778},
  abstract={This paper explores the design intent and functional structure of the human resource management information system. Based on specific circumstances, it provides a comprehensive plan for the human resource management information system, explaining the system's functions through individual modules. In this project, multi-objective particle swarm optimization algorithm is used to fuse multiple elements, and genetic optimization results are used to optimize solutions. Orthogonal optimization is used to initialize the particle swarm to ensure the convergence of the solution results through the performance test of the method. The results show that the optimal solutions obtained by this method are smaller than those obtained by the control method, and the final iteration time is shortest, which shows a better comprehensive effect. The proposed method can efficiently solve the optimal allocation of personnel, so as to achieve the purpose of the optimal allocation of personnel.},
  keywords={Fuses;Simulation;Genetics;Sensors;Resource management;Personnel;Particle swarm optimization;Optimization;Information systems;Convergence;Human resource management;particle swarm optimization;fitness;orthogonal initialization;information management;decision support;dynamic query;data security},
  doi={10.1109/ICSECE61636.2024.10729376},
  ISSN={},
  month={Aug},}@ARTICLE{10440554,
  author={Wang, Xubin and Shangguan, Haojiong and Huang, Fengyi and Wu, Shangrui and Jia, Weijia},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional Feature Selection}, 
  year={2024},
  volume={36},
  number={8},
  pages={4020-4033},
  abstract={Feature selection is a crucial step in data mining to enhance model performance by reducing data dimensionality. However, the increasing dimensionality of collected data exacerbates the challenge known as the “curse of dimensionality”, where computation grows exponentially with the number of dimensions. To tackle this issue, evolutionary computational (EC) approaches have gained popularity due to their simplicity and applicability. Unfortunately, the diverse designs of EC methods result in varying abilities to handle different data, often underutilizing and not sharing information effectively. In this article, we propose a novel approach called PSO-based Multi-task Evolutionary Learning (MEL) that leverages multi-task learning to address these challenges. By incorporating information sharing between different feature selection tasks, MEL achieves enhanced learning ability and efficiency. We evaluate the effectiveness of MEL through extensive experiments on 22 high-dimensional datasets. Comparing against 24 EC approaches, our method exhibits strong competitiveness. In addition, we have open-sourced our code on GitHub.},
  keywords={Feature extraction;Task analysis;Multitasking;Statistics;Sociology;Vectors;Particle swarm optimization;Feature selection;high-dimensional classification;knowledge transfer;multi-task learning;particle swarm optimization},
  doi={10.1109/TKDE.2024.3366333},
  ISSN={1558-2191},
  month={Aug},}@ARTICLE{10945804,
  author={Li, Rui and Wang, Ling and Sang, Hongyan and Yao, Lizhong and Pan, Lijun},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={LLM-Assisted Automatic Memetic Algorithm for Lot-Streaming Hybrid Job Shop Scheduling With Variable Sublots}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This study addresses the lot-streaming hybrid job shop scheduling problem with variable sublots (LHJSV), inspired by a real-world aircraft tooling shop. A computational model is developed to represent the complex scheduling processes of the tooling shop. To solve this problem, we propose an automatic memetic algorithm enhanced by a heuristic designed with the assistance of a large language model (LLM). The approach is designed as follows: first, a memetic computing framework with automated algorithmic design is proposed for LHJSV. Second, a cooperative evolutionary heuristic framework based on problem decomposition is introduced, enabling the LLM to comprehend the LHJSV characteristics and generate feasible algorithms. Third, problem-specific prompts for LHJSV are carefully designed to guide the LLM. To evaluate the effectiveness of the proposed method, 20 benchmark instances derived from the Taillard dataset and a real-world case involving 575 operations are utilized. The proposed algorithm is compared against three swarm-based algorithms, an end-to-end method, and an LLM-based algorithm. Experimental results demonstrate that our method outperforms the compared algorithms on 85% of benchmark instances and exhibits significant superiority in real-world scenarios.},
  keywords={Job shop scheduling;Memetics;Processor scheduling;Heuristic algorithms;Scheduling;Parallel machines;Aircraft;Complexity theory;Aircraft manufacture;Computational modeling;Large language model;Evolutionary Computation;Automatic algorithm design;Lot-streaming scheduling;Memetic Computing},
  doi={10.1109/TEVC.2025.3556186},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10254079,
  author={Khosrowshahli, Rasa and Rahnamayan, Shahryar},
  booktitle={2023 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Block Differential Evolution}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={In order to solve huge-scale optimization problems, many evolutionary algorithms have been proposed. In this paper, we introduce Block Differential Evolution (BDE) algorithm. The BDE can be categorized into the class of memory-efficient optimization algorithms. The main contribution is to solve large and huge-scale problems effectively and efficiently by reducing the problem dimension by utilizing a dimension-blocking scheme. With respect to the block size times reduced memory usage, furthermore, the proposed algorithm is computationally more efficient because DE operations (i.e., mutation, crossover, and selection) are performed on much smaller vector sizes. In fact, the employed blocking approach helps us to map the higher-dimensional problems into a lower-dimensional one which is more convenient to process during the optimization steps. There is a great demanding potential for the proposed approach to be utilized in embedded systems with low computational resources as a compressed optimization algorithm. This strategy is instantiated and evaluated on some well-known benchmark problems and compared with the baseline classic DE algorithm; the reported results are promising and encouraging for conducting further investigations. To the best of our knowledge, that is the first time a variable blocking scheme has been used in any meta-heuristic algorithm. A detailed explanation of the geometrical behavior of the proposed blocking approach is provided which explains how in a higher search space, a blocking approach is meaningful and applicable to accelerate convergence rate while the memory saving is huge. The reported results in this paper show the experiments on Large-Scale Global Optimization Problems proposed in CEC-2013 benchmark suite with 1,000, 10,000, and 100,000 dimensions and clearly are evidence of the possibility of satisfying two conflicting objectives, namely, efficiency and effectiveness, simultaneously. In order to utilize CEC-2013 benchmark problems for the huge dimensions 10,000D and 100,000D, some modifications and expansions have been done. The proposed approach can be utilized in another population-based optimization algorithm (swarm or evolutionary), and it is not restricted to the DE algorithm. In this paper, DE has been used as a parent algorithm for our conducted case study.},
  keywords={Embedded systems;Metaheuristics;Memory management;Evolutionary computation;Benchmark testing;Computational efficiency;Behavioral sciences;Differential Evolution;Large-scale Global Optimization;LSGO;Block;Dimension Reduction;Block Population-based Algorithms},
  doi={10.1109/CEC53210.2023.10254079},
  ISSN={},
  month={July},}@INPROCEEDINGS{11064235,
  author={Biswas, Anushka and John Joshua, H and P, Kalpana and Vasanth, U. and Ramakrishna Gondkar, Raju and Jose, Teena},
  booktitle={2025 International Conference on Electronics, Computing, Communication and Control Technology (ICECCC)}, 
  title={A Hybrid Genetic Algorithm and Large Language Model Approach for Agricultural Products Price Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces a hybrid approach, based on Genetic Algorithm (GA) and Large Language Models (LLMs), namely Mixtral 8x7B, to optimize pricing strategies for agricultural products. The method processes real-time market data, using Machine Learning (ML) techniques to generate competitive and profitable price recommendations. GAs allow for adaptive optimization, while LLMs capture complex trends in the market, making this approach more precise with respect to the pricing strategy. Case studies related to onions and tomatoes illustrate the efficiency of the optimization process. The outcome shows that the optimized prices achieve a fitness score of 0.915 (onions) and a competitive index of 0.89 (onions) compared to the market averages. Compared to traditional methods, the proposed hybrid model provides a better approach towards decision making through multi-objective optimization and real-time data analysis. This research contributes to improved profitability for farmers by adopting sustainable pricing strategies and agricultural market efficiency.},
  keywords={Profitability;Large language models;Decision making;Pricing;Machine learning;Market research;Agricultural products;Real-time systems;Optimization;Genetic algorithms;Agricultural Price Optimization;Genetic Algorithms;Large Language Models;Mixtral 8x7B;Machine Learning;Market Efficiency;Farm Profitability;Sustainable Agriculture},
  doi={10.1109/ICECCC65144.2025.11064235},
  ISSN={},
  month={May},}@ARTICLE{10858704,
  author={Stojkovic, Aleksandar and Nikolic, Bosko and Zivkovic, Miodrag and Bacanin, Nebojsa},
  journal={IEEE Access}, 
  title={Photovoltaic Farm Production Forecasting: Modified Metaheuristic Optimized Long Short-Term Memory-Based Networks Approach}, 
  year={2025},
  volume={13},
  number={},
  pages={25198-25222},
  abstract={The finite availability and unsustainable nature of fossil fuel sources have spurred growing interest in renewable energy sources. Nevertheless, substantial efforts are still required to fully incorporate energy coming from renewable sources into current power distribution networks. Although reliability plays a crucial role in enhancing the sustainability of energy production, the dependence of solar power plants on weather conditions poses challenges to maintaining consistent output without significant storage expenses. Consequently, precise forecasting of photovoltaic power generation is essential for effective grid management and energy trade market. Machine learning models have proven to be a prospective resolution due to their ability to process large datasets and capture intricate patterns within the data. This study investigates the application of metaheuristics optimization techniques to enhance light-weighted long short-term memory (LSTM) based models with and without attention for predicting power generation from photovoltaic plants. Furthermore, a modified metaheuristics optimization method based on the renowned particle swarm optimization algorithm is proposed to address the rigorous demands of hyperparameters’ optimization. Rigorous simulations on a real-world data were carried out, along with strict comparative analysis with other potent metaheuristics algorithms. A publicly available photovoltaic dataset consisting of the measurements from two plants in India was used. Additionally, this study utilized a supplementary dataset collected from a photovoltaic power plant located on the roof of Institute Mihailo Pupin (IMP) in Belgrade, Serbia. Proposed research tries to fill-in the gap in this research domain, since light-weighted LSTM models were not examined enough for this specific challenge according to the literature survey. The best produced models attained mean squared error (MSE) scores of only 0.007297 for Indian Plant 1, 0.007662 for Indian Plant 2, and 0.001812 for Institute Mihailo Pupin dataset, emphasizing considerable potential of the suggested approach for real-world applications. Finally, the applicability of the top-performance models was validated with tiny machine learning (TinyML).},
  keywords={Long short term memory;Production;Forecasting;Metaheuristics;Optimization;Predictive models;Logic gates;Photovoltaic systems;Data models;Accuracy;Optimization;renewable energy;solar power;forecasting;particle swarm optimization;LSTM},
  doi={10.1109/ACCESS.2025.3537407},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10071360,
  author={Yu, Zhicheng and Sun, Haoyue and Zhang, Bining},
  booktitle={2022 4th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM)}, 
  title={Research on Power Load Forecasting Based on PSO-LSTM}, 
  year={2022},
  volume={},
  number={},
  pages={167-170},
  abstract={In order to improve the prediction accuracy of electricity consumption, the particle swarm optimization algorithm was proposed to find the optimal hyperparameters of long-term and short-term memory (LSTM) neural networks, and the two models are combined to form a power load forecasting model. Aiming at the problem that it is difficult to manually select the LSTM hyperparameters, the PSO algorithm can effectively find the global optimal solution to find the hyperparameters of LSTM model. After continuous training, we find the appropriate hyperparameters and verify them The experimental results show that compared with the traditional LSTM network, the performance and prediction accuracy of the combined pso-lstm combination model have been significantly improved, which has certain academic value and application significance.},
  keywords={Training;Analytical models;Load forecasting;Neural networks;Predictive models;Prediction algorithms;Data models;had forecasting;particle swarm optimization;long-term and short-term memory neural networks;hyperparameter;optimal solution},
  doi={10.1109/AIAM57466.2022.00038},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11043029,
  author={Li, Danlin and Yan, Bo and Long, Quan and Wang, Bin},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={DE-KAN: A Differential Evolution-Based Optimization Framework for Enhancing Kolmogorov-Arnold Networks in Complex Nonlinear Modeling}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Kolmogorov-Arnold Networks (KANs) offer superior fitting ability and interpretability compared to traditional Multi-Layer Perceptrons (MLPs). However, their complex structure and lengthy training process pose significant challenges in practical applications. Existing optimization methods, primarily focused on replacing activation functions, fail to address the core issue of model complexity. In this paper, we introduce DE-KAN, a novel framework that leverages Differential Evolution (DE) to optimize the network structure of KANs. By modeling KAN as a discrete optimization problem, DE-KAN automates the selection of optimal connection patterns between network layers, significantly enhancing both efficiency and performance. Our experimental results on classification and regression datasets demonstrate that DE-KAN not only simplifies model complexity but also achieves notable improvements in accuracy and interpretability compared to traditional KANs and other baseline models.},
  keywords={Training;Technological innovation;Accuracy;Neural networks;Fitting;Optimization methods;Evolutionary computation;Robustness;Complexity theory;Convergence;Neural Networks;Kolmogorov-Arnold Networks;Differential Evolution},
  doi={10.1109/CEC65147.2025.11043029},
  ISSN={},
  month={June},}@INPROCEEDINGS{10616654,
  author={Ouhssini, Mohamed and Afdel, Karim and Akouhar, Mohamed and Agherrabi, Elhafed and Abarda, Abdallah},
  booktitle={2024 International Conference on Circuit, Systems and Communication (ICCSC)}, 
  title={Interpretable Deep Learning for DDoS Defense: A SHAP-based Approach in Cloud Computing}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper proposes an explainable deep learning model that combines CNNs and LSTMs to detect and mitigate DDoS attacks in cloud computing environments. The model leverages spatial and temporal patterns in network traffic data, and integrates SHAP for interpretability. Evaluation using diverse datasets confirms its effectiveness, and a Genetic Algorithm optimizes hyperparameters. The model provides actionable insights to aid security professionals in safeguarding cloud systems.},
  keywords={Deep learning;Cloud computing;Computational modeling;Telecommunication traffic;Denial-of-service attack;Data models;Stakeholders;Deep learning;DDoS attacks;explainability;cloud computing},
  doi={10.1109/ICCSC62074.2024.10616654},
  ISSN={},
  month={June},}@INPROCEEDINGS{10611754,
  author={Chen, Xinan and Yi, Wenjie and Bai, Ruibin and Qu, Rong and Jin, Yaochu},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A Hierarchical Cooperative Genetic Programming for Complex Piecewise Symbolic Regression}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In regression analysis, methodologies range from black-box approaches like artificial neural networks to white-box techniques like symbolic regression. Renowned for its trans-parency and interpretability, symbolic regression has become increasingly prominent in elucidating complex data relationships. Nevertheless, its effectiveness in managing complex piecewise symbolic regression tasks poses significant challenges. This paper introduces a novel Hierarchical Cooperative Genetic Program-ming (HCGP) framework to address this issue. The HCGP model utilizes a unique hierarchical structure, incorporating dual cooperative genetic programming (GP) populations. This innovative design significantly enhances the capability to solve complex piecewise symbolic regression problems. Implementing a scenario-based GP is central to the HCGP framework, which strategically selects the appropriate underlying calculation GP. This feature enables the system to autonomously learn and adapt to complex scenarios, selecting the most suitable calculation GPs for each case. Our HCGP approach distinguishes itself from traditional and state-of-the-art methods. It demonstrates particular proficiency in modeling piecewise expressions within complex scenarios. The empirical evaluation of our model, conducted using benchmark datasets, has exhibited its superior accuracy and computational efficiency. This progress emphasizes the potential of HCGP in sophisticated data modeling and marks a substantial advancement in a hierarchical structure in complex piecewise symbolic regression.},
  keywords={Adaptation models;Computational modeling;Sociology;Genetic programming;Evolutionary computation;Data models;Regression analysis;genetic programming;symbolic regression;hierarchical structure;evolutionary algorithm},
  doi={10.1109/CEC60901.2024.10611754},
  ISSN={},
  month={June},}@INPROCEEDINGS{10063510,
  author={Naretto, Francesca and Monreale, Anna and Giannotti, Fosca},
  booktitle={2022 IEEE 4th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Evaluating the Privacy Exposure of Interpretable Global Explainers}, 
  year={2022},
  volume={},
  number={},
  pages={13-19},
  abstract={In recent years we are witnessing the diffusion of AI systems based on powerful Machine Learning models which find application in many critical contexts such as medicine, financial market and credit scoring. In such a context it is particularly important to design Trustworthy AI systems while guaranteeing transparency, with respect to their decision reasoning and privacy protection. Although many works in the literature addressed the lack of transparency and the risk of privacy exposure of Machine Learning models, the privacy risks of explainers have not been appropriately studied. This paper presents a methodology for evaluating the privacy exposure raised by interpretable global explainers able to imitate the original black-box classifier. Our methodology exploits the well-known Membership Inference Attack. The experimental results highlight that global explainers based on interpretable trees lead to an increase in privacy exposure.},
  keywords={Privacy;Closed box;Machine learning;Cognition;Machine intelligence;Context modeling;Data privacy;Explainable AI;Machine Learning;Global Explainers},
  doi={10.1109/CogMI56440.2022.00012},
  ISSN={},
  month={Dec},}@ARTICLE{10466603,
  author={Al-Helali, Baligh and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Genetic Programming for Feature Selection Based on Feature Removal Impact in High-Dimensional Symbolic Regression}, 
  year={2024},
  volume={8},
  number={3},
  pages={2269-2282},
  abstract={Symbolic regression is increasingly important for discovering mathematical models for various prediction tasks. It works by searching for the arithmetic expressions that best represent a target variable using a set of input features. However, as the number of features increases, the search process becomes more complex. To address high-dimensional symbolic regression, this work proposes a genetic programming for feature selection method based on the impact of feature removal on the performance of SR models. Unlike existing Shapely value methods that simulate feature absence at the data level, the proposed approach suggests removing features at the model level. This approach circumvents the production of unrealistic data instances, which is a major limitation of Shapely value and permutation-based methods. Moreover, after calculating the importance of the features, a cut-off strategy, which works by injecting a number of random features and utilising their importance to automatically set a threshold, is proposed for selecting important features. The experimental results on artificial and real-world high-dimensional data sets show that, compared with state-of-the-art feature selection methods using the permutation importance and Shapely value, the proposed method not only improves the SR accuracy but also selects smaller sets of features.},
  keywords={Feature extraction;Data models;Computational modeling;Genetic programming;Task analysis;Predictive models;Machine learning;Feature selection;genetic programming;high dimensionality;symbolic regression},
  doi={10.1109/TETCI.2024.3369407},
  ISSN={2471-285X},
  month={June},}@INPROCEEDINGS{9882755,
  author={Fuchs, Caro and Kaymak, Uzay and Nobile, Marco S.},
  booktitle={2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Building Interpretable and Parsimonious Fuzzy Models using a Multi-Objective Approach}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Nowadays, the growing amounts of collected data enable the training of machine learning models that can be used to extract insights from the data and make better-informed decisions. Among the possible models that can be learned from data are fuzzy rule-based models, which are transparent and enable – when properly designed – interpretable artificial intelligence. One of the requirements of interpretability is a simple model structure, which can be achieved by performing feature selection and by limiting the number of rules in the model. However, the chosen feature set and the number of rules may interact and strongly affect the model’s accuracy. In this study, we employ techniques from the field of evolutionary computation to perform feature and rule number selection simultaneously. To ensure the developed models do not only perform well but are also interpretable and have good generalization capabilities, we adopt a multi-objective approach in which we train the models focusing on three objectives: performance, complexity, and model stability. In this way, we strive to develop simple, well-performing parsimonious fuzzy models. We show the effectiveness of our approach on three benchmark data sets.},
  keywords={Measurement;Training;Limiting;Computational modeling;Focusing;Machine learning;Data models;Fuzzy model;Feature selection;Model parameter estimation;Explainable AI (XAI;Multi-objective optimization},
  doi={10.1109/FUZZ-IEEE55066.2022.9882755},
  ISSN={1558-4739},
  month={July},}@ARTICLE{10734168,
  author={Dhurandhar, Amit and Pedapati, Tejaswini and Balakrishnan, Avinash and Chen, Pin-Yu and Shanmugam, Karthikeyan and Puri, Ruchir},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={Model Agnostic Contrastive Explanations for Classification Models}, 
  year={2024},
  volume={14},
  number={4},
  pages={789-798},
  abstract={Extensive surveys on explanations that are suitable for humans, claims that an explanation being contrastive is one of its most important traits. A few methods have been proposed to generate contrastive explanations for differentiable models such as deep neural networks, where one has complete access to the model. In this work, we propose a method, Model Agnostic Contrastive Explanations Method (MACEM), that can generate contrastive explanations for any classification model where one is able to only query the class probabilities for a desired input. This allows us to generate contrastive explanations for not only neural networks, but also models such as random forests, boosted trees and even arbitrary ensembles that are still amongst the state-of-the-art when learning on tabular data. Our method is also applicable to the scenarios where only the black-box access of the model is provided, implying that we can only obtain the predictions and prediction probabilities. With the advent of larger models, it is increasingly prevalent to be working in the black-box scenario, where the user will not necessarily have access to the model weights or parameters, and will only be able to interact with the model using an API. As such, to obtain meaningful explanations we propose a principled and scalable approach to handle real and categorical features leading to novel formulations for computing pertinent positives and negatives that form the essence of a contrastive explanation. A detailed treatment of this nature where we focus on scalability and handle different data types was not performed in the previous work, which assumed all features to be positive real valued with zero being indicative of the least interesting value. We part with this strong implicit assumption and generalize these methods so as to be applicable across a much wider range of problem settings. We quantitatively as well as qualitatively validate our approach over public datasets covering diverse domains.},
  keywords={Data models;Closed box;Computational modeling;Integrated circuit modeling;Predictive models;Circuits and systems;Signal processing algorithms;Random forests;Artificial neural networks;Perturbation methods;Explainable AI;Machine learning},
  doi={10.1109/JETCAS.2024.3486114},
  ISSN={2156-3365},
  month={Dec},}@ARTICLE{9839598,
  author={Pranolo, Andri and Mao, Yingchi and Wibawa, Aji Prasetya and Utama, Agung Bella Putra and Dwiyanto, Felix Andika},
  journal={IEEE Access}, 
  title={Robust LSTM With Tuned-PSO and Bifold-Attention Mechanism for Analyzing Multivariate Time-Series}, 
  year={2022},
  volume={10},
  number={},
  pages={78423-78434},
  abstract={The need for accurate time-series results is badly demanding. LSTM has been applied for forecasting time series, which is generated when variables are observed at discrete and equal time intervals. Nevertheless, the problem of determining hyperparameters with a relatively high random rate will reduce the accuracy of the prediction results. This paper aims to promote LSTM with tuned-PSO and Bifold-Attention mechanism. PSO optimizes LSTM hyperparameters, and Bifold-attention mechanism selects the optimal input for LSTM. An accurate, adaptive, and robust time-series forecasting model is the main contribution, compared with ARIMA, MLP, LSTM, PSO-LSTM, A-LSTM, and PSO-A-LSTM. The model comparison is based on the accuracy of each model in forecasting Beijing PM2.5, Beijing Multi-Site, Air Quality, Appliances Energy, Wind Speed, and Traffic Flow. The Proposed model, LSTM with tuned-PSO and Bifold-Attention mechanism, has lower MAPE and RMSE than baselines. In other words, the model outperformed all LSTM base models in this study. The proposed model’s accuracy is adaptable in daily, weekly, and monthly multivariate time-series datasets. This ground-breaking innovation is valuable for time-series analysis research, particularly the implementation of deep learning for time-series forecasting.},
  keywords={Logic gates;Forecasting;Predictive models;Atmospheric modeling;Adaptation models;Time series analysis;Computer architecture;Bifold-attention mechanism;PSO;LSTM;multivariate time-series;forecasting},
  doi={10.1109/ACCESS.2022.3193643},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10101590,
  author={Udas, Pritom Biswas and Roy, Kowshik Sankar and Karim, Md. Ebtidaul and Azmat Ullah, Shah Muhammad},
  booktitle={2023 International Conference on Electrical, Computer and Communication Engineering (ECCE)}, 
  title={Attention-based RNN architecture for detecting multi-step cyber-attack using PSO metaheuristic}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the intensive usage of electronic devices called for a greater threat to preventing a massive volume of information generated by billions of users every second. Therefore, ensuring the stability of these data is deemed to be the cornerstone of the field of cyber security. However, the reliability of any cyber security system has often been compromised with the introduction of various malware and intrusive features within the system. To deal with such abnormal characteristics, an Intrusion Detection System (IDS) has played a vital role over the years. Countless work has continuously been performed to make the IDS more effective and reliable than ever. In this paper, an attention-based Recurrent Neural Network (RNN) model has been proposed for detecting various multi-step cyber-attacks in the network. Our classification model comprises a Long Short-Term Memory (LSTM) unit with an Attention layer. A metaheuristic approach, Particle Swarm Optimization (PSO), has been utilized to exploit the most effective and suitable features with a 72.73% reduction rate from the dataset along with reduced computational complexity and time consumption of around three times less as well as improved detection rate by greater than 1%. This proposed method's performance is evaluated against several evaluation metrics and further analyzed against several traditional classifiers. When compared to the corresponding values of different models on the same dataset, experimental results show significantly improved results in different aspects using the proposed approach.},
  keywords={Measurement;Recurrent neural networks;Computational modeling;Metaheuristics;Network intrusion detection;Computer architecture;Stability analysis;Cyber Security;Deep Learning;Attention Layer;Feature Selection;Network Intrusion Detection;Particle Swarm Optimization},
  doi={10.1109/ECCE57851.2023.10101590},
  ISSN={},
  month={Feb},}@ARTICLE{10697118,
  author={Ileberi, Emmanuel and Sun, Yanxia},
  journal={IEEE Access}, 
  title={Machine Learning-Assisted Cervical Cancer Prediction Using Particle Swarm Optimization for Improved Feature Selection and Prediction}, 
  year={2024},
  volume={12},
  number={},
  pages={152684-152695},
  abstract={Cervical cancer is a common and deadly disease that affects women worldwide. Early diagnosis and treatment can improve the survival and quality of life of patients. Machine learning techniques can help to analyze complex and high-dimensional data related to cervical cancer and provide accurate and reliable predictions. However, selecting the most relevant and informative features from the data is a challenging task that affects the performance and interpretability of machine learning models. This paper proposes a novel method that uses particle swarm optimization (PSO) to perform feature selection and optimization for cervical cancer prediction. PSO is a bio-inspired algorithm that mimics the social behavior of a swarm of particles that search for the optimal solution in the feature space. The use of PSO to select the best subset of features that maximize the classification accuracy of eight machine learning models: Support Vector Machines (SVM), Gaussian Naive Bayes (GNB), Random Forests (RF), Decision Trees (DT), Extreme Gradient Boosting (XGB), Linear Regression (LR), Adaptive Boosting (AdaBoost), and K-nearest neighbor (KNN).To evaluate the method, a publicly available dataset was used, the Cervical Cancer Risk Factors Dataset (CCRFD). Then, compare the results with several state-of-the-art methods that use different feature selection techniques and ML algorithms. The experimental results show that the method achieves superior performance in terms of feature reduction rate, accuracy, precision, and AUC. Specifically, the Adaboost-PSO model performed best in terms of feature reduction rate with a reduction of rate 100% while the RF-PSO model performed best in terms of accuracy and precision, with an accuracy of 98% and precision of 100%.},
  keywords={Cervical cancer;Machine learning;Accuracy;Feature extraction;Nearest neighbor methods;Data models;Support vector machines;Predictive models;Particle swarm optimization;Random forests;Machine learning;feature selection;cervical cancer;particle swarm optimization},
  doi={10.1109/ACCESS.2024.3469869},
  ISSN={2169-3536},
  month={},}@ARTICLE{10473134,
  author={Li, Tao and Qian, Yuhua and Li, Feijiang and Liang, Xinyan and Zhan, Zhi-Hui},
  journal={IEEE Transactions on Big Data}, 
  title={Feature Subspace Learning-Based Binary Differential Evolution Algorithm for Unsupervised Feature Selection}, 
  year={2025},
  volume={11},
  number={1},
  pages={99-114},
  abstract={It is a challenging task to select the informative features that can maintain the manifold structure in the original feature space. Many unsupervised feature selection methods still suffer the poor cluster performance in the selected feature subset. To tackle this problem, a feature subspace learning-based binary differential evolution algorithm is proposed for unsupervised feature selection. First, a new unsupervised feature selection framework based on evolutionary computation is designed, in which the feature subspace learning and the population search mechanism are combined into a unified unsupervised feature selection. Second, a local manifold structure learning strategy and a sample pseudo-label learning strategy are presented to calculate the importance of the selected feature subspace. Third, the binary differential evolution algorithm is developed to optimize the selected feature subspace, in which the binary information migration mutation operator and the adaptive crossover operator are designed to promote the searching for the global optimal feature subspace. Experimental results on various types of real-world datasets demonstrate that the proposed algorithm can obtain more informative feature subset and competitive cluster performance compared with eight state-of-the-art unsupervised feature selection methods.},
  keywords={Feature extraction;Manifolds;Optimization;Clustering algorithms;Sociology;Search problems;Big Data;Evolutionary computation;local manifold structure;pseudo-label;unsupervised feature selection},
  doi={10.1109/TBDATA.2024.3378090},
  ISSN={2332-7790},
  month={Feb},}@INPROCEEDINGS{10092226,
  author={Straub, Jeremy},
  booktitle={2022 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)}, 
  title={Increasing Trust in Artificial Intelligence with a Defensible AI Technique}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Artificial intelligence (AI) systems are prevalent throughout society and have significant impact on peoples’ everyday lives. Explainable artificial intelligence techniques have been developed in response to concerns about the opaqueness of many AI techniques, given their potential impact. Explainable techniques, though, do not guarantee performance – instead, they simply explain what was recommended or decided. This paper discusses how a new class of AI techniques, defensible AI (DAI) can increase public trust in AI. Issues with existing techniques are reviewed and an example DAI technique is presented and its benefits – relative to reliability, trust and security – are assessed.},
  keywords={Conferences;Pattern recognition;Security;Reliability;Artificial intelligence;artificial intelligence;trust;defensible AI;DAI;explainable AI;XAI;neural networks},
  doi={10.1109/AIPR57179.2022.10092226},
  ISSN={2332-5615},
  month={Oct},}@ARTICLE{10679181,
  author={Yu, Kunjie and Lian, Jintao and Bi, Ying and Liang, Jing and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={An Automated and Interpretable Computer-Aided Approach for Skin Cancer Diagnosis Using Genetic Programming}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Malignant melanoma is a very deadly form of skin cancer and early diagnosis can significantly reduce the mortality rate. Many computer-aided diagnosis (CAD) systems have been developed as second opinion diagnostic aids to assist dermatologists in diagnosing malignant melanoma. However, traditional CAD systems often require domain knowledge for feature extraction, while neural network-based CAD systems require specialized knowledge for designing network structures and often have poor interpretability. In this paper, we propose a new skin cancer CAD system based on genetic programming (GP) to automatically learn effective features for classification with strong interpretability. The approach can automatically evolve variable-length models to extract informative features for describing skin cancer images based on a relatively simple program structure, a new function set, and a terminal set. In addition, compared with other GP methods, this approach employs a newly proposed duplicate subtree removing mechanism, which can effectively prevent the duplication of features, thereby simplifying the model and enhancing its interpretability. The proposed approach has been examined on five real-world skin cancer classification tasks. The results suggest that the proposed approach achieves better performance than GP-based, neural network-based feature learning comparison methods and traditional comparison methods in most cases. Further analysis shows that the proposed approach has employed a smaller tree structure and can automatically evolve/learn models with potentially high interpretability.},
  keywords={Skin cancer;Feature extraction;Image classification;Skin;Representation learning;Solid modeling;Computational modeling;genetic programming;skin cancer computer-aided diagnosis systems;interpretability;evolutionary computation;image classification},
  doi={10.1109/TEVC.2024.3459096},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10767477,
  author={Sonu and Nisha and Narayan, Satya and Jain, Vinesh Kumar},
  booktitle={2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC)}, 
  title={Enhanced Hand Gesture Recognition Using Image Transformer Model and Particle Swarm Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This study introduces the Image Transformer Model, a novel approach to enhance hand gesture recognition, leveraging recent advancements in deep learning and computer vision. By utilizing the Transformer's attention mechanism, the model excels in capturing intricate spatial correlations within visual data. It processes input as flattened patches, enabling comprehensive interpretation of spatial relationships in hand gesture images. The model thoughtfully combines various elements, including Multi-Head Self-Attention, FFN Network, Layer Normalization, & residual connections, resulting in superior performance compared to established models. The research further extends the model's capabilities through the incorporation of a Multi-Head Attention-based Transformer Network, complemented by Particle Swarm Optimization (PSO). By successfully optimizing hyperparameters with PSO, the model demonstrates improved recognition of complex spatial correlations in hand gesture images, outperforming such methods. The fusion of the Image Transformer Model & PSO tuning represents a significant advancement in the field of hand gesture identification, promising valuable applications across diverse domains.},
  keywords={Visualization;Sign language;Accuracy;Image recognition;Correlation;Computational modeling;Transformers;Data models;Particle swarm optimization;Tuning;Hand Gesture Recognition;Image Transformer Model;Spatial Dependencies;Multi-Head Self-Attention;PSO},
  doi={10.1109/ETNCC63262.2024.10767477},
  ISSN={},
  month={July},}@INPROCEEDINGS{10263962,
  author={Jovanovic, Andjela and Dogandzic, Tea and Dobrojevic, Milos and Sarac, Marko and Bacanin, Nebojsa and Zivkovic, Miodrag},
  booktitle={2023 IEEE World Conference on Applied Intelligence and Computing (AIC)}, 
  title={Gold Prices Forecasting Using Recurrent Neural Network with Attention Tuned by Metaheuristics}, 
  year={2023},
  volume={},
  number={},
  pages={345-350},
  abstract={A large number of statistical studies have proven that the value of gold is highly valued nowadays, despite the numerous crises that have hit the global market. Due to the great risks that daily affect sudden changes in gold prices on the global market, it is of great benefit to develop tools that will enable automated monitoring and prediction of gold price changes. This can be quite helpful for those countries and major corporations whose economy depends on this. In this paper recurrent neural network with attention layer was used to forecast the gold price, while the hyperparameters of the network were tuned by the novel variant of the particle swarm optimization algorithm. Obtained results in terms of standard regression metrics were compared to those generated by other cutting-edge methods and proposed method proved to be very promising in this area.},
  keywords={Gold;Recurrent neural networks;Metaheuristics;Globalization;Prediction algorithms;Stakeholders;Task analysis;Neural networks;AI;RNN;attention;PSO;gold prices;time-series;prediction;metaheuristics optimization},
  doi={10.1109/AIC57670.2023.10263962},
  ISSN={},
  month={July},}@INPROCEEDINGS{11004766,
  author={TOUMI, Amina and Mohamed, Hagar M. and Elsayed, Sally M.},
  booktitle={2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)}, 
  title={Harnessing Computational Intelligence: In-Depth Applications in Biology and Medicine}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Computational Intelligence (CI) has significantly impacted biology and medicine by enhancing diagnostics, treatment planning, and biological research. CI techniques like artificial neural networks, fuzzy logic, and evolutionary algorithms have revolutionized diagnostics, treatment planning, and biological research by processing high-dimensional, nonlinear, and uncertain data. This study highlights the role of CI in advancing healthcare through innovations such as explainable AI, adaptive systems, and multimodal data fusion. While CI improves accuracy and personalization, challenges remain in data quality, interpretability, and computational demands. Integrative approaches, combining various CI techniques, are key in areas like drug discovery, personalized medicine, and disease modeling. Future research should focus on interdisciplinary collaboration, standardization, and ethical governance to ensure sustainable progress.},
  keywords={Technological innovation;Ethics;Computational modeling;Precision medicine;Collaboration;Medical services;Transforms;Standardization;Planning;Medical diagnostic imaging;Computational Intelligence;Computational modeling;Biological system modeling;Decision making;Ethical and Legal issues},
  doi={10.1109/ITIKD63574.2025.11004766},
  ISSN={},
  month={April},}@INPROCEEDINGS{10611755,
  author={Anfar, Mohamad Rimas Mohamad and Chen, Qi and Zhang, Mengjie},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Feature Selection for GPSR Based on Maximal Information Coefficient and Shapley Values}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Feature selection is a critical aspect of improving the interpretability of machine learning models. Genetic Programming (GP) has a built-in feature selection mechanism that explores the search space to include informative features in models. However, this built-in mechanism is insufficient for identifying important features, when dealing with high-dimensional feature spaces. To overcome this limitation, the paper introduces a novel feature importance measurement based on the Maximal Infor-mation Coefficient and Shapley Values. The proposed algorithm operates in two stages. In the first stage, it identifies the best individuals from different populations. In the second stage, the best individuals from the first stage are utilized for the calculation of the novel individual feature importance measurement. The new feature importance measurement offers valuable insights into the significance and relevance of the selected features. Regression experiments were conducted on six datasets to assess the effectiveness of the proposed method. Furthermore, comparisons were made with two other algorithms to evaluate its performance. The results indicate that the proposed approach enhances GP performance for high dimensional datasets while maintaining GP trees of similar size compared to standard GP.},
  keywords={Microwave integrated circuits;Filters;Genetic programming;Focusing;Machine learning;Feature extraction;Time measurement;Space exploration;Standards;Testing;Feature importance;Genetic programming;MIC;symbolic regression;Shapley value},
  doi={10.1109/CEC60901.2024.10611755},
  ISSN={},
  month={June},}@ARTICLE{10198433,
  author={Ahsan, Md. Manjurul and Ali, Md. Shahin and Hassan, Md. Mehedi and Abdullah, Tareque Abu and Gupta, Kishor Datta and Bagci, Ulas and Kaushal, Chetna and Soliman, Naglaa F.},
  journal={IEEE Access}, 
  title={Monkeypox Diagnosis With Interpretable Deep Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={81965-81980},
  abstract={As the world gradually recovers from the impacts of COVID-19, the recent global spread of Monkeypox disease has raised concerns about another potential pandemic, highlighting the urgency of early detection and intervention to curb its transmission. Deep Learning (DL)-based disease prediction presents a promising solution, offering affordable and accessible diagnostic services. In this study, we harnessed Transfer Learning (TL) techniques to tweak and assess the performance of an array of six different DL models, encompassing VGG16, InceptionResNetV2, ResNet50, ResNet101, MobileNetV2, VGG19, and Vision Transformer (ViT). Among this diverse collection, it was the modified versions of the VGG19 and MobileNetV2 models that outshone the others, boasting striking accuracy rates ranging from an impressive 93% to an astounding 99%. Our results echo the findings of recent research endeavors that similarly showcase enhanced performance when developing disease diagnostic models armed with the power of TL. To add to this, we used Local Interpretable Model Agnostic Explanations (LIME) to lend a sense of transparency to our model’s predictions and identify the crucial features correlating with the onset of Monkeypox disease. These findings offer significant implications for disease prevention and control efforts, particularly in remote and resource-limited areas.},
  keywords={Diseases;Skin;Computer viruses;Lesions;Deep learning;Data models;Transfer learning;Image processing;Deep learning;monkeypox;disease diagnosis;transfer learning;image processing;LIME},
  doi={10.1109/ACCESS.2023.3300793},
  ISSN={2169-3536},
  month={},}@ARTICLE{10965770,
  author={Huang, Yuxiao and Wu, Shenghao and Zhang, Wenjie and Wu, Jibin and Feng, Liang and Tan, Kay Chen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Autonomous Multi-Objective Optimization Using Large Language Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Multi-objective optimization problems (MOPs) are ubiquitous in real-world applications, presenting a complex challenge of balancing multiple conflicting objectives. Traditional multi-objective evolutionary algorithms (MOEAs), though effective, often rely on domain-specific expertise for improved optimization performance, hindering adaptability to unseen MOPs. In recent years, the Large Language Models (LLMs) has revolutionized software engineering by enabling the autonomous generation and refinement of programs. Leveraging this breakthrough, we propose a new LLM-based framework that autonomously designs MOEAs for solving MOPs. The proposed framework includes a robust testing module to refine the generated MOEA through error-driven dialogue with LLMs, a dynamic selection strategy along with informative prompting-based crossover and mutation to fit textual optimization pipeline. Our approach facilitates the design of MOEA without the extensive demands for expert intervention, thereby speeding up the innovation of MOEA. Empirical studies across various MOP categories validate the robustness and superior performance of our proposed framework.},
  keywords={Optimization;Search problems;Traveling salesman problems;Testing;Large language models;Urban areas;Programming;Pipelines;Lead;Heuristic algorithms;Multi-objective Optimization;Automatic Algorithm Design;Large Language Model},
  doi={10.1109/TEVC.2025.3561001},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10776111,
  author={Wang, Xin-yue and Hu, Ying and Luo, Yong-long and Jin, Xin and Kan, Zi-shun},
  booktitle={2024 International Conference on New Trends in Computational Intelligence (NTCI)}, 
  title={A PSO-based Surrogate-Assisted Federated Feature Selection Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={256-264},
  abstract={High-dimensional feature selection (FS) problems face challenges such as the “curse of dimensionality” and high computational costs. In addition, a large amount of high-dimensional data describing the same learning task may be horizontally distributed among different institutions (called participants) and cannot be shared because of privacy protection limitations, further increasing the difficulty of high-dimensional FS problems. Therefore, a surrogate-assisted federated evolutionary FS algorithm based on particle swarm optimization (PSO) is proposed to solve the FS problem of high-dimensional data with multi-party participation under privacy protection. First, a joint filtered FS method based on the XGBoost model is proposed, which significantly reduces the initial space of features while ensuring privacy. Subsequently, a surrogate-assisted federated evolutionary FS algorithm framework under privacy protection is designed, and based on this framework, a joint construction and management strategy for the surrogate model, a joint evaluation strategy based on the surrogate model, and a joint update strategy for particles are developed. Finally, the proposed algorithm is applied to 10 test datasets, and compared with two typical evolutionary FS algorithms. The experimental results show that the proposed algorithm can not only ensure the classification performance but also significantly improve the efficiency of the algorithm while protecting the privacy of the participant data.},
  keywords={Privacy;Data privacy;Federated learning;Filtering algorithms;Feature extraction;Market research;Classification algorithms;Computational efficiency;Protection;Particle swarm optimization;feature selection;evolutionary algorithm;surrogate-assisted;privacy protection},
  doi={10.1109/NTCI64025.2024.10776111},
  ISSN={},
  month={Oct},}@ARTICLE{9782691,
  author={Bidgoli, Azam Asilian and Rahnamayan, Shahryar and Dehkharghanian, Taher and Riasatian, Abtin and Tizhoosh, Hamid R.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Evolutionary Computation in Action: Hyperdimensional Deep Embedding Spaces of Gigapixel Pathology Images}, 
  year={2023},
  volume={27},
  number={1},
  pages={52-66},
  abstract={One of the main obstacles of adopting digital pathology is the challenge of efficient processing of hyperdimensional digitized biopsy samples, called whole slide images (WSIs). Exploiting deep learning and introducing compact WSI representations are urgently needed to accelerate image analysis and facilitate the visualization and interpretability of pathology results in a postpandemic world. In this article, we introduce a new evolutionary approach for WSI representation based on large-scale multiobjective optimization (LSMOP) of deep embeddings. We start with patch-based sampling to feed KimiaNet, a histopathology-specialized deep network, and to extract a multitude of feature vectors. Coarse multiobjective feature selection uses the reduced search space strategy guided by the classification accuracy and the number of features. In the second stage, the frequent features histogram (FFH), a novel WSI representation, is constructed by multiple runs of coarse LSMOP. Fine evolutionary feature selection is then applied to find a compact (short-length) feature vector based on the FFH and contributes to a more robust deep-learning approach to digital pathology supported by the stochastic power of evolutionary algorithms. We validate the proposed schemes using The Cancer Genome Atlas (TCGA) images in terms of WSI representation, classification accuracy, and feature quality. Furthermore, a novel decision space for multicriteria decision making in the LSMOP field is introduced. Finally, a patch-level visualization approach is proposed to increase the interpretability of deep features. The proposed evolutionary algorithm finds a very compact feature vector to represent a WSI (almost 14000 times smaller than the original feature vectors) with 8% higher accuracy compared to the codes provided by the state-of-the-art methods},
  keywords={Feature extraction;Optimization;Evolutionary computation;Data mining;Histopathology;Cancer;Task analysis;Deep neural network (DNN);digital pathology;dimension reduction;evolutionary computation (EC);feature selection;image representation;innovization;large-scale multiobjective optimization (LSMOP);transfer learning},
  doi={10.1109/TEVC.2022.3178299},
  ISSN={1941-0026},
  month={Feb},}
