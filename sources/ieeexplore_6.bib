@ARTICLE{11029210,
  author={Fanani, Ahmad Zainul and Maulana Syarif, Arry and Novita Dewi, Ika and Karim, Abdul},
  journal={IEEE Access}, 
  title={Enhancing Creativity and Validation in Explanatory Deep Learning-Based Symbolic Music Generation: A Hybrid Approach With LSTM and Genetic Algorithms}, 
  year={2025},
  volume={13},
  number={},
  pages={105280-105301},
  abstract={This research proposes an explanatory deep learning-based music generation approach, where the output of a deep learning model is validated through a set of predefined musical rules, with a refinement process applied when inaccuracies are detected. The study focuses on gamelan, a traditional form of Indonesian music. A Long Short-Term Memory (LSTM) network is used to generate musical compositions, while a modified Genetic Algorithm (GA), omitting the selection and crossover operators, performs validation and, when necessary, refinement via mutation. The LSTM network produces initial compositions, and the GA module ensures compliance with musical rules, enhancing both explainability and creativity. The model successfully generates new bars and lines with notation sequences not found in the original dataset, indicating creative variation. Whether produced directly by the LSTM or refined through GA, the generated output demonstrates the system’s ability to innovate while preserving core musical characteristics. Furthermore, the GA-based validation allows the generated music to be interpreted in terms of the underlying rule constraints. The evaluation using the Pearson’s Correlation Coefficient T-test provides supporting evidence that the proposed automatic music generation (AMG) model is capable of learning and generating gamelan music effectively. The LSTM component, functioning based on its ability to creatively generate note sequences, and the GA component, tasked with validation and refinement, have both proven to collaborate effectively and fulfill their respective roles. These findings support the effectiveness of the proposed model in fostering creative exploration of new tonal patterns aligned with the target genre.},
  keywords={Music;Long short term memory;Genetic algorithms;Deep learning;Artificial intelligence;Creativity;Training;Bars;Tuning;Computational modeling;Automatic music generation;long-short term memory;genetic algorithms;LSTM-GA;explanatory-based music generation;gamelan},
  doi={10.1109/ACCESS.2025.3578449},
  ISSN={2169-3536},
  month={},}@ARTICLE{10746601,
  author={Li, Xiang and Zhao, Lin and Zhang, Lu and Wu, Zihao and Liu, Zhengliang and Jiang, Hanqi and Cao, Chao and Xu, Shaochen and Li, Yiwei and Dai, Haixing and Yuan, Yixuan and Liu, Jun and Li, Gang and Zhu, Dajiang and Yan, Pingkun and Li, Quanzheng and Liu, Wei and Liu, Tianming and Shen, Dinggang},
  journal={IEEE Reviews in Biomedical Engineering}, 
  title={Artificial General Intelligence for Medical Imaging Analysis}, 
  year={2025},
  volume={18},
  number={},
  pages={113-129},
  abstract={Large-scale Artificial General Intelligence (AGI) models, including Large Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented success in a variety of general domain tasks. Yet, when applied directly to specialized domains like medical imaging, which require in-depth expertise, these models face notable challenges arising from the medical field's inherent complexities and unique characteristics. In this review, we delve into the potential applications of AGI models in medical imaging and healthcare, with a primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We provide a thorough overview of the key features and enabling techniques of LLMs and AGI, and further examine the roadmaps guiding the evolution and implementation of AGI models in the medical sector, summarizing their present applications, potentialities, and associated challenges. In addition, we highlight potential future research directions, offering a holistic view on upcoming ventures. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare, and beyond.},
  keywords={Biomedical imaging;Transformers;Artificial general intelligence;Adaptation models;Data models;Training;Biological system modeling;Analytical models;Reviews;Medical diagnostic imaging;Artificial general intelligence;foundation model;large language model;large vision model;medical imaging},
  doi={10.1109/RBME.2024.3493775},
  ISSN={1941-1189},
  month={},}@INPROCEEDINGS{10069323,
  author={Lehavi, Adam and Kim, Seongtae},
  booktitle={2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Feature Reduction Method Comparison Towards Explainability and Efficiency in Cybersecurity Intrusion Detection Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1326-1333},
  abstract={In the realm of cybersecurity, intrusion detection systems (IDS) detect and prevent attacks based on collected computer and network data. In recent research, IDS models have been constructed using machine learning (ML) and deep learning (DL) methods such as Random Forest (RF) and deep neural networks (DNN). Feature selection (FS) can be used to construct faster, more interpretable, and more accurate models. We look at three different FS techniques; RF information gain (RF-IG), correlation feature selection using the Bat Algorithm (CFS-BA), and CFS using the Aquila Optimizer (CFS-AO). Our results show CFS-BA to be the most efficient of the FS methods, building in 55% of the time of the best RF-IG model while achieving 99.99% of its accuracy. This reinforces prior contributions attesting to CFS-BA’s accuracy while building upon the relationship between subset size, CFS score, and RF-IG score in final results.},
  keywords={Radio frequency;Deep learning;Correlation;Machine learning algorithms;Computational modeling;Buildings;Neural networks;Correlation Feature Selection;Information Gain;Metaheuristic Optimizer;Bat Algorithm;Aquila Algorithm;Intrusion Detection;Correlation;Cyber Security;Random Forest;Deep Neural Network;Explainability},
  doi={10.1109/ICMLA55696.2022.00211},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10363847,
  author={Pedron, Maxime and Ganesan, Prasanth and Feng, Ruibin and Deb, Brototo and Chang, Hui and Ruiperez-Campillo, Samuel and Somani, Sulaiman and Desai, Yaanik and Rogers, Albert J and Clopton, Paul and Narayan, Sanjiv M},
  booktitle={2023 Computing in Cardiology (CinC)}, 
  title={Defining the Predictive Ceiling of Electrogram Features Alone for Predicting Outcomes From Atrial Fibrillation Ablation}, 
  year={2023},
  volume={50},
  number={},
  pages={1-4},
  abstract={The aim of this study is to improve the prediction of long-term outcomes in patients with atrial fibrillation solely using electrogram (EGM) features. We developed three distinct models based on data from a cohort of $N=561$ patients, each targeting different aspects of EGM analysis: •Principal Component Analysis (PCA): We applied PCA to analyze the variances of eigenvectors projecting more than a fixed threshold of the overall variance (15%). To identify common projection axes among these eigenvectors, we employed the k-means algorithm for clustering. •Auto Regressive: This technique involves applying a bijective transformation to the coefficients, which are subsequently used as input for various machine learning classifiers, including Random Forest or Support Vector Classifier. •Feature Engineering: We performed feature engineering by extracting voltage, rate, and shape similarity metrics from raw EGM (Electrogram) data.},
  keywords={Measurement;Machine learning algorithms;Shape;Soft sensors;Atrial fibrillation;Support vector machine classification;Feature extraction},
  doi={10.22489/CinC.2023.073},
  ISSN={2325-887X},
  month={Oct},}@ARTICLE{9573343,
  author={Ganguly, Biswarup and Dey, Debangshu and Munshi, Sugata},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Image Visibility Filter-Based Interpretable Deep Learning Framework for Skin Lesion Diagnosis}, 
  year={2022},
  volume={18},
  number={8},
  pages={5138-5147},
  abstract={Computer-aided diagnosis have made a significant breakthrough in skin lesion diagnosis employing deep learning (DL) frameworks over the years, but it hardly reveals the transparency of the DL architecture. To mitigate this issue, in this article, we propose an image visibility filter (IVF) based DL framework for skin lesion diagnosis. The proposed IVF-DL network employs a ResNet architecture where visibility patches, extracted from the image visibility graph (IVG), are used as the convolutional kernels to extract salient features from dermoscopic images. The primary aim of this article is not only to classify skin lesions but also to depict the interpretable results after each residual block in a supervised manner. An optimal performance has been obtained by tuning three hyperparameters of the proposed method. Furthermore, the final interpretable result has been analyzed via IVG to resemble its spatial characteristics. Experimental results reveal that the proposed system outperforms the state-of-the-art classification methods quantitatively in terms of four performance metrics (accuracy, sensitivity, specificity, and area under the receiver operating curve) and qualitatively in terms of class activation map and relevance map considering two benchmark datasets.},
  keywords={Lesions;Skin;Feature extraction;Convolution;Cancer;Melanoma;Sensitivity;Computer-aided diagnosis (CAD);deep learning (DL);dermoscopic images;image visibility filter (IVF);skin lesion interpretation},
  doi={10.1109/TII.2021.3119711},
  ISSN={1941-0050},
  month={Aug},}@ARTICLE{10485415,
  author={Huynh, Duy C. and Ho, Loc D. and Pham, Hieu M. and Dunnigan, Matthew W. and Barbalata, Corina},
  journal={IEEE Access}, 
  title={Water Wave Optimization Algorithm-Based Dynamic Optimal Dispatch Considering a Day-Ahead Load Forecasting in a Microgrid}, 
  year={2024},
  volume={12},
  number={},
  pages={48027-48043},
  abstract={A novel strategy is proposed to tackle an optimal dispatch of a microgrid in response to dynamic conditions, utilizing a water wave optimization (WWO) algorithm and considering a day-ahead load forecasting. Amongst meta-heuristic algorithms, the WWO algorithm stands out in terms of population size, parameter tuning, exploitation and exploration, convergence speed, as well as optimization mechanism. It leverages its ability to efficiently explore solution spaces and adapt to changing conditions. It is applied to the dynamic optimal dispatch of a microgrid with the uncertainty of load power considered and solved by day-ahead load forecasting. It dynamically adjusts the microgrid operation in response to these inputs, ensuring optimal decision-making in the face of varying load scenarios. With the competition of various day-ahead load forecasting techniques in the microgrid, a multi-variate linear regression (MLR) model shows its advantage features, being more transparent, more effective, and more robust than other techniques, especially transparent explainability, as well as simple and fast in model training. These are requirements to achieve the result of day-ahead load forecasting. Thus, the MLR model is proposed to forecast day-ahead load in the microgrid in this paper. The simulation results show that the percentage error (PE) between the MLR model-based forecasted and actual load powers is always less than 4.42%, the mean absolute percentage error (MAPE) of the forecasting result is 3.33%, and the execution time is 49 (s). These achievements meet the accurate and fast requirements. They are completely competitive with the results of using other techniques such as convolutional neural networks (CNN) and long short-term memory (LSTM), especially in the execution time. This has contributed to improving the efficiency of the dynamic optimal dispatch in the microgrid. Then, the diesel generation, battery energy storage, and total microgrid generation costs are 68.76 ( ${\$}$ ), 5.09 ( ${\$}$ ), and 73.85 ( ${\$}$ ) respectively by using the WWO algorithm which are better than those by using a genetic algorithm (GA), a non-dominated sorting genetic algorithm-II (NSGA-II), a particle swarm optimization (PSO) algorithm, and a transient search optimization (TSO) algorithm in the microgrid. The findings offer valuable insights for microgrid operators, energy planners, and policymakers seeking sustainable and cost-effective solutions for distributed energy resource management.},
  keywords={Microgrids;Heuristic algorithms;Optimization;Power system dynamics;Load modeling;Load forecasting;Predictive models;Load forecasting;Genetic algorithms;Convolutional neural networks;Energy storage;Dynamic optimal dispatch;day-ahead load forecasting;microgrid;water wave optimization algorithm},
  doi={10.1109/ACCESS.2024.3382982},
  ISSN={2169-3536},
  month={},}@ARTICLE{10683701,
  author={Islem Adnane, Youcef and Zerari, Mounira},
  journal={IEEE Access}, 
  title={Optimizing Business Intelligence Classification Rule Mining Using Quantum-Inspired Genetic Algorithm}, 
  year={2024},
  volume={12},
  number={},
  pages={137041-137053},
  abstract={This research introduces a novel approach to enhance knowledge discovery through the construction of classification rules for improved event prediction within the domain of business intelligence. One of the applications of the solution can be the improvement of large-scale advertising campaign forecasting. In order to solve the existing problems of data imbalance and high dimensionality in practical applications, we present a new approach of quantum-inspired genetic algorithm (QIGA). Our methodology employs a two-phase strategy: the first phase utilizes QIGA for fast attribute selection while the second phase enhances the manner in which categorical data is represented to enhance rule interpretability. This combined approach is very efficient in producing accurate and usable classification rules without requiring a lot of data pre-processing. Experimental evaluation on benchmark datasets demonstrates the superiority of our proposed method in terms of precision, reliability, and efficiency when compared to traditional approaches. Thus, the proposed algorithm enhances the state-of-art in knowledge discovery by providing a practical and scalable solution to the problem of handling imbalanced data and reducing the effect of high dimensionality, which allows for improving the accuracy of event prediction. Thus, the findings of this research can be applied to various fields other than advertising including fraud detection, customer churn, and medical diagnosis.},
  keywords={Genetic algorithms;Classification algorithms;Accuracy;Optimization;Quantum mechanics;Business intelligence;Probabilistic logic;Data mining;Business intelligence;classification rule;data mining;genetic algorithm;quantum-inspired algorithm},
  doi={10.1109/ACCESS.2024.3463506},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10707760,
  author={Han, Bin and Guo, Tao},
  booktitle={2024 IEEE International Conference on Sensing, Diagnostics, Prognostics, and Control (SDPC)}, 
  title={Research on Sliding Bearing Fault Diagnosis Method based on GA-MSCNN}, 
  year={2024},
  volume={},
  number={},
  pages={220-223},
  abstract={Aiming at the problem that various faults may occur in plain bearings due to long-term operation and load changes, this paper proposes a fault diagnosis method for plain bearings based on graph-attention-multiscale convolutional neural network (GA-MSCNN). Firstly, two-dimensional features are extracted using Markov transfer field (MTF), and then the GA-MSCNN model is built, and the effective global features obtained by using GA and the effective local features obtained by using MSCNN are fused to obtain a strengthened feature map, which accurately captures the time-dependent features extracted by MTF; finally, the two-dimensional features extracted by MTF are input into AM-MSCNN to complete the feature extraction and fault classification.},
  keywords={Fault diagnosis;Vibrations;Training;Adaptation models;Feature extraction;Sensors;Convolutional neural networks;Load modeling;fault diagnosis;graph attention mechanism;MSCNN},
  doi={10.1109/SDPC62810.2024.10707760},
  ISSN={},
  month={July},}@INPROCEEDINGS{10984080,
  author={Kaur, Harminder and Raheja, Neeraj and Bindal, Amit Kumar},
  booktitle={2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Optimization and Classification for Plant Leaf Detection Using Multi-Objective Genetic Algorithm and Random Forest}, 
  year={2024},
  volume={},
  number={},
  pages={170-175},
  abstract={The agricultural sector in India, a developing nation, relies heavily on agriculture for its population's livelihood and food security. Plants are essential for sustenance, medicine, and various industries. This study is focused on the production and subsequent evaluation of an advanced plant disease classification method using Plant Village dataset. The proposed approach integrates texture feature extraction, multi-objective optimization, and Random Forest Classifier to enhance classification accuracy and efficiency. The NSGRF approach, a key component of the system, significantly outperforms in terms of precision, F-score, recall, and accuracy. In experiment survey the algorithm NSGRF improves 2% accuracy, 1 % precision and 2 % of recall and 1% of f-score as compared to other approaches. Author describes the process of the proposed model across various classes of Tomato, Potato and Pepper-Bell. They have successfully verified the performance of proposed model on a plant village dataset consisting of 15 different classes, including Tomato, Potato, and Bell-Pepper. Additionally, the study discussed their findings and contrasted this with the proposed model. The proposed NSGRF method exhibits superior performance in comparison to alternative methods, achieving the utmost 99.7% of accuracy with an error rate of 0.3%, 99.72% of precision, 99.8% of recall, and 99.78% of F-score. The study's findings indicate that this integrated approach is not only more accurate but also offers faster inference times and improved interpretability, making it a promising tool for automated plant disease detection within the domain of agricultural technology.},
  keywords={Surveys;Plant diseases;Accuracy;Error analysis;Feature extraction;Robustness;Classification algorithms;Random forests;Optimization;Genetic algorithms;Plant Disease;Feature Extraction;Multi Objective Optimization;Machine Learning;Genetic Algorithm},
  doi={10.1109/PDGC64653.2024.10984080},
  ISSN={2573-3079},
  month={Dec},}@INPROCEEDINGS{11004674,
  author={Poongodi, S. and Sasirekha, K. and Rini, Sheela and S, Jeyapriya. and Rashmi, G.Dona},
  booktitle={2025 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={An Enchanced Approach for Early Chronic Kidney Disease Prediction Using Advanced Machine Learning and Data Processing Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1090-1095},
  abstract={Chronic renal disease is a medical disorder in which the kidneys gradually slow down, reducing their ability to filter blood. Diabetes, high blood pressure, heart disease, and a family history of renal failure are the primary risk factors for this condition. The prognosis for patients with chronic kidney disease (CKD) varies according to the stage at which they are diagnosed. Stages 0 and 1 represent the early stages of the disease, whereas stage 4 represents the severe stages, where the kidneys are nearly at the point of failure. Early diagnosis is therefore essential for the patient's survival and the appropriate therapies. Blood tests, biopsies, urine tests, and imaging tests are among the medical diagnostic techniques that can be used to diagnose chronic kidney disease (CKD). However, these medical diagnostic techniques have certain drawbacks and restrictions. They are employed to identify diseases in their later stages and can occasionally yield erroneous results; they are also expensive. Consequently, the researcher has discovered a novel technique for the early identification of CKD that use machine learning algorithms to overcome these complications because machine learning algorithms are becoming increasingly significant in health care datasets. These methods also have issues with overfitting, class imbalance, biased results, problems with dataset interpretability, and high computing costs. Therefore, improved preprocessing techniques and machine learning algorithms are used in this research work to overcome the inadequacies of the existing approaches for CKD prediction. The model is tested using the Kaggle dataset on chronic renal disease. Class imbalance and missing attribute values are issues with this dataset. Additionally, this dataset has several categorical attribute values and additional variances in attribute values. A few preprocessing techniques are used to improve the data quality, including K-Nearest Neighbour for filling in missing attribute values, SMOTE for class imbalance, Label encoding for transferring categorical values, and Min-max scaling. The Adaptive Neural Optimized Model is used for the classification process, which leverages the Extreme Learning Model's power for classification. The particle swarm optimization method is used for feature selection and optimization. The algorithm's output is evaluated using a number of performance criteria, including as accuracy, precision, and recall. With the highest accuracy of 98%, the suggested model performs better than the current models.},
  keywords={Adaptation models;Accuracy;Machine learning algorithms;Computational modeling;Machine learning;Predictive models;Chronic kidney disease;Encoding;Optimization;Diseases;Chronic Kidney Disease;ELM;K-NN;PSO;SMOTE},
  doi={10.1109/ICICT64420.2025.11004674},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10815746,
  author={Quincozes, Vagner E. and Quincozes, Silvio E. and Albuquerque, Célio and Passos, Diego and Mossé, Daniel},
  booktitle={2024 IEEE 13th International Conference on Cloud Networking (CloudNet)}, 
  title={Efficient Feature Selection for Intrusion Detection Systems with Priority Queue-Based GRASP}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The Greedy Randomized Adaptive Search Procedure for Feature Selection (GRASP-FS) is a recently-proposed metaheuristic that optimizes the feature selection process for Intrusion Detection Systems (IDS) by combining exploration and refinement techniques for more assertive intrusion detection. However, GRASP-FS may be time and resource-consuming for large datasets. In this work, we propose GRASPQ-FS, an extended version of GRASP-FS using Priority Queues to reduce resource consumption and processing time. As an additional contribution, we provide a comprehensive analysis of the most suitable parameters for our GRASPQ-FS. Our results reveal that GRASPQ-FS can speed up feature selection up to 90% over GRASP-FS, without compromising F1-Score. Also, we observed that a priority queue with 50 solutions saved 50% in execution time while increasing the F1-Score by 4.5%.},
  keywords={Adaptive systems;Explainable AI;Metaheuristics;Diversity reception;Intrusion detection;Feature extraction;Real-time systems;Proposals;Medical diagnosis;Intrusion Detection System (IDS);Feature Selection;GRASP;Cyber-Physical System (CPS)},
  doi={10.1109/CloudNet62863.2024.10815746},
  ISSN={2771-5663},
  month={Nov},}@INPROCEEDINGS{11077524,
  author={P, Asha Rani K and S, Gowrishankar},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Agentic AI for Pathogen-Based Plant Disease Detection}, 
  year={2025},
  volume={},
  number={},
  pages={323-328},
  abstract={Plant disease detection is crucial for ensuring global food security and sustainable agriculture. Traditional methods rely on manual inspection, which is time consuming, error prone and requires expert knowledge. AI-driven approaches, particularly deep learning models have significantly improved disease classification and early detection. However existing AI models suffer from key limitations, including the need for large, annotated datasets, poor generalization across different crop varieties and environmental conditions, and limited adaptability to real-time dynamic scenarios. To address these challenges, we propose an Agentic AI framework for plant disease detection that goes beyond passive classification. Our approach integrates autonomous decision making, continuous learning and explainable AI, our system dynamically refines its predictions, reduces dependency on extensive labeled datasets and provides interpretable insights to farmers. Plant disease detection is being transformed by Agentic Artificial Intelligence (AAI), which offers proactive, self-governing, and accurate solutions to counteract pathogen-based risks. Plant disease problems can be effectively addressed by Agentic AI by combining real-time data gathering, pathogen detection models, decision-making procedures, and feedback mechanisms. This paper examines the vital role that artificial intelligence (AI) plays in agriculture, emphasizing its main features, benefits, and uses, including precision farming, crop yield optimization, and early disease detection. Its practical advantages are demonstrated through a case study on AI-powered disease detection in tomato crops, and its difficulties and moral implications are examined to guarantee responsible implementation. Finally, agentic AI's potential to revolutionize sustainable plant disease management techniques is highlighted by its promising future.},
  keywords={Plant diseases;Pathogens;Ethics;Data integrity;Decision making;Food security;Real-time systems;Artificial intelligence;Optimization;Farming;Agentic AI;Pathogen Detection;Plant Disease Management;Early Disease Diagnosis;Precision Agriculture;Crop Yield Optimization;Autonomous Systems;Sustainable Farming;Data Quality in AI;Real-Time Decision-Making;Feedback Mechanisms;Tomato Crop Case Study},
  doi={10.1109/AIRC64931.2025.11077524},
  ISSN={},
  month={May},}@ARTICLE{11078154,
  author={Gan, Jianhong and Kang, Runqing and Deng, Xun and Mao, Chentao and Li, Zhibin and Wei, Peiyang and Wu, Chunjiang and He, Tongli},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Multi-Station Wind Speed Forecasting Based on Dynamic Spatio-Temporal Graph Convolutional Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Wind speed forecasting is significant in practical applications such as energy dispatch and meteorological early warning systems. However, spatio-temporal correlations of wind speed are dynamically influenced by weather conditions, seasonal variations, and diurnal fluctuations, resulting in constantly changing spatio-temporal patterns. Meanwhile, wind speed data inherently include short-term high-frequency fluctuations and long-term low-frequency trends, which traditional methods struggle to adapt to and accurately capture multiscale features. This paper proposes a dynamic spatio-temporal graph convolutional network model (DSTGFP) for multi-station wind speed prediction to address this challenge. First, the model constructs an adaptive dynamic adjacency matrix (ADAM) by integrating geographical locations among stations, dynamic time warping (DTW), and mutual information (MI), facilitating dynamic graph modeling. Next, we introduce a novel spatio-temporal feature extraction framework, which employs residual graph convolutional networks combined with a multi-head attention mechanism to extract spatial features. We simultaneously integrate temporal-domain convolution and frequency-domain convolution to capture multiscale temporal-frequency features. Finally, the particle swarm optimization (PSO) algorithm is used for hyperparameter optimization to improve the prediction accuracy. Experimental results demonstrate that the DSTGFP model achieves reductions of 24.66% in mean absolute error (MAE) and 25.47% in root mean square error (RMSE) compared to existing deep learning methods, highlighting its superior predictive performance.},
  keywords={Wind speed;Feature extraction;Adaptation models;Predictive models;Convolution;Forecasting;Data models;Monitoring;Meteorology;Graph convolutional networks;Wind Speed Forecasting;Dynamic Time Warping;Adjacency matrix;Graph Convolution;Particle Swarm Optimization},
  doi={10.1109/JSTARS.2025.3588260},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{10606807,
  author={Yu, Guangji and Zhao, Haiquan and Liang, Yangyang and Gao, Yong and Zhang, Weiyong and Sader, Malika},
  booktitle={2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS)}, 
  title={Data-Driven Soft Sensing of Polyoxymethylene Melt Index using Takagi-Sugeno Fuzzy Neural Network and Quantum Genetic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={529-534},
  abstract={As a frequently used polymer material, polyoxymethylene (POM) has played an indispensable role in a variety of industrial fields. For production efficiency and safety, online monitoring of POM melt index is of importance in industrial practice. However, current data-driven soft sensors for POM melt index cannot address the pure delays within process variables. In this work, we propose time-delayed Takagi-Sugeno (T-S) fuzzy neural network as a novel data-driven soft sensor model, and improved quantum genetic algorithm (IQGA) for parameter estimation. By considering time-delayed process variables, the predictive performance and interpretability of soft sensor models can be improved. However, it is computationally cumbersome to find an optimal choice of time delays, and thus IQGA is proposed to resolve this problem. Case studies on industrial data from a real-world POM plant illustrate the usefulness of the proposed soft sensing method for POM melt index prediction.},
  keywords={Adaptation models;Parameter estimation;Soft sensors;Computational modeling;Predictive models;Fuzzy neural networks;Data models;Soft sensor;industrial big data;fuzzy neural network;time delay;genetic algorithm},
  doi={10.1109/DDCLS61622.2024.10606807},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10598550,
  author={Xia, Guoxin and Zhao, Yanqiao and Han, Chaohui and Zhao, Xiaosong and Zhang, Lei},
  booktitle={2024 39th Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, 
  title={Lightweight Intrusion Detection Based on Hybrid Feature Selection Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1385-1388},
  abstract={Industrial control security is the lifeblood of a country and the core component of production and life. It targets the issues of diverse attack methods and unbalanced training sample data in traditional industrial control systems. This paper proposes a novel hybrid machine-learning model that integrates PSO-CNN-Attention-BiLSTM. SMOTE algorithm is used to solve the problem of small samples and unbalanced attacks in training and generate missing sample data. The backbone network employs a CNN-Attention-BiLSTM hybrid model for training, extracting feature characteristics from sample data. The backbone network considers the time series relationship in the input sample and the degree of spatial feature relationship inside the sample. It uses an attention mechanism to extract relationship features within samples. Finally, it uses the classification module to classify the prediction results. Through experimental tests, the model has a classification accuracy of 98.18% and an F1 score of 0.9809 on the intrusion detection data set of an industrial production PLC device in Hebei Province. Compared with the conventional intrusion detection model, this method has a higher classification accuracy and better performance than the traditional method.},
  keywords={Training;Accuracy;Industrial control;Time series analysis;Intrusion detection;Production;Feature extraction;Intrusion Detection;Industrial Control Security;CNN;BiLSTM},
  doi={10.1109/YAC63405.2024.10598550},
  ISSN={2837-8601},
  month={June},}@ARTICLE{9837105,
  author={Yan, Tongtong and Fu, Yichu and Lu, Ming and Li, Zhinong and Shen, Changqing and Wang, Dong},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Integration of a Novel Knowledge-Guided Loss Function With an Architecturally Explainable Network for Machine Degradation Modeling}, 
  year={2022},
  volume={71},
  number={},
  pages={1-12},
  abstract={The suitability of a health index (HI) is significant to improve machine diagnostic and prognostic performance. A life cycle HI can be applied to the detection of incipient faults and determination of the first prediction time, and then, its monotonic curve after FPT can be used as an immediate variable for prognostic analysis. Although existing data-driven methodologies for HI construction have considerable nonlinear mapping, they lack transparency and interpretability for subsequent studies and analysis. Moreover, these HIs have some unknown burrs and fluctuations. To overcome these limitations, an architecturally explainable network for machine degradation modeling is proposed in this article. The first three hidden layers are reformulated from three advanced signal processing technologies, including Hilbert transform, squared envelope, and Fourier transform, to map temporal signals in the time domain into demodulated signals in the squared envelope spectrum domain so as to directly link the proposed network with fault frequencies and their harmonics in the frequency domain. The fourth hidden layer consists of a full connection layer with one hidden node and a novel knowledge-guided loss function specifically designed for exploring and extracting informative degradation features. Case studies are implemented to verify the proposed methodology and show that the proposed HIs have more stable and robust performance compared to state-of-the-art methods. Another superiority of the proposed network lies in its full transparency and interpretability by effectively integrating physics-based signal processing technologies with an interpretable artificial network structure for machine degradation modeling.},
  keywords={Degradation;Signal processing;Feature extraction;Convolution;Vibrations;Predictive models;Indexes;Architecturally explainable network;health index (HI) construction;machine degradation modeling;novel knowledge-guided loss function},
  doi={10.1109/TIM.2022.3193196},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10140127,
  author={Stringer, Alexander and Dolinger, Geoffrey and Sharp, Timothy and Hogue, Debra and Karch, Joseph and Borowska, Lesya and Metcalf, Justin G.},
  booktitle={2023 IEEE/ION Position, Location and Navigation Symposium (PLANS)}, 
  title={Improving Predictive Navigation Through the Optimization of Counterfactual Track Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={93-104},
  abstract={Modern navigation applications are confronting the challenge of path identification and prediction. Because of the inherent noisiness of measurement techniques, positional data often contains errors. Over time, when attempting to predict future positions, these errors can compound, causing drift in the target's path. Filtering or regression techniques can use periodic high-fidelity measurements, like those from GPS sensors, to correct positional data and reduce historic errors. These techniques have been much less effective in specialized environments where GPS is intermittent or denied. At the same time, the development of semi- and fully-autonomous systems has increased the need for accurate predictive navigation. To address this problem, previous methods were proposed for repairing tracking data using causality-aware machine learning (ML). It combined a long short-term memory (LSTM) network that predicted target paths with the non-dominated sorting genetic algorithm II (NSGA-II) which identified and evaluated counterfactual paths. Here te authors expand on that work by improving the simulated data used to train and test the system, expanding the GA by adding additional first principles-based objective functions, improving upon the LSTM implementation, and utilizing Extended Kalman Filter (EKF) pre-processing. System testing is conducted on Matlab-generated navigation scenarios, and results are compared to both EKF correction and spline interpolation. The proposed counterfactual track repair (CTR) tool produces paths with less repeatability than traditional approaches. However, it is shown to consistently generate more realistic path corrections, lower error in predictions based on its corrected paths, and is highly configurable, demonstrating the value and utility of this approach.},
  keywords={Navigation;Gaussian noise;Position measurement;Linear programming;Mathematical models;Pollution measurement;Velocity measurement;Machine Learning;Causal Learning;Genetic Algorithms;Navigation},
  doi={10.1109/PLANS53410.2023.10140127},
  ISSN={2153-3598},
  month={April},}@INPROCEEDINGS{9870309,
  author={Takahashi, Kenjiro and Fukuyama, Yoshikazu and Kawaguchi, Shuhei and Sato, Takaomi},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Optimal Production Scheduling using a Production Simulator and Multi-population Global-best Modified Brain Storm Optimization}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper proposes an optimal production scheduling method using the production simulator and multi-population global-best modified brain storm optimization (MP-GMBSO). Currently, in industry sector, decarbonization and carbon neutrality are approached by technical innovations such as Industry 4.0. In particular, optimal production scheduling researches which are important in production environments have been conducted actively. However, there is a gap between the previous optimal production scheduling researches and production schedule generating methods of practical production environments. The proposed method can fill the gap and it can be applied to the practical production environments. Results of the proposed method are compared with those of the conventional MBSO [7] and GMBSO based methods. It is verified that the proposed MP-GMBSO based method can find higher quality production schedules. In addition, it is verified that there is a significant difference among the conventional MBSO and GMBSO based methods, and the proposed MP-GMBSO based method with 0.05 significant level by the Friedman test as a priori test and the Wilcoxon signed rank test with Bonferroni-Holm correction as a post hoc test. In addition, the objective function of the target production scheduling has needles and it is found that the problem is one of the challenging problems to be optimized. The proposed MP-GMBSO based method can solve the problem better than the conventional MBSO and GMBSO based methods even with the challenging characteristic of the problem.},
  keywords={Schedules;Technological innovation;Job shop scheduling;Storms;Processor scheduling;Production;Low-carbon economy;decarbonization;optimal production scheduling;production simulator;multi-population global-best modified brain storm optimization},
  doi={10.1109/CEC55065.2022.9870309},
  ISSN={},
  month={July},}@INPROCEEDINGS{10771304,
  author={Pei, Changhua and Liu, Zihan and Li, Jianhui and Zhang, Erhan and Zhang, Le and Zhang, Haiming and Chen, Wei and Pei, Dan and Xie, Gaogang},
  booktitle={2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Self-Evolutionary Group-wise Log Parsing Based on Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={49-60},
  abstract={Log parsing involves extracting appropriate templates from semi-structured logs, providing foundational information for downstream log analysis tasks such as anomaly detection and log comprehension. Initially, the task of log parsing was approached by domain experts who manually designed heuristic rules to extract templates. However, the effectiveness of these manual rules deteriorates when certain characteristics of a new log dataset do not conform to the pre-designed rules. To address these issues, introducing large language models (LLM) into log parsing has yielded promising results. Nevertheless, there are two limitations: one is the reliance on manually annotated templates within the prompt, and the other is the low efficiency of log processing. To address these challenges, we propose a self-evolving method called SelfLog, which, on the one hand, uses similar <group, template> pairs extracted by LLM itself in the historical data to act as the prompt of a new log, allowing the model to learn in a self-evolution and labeling-free way. On the other hand, we propose an N-Gram-based grouper and log hitter. This approach not only improves the parsing performance of LLM by extracting the templates in a group-wise way instead of a log-wise way but also significantly reduces the unnecessary calling to LLMs for those logs whose group template is already extracted in history. We evaluate the performance and efficiency of SelfLog on 16 public datasets, involving tens of millions of logs, and the experiments demonstrate that SelfLog has achieved state-of-the-art (SOTA) levels in 0.975’s GA, and 0.942’s PA. More importantly, without sacrificing accuracy, the processing speed has reached a remarkable 45,000 logs per second.},
  keywords={Accuracy;Annotations;Large language models;Manuals;Data models;Software reliability;History;Labeling;Few shot learning;Anomaly detection;large language model;log parsing;self-evolution},
  doi={10.1109/ISSRE62328.2024.00016},
  ISSN={2332-6549},
  month={Oct},}@INPROCEEDINGS{11042357,
  author={Shwetha, Sirikonda and Ramana, N},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Hybrid Computational Intelligence Techniques for Automated Lung Cancer Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={lung diseases like pneumonia, tuberculosis, and lung cancer remain a major global health problem. Early and precise diagnosis is vital to improving patient outcomes and ensuring effective treatment. Thus, we are proposing a unique hybrid approach that combines swarm intelligence-based optimization techniques and attention-based deep learning to achieve better identification of lung disease. The hybrid framework that we proposed contains a Contrast Multiscale Binary Pattern for preprocessing, an Augmented Graph Bee Colony algorithm for spatial relationships in medical images, and Particle Swarm Optimization with ResNet R-network to find small and subtle abnormality in lung structures. Elitist Ant Colony Optimization is then used to achieve optimization for feature selection and features optimization. InceptionNet is finally used to classify lung cancer. The experimental results show that our proposed deep CNN models represent a huge improvement over the accuracy and computational efficacy than the more conventional deep learning method or model for lungs disease identification purposes.},
  keywords={Deep learning;Accuracy;Pneumonia;Tuberculosis;Lungs;Computational modeling;Lung cancer;Particle swarm optimization;Optimization;Medical diagnostic imaging;Lung Disease Identification;Deep Learning;Attention Mechanism;Swarm Intelligence;Optimization;Medical Imaging},
  doi={10.1109/RMKMATE64874.2025.11042357},
  ISSN={},
  month={May},}@INPROCEEDINGS{9945130,
  author={Ma, Yujunrong and Nakamura, Kiminori and Lee, Eung-Joo and Bhattacharyya, Shuvra S.},
  booktitle={2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={EADTC: An Approach to Interpretable and Accurate Crime Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={170-177},
  abstract={Machine learning applications related to high-stakes decisions are often surrounded by significant amounts of controversy. This has led to increasing interest in interpretable machine learning models. A well-known class of interpretable models is that of decision trees (DTs), which mirror a common strategy used by humans to arrive at solutions through a series of well-defined decisions. However, much of previous research on DTs for criminal justice predictions has focused primarily on collections (ensembles) of DTs whose results are aggregated together. Such DT ensembles are used to help improve accuracy; however, their increased complexity and deviation from human decision-making processes makes them much less interpretable compared to single-DT approaches. In this paper, we present a new DT model for criminal recidivism prediction that is designed with high interpretability, accuracy, and fairness as core objectives. The interpretability of the model stems from its formulation in terms of a single DT structure, while accuracy is achieved through an intensive optimization process of DT parameters that is carried out using a novel evolutionary algorithm. Through extensive experiments, we analyze the performance of our proposed EADTC (Evolutionary Algorithm Decision Tree for Crime prediction) method on relevant datasets. Our experiments show that the EADTC approach achieves competitive accuracy and fairness with respect to state-of-the-art ensemble DT models, while achieving higher interpretability due to the simpler, single-DT structure.},
  keywords={Analytical models;Evolutionary computation;Machine learning;Predictive models;Data models;Complexity theory;Decision trees},
  doi={10.1109/SMC53654.2022.9945130},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{10063373,
  author={Suprem, Abhijit and Vaidya, Sanjyot and Cherkadi, Suma and Singh, Purva and Ferreira, Joao Eduardo and Pu, Calton},
  booktitle={2022 IEEE 4th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Constructive Interpretability with CoLabel: Corroborative Integration, Complementary Features, and Collaborative Learning}, 
  year={2022},
  volume={},
  number={},
  pages={74-83},
  abstract={Machine learning models with explainable predictions are increasingly sought after, especially for real-world, mission-critical applications that require bias detection and risk mitigation. Inherent interpretability, where a model is designed from the ground-up for interpretability, provides intuitive insights and transparent explanations on model prediction and performance. In this paper, we present CoLabel, an approach to build interpretable models with explanations rooted in the ground truth. We demonstrate CoLabel in a vehicle feature extraction application in the context of vehicle make-model recognition (VMMR). By construction, CoLabel performs VMMR with a composite of interpretable features such as vehicle color, type, and make, all based on interpretable annotations of the ground truth labels. First, CoLabel performs corroborative integration to join multiple datasets that each have a subset of desired annotations of color, type, and make. Then, CoLabel uses decomposable branches to extract complementary features corresponding to desired annotations. Finally, CoLabel fuses them together for final predictions. During feature fusion, CoLabel harmonizes complementary branches so that VMMR features are compatible with each other and can be projected to the same semantic space for classification. With inherent interpretability, CoLabel achieves superior performance to the state-of-the-art black-box models, with accuracy of 0.98, 0.95, and 0.94 on CompCars, Cars196, and BoxCars116K, respectively. CoLabel provides intuitive explanations due to constructive interpretability, and subsequently achieves high accuracy and usability in mission-critical situations.},
  keywords={Annotations;Fuses;Mission critical systems;Semantics;Color;Predictive models;Feature extraction;Vehicle Re id;Interpretability;VMMR},
  doi={10.1109/CogMI56440.2022.00021},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11065636,
  author={Lin, Zhengyu},
  booktitle={2025 IEEE 14th Data Driven Control and Learning Systems (DDCLS)}, 
  title={Key node-based Observable and Predictable Technology for Distributed PV Clusters Research}, 
  year={2025},
  volume={},
  number={},
  pages={1040-1045},
  abstract={To address the problem of new energy regulation "blind zone" caused by the high-density and dispersed distribution of large-scale distributed photovoltaic power systems connecting to the distribution grid, firstly, the community detection algorithm and tabu search algorithm are used to divide the PV clusters effectively based on the electrical distance and regional voltage regulation ability. Then, the voltage sensitivity matrix calculation is used to determine the key nodes within each cluster to reduce the cost of data collection. Next, the genetic algorithm (GA) and BP neural network are combined to predict the PV power output of the cluster using the data of the key nodes, achieving the goal of observable and predictable. Finally, the validity of the proposed method is verified by MATLAB software simulation.},
  keywords={Photovoltaic systems;Costs;Accuracy;Neural networks;Clustering algorithms;Data collection;Prediction algorithms;Detection algorithms;Voltage control;Genetic algorithms;Distributed PV clusters;key nodes;community detection algorithm;GA-BP neural network;observable and predictable technology},
  doi={10.1109/DDCLS66240.2025.11065636},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10960945,
  author={N, Sasipriyaa and Ravikumar, R. and Mangaiyarkarasi, D. and Dhanushika, T. and Harsha, A.B. and Swetha, P.},
  booktitle={2024 First International Conference on Data, Computation and Communication (ICDCC)}, 
  title={A Hybrid Approach for Recognising Alzheimer Disease Using GA Enabled GAN}, 
  year={2024},
  volume={},
  number={},
  pages={457-462},
  abstract={Alzheimer's disease (AD) is a chronic neurodegenerative disease, where early stages of detection play a crucial role in improving patient treatment. However, patients with Fronto Temporal Dementia (FTD) are often misdiagnosed with Alzheimer's disease due to limitations in diagnosis algorithms. While various machine learning and deep learning techniques have been applied to classify the stages of Alzheimer's disease, accurate early-stage diagnosis remains challenging which would give a better explanation of its variations with FTD. Though many theories have been developed to diagnose it, Magnetic Resonance Imaging (MRI) has proven to be a powerful tool in observing detailed patient images. Several machine learning models have been exploited by researchers to diagnose Alzheimer's disease. Though many techniques have been applied to the diagnosis and classification of Alzheimer's disease, there is a need for more accuracy in early diagnosis solutions. In this study, the Open Access Series of Imaging Studies (OASIS) dataset is used to predict the disease diagnosis using the Genetic Algorithm (GA). The results of GAGAN (Genetic Algorithm based Generative Adversarial Network) model is compared to traditional GAN (Generative Adversarial Network) to evaluate performance, with a specific focus on improved classification accuracy and sensitivity. Results demonstrate that GA optimization enhances GAN's diagnostic accuracy, offering a more robust framework for real-world application in early AD detection, which can contribute to better patient care and quality of life.},
  keywords={Deep learning;Accuracy;Magnetic resonance imaging;Sensitivity and specificity;Generative adversarial networks;Alzheimer's disease;Optimization;Diseases;Genetic algorithms;Synthetic data;Magnetic Resonance Imagining;Deep Neural Network;OASIS;Generative Adversarial Networks,CNN;Genetic Algorithm},
  doi={10.1109/ICDCC62744.2024.10960945},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10408601,
  author={Li, Jinhu and Ma, Hanbin and Huang, Feng and Huang, Chao and Wang, Huaiqiang},
  booktitle={2023 IEEE 6th International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)}, 
  title={Optimal scheduling of regional integrated energy systems based on joint source-load forecasting}, 
  year={2023},
  volume={},
  number={},
  pages={589-592},
  abstract={Accurate source-load prediction results are important for new energy consumption and improving grid stability. The traditional BP algorithm has defects such as easy to fall into local optimum and premature maturity, and the genetic algorithm is to optimise the BP parameters to improve the prediction accuracy. The GA-BP is used to establish PV power generation prediction model and household load prediction model respectively. Comparative simulation analysis reveals that the proposed genetic algorithm optimised BP has a smaller prediction error than the traditional BP and PSO-BP, which verifies the reliability of the proposed method.},
  keywords={Predictive models;Power system stability;Reliability engineering;Prediction algorithms;Stability analysis;Genetic algorithms;Load modeling;joint source-load;forecast;BP;GA},
  doi={10.1109/AUTEEE60196.2023.10408601},
  ISSN={2831-4549},
  month={Dec},}@INPROCEEDINGS{10350132,
  author={Locci, Stefano and Di Caro, Luigi and Livraga, Giovanni and Viviani, Marco},
  booktitle={2023 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)}, 
  title={Explainability of the Effects of Non-Perturbative Data Protection in Supervised Classification}, 
  year={2023},
  volume={},
  number={},
  pages={402-408},
  abstract={The increasing availability of online data has meant that data-driven models have been applied to more and more tasks in recent years. In some domains and/or applications, such data must be protected before they are used. Hence, one of the problems only partially addressed in the literature is to determine how the performance of Machine Learning models is affected by data protection. More important, the explainability of the results of such models as a consequence of data protection has been even less investigated to date. In this paper, we refer to this very problem by considering non-perturbative data protection, and by studying the explainability of supervised models applied to the data classification task.},
  keywords={Data protection;Machine learning;Data models;Intelligent agents;Task analysis;Explainability;Data Protection;Machine Learning;Privacy;Classification},
  doi={10.1109/WI-IAT59888.2023.00066},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10580580,
  author={Ye, Songtao and Zheng, Saisai and Xia, Yizhang},
  booktitle={2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={Channel Attention-Based Method for Searching Task-Specific Multi-Task Network Structures}, 
  year={2024},
  volume={},
  number={},
  pages={562-569},
  abstract={Multi-task learning (MTL) simultaneously learns multiple related tasks, aiming to improve overall outcomes by leveraging task correlations. The MTL network structure choice greatly impacts individual task results. In contrast, Evolutionary Neural Architecture Search (ENAS) has shown remarkable proficiency in automatically identifying optimal neural network structures for MTL. However, existing methods present certain limitations. Manually designed multi-task learning networks are constrained by the designer’s skill, and they often fail to fully capture multi-task feature interactions within the backbone network. Moreover, these networks do not incorporate the residual concept to preserve crucial backbone network output features. In contrast, automatically searched structures embrace residuals but still need improvement in facilitating multi-task feature interactions. This paper introduces a novel framework for evolutionary MTL network search. It includes a backbone with residuals and a Multi-Task Feature Fusion and Extraction Module (FFEM) with channel attention. The FFEM combines task features and weighs channel(feature) importance. Adopting the residual concept reintegrates them into the backbone network and fuses with the backbone network’s features. Experimental results validate our approach’s efficacy, achieving competitive performance on the NYUD-v2 dataset.},
  keywords={Correlation;Fuses;Federated learning;Semantic segmentation;Neural networks;Estimation;Evolutionary computation;Multi-task learning;Neural network structure search;Evolutionary algorithms;Attention mechanism},
  doi={10.1109/CSCWD61410.2024.10580580},
  ISSN={2768-1904},
  month={May},}@INPROCEEDINGS{10969006,
  author={Xie, Qian},
  booktitle={2025 3rd International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Marketing Strategy Support System based on Temporal Fusion Transformer}, 
  year={2025},
  volume={},
  number={},
  pages={01-05},
  abstract={Nowadays, the marketing strategy support system is designed to aid marketing professionals and businesses in developing the effective marketing strategies. However, the existing Customer Relationship Management (CRM) system limited by data quality issues due to the vast amounts of available data coupled with the intricacies of market dynamics. Hence, this research proposes the marketing strategy support system namely Temporal Fusion Transformer (TFT) based on stock price data. Initially, the input data is collected from Nifty500 stocks dataset which is available at Kaggle platform. Then, the data is preprocessed by using min-max normalization to rescale the data into a specific range. After that, the proposed TFT is introduced to forecast the stock prices by using self-attention mechanism and decoder. Finally, the proposed TFT predicted the technical indicators including Money Flow Index (MFI), Relative Strength Index (RSI), Resistance Level (RL) and Fibonacci Retracement (FR) effectively for efficient stock price forecasting. From the results, the proposed TFT provided outstanding results in terms of Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Mean Square Error (MSE), and Root Mean Square Error (RMSE) with 16.82, 5.19, 9.31, and 2.73 respectively when compared with existing Long Short-Term Memory and Transformer with Particle Swarm Optimization (LTPNet) model.},
  keywords={Customer relationship management;Transformers;Natural language processing;Thin film transistors;Decoding;Indexes;Forecasting;Usability;Root mean square;Business;marketing strategy support system;min-max normalization;self-attention mechanism;stock price and temporal fusion transformer},
  doi={10.1109/ICICACS65178.2025.10969006},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10763320,
  author={Hairullah, Mochammad and Wijayaningrum, Vivi Nur and Hendrawan, Muhammad Afif and Al Hadid Firdaus, Vipkas and Noprianto and Hani'ah, Mamluatul},
  booktitle={2024 International Conference on Electrical and Information Technology (IEIT)}, 
  title={Leveraging Genetic Algorithm-Optimized Isolation Forest for Anomaly Detection in Compressor Machines}, 
  year={2024},
  volume={},
  number={},
  pages={152-157},
  abstract={In modern industries, compressors play a vital role in various applications, including energy production, gas processing, and commercial cooling systems. However, in daily operations, compressors can encounter several issues that threaten operational consistency and efficiency. Common problems include component wear, abnormal vibrations, and leaks. To minimize the risk of serious damage and reduce high maintenance costs, this study proposed an anomaly detection technique using the Isolation Forest algorithm and the application of Shapley Additive exPlanations (SHAP) to identify the most influential attributes in determining compressor anomalies. There are nine main attributes in compressors, including Delivery Pressure, Delivery Temperature, Oil Pressure, Oil Temperature, Horizontal Temperature, Stage 1 Temperature, Stage2 Temperature, Stage3 Temperature, and Water Temperature. To detect anomalies based on these attributes more effectively, the performance of the Isolation Forest was enhanced by applying a Genetic Algorithm to optimize the parameters of the Isolation Forest, which include contamination, n_estimators, max_samples, n_jobs, and max_features. The optimization results from the Genetic Algorithm produced the following Isolation Forest parameters, with contamination at 0.16, n_estimators at 100, max_samples at 267, n_jobs at -1, and max_features at 9. The evaluation results using these optimal parameters showed an average accuracy of 0.993. The evaluation using SHAP calculations demonstrated consistency with conventional methods, ensuring that identifying the most influential attributes in detecting compressor anomalies is accurate and reliable.},
  keywords={Vibrations;Accuracy;Oils;Forestry;Compressors;Water pollution;Anomaly detection;Optimization;Contamination;Genetic algorithms;anomaly detection;compressors;optimization;SHAP evaluation;temperature},
  doi={10.1109/IEIT64341.2024.10763320},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10581420,
  author={Wang, Lulin and Chen, Yiyuan and Qin, Xiaowei and Xin, Tao},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={VCSR-AβPSO: A Hybrid Feature Selection for Enhanced Android Scrolling Scenario Recognition in High-Dimensional Imbalanced Data}, 
  year={2024},
  volume={},
  number={},
  pages={880-888},
  abstract={Scrolling scenario recognition in the lower-level Android system faces a high-dimensional imbalance problem. Most current research employs multi-stage feature selection methods for dimension reduction. However, it has some drawbacks: 1) The first stage is based on a combination of different feature importance, ignoring the interactions between the features; 2) Further reduction often traps in the problem of local optima due to fixed search steps in the feature space; 3) The reduced feature dimensions still cannot satisfy the real-time operational requirements of Android terminals. To tackle these issues, this work introduces VCSR-AβPSO, a two-stage hybrid feature selection method. The ELimination Et Choix Traduisant la REalité (ELECTRE) approach combines the importance of random forest features and cost-sensitive symmetric uncertainty to take feature interactions into consideration. Moreover, an adaptive β-hill climbing (AβHC)-enhanced Binary Particle Swarm Optimization (BPSO) algorithm is proposed to increase randomness in the search space, avoiding local optima and further reducing feature dimensions to improve the algorithm's real-time performance in terminal operation. AISSV dataset comprising various Android view features was constructed to validate the effectiveness and real-time capability of the proposed algorithm. Experiments on this dataset and other six public datasets have shown that the method performs exceptionally, achieving a 93.34%F1 score in scrolling scenario recognition, surpassing other baseline algorithms to reach state-of-the-art levels, with model runtime controlled within 0.3 milliseconds, significantly improving the real-time performance.},
  keywords={Dimensionality reduction;Training;Accuracy;Uncertainty;Termination of employment;Feature extraction;Real-time systems;High-dimensional and imbalance data;feature selection;scrolling scenario recognition;ELimination Et Choix Traduisant la REalité (ELECTRE);Binary Particle Swarm Optimization (BPSO);Adaptive β-hill Climbing (AβHC)},
  doi={10.1109/AINIT61980.2024.10581420},
  ISSN={},
  month={March},}@ARTICLE{9745612,
  author={Zhao, Jianwei and Cao, Bin and Liu, Xin and Yang, Peng and Singh, Amit Kumar and Lv, Zhihan},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Multiobjective Multiple Mobile Sink Scheduling via Evolutionary Fuzzy Rough Neural Network for Wireless Sensor Networks}, 
  year={2022},
  volume={30},
  number={11},
  pages={4630-4641},
  abstract={The sensor nodes in wireless sensor networks have the deficiency of limited energy, and the multihop transmission of information will lead to a premature paralysis of nodes near the sink. The use of the mobile sink can balance the energy consumption and greatly prolong the lifetime. Therefore, this article studies the scheduling strategy of multiple mobile sinks and proposes a heuristic strategy based on interval type-2 fuzzy rough neural network. The energy and lifetime of sensor nodes, as well as location information of the mobile sink and special nodes are taken as input features. Through neural network learning, the outputs determine whether to move, moving direction, moving distance, and residence time, which can complete the scheduling task. The scheduling problem is regarded as a multiobjective optimization problem, and the network lifetime, the moving path length, and the network interpretability are optimized at the same time, so as to obtain a lightweight network with good interpretability and performance. Based on the parallel multiobjective evolutionary algorithm, a multiobjective neural evolutionary framework is constructed. This framework can balance multiple objectives and complete complex scheduling tasks. Compared with static sinks, random-moving sinks, sinks with manually designed strategy, gene expression programming-based sinks, as well as the other state-of-the-art multiobjective evolutionary algorithms, the proposed framework can achieve superior results.},
  keywords={Wireless sensor networks;Artificial neural networks;Scheduling;Optimization;Rough sets;Fuzzy sets;Wireless communication;Fuzzy rough neural network (FRNN);multi-objective evolutionary algorithm (MOEA);network lifetime;multiple mobile sink scheduling;neural evolution},
  doi={10.1109/TFUZZ.2022.3163909},
  ISSN={1941-0034},
  month={Nov},}@ARTICLE{10449338,
  author={He, Jiaxin and Cheng, Yong and Wang, Wei and Gu, Yakang and Wang, Yixuan and Zhang, Wenjie and Shankar, Achyut and Selvarajan, Shitharth and Kumar, Sathish A. P.},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={EC-YOLOX: A Deep-Learning Algorithm for Floating Objects Detection in Ground Images of Complex Water Environments}, 
  year={2024},
  volume={17},
  number={},
  pages={7359-7370},
  abstract={Correct detection of floating objects in complex water environments is a challenge because of the problems of obscuration and dense floating objects. In view of the above issues, this article proposed a network called EC-YOLOX by introducing the coordinate attention (CA) and efficient channel attention (ECA) mechanism and improving the loss function to further the multifeature extraction and detection accuracy of floating objects. In this article, ablation experiments and comparison experiments were conducted on the river floating objects dataset. The ablation experiments showed that the ECA and CA mechanism played a great role in EC-YOLOX, which can reduce the missed detection rate by 5.86% and increase the mean average precision (mAP) by 5.53% compared with YOLOX. The EC-YOLOX was also applicable to different types of floating objects; the mAP of the ball, plastic garbage, plastic bag, leaf, milk box, grass, and branches were, respectively, improved by 4%, 4%, 4%, 6%, 4%, 18%, and 5%. The mAP of the comparison experiments was improved by 15.13%, 9.30%, and 8.03% compared to faster R-CNN, YOLOv5, and YOLOv3, respectively. This method facilitates the precise extraction of floating objects from images, which holds paramount importance for monitoring and safeguarding water environments. It offers significant contributions to water environment monitoring and protection.},
  keywords={Feature extraction;YOLO;Task analysis;Target recognition;Rivers;Interference;Information science;Attention mechanism;floating objects;loss function;missed detection rate;YOLOX},
  doi={10.1109/JSTARS.2024.3367713},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{9982104,
  author={Daruna, Angel and Das, Devleena and Chernova, Sonia},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Explainable Knowledge Graph Embedding: Inference Reconciliation for Knowledge Inferences Supporting Robot Actions}, 
  year={2022},
  volume={},
  number={},
  pages={1008-1015},
  abstract={Learned knowledge graph representations supporting robots contain a wealth of domain knowledge that drives robot behavior. However, there does not exist an inference reconciliation framework that expresses how a knowledge graph representation affects a robot's sequential decision making. We use a pedagogical approach to explain the inferences of a learned, black-box knowledge graph representation, a knowledge graph embedding. Our interpretable model uses a decision tree classifier to locally approximate the predictions of the black-box model and provides natural language explanations interpretable by non-experts. Results from our algorithmic evaluation affirm our model design choices, and the results of our user studies with non-experts support the need for the proposed inference reconciliation framework. Critically, results from our simulated robot evaluation indicate that our explanations enable non-experts to correct erratic robot behaviors due to nonsensical beliefs within the black-box.},
  keywords={Natural languages;Closed box;Predictive models;Approximation algorithms;Prediction algorithms;Classification algorithms;Behavioral sciences},
  doi={10.1109/IROS47612.2022.9982104},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{10521732,
  author={Gazi, Asim H. and Sanchez-Perez, Jesus Antonio and Saks, Georgia L. and Alday, Erick A. Perez and Haffar, Ammer and Ahmed, Hashir and Herraka, Duaa and Tarlapally, Nitya and Smith, Nicholas L. and Bremner, J. Douglas and Shah, Amit J. and Inan, Omer T. and Vaccarino, Viola},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Quantifying Posttraumatic Stress Disorder Symptoms During Traumatic Memories Using Interpretable Markers of Respiratory Variability}, 
  year={2024},
  volume={28},
  number={8},
  pages={4912-4924},
  abstract={Background: Posttraumatic stress disorder (PTSD) causes heightened fight-or-flight responses to traumatic memories (i.e., hyperarousal). Although hyperarousal is hypothesized to cause irregular breathing (i.e., respiratory variability), no quantitative markers of respiratory variability have been shown to correspond with PTSD symptoms in humans. Objective: In this study, we define interpretable markers of respiration pattern variability (RPV) and investigate whether these markers respond during traumatic memories, correlate with PTSD symptoms, and differ in patients with PTSD. Methods: We recruited 156 veterans from the Vietnam-Era Twin Registry to participate in a trauma recall protocol. From respiratory effort and electrocardiogram measurements, we extracted respiratory timings and rate using a robust quality assessment and fusion approach. We then quantified RPV using the interquartile range and compared RPV between baseline and trauma recall conditions, correlated PTSD symptoms to the difference between trauma recall and baseline RPV (i.e., $\Delta$RPV), and compared $\Delta$RPV between patients with PTSD and trauma-exposed controls. Leveraging a subset of 116 paired twins, we then uniquely controlled for factors shared by co-twins via within-pair analysis for further validation. Results: We found RPV was increased during traumatic memories (p $<$ .001), $\Delta$ RPV was positively correlated with PTSD symptoms (p $<$ .05), and patients with PTSD exhibited higher $\Delta$ RPV than trauma-exposed controls (p $<$ . 05). Conclusions: This paper is the first to elucidate RPV markers that respond during traumatic memories, especially in patients with PTSD, and correlate with PTSD symptoms. Significance: These findings encourage future studies outside the clinic, where interpretable markers of respiratory variability are used to track hyperarousal.},
  keywords={Biomedical monitoring;Stress;Heart rate variability;Electrocardiography;Mental disorders;Respiratory system;Wearable devices;Stress;respiration pattern variability (RPV);posttraumatic stress disorder (PTSD);sensor informatics;feature engineering},
  doi={10.1109/JBHI.2024.3397589},
  ISSN={2168-2208},
  month={Aug},}@INPROCEEDINGS{10150274,
  author={Paraschou, Eva and Yfantidou, Sofia and Vakali, Athena},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={UnStressMe: Explainable Stress Analytics and Self-tracking Data Visualizations}, 
  year={2023},
  volume={},
  number={},
  pages={340-342},
  abstract={Self-tracking technology for behavior monitoring is prevalent in various aspects of human life. It enables users' activities tracking with data produced “in the wild”, namely capturing real-world physical activity, sleep patterns, and stress levels, among others. Advanced new sensors integrated into commercial self-tracking devices have empowered a new era of sensing data exploration and self-improvement recommendations, aiming to enhance physical and mental well-being. However, the collected data and related inferred knowledge are not always well-explained or well-presented and discourage users' commitment leading to sensing devices' abandonment. To sustain user engagement with self-tracking technology for well-being, this paper introduces a comprehensive framework and respective full-stack web service called “UnStressMe” for the analysis of diverse data modalities tracked in the wild, the prediction of future stress behavior and the production and provision of personalized, model-agnostic explanations and interactive visualizations. We showcase the utility of our framework through a mental health use case, paving the way for explainable, transparent, and human-centric self-tracking technology.},
  keywords={Pervasive computing;Web services;Conferences;Data visualization;Production;Mental health;Predictive models;Personal Informatics;XAI;ML;Visualizations;A/B testing;Wearable Technology},
  doi={10.1109/PerComWorkshops56833.2023.10150274},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10885376,
  author={Caro-Reyna, Fernando and Arcos-Bravo, David Gamaliel and Sánchez, Claudia N.},
  booktitle={2024 IEEE 6th International Conference on BioInspired Processing (BIP)}, 
  title={Investment Portfolio Optimization Using Technical Indicators and White-Box Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Quantitative trading has revolutionized in recent years with the integration of machine learning. However, most proposals are complex models that often need help with model understanding and feature importance identification. This study presents a methodology for optimizing investment portfolios using the XGBoost algorithm and a comprehensive set of technical indicators. The primary objective is to maximize returns by accurately predicting stock prices and selecting the most profitable stocks. Our proposal is based on decision trees, eliminating the need for recurrent neural networks or time series representations of data and enabling white-box machine learning models that are easier to interpret. We tried our proposal with real data corresponding to a collection of stocks of the 500 most influential companies in the United States of America, utilizing historical data such as open prices, highest and lowest prices, and trading volume. Experimental results demonstrated that our approach successfully identified the most profitable stocks, outperforming random portfolios and showing significant profit accumulation over time. This approach recognizes the most feasible indicators and facilitates the automatic design of investment portfolios and the analysis of the importance of technical indicators in complex data.},
  keywords={Recurrent neural networks;Time series analysis;Machine learning;Predictive models;Prediction algorithms;Proposals;Portfolios;Optimization;Investment;Glass box;Investment portfolio optimization;technical indicators;machine Learning;XGBoost},
  doi={10.1109/BIP63158.2024.10885376},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10910287,
  author={Wanigasekara, Sashini and Asanka, Dinesh and Rajapakse, Chathura and Wickramaarachchi, Dilani and Wijesinghe, Abhiru},
  booktitle={2024 IEEE 3rd International Conference on Data, Decision and Systems (ICDDS)}, 
  title={Comparing the Adaptability of a Genetic Algorithm and an LLM-Based Framework for Automated Software Test Data Generation: In the Context of Web Applications}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the fast-paced world of software development, ensuring software quality is paramount. Software Quality Assurance (SQA) plays a vital role, primarily through testing, which can be carried out manually or automatically. Yet, creating comprehensive test data (TD) for web applications can be a formidable task. Manual test data generation (TDG) is time-consuming and error prone. Automation of TDG has become increasingly important in the realm of software quality assurance as it enables efficient and effective testing of software systems. The need for an appropriate framework for automated TDG is critical to achieve comprehensive and reliable test coverage. Automated TDG offers significant advantages, including time and resource savings, improved test coverage, and seamless integration into the software development process. The core aim of this research is to bridge the gap between manual and existing automated methods, resulting in time and cost savings, heightened testing efficiency, and elevated software quality. Research objectives encompass comparing the adaptability of an AGA based automated TDG model and a LLM based automated TDG model to a web application. The results from the LLM model for triangle classification program was found to be potentially acceptable and accurate than the AGA model's results. This research discusses the challenges encountered when implementing and using the AGA-based framework in the web application context and how an LLM model could overcome the challenges. The study highlights the benefits of using the LLM approach, demonstrating its relevance and accuracy in generating test data compared to the Genetic Algorithm-based model. The practical implications for software quality assurance practices are discussed, emphasizing the enhanced efficiency and effectiveness of the LLM model in improving software quality.},
  keywords={Adaptation models;Automation;Large language models;Software quality;Manuals;Data collection;Software systems;Testing;Genetic algorithms;Software development management;Adaptive Genetic Algorithm;Automated test data generation;Large Language Model;Retrieval Augmented Generation;Test automation},
  doi={10.1109/ICDDS62937.2024.10910287},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10905556,
  author={Löppenberg, Marlon and Schwung, Andreas},
  booktitle={IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={Structured Graph Generation by Evolutionary Algorithm for Program Code Development}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Understanding and interpreting complex coupled systems remains one of the biggest challenges in the world. Examples of these applications range from industrial manufacturing to the temporal characteristics of real-world conditions. To address this challenge, this paper presents a novel approach to structured program code development based on graph generation. The problem is considered from the perspective of an inductive link prediction problem structured by an evolutionary algorithm. The self-adaptation of relevant knowledge takes place in a closed loop, where systematic relationships are constantly improved and extended. The required system behaviour is mapped step by step, taking into account constraints, limitations and expert knowledge. Structured graph generation is used to represent logic functions and interpret complex coupled relationships. The presented strategy enables targeted plant control through customised program code concepts, which are used to optimise processes and increase efficiency. The approach is validated through the design of interpretable programmable control logic on an industrial manufacturing process and obtain a comparable solution to the work of a trained professional. The achieved results demonstrate the next level of independent self-optimisation in learning and interpreting logical relationships in automation.},
  keywords={Programmable control;Codes;Systematics;Manufacturing processes;Process control;Evolutionary computation;Prediction algorithms;Logic functions;Manufacturing;Logic;inductive link prediction;knowledge graphs;evolutionary algorithm},
  doi={10.1109/IECON55916.2024.10905556},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10775866,
  author={Wang, Yongrui and Li, Nan and Yang, Han},
  booktitle={2024 5th International Conference on Computer Engineering and Intelligent Control (ICCEIC)}, 
  title={Improvement of the Greenhouse Temperature Analysis Model for Explanatory and Adaptability}, 
  year={2024},
  volume={},
  number={},
  pages={178-182},
  abstract={The greenhouse is a typical microclimate regulation system, where the indoor environment is influenced by numerous external variables and is prone to significant overall fluctuations. Under such circumstances, conventional methods such as fixed temperature thresholds and linear control are inadequate in addressing the energy wastage issues caused by excessive temperature adjustments. This paper investigates a multiparameter analysis method for sunlit greenhouses centered on historical data mining, aiming to provide reasonable temperature predictions for sunlit greenhouses through multiparameter analysis while enhancing model interpretability, thereby laying a foundation for precise regulation of the greenhouse environment. Unlike traditional analysis networks that rely on fixed parameters, this study proposes a framework that combines fuzzy networks with parameter optimization. It utilizes a priori superior architectures to implement fuzzy settings for the CNN network, employs KAN modules to improve interpretability, and conducts global parameter optimization. The training costs are reduced by 9% based on pre-training, while the accuracy increases by 11%. Furthermore, as the number of parameters continues to rise, the training accuracy consistently improves. The model is also capable of fine-tuning optimization under varying weather conditions, thus mitigating the impact of significant fluctuations in the internal environment of the sunlit greenhouse on model accuracy.},
  keywords={Training;Adaptation models;Analytical models;Temperature distribution;Accuracy;Green products;Neural networks;Regulation;Temperature control;Optimization;component;Greenhouse;Temperature;PSO;CNN},
  doi={10.1109/ICCEIC64099.2024.10775866},
  ISSN={},
  month={Oct},}@ARTICLE{11053828,
  author={García, Rodrigo and Aguilar, Jose and Pinto, Angel and Hoyos, William},
  journal={IEEE Access}, 
  title={A Prescriptive Approach Based on Fuzzy Cognitive Maps and Genetic Algorithms for Disease Management in Beef Production}, 
  year={2025},
  volume={13},
  number={},
  pages={112011-112020},
  abstract={Livestock disease diagnosis and treatment often rely on the experience of veterinarians and the availability of clinical signs, which can vary significantly between cases. This paper proposes a novel prescriptive analytics approach based on Fuzzy Cognitive Maps (FCMs) integrated with Genetic Algorithms (GAs) to support decision-making in the treatment of common cattle diseases. The FCM captures expert knowledge through causal relationships between symptoms, treatments, and diagnoses, while the GA optimizes treatment actions to achieve desired health outcomes. We evaluated our approach using three case studies –babesiosis, anaplasmosis, and coccidiosis– on datasets comprising 3000 cattle records each. The predictive model achieved accuracies of 92%, 87%, and 87% for the respective diseases. The prescriptive model yielded high performance with average  $R^{2}$  values above 0.93 and low RMSE values, demonstrating that the recommended treatments closely matched the optimal solutions. This work contributes a hybrid, explainable, and data-efficient framework that can be integrated into intelligent agriculture systems for improved livestock health management.},
  keywords={Livestock;Cows;Diseases;Genetic algorithms;Farming;Adaptation models;Sensors;Production;Decision making;Fuzzy cognitive maps;Fuzzy cognitive maps;genetic algorithms;prescriptive models;animal welfare;precision livestock farming},
  doi={10.1109/ACCESS.2025.3583670},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10073364,
  author={Li, Zhichuan and Lan, Sheng and Wei, Ke},
  booktitle={2022 12th International Conference on Power and Energy Systems (ICPES)}, 
  title={Single Pole Ground Fault Location Method for LCC-MMC Hybrid DC Transmission Lines Based on Extremely Randomized Trees}, 
  year={2022},
  volume={},
  number={},
  pages={230-234},
  abstract={Aiming at the difficulty of locating single pole ground fault in LCC-MMC hybrid DC transmission lines, a single pole ground fault location method for transmission lines based on Variational model decomposition (VMD) - Decision Tree (DT) feature selection and Extremely randomized trees (Extra-Trees) is proposed. First, the collected two terminal fault waveforms are connected in series, sent to the VMD algorithm for decomposition, and then the decomposed modal components are connected in series with the original waveform. Then, the importance of features is calculated using the feature importance quantification method of DT algorithm, and the features with higher importance are constructed into a new feature set. Finally, the Extra-Trees model is built and trained with the new feature set to make it have the ability of fault prediction. A ±800kV LCC-MMC hybrid DC transmission system is built to verify the proposed method. The simulation results show that the proposed method can accurately locate the single pole ground fault location.},
  keywords={Resistance;Power transmission lines;Grounding;Simulation;Voltage;Fault location;Predictive models;Hybrid DC system;variational model decomposition;decision Tree;extremely randomized trees;fault location},
  doi={10.1109/ICPES56491.2022.10073364},
  ISSN={2767-732X},
  month={Dec},}@INPROCEEDINGS{10828067,
  author={Ma, Ke and Zhang, Naiwen and Mei, Xinyi and Feng, Cheng and Hou, Wentao and Ye, Zi},
  booktitle={2024 IEEE 6th International Conference on Civil Aviation Safety and Information Technology (ICCASIT)}, 
  title={Research on Optimization of Shared Bicycle Scheduling Based on Genetic Algorithm and LSTM}, 
  year={2024},
  volume={},
  number={},
  pages={936-940},
  abstract={In this paper, a dynamic scheduling algorithm based on multi-objective optimization is designed and illustrated with the example of shared bicycle scheduling optimization. Firstly, this research conducted a spatio-temporal analysis based on the publicly available dataset of Citi Bike in New York, and by applying the K-means clustering algorithm, user behaviors were classified into three major categories with significant differences in the frequency of use and riding paths. On this basis, this paper proposes and constructs a demand prediction model based on LSTM (Long Short-Term Memory Network) introducing the attention mechanism. Finally, this paper innovatively combines the global search ability of genetic algorithm and the local optimal search advantage of dynamic programming to design a dynamic scheduling algorithm based on multi-objective optimization. By introducing an adaptive cross-variance strategy, the algorithm not only significantly improves the convergence speed, but also enhances the adaptability to complex demand patterns. The results show that the dynamic scheduling scheme proposed in this paper reduces the average waiting time of users by about 35% and improves the turnover rate of a single vehicle by about 30% compared with the traditional static scheduling strategy. Especially during peak hours, the scheduling scheme greatly alleviates the bicycle shortage problem and significantly improves the overall efficiency of the system and user satisfaction.},
  keywords={Heuristic algorithms;Clustering algorithms;Bicycles;Predictive models;Dynamic scheduling;Prediction algorithms;Dynamic programming;Optimization;Long short term memory;Genetic algorithms;spatio-temporal analysis;K-means clustering algorithm;LSTM;genetic algorithm},
  doi={10.1109/ICCASIT62299.2024.10828067},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11043090,
  author={Wu, Zhicheng and Xue, Bing and Zhang, Mengjie},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Multitree GP-Based Feature Learning for Multimodal Medical Image Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Multimodal medical image classification (MMIC) refers to the process of extracting and combining information from various modalities to classify medical images, ultimately improving diagnostic accuracy. Most existing methods extract discriminative features from different modalities for specific tasks but often lack adaptability to other tasks. Additionally, they suffer from poor interpretability, which is critical in medical image analysis, as understanding the decision-making process is essential. Genetic programming (GP), particularly multitree GP, provides a flexible framework for evolving multimodal features. However, current multitree GP methods only perform feature-level fusion and remain underexplored in medical multimodal feature learning. To address these issues, this paper proposes a novel multitree GP method, Multimodal Feature GP (MFGP), to automatically extract informative feature vectors from different modalities. To fully utilize both modality-specific features and fused multimodal features, we integrate feature-level fusion and decision-level fusion strategies into our framework. The performance of the proposed method is evaluated on two distinct MMIC tasks, namely polyp classification and glaucoma classification, representing different medical scenarios. The results are compared with both single-modality and multimodal methods. Experimental results demonstrate that the proposed method significantly outperforms all single-modality approaches and most multimodal benchmark methods. Further analysis reveals that the evolved models can effectively capture the unique characteristics of different modalities.},
  keywords={Representation learning;Three-dimensional displays;Magnetic resonance imaging;Genetic programming;Feature extraction;Vectors;Robustness;Data mining;Medical diagnostic imaging;Image classification;Multimodal;Medical Image Classification;Genetic Programming;Feature Learning;Fusion Strategy},
  doi={10.1109/CEC65147.2025.11043090},
  ISSN={},
  month={June},}@ARTICLE{10901976,
  author={Xiao, Ma and Qin, Bolin and Yang, Yixuan and He, Kaiyan and Li, Congcong and Sheng, Jingwei and Yu, Lili and Huang, Yingkun and Pang, Wei and Lyu, Bingjiang and Gao, Jia-Hong},
  journal={IEEE Sensors Journal}, 
  title={Bandwidth Enhancement for Magnetic-Field-Modulation-Free SERF Magnetometers}, 
  year={2025},
  volume={25},
  number={7},
  pages={10894-10904},
  abstract={Magnetoencephalography (MEG) using optically pumped magnetometers (OPMs) enables precise measurement of brain neural activity with enhanced signal strength and spatial detail. Most OPM-MEG systems use spin-exchange-relaxation-free (SERF) OPMs, which have a narrow bandwidth (<100 Hz), limiting their ability to measure broadband neural activity. Existing bandwidth enhancement methods for SERF-OPMs face challenges, including sensor interference, difficulties in miniaturizing light modulation devices, and insufficient theoretical explanations. To address these issues, this study introduces a magnetic-field-modulation-free (MFMF) SERF OPM that significantly enhances the response bandwidth of compact stand-alone SERF OPMs without magnetic field interference, enabling high-density detection. Specifically, we conducted a detailed theoretical analysis to develop a frequency response model that accounts for the large polarization gradient. We also applied heuristic optimization methods to accurately calculate the frequency response of OPMs with optically thick cells using only premeasured amplitude response. This approach minimizes amplitude attenuation and phase shift, achieving a flat frequency response (frequency response linearity <3% up to 1000 Hz) while maintaining a sensitivity of 20 fT/Hz $^{\text {1/2}}$  up to 500 Hz, typically. Our method achieves an approximately eightfold bandwidth increase for individual OPMs and enhances the common-mode rejection ratio (CMRR) of sensor array synthetic gradiometers by over fivefold. Thus, the enhanced compact MFMF SERF OPM, characterized by its broad response bandwidth, high sensitivity, and the absence of crosstalk effect, holds the potential for developing high-density detection arrays capable of more accurate and reliable biomagnetic imaging with exceptional spatial resolution across a broad frequency range.},
  keywords={Magnetometers;Bandwidth;Frequency response;Sensors;Optical pumping;Magnetic fields;Sensitivity;Optical sensors;Magnetic sensors;Optical polarization;High bandwidth;high-density MEG;magnetic-field-modulation-free (MFMF);optically pumped magnetometer (OPM);spin-exchange-relaxation-free (SERF)},
  doi={10.1109/JSEN.2025.3542464},
  ISSN={1558-1748},
  month={April},}@INPROCEEDINGS{11043002,
  author={Vu, Trung Hieu and Thanh Nguyen, Tien and Elyan, Eyad},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={An Evolutionary Neural Architecture Search-Based Approach for Time Series Forecasting}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Time series forecasting (TSF) is one of the most prevalent research topics in artificial intelligence and has garnered significant attention in the research community. In recent years, significant breakthroughs have been made in TSF research, shifting from traditional statistical models to deep learning (DL), and attention-based methods. While attention-based methods excel at capturing global dependencies, they often face challenges in effectively modeling local patterns. Additionally, the design of these networks typically demands substantial human expertise, experimental work, and manual configuration. To address these issues, we propose an Evolutionary Neural Architecture Search for Time Series Forecasting, entitled ENAS-TSF to automate TSF architecture design. Concretely, we propose a novel local/ global context module encoding strategy to define a search space. Each local context module includes various convolutions with different kernel sizes to capture temporal dependencies, aiming to enhance the local features and pattern recognition. Global encoding meanwhile contains attention mechanisms and feedforward layers for global context modeling. We propose an evolutionary neural architecture search approach to identify the optimal ENAS-TSF architectures, achieving the ideal balance of local/ global context modeling. Extensive experiments on common benchmark datasets show that ENAS-TSF achieves competitive performance compared to state-of-the-art methods, demonstrating the proposed framework’s effectiveness.},
  keywords={Deep learning;Computational modeling;Time series analysis;Computer architecture;Evolutionary computation;Encoding;Neural architecture search;Forecasting;Kernel;Context modeling;Time series forecasting;neural architecture search;deep learning;evolutionary algorithm},
  doi={10.1109/CEC65147.2025.11043002},
  ISSN={},
  month={June},}@INPROCEEDINGS{10980765,
  author={Kamran, Sharif A. and Lucas, Molly V. and Lutnick, Brendon and Parmar, Chaitanya and Pal, Basudha and Shah, Asha Patel and Apfel, David and Fakharzadeh, Steven and Miller, Lloyd and Yip, Stephen and Standish, Kristopher and Cula, Gabriela Oana},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)}, 
  title={PSO-NET: Development of an Automated Psoriasis Assessment System Using Attention-Based Interpretable Deep Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Psoriasis is a chronic skin condition that requires long-term treatment and monitoring. Although, the Psoriasis Area and Severity Index (PASI) is utilized as a standard measurement to assess psoriasis severity in clinical trials, it has many draw-backs such as (1) patient burden for in-person clinic visits for assessment of psoriasis, (2) time required for investigator scoring and (3) variability of inter-and intra-rater scoring. To address these drawbacks, we propose a novel and inter-pretable deep learning architecture called PSO-Net, which maps digital images from different anatomical regions to derive attention-based scores. Regional scores are further combined to estimate an absolute PASI score. Moreover, we devise a novel regression activation map for interpretability through ranking attention scores. Using this approach, we achieved inter-class correlation scores of 82.2% [95% CI: 77- 87%] and 87.8% [95% CI: 84–91%] with two different clinician raters, respectively.},
  keywords={Deep learning;Correlation;Psoriasis;Digital images;Clinical trials;Time measurement;Skin;Indexes;Standards;Monitoring;Psoriasis;Deep Learning;Attention;PASI;Convolutional Neural Networks},
  doi={10.1109/ISBI60581.2025.10980765},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10958899,
  author={Jain, Arinjay and Pramod, Dhanya},
  booktitle={2025 Fifth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, 
  title={Data-Driven Credit Scoring: Integrating Genetic Algorithms With Ensemble Learning for Multi Class Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In the unexpectedly dynamic financial world, credit scoring plays a pivotal role in assessing the creditworthiness of people and agencies. Traditional statistical models, though effective, regularly face obstacles in managing complex and large datasets. This study introduces a unique method to credit score scoring by using integrating genetic algorithms with ensemble learning strategies to improve class accuracy. The research utilizes a dataset of consumer financial and demographic variables to broaden predictive models, mainly the use of XGBoost and Random Forest classifiers. Through hyperparameter optimization using genetic algorithms, the models acquire achieve improvements in overall performance. Further, ensemble techniques, consisting of weighted ensembling and stacking, are hired to leverage the strengths of a couple of models. This research promotes the capability of combining genetic algorithms and superior ensemble techniques in growing strong and correct credit score scoring models, contributing to extra efficient risk control inside the financial zone. The findings suggest large implications for banks and monetary establishments in improving decision-making tactics and customer segmentation.},
  keywords={Accuracy;Stacking;Propulsion;Predictive models;Hyperparameter optimization;Ensemble learning;Reliability;Optimization;Random forests;Genetic algorithms;Credit Scoring;Genetic Algorithm;Ensemble Learning;Random Forest. XGBoost;Hyperparameter Optimization},
  doi={10.1109/ICAECT63952.2025.10958899},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10316839,
  author={Choi, Daegyun and Chhabra, Anirudh and Kim, Donghoon},
  booktitle={2023 23rd International Conference on Control, Automation and Systems (ICCAS)}, 
  title={Fuzzy Inference System-Applied Spacecraft Control for Final Approach of Rendezvous Process}, 
  year={2023},
  volume={},
  number={},
  pages={1401-1406},
  abstract={In-space servicing has become popular for extending the lifetime of aging satellites that may have faulty components or no fuel. For such missions, a servicing spacecraft, referred to as the ‘chaser,’ approaches a target spacecraft in need of servicing. This work proposes an intelligent spacecraft control strategy using a fuzzy inference system (FIS) for a safe final approach of the chaser toward the target. The proposed FIS models are trained by a genetic algorithm using representative initial conditions, without considering disturbances, with the objective of minimizing the chaser's energy consumption. To validate the performance and effectiveness of the proposed model, the trained FIS-based control strategy is applied to various testing scenarios that consider random initial relative positions of the chaser, even in the presence of external disturbances.},
  keywords={Space vehicles;Fuzzy logic;Energy consumption;Satellites;Force;Process control;Control systems;spacecraft control;final approach;rendezvous;fuzzy inference system},
  doi={10.23919/ICCAS59377.2023.10316839},
  ISSN={2642-3901},
  month={Oct},}@ARTICLE{10363771,
  author={Qu, Gang and Orlichenko, Anton and Wang, Junqi and Zhang, Gemeng and Xiao, Li and Zhang, Kun and Wilson, Tony W. and Stephen, Julia M. and Calhoun, Vince D. and Wang, Yu-Ping},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Interpretable Cognitive Ability Prediction: A Comprehensive Gated Graph Transformer Framework for Analyzing Functional Brain Networks}, 
  year={2024},
  volume={43},
  number={4},
  pages={1568-1578},
  abstract={Graph convolutional deep learning has emerged as a promising method to explore the functional organization of the human brain in neuroscience research. This paper presents a novel framework that utilizes the gated graph transformer (GGT) model to predict individuals’ cognitive ability based on functional connectivity (FC) derived from fMRI. Our framework incorporates prior spatial knowledge and uses a random-walk diffusion strategy that captures the intricate structural and functional relationships between different brain regions. Specifically, our approach employs learnable structural and positional encodings (LSPE) in conjunction with a gating mechanism to efficiently disentangle the learning of positional encoding (PE) and graph embeddings. Additionally, we utilize the attention mechanism to derive multi-view node feature embeddings and dynamically distribute propagation weights between each node and its neighbors, which facilitates the identification of significant biomarkers from functional brain networks and thus enhances the interpretability of the findings. To evaluate our proposed model in cognitive ability prediction, we conduct experiments on two large-scale brain imaging datasets: the Philadelphia Neurodevelopmental Cohort (PNC) and the Human Connectome Project (HCP). The results show that our approach not only outperforms existing methods in prediction accuracy but also provides superior explainability, which can be used to identify important FCs underlying cognitive behaviors.},
  keywords={Transformers;Brain modeling;Logic gates;Neuroimaging;Functional magnetic resonance imaging;Computational modeling;Prediction algorithms;Graph deep learning;transformer;fMRI;functional connectivity;human cognition},
  doi={10.1109/TMI.2023.3343365},
  ISSN={1558-254X},
  month={April},}@INPROCEEDINGS{10421719,
  author={Liang, Xianhuai},
  booktitle={2023 3rd International Conference on Intelligent Communications and Computing (ICC)}, 
  title={Credit Default Prediction Algorithm Based on Improved TabNet}, 
  year={2023},
  volume={},
  number={},
  pages={110-114},
  abstract={With the rapid development of the economy and the continuous growth of personal consumption demand, an increasing number of individuals are opting for loan-based consumption. In the face of an ever-expanding lending market, it is crucial to differentiate borrowers and control credit default risks effectively. TabNet is a neural network developed by Google specifically designed for tabular data. However, it performs poorly on credit data that lacks sequential relationships. Therefore, this paper proposes an improved TabNet-based credit default prediction algorithm GA-TabNet. It leverages a genetic algorithm to optimize TabNet's feature selection module. To solve the problem of premature convergence in genetic algorithms, an adaptive crossover and mutation rate calculation method was used, and the optimal individual retention strategy was adopted. Furthermore, a comparison is conducted with popular algorithms such as XGBoost, LightGBM, and Random Forest. The experimental results demonstrate that the proposed GA-TabNet algorithm outperforms the compared algorithms in terms of accuracy and AUC, establishing its effectiveness in credit default prediction.},
  keywords={Reinforcement learning;Predictive models;Prediction algorithms;Feature extraction;Risk management;Random forests;Genetic algorithms;Credit Default Predict;Genetic Algorithm;TabNet},
  doi={10.1109/ICC59986.2023.10421719},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10760029,
  author={Ma, Hanbo and Ma, Yaofei and Yuan, Haitao and Wang, Meijia and Hu, Jingwei and Wang, Yihuan and Yang, Hanbo},
  booktitle={2024 International Conference on Networking, Sensing and Control (ICNSC)}, 
  title={DMGA: A Directional-Mutation Genetic Algorithm for CDMS Problem of Kafka}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the increasing role of distributed message systems (DMS) represented by Kafka in handling large-scale data streams, it is critical to improve system performance by optimizing configuration parameters in different production environments. Due to the target system possessing numerous configuration parameters and the complex interactions between them, parameter optimization becomes a complex and time-consuming process that relies heavily on human effort and an iterative trial-and-error approach. At present, this type of configuration parameter problem has been classified as the Configuration of Distributed Message Systems (CDMS) problem, for which the goal is to obtain the optimal set of parameters for achieving the best performance. In order to deal with this complex problem, an automatic optimization method is proposed in this paper, which combines an automatic script-based deployment and running framework with an improved Genetic Algorithm (GA) in cooperation with the Random Forest (RF) and statistical methods, named the Directional-Mutation Genetic Algorithm (DMGA). The framework and algorithm are designed to find the best configuration efficiently, obtaining optimal parameters accurately without human supervision. Actual results of comparison experiments based on the Kafka system show that the DMGA algorithm significantly improves the data throughput performance of Kafka, and its optimization speed is more efficient than the basic GA, highlighting its potential to quickly optimize Kafka's operational efficiency in different scenarios.},
  keywords={Statistical analysis;System performance;Production;Throughput;Sensors;Tuning;Streams;Genetic algorithms;Message systems;Convergence;Kafka;CDMS;Genetic Algorithm;Performance tuning},
  doi={10.1109/ICNSC62968.2024.10760029},
  ISSN={2766-8665},
  month={Oct},}@INPROCEEDINGS{10780059,
  author={Guna, G. and Rani, V. Anusha and Manonmani, A. and Yuvaraj, P. and Priya, J. Shalini and Ambika, A.},
  booktitle={2024 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, 
  title={Efficient Design and Analysis of Inverse Definite Minimum Time Overcurrent Relay: A Matlab Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The paramount importance of generator security in modern power systems is highlighted through a study using MATLAB-based simulation strategies for optimizing reverse power relay protection. The methodology involves developing detailed models of generators and power systems, implementing reverse power relay algorithms, and simulating real-world scenarios. The simulations evaluate the effectiveness of the protection system in detecting and mitigating abnormal conditions, ensuring robust generator security under various scenarios. The improved protection system is rigorously tested against real-world data or set criteria in order to validate and verify its functionality. The study explores MATLAB optimization methods for refining reverse power relay algorithms' parameters, aiming to increase system reliability, reduce frequency of visits, and balance sensitivity and selectivity. To make sure that the protective system's performance and reliability requirements are satisfied, its performance is evaluated against predefined standards. The study also emphasizes the significance of reporting and documentation, offering a thorough explanation of the methodology, simulation configuration, outcomes, and conclusions. To sum up, this research offers a thorough method for optimizing generator security using simulation methodologies for reverse power relay protection that are based on MATLAB. Through the utilization of MATLAB's functionalities, the suggested approach provides a strong and effective means of augmenting generator security, consequently adding to the general dependability and stability of power systems.},
  keywords={System performance;Stability criteria;Protective relaying;Power system stability;Generators;Security;Reliability;MATLAB;Protection;Standards;Efficient design;Inverse Definite Minimum Time overcurrent relay;MATLAB approach;Optimization;power system;etc},
  doi={10.1109/ICPECTS62210.2024.10780059},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10739174,
  author={Ecik, Emre and John, Werner and Withöft, Julian and Brüning, Ralf and Götze, Jürgen},
  booktitle={2024 Kleinheubach Conference}, 
  title={An Approach for SI-Compliant Parameter Space Evaluation Using a Decision Tree-Based AI Module}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The application of high-speed systems is associated with a high degree of design complexity. In particular, maintaining the signal integrity (SI) must be ensured by detailed simulations using EDA design environments. The PCB designer has to find suitable parameter combinations for the transmission line networks under consideration in order to obtain adequate signal quality. AI-based optimization methods such as Bayesian optimization (BO) or genetic algorithm (GA) can already be found in literature for speeding up SI compliant design. Nevertheless, these algorithms can become very complex for a large number of design parameters and the given AI solutions must be accepted without insight. To overcome these challenges, this contribution presents an approach based on the combination of a decision tree (DT) and a support vector regression (SVR) surrogate model. The parameter space available to the PCB designer is first evaluated and SI-compliant parameter sets are predicted using the combined DT/SVR module. Finally, an optimal parameter space is obtained by evaluating the marginal probability mass functions (marginal PMFs) of the SI-conform combinations. The traceable structure of the decision tree in conjunction with the statistical evaluation enables the PCB designer to understand the DT/SVR module’s proposals in order to make the final decision.},
  keywords={Support vector machines;Network topology;Stars;Vectors;Topology;Proposals;Artificial intelligence;Signal integrity;Regression tree analysis;Genetic algorithms;Signal integrity;anomaly detection;decision tree;marginal probability mass functions;support vector regression;waveform assessment;explainable AI},
  doi={10.23919/IEEECONF64570.2024.10739174},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11043093,
  author={Wang, Yujianing and Wang, Qiang and Fan, Huijie},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Joint Attention Mechanism and Multi-task Learning for Weakly Supervised Skin Image Segmentation}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={In recent years, the application of deep learning technology in the field of medical image segmentation has become increasingly mature and has made certain progress. Applying this technique requires the use of a large number of medical image datasets with pixel-level annotations, however, the cost of pixel-level annotation of medical images is high. For this situation, we propose a weakly supervised medical image semantic segmentation model based on attention mechanism and multi-task learning. The attention mechanism can be used to focus on the information that is more critical to the current task in a large number of input information, and multi-task learning can share information among related tasks to promote network learning. As a result, the model can achieve better segmentation performance by using only image-level groundtruth labels. Since semantic segmentation task and saliency detection task are dense pixel prediction tasks,and class activation map (CAM) extracted from classification task is also used to represent pixel-level semantic information, it shows that these two tasks are highly related to the semantic segmentation task. Based on this premise,We propose the module of finding similarity from attention(SFA), which is used to calculate the similarity between multi-task feature maps to learn the correlation between tasks, and use similarity to optimize the prediction results of specific tasks. In addition, in order to extensively explore context relationships in dense pixel prediction tasks to achieve more accurate prediction results, we also propose a global context module (GCM) that pays attention to the global information of dense prediction tasks, captures long-distance dependencies in images, and improves the segmentation performance of the network. We did a lot of experiments, our method achieves 68.56% and 62.32% Miou on ISBI2016 and ISIC2017 datasets, respectively, and F1 -score is 78.25% on PH2 data set, significantly outperforming several recent state-of-the-art weakly supervised semantic segmentation methods.},
  keywords={Attention mechanisms;Correlation;Annotations;Semantic segmentation;Semantics;Multitasking;Skin;Iterative methods;Biomedical imaging;Saliency detection;Weakly supervised semantic segmentation;multitask learning;attentional mechanisms},
  doi={10.1109/CEC65147.2025.11043093},
  ISSN={},
  month={June},}@ARTICLE{10274149,
  author={Ye, Peijun and Qi, Hao and Zhu, Fenghua and Lv, Yisheng},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Counterfactual Evolutionary Reasoning for Virtual Driver Reinforcement Learning in Safe Driving}, 
  year={2023},
  volume={8},
  number={12},
  pages={4696-4705},
  abstract={Safety is the primary concern in the motion planning and decision-making of the virtual driver that provides prescriptions to the real human driver and even performs self-driving in the absence of human take-over. For such an issue, traditional reinforcement learning methods, limited by their learning mechanisms, suffer from a slow convergence of model training as well as a less consideration for early warning of possible accidents. To address the above deficiency, this paper proposes a new method based on counterfactual evolutionary reasoning that can be used to build the virtual driver. The method treats safe driving as a sequential decision-making problem with sparse rewards, and employs counterfactual evolutionary reasoning to guide the searching direction as well as to accelerate the model training. An intervention mechanism from outlier distributions is further introduced to enhance the model's ability of exploration. Experiments in the virtual test environment indicate that the proposed method, compared with other typical reinforcement learning techniques, both achieves a higher safe arrival rate and a faster convergence speed.},
  keywords={Safety;Accidents;Decision making;Cognition;Trajectory;Vehicle safety;Reinforcement learning;Evolutionary computation;Autonomous driving;Safe driving;reinforcement learning;counter factual reasoning;evolutionary search},
  doi={10.1109/TIV.2023.3322694},
  ISSN={2379-8904},
  month={Dec},}@ARTICLE{10174269,
  author={Ghatasheh, Nazeeh and Altaharwa, Ismail and Aldebei, Khaled},
  journal={IEEE Access}, 
  title={Modeling the Telemarketing Process Using Genetic Algorithms and Extreme Boosting: Feature Selection and Cost-Sensitive Analytical Approach}, 
  year={2023},
  volume={11},
  number={},
  pages={67806-67824},
  abstract={Currently, almost all direct marketing activities take place virtually rather than in person, weakening interpersonal skills at an alarming pace. Furthermore, businesses have been striving to sense and foster the tendency of their clients to accept a marketing offer. The digital transformation and the increased virtual presence forced firms to seek novel marketing research approaches. This research aims at leveraging the power of telemarketing data in modeling the willingness of clients to make a term deposit and finding the most significant characteristics of the clients. Real-world data from a Portuguese bank and national socio-economic metrics are used to model the telemarketing decision-making process. This research makes two key contributions. First, propose a novel genetic algorithm-based classifier to select the best discriminating features and tune classifier parameters simultaneously. Second, build an explainable prediction model. The best-generated classification models were intensively validated using 50 times repeated 10-fold stratified cross-validation and the selected features have been analyzed. The models significantly outperform the related works in terms of class of interest accuracy, they attained an average of 89.07% and 0.059 in terms of geometric mean and type I error respectively. The model is expected to maximize the potential profit margin at the least possible cost and provide more insights to support marketing decision-making.},
  keywords={Predictive models;Business;Data models;Feature extraction;Genetic algorithms;Decision making;Computational modeling;Data analysis;Market research;Evolutionary computation;Electronic commerce;Business analytics;cost-sensitive analysis;marketing research;electronic business;evolutionary algorithms;telemarketing},
  doi={10.1109/ACCESS.2023.3292840},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10611577,
  author={Liu, Qishuai and Brandão, Martim},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Generating Environment-based Explanations of Motion Planner Failure: Evolutionary and Joint-Optimization Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={15263-15269},
  abstract={Motion planning algorithms are important components of autonomous robots, which are difficult to understand and debug when they fail to find a solution to a problem. In this paper we propose a solution to the failure-explanation problem, which are automatically-generated environment-based explanations. These explanations reveal the objects in the environment that are responsible for the failure, and how their location in the world should change so as to make the planning problem feasible.Concretely, we propose two methods—one based on evolutionary optimization and another on joint trajectory-and-environment continuous-optimization. We show that the evolutionary method is well-suited to explain sampling-based motion planners, or even optimization-based motion planners in situations where computation speed is not a concern (e.g. post-hoc debugging). However, the optimization-based method is 4000 times faster and thus more attractive for interactive applications, even though at the cost of a slightly lower success rate. We demonstrate the capabilities of the methods through concrete examples and quantitative evaluation.},
  keywords={Point cloud compression;Costs;Debugging;User interfaces;Lead;Approximation algorithms;Planning},
  doi={10.1109/ICRA57147.2024.10611577},
  ISSN={},
  month={May},}@ARTICLE{10568457,
  author={Li, Jinqi and Tian Dai, Bing and Niu, Yunyun and Xiao, Jianhua and Wu, Yaoxin},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Multi-Type Attention for Solving Multi-Depot Vehicle Routing Problems}, 
  year={2024},
  volume={25},
  number={11},
  pages={17831-17840},
  abstract={In recent years, there has been a growing trend towards using deep reinforcement learning (DRL) to solve the NP-hard vehicle routing problems (VRPs). While much success has been achieved, most of the previous studies solely focused on single-depot VRPs, which became less effective in handling more practical scenarios, such as multi-depot VRPs. Although there are many preprocessing measures, such as natural decomposition, those scenarios are still more challenging to optimize. To resolve this issue, we propose the multi-depot multi-type attention (MD-MTA) to solve the multi-depot VRP (MDVRP) and multi-depot open VRP (MDOVRP), respectively. We design a multi-type attention in the network to combine different types of embeddings and the state of the environment at each step, so as to accurately select the next node to visit and construct the route. We introduce a depot rotation augmentation to enhance solution decoding. Results show that it performs favorably against various representative traditional baselines and DRL-based baselines.},
  keywords={Vehicle routing;Transformers;Heuristic algorithms;Decoding;Decision making;Computer architecture;Training;Deep reinforcement learning;learning to optimize;multi-depot vehicle routing problem;multi-depot open vehicle routing problem;attention mechanism;transformer model},
  doi={10.1109/TITS.2024.3413077},
  ISSN={1558-0016},
  month={Nov},}@ARTICLE{10975794,
  author={Lin, Shuqi and Li, Ziming and Xu, Zhuonong and Sun, Lixiang and Zhou, Guoxiong and Han, Guangjie},
  journal={IEEE Internet of Things Journal}, 
  title={PSSNet: An Optimized High-Accuracy Method for Forest Fire Smoke Detection}, 
  year={2025},
  volume={12},
  number={14},
  pages={27808-27817},
  abstract={In the field of early automatic detection of smoke from forest fires, there is the issue of the small size and interference of smoke detection by clouds. The conventional nonmaximum suppression (NMS) requires manual adjustment of the threshold, which may result in missed or erroneous detection. This article proposes a high-accuracy anti-interference forest fire smoke detection network for small objects. First, a window feature extractor based on singular value decomposition (SVD-STR) is designed. This extractor is capable of extracting more representative features, of capturing small and inconspicuous features in the image, and of reducing the complexity and computation of the model. Second, a sinthreshold screening attention mechanism (SinAttention) is proposed, which can filter interference information and enhance the discriminative power of the features, thereby facilitating the accurate recognition and distinction of smoke and clouds. Subsequently, a variational particle swarm soft suppression optimization (PGS) is proposed as a means of further enhancing the optimization effect. This is achieved by adjusting the suppression strategy and incorporating a Gaussian variational particle swarm algorithm. In conclusion, an Internet of Things forest fire detection system based on PSSNet has been constructed. The experimental results demonstrate that the mAP50 value of the method is 98.2%, the value of mAP50-95 is 80.4%, and the FPS value is 35.7. These values are superior to those of current forest fire smoke detection methods and can be utilized for the precise detection of forest fire smoke, thereby providing technical support for forest ecological protection.},
  keywords={Feature extraction;Forestry;Accuracy;Computational modeling;Transformers;Particle swarm optimization;Optimization;Internet of Things;YOLO;Cloud computing;Forest fire smoke detection;Internet of Things (IoT);sine threshold screening attention mechanism (SinAttention);variational particle swarm soft suppression optimization (PGS);window feature extractor based on SVD (SVD-STR)},
  doi={10.1109/JIOT.2025.3564058},
  ISSN={2327-4662},
  month={July},}@INPROCEEDINGS{11064442,
  author={Jin, Chenfeng and Bai, Jie},
  booktitle={2025 5th International Conference on Neural Networks, Information and Communication Engineering (NNICE)}, 
  title={The Application of DBO-VMD and GAN-Based Data Augmentation Techniques in Fault Diagnosis of Aircraft Engine Bearings}, 
  year={2025},
  volume={},
  number={},
  pages={1867-1870},
  abstract={With the rapid development of aviation engine technology, rolling bearing fault diagnosis has become crucial in ensu ring equipment reliability and extending service life. Due to the co mplexity of the installation process of wind turbine bearings, mai ntenance personnel often replace bearings before the end of their service life or after a fault occurs to avoid downtime losses, leadin g to difficulty in obtaining wind turbine bearing fault data. The sc arcity of fault samples limits the generalization ability of deep lea rning models and reduces diagnostic accuracy. To address this iss ue, this paper proposes a comprehensive fault diagnosis method t hat combines various advanced algorithms and deep learning mo dels, aiming to tackle the challenges of bearing fault feature extra ction and diagnosis under complex working conditions. To addres s the issue of strong noise in bearing fault signals, this paper empl oys Differential Butterfly Optimization (DBO), Particle Swarm O ptimization (PSO), and Dynamic Programming (DP) to optimize t he parameters of Variational Mode Decomposition (VMD) respec tively. This approach enables the fine decomposition and reconstr uction of the signal, maximizing the retention of key fault feature s. In the experiment, unbalanced sample fault diagnosis tests were performed using the CWRU dataset. The results show that the Ti meGAN-CNN-BiGRU-SAM fault diagnosis method effectively ge nerates the virtual fault data consistent with the real data distribution, and significantly improves the accuracy and robustness of th e diagnosis model, in which the accuracy and F1-score reach 98.9 5% and 99.78%, respectively.},
  keywords={Fault diagnosis;Deep learning;Accuracy;Atmospheric modeling;Heuristic algorithms;Noise;Data augmentation;Feature extraction;Data models;Wind turbines;Deep Learning;Fault Diagnosis;Data Augmentation;Signal Analysis},
  doi={10.1109/NNICE64954.2025.11064442},
  ISSN={},
  month={Jan},}@ARTICLE{9815240,
  author={Ou, Yun and Ye, Shao-Qiang and Ding, Lei and Zhou, Kai-Qing and Zain, Azlan Mohd},
  journal={IEEE Access}, 
  title={Hybrid Knowledge Extraction Framework Using Modified Adaptive Genetic Algorithm and BPNN}, 
  year={2022},
  volume={10},
  number={},
  pages={72037-72050},
  abstract={Fault diagnosis based on the expert system (ES) is still a research topic of manufacturing in Industry 4.0 because of the stronger interpretability. As the core component of the ES, fault diagnosis accuracy is positively correlated to the precision of the knowledge base. But it is difficult for users to understand the knowledge obtained from the original dataset utilizing the existing knowledge extraction method. Therefore, it is of great significance to extract easy-to-understand and exact rules from the NN framework. This paper proposes a hybrid extraction framework to perform the rule extraction for overcoming this drawback. First, an improved adaptive genetic algorithm (GA) using a logistic function, namely LAGA, is proposed to solve the traditional GA’s insufficient prediction performance issue. Compared with the other three mainstream adaptive GAs, the experiment results of optimizing six selected test functions by these GA variants show that the LAGA algorithm’s convergence accuracy and speed have been greatly improved, especially for high latitude functions. On this basis, a rule extraction method based on the symbol rule and NN, namely the LAGA-BP framework, is discussed in this manuscript to classify the real-valued attributes. This framework obtains hidden knowledge (knowledge refinement process) by NN and further transforms the acquired hidden knowledge into more easy-to-understand rule knowledge (rule extraction process). The execution of the LAGA-BP framework could be separated into two phases. The first phase is to optimize a back propagation NN (BPNN) using the LAGA and refine prediction classification knowledge over the optimized BPNN. In the second phase, an attribute reduction algorithm using multi-layered NN (SD algorithm) based on two different superposed networks is used in this framework to reduce data-set attributes and then uses the K-means clustering algorithm to extract the if-then rule from the simplified attributes. The Wisconsin breast cancer dataset is used as a case study to reveal the correctness and robustness of the proposed LAGA-BP method. Consulting relevant medical personnel and referencing relevant data shows that the rules extracted using this method help verify the diagnosis results, thus verifying the proposed framework’s feasibility and practicality.},
  keywords={Artificial neural networks;Knowledge engineering;Genetic algorithms;Feature extraction;Classification algorithms;Clustering algorithms;Expert systems;Adaptive genetic algorithm;back propagation neural network;attribute reduction;classification prediction;knowledge extraction},
  doi={10.1109/ACCESS.2022.3188689},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10984723,
  author={Tan, Lianghao and Peng, Zhuo and Liu, Xiaoyi and Wu, Weixi and Liu, Dong and Zhao, Ruobing and Jiang, Huangqi},
  booktitle={2025 5th International Conference on Consumer Electronics and Computer Engineering (ICCECE)}, 
  title={Efficient Grey Wolf: High-Performance Optimization for Reduced Memory Usage and Accelerated Convergence}, 
  year={2025},
  volume={},
  number={},
  pages={300-305},
  abstract={This paper presents an efficient Grey Wolf Optimizer (EGWO) designed to address the limitations of the standard Grey Wolf Optimizer (GWO), focusing on reducing memory usage and accelerating convergence. The proposed method integrates Sinusoidal Mapping for enhanced population diversity and a Transverse Longitudinal Crossover strategy to balance global exploration and local exploitation. These innovations improve search efficiency and optimization precision while maintaining a lightweight computational footprint. Experimental evaluations on 16 benchmark functions demonstrate EGWO's superior performance in convergence speed, solution accuracy, and robustness. Its application to hyperparameter tuning of a Random Forest model for a housing price dataset confirms its practical utility, further supported by SHAP-based interpretability analysis.},
  keywords={Technological innovation;Accuracy;Computational modeling;Memory management;Benchmark testing;Robustness;Optimization;Tuning;Standards;Convergence;Grey Wolf Optimizer;Lightweight Optimization;Sinusoidal Mapping;Crossover Strategy;Random Forest;SHAP Analysis},
  doi={10.1109/ICCECE65250.2025.10984723},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10469673,
  author={Hussein, Ahmed Abdulmunem and Yassen, Esam Taha and Rashid, Ahmed N.},
  booktitle={2023 16th International Conference on Developments in eSystems Engineering (DeSE)}, 
  title={Learning-Based Grey Wolf Optimizer for Job Shop Scheduling Problem}, 
  year={2023},
  volume={},
  number={},
  pages={864-869},
  abstract={This study introduces a novel integration of a discretized Grey Wolf Optimizer (DGWO) with Q-Learning (QL), marking a significant step in optimization techniques to solve Job Shop Scheduling Problem (JSSP). This innovative approach not only tailors the GWO for discrete optimization challenges but also utilizes QL for dynamic parameter tuning, a first in the field of JSSP. The synergy between these two methodologies advances solution quality and computational efficiency to new heights. Rigorous benchmarking against leading algorithms demonstrates the DGWO-QL’s superior performance, achieving the best-known solutions in 32 out of 34 cases. This breakthrough underscores the method’s robustness and its promising applicability to real-world scheduling complexities.},
  keywords={Measurement;Job shop scheduling;Q-learning;Statistical analysis;Processor scheduling;Benchmark testing;Robustness;Grey wolf optimizer;Job shop scheduling problem;Machine learning;Metaheuristics;Parameter tunning;Reinforcement learning},
  doi={10.1109/DeSE60595.2023.10469673},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10062084,
  author={Hu, Zhaohui and Chen, Shanfeng and Chen, Haiguang},
  booktitle={2022 4th International Academic Exchange Conference on Science and Technology Innovation (IAECST)}, 
  title={Convolutional Neural Network Based Power Information Network Security Situational Awareness Model}, 
  year={2022},
  volume={},
  number={},
  pages={243-247},
  abstract={At present, most of the external attacks against the power network are through the intrusion of the network layer to tamper with control instructions and sensor data, resulting in abnormal operation of the power system, thus causing serious damage to the power grid process. A variety of defensive measures for security have solved the security problems in the power grid in a variety of ways, but they still can not improve the comprehensive analysis of data in situational awareness. This paper focuses on the collected error or abnormal data, which will lead to abnormal large or small range, and can not normally extract the characteristics of the data. A power load forecasting algorithm based on attention mechanism is proposed by combining the convolutional neural network and GRU. Embedding and convolutional neural networks are applied to prioritize the description of vulnerabilities, which effectively improves forecasting accuracy. The experimental results verify that the model in this paper has a good practical application effect in the power network situation prediction. It can predict the possible attack range and the attack purpose, and establish an effective early warning means to protect the network from attack.},
  keywords={Technological innovation;Power measurement;Process control;Predictive models;Network security;Prediction algorithms;Power grids;Power network;Information security;Network attack;Perception and prediction;Neural network},
  doi={10.1109/IAECST57965.2022.10062084},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11064595,
  author={Reddy, K. Anji and Jyothi, V. Esther and Sai, D.M.V. Satya Siva and Vardhan, G. Chandhu Prabhu and Priyanka, D. and Reddy, K. Rishi Kaushal},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Interpretable AI for Cyber Security: Enhancing DDoS Detection with Lime and Population-Based Training Models}, 
  year={2025},
  volume={3},
  number={},
  pages={1766-1772},
  abstract={Due to increasing complexity and the proliferation of cyber threats, ML-based DDoS attacks are becoming more important. DDoS attacks in which multiple attacker systems send large amounts of data to a single server or network target. It can crash applications, reduce speed, and cause significant financial and image loss. The proximity of traditional standards-based detection systems and their reliance on predefined signatures sometimes prevents them from detecting new and changing threat patterns. Distributed Denial of Service (DDoS) attacks that increase access to target servers disrupting critical infrastructure causing economic loss and cause damage to reputation Traditional detection technology products and legal systems compete to match the hallmarks of today's DDoS attacks. Machine learning (ML) provides an unprecedented new technology for adaptive visibility and intelligently analyze different levels of network traffic to detect violations. In contrast to proactive routing and regular navigation, ML-based systems offer the advantage of continuous learning and flexibility. This makes it ideal for high-speed communications. This research explores existing ML methods such as multivariate augmentation and population learning modeling (PBTLGM), which increase identification accuracy. and use interpretation tools like LIME to make the identification process more transparent and reliable for cybersecurity professionals. The results show how the combination of large datasets improves the reliability of the model. This leads to model's identification accuracy level as high as 96.8%, in addition to the raw statistics. This study underscores how important it is to emphasize that predictive AI can Use it to provide actionable insights to security teams. By combining cutting-edge ML technology, this research enables powerful, real-time solutions to stay ahead of evolving threats. And it keeps everyone connected, secure, and very stable.},
  keywords={Training;Analytical models;Accuracy;Telecommunication traffic;Denial-of-service attack;Real-time systems;Complexity theory;Servers;Reliability;Computer crime;DDoS Attack Detection;Feature Fusion;Population-Based Training Gradient Boosting Model (PBTLGM);Network Security;Traffic Analysis;Anomaly Detection},
  doi={10.1109/ICCSAI64074.2025.11064595},
  ISSN={},
  month={April},}@INPROCEEDINGS{10340837,
  author={Ellis, Charles A. and Miller, Robyn L. and Calhoun, Vince D.},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Neuropsychiatric Disorder Subtyping Via Clustered Deep Learning Classifier Explanations *}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Identifying subtypes of neuropsychiatric disorders based on characteristics of their brain activity has tremendous potential to contribute to a better understanding of those disorders and to the development of new diagnostic and personalized treatment approaches. Many studies focused on neuropsychiatric disorders examine the interaction of brain networks over time using dynamic functional network connectivity (dFNC) extracted from resting-state functional magnetic resonance imaging data. Some of these studies involve the use of either deep learning classifiers or traditional clustering approaches, but usually not both. In this study, we present a novel approach for subtyping individuals with neuropsychiatric disorders within the context of schizophrenia (SZ). We trained an explainable deep learning classifier to differentiate between dFNC data from individuals with SZ and controls, obtaining a test accuracy of 79%. We next used cross-validation to obtain robust average explanations for SZ training participants across folds, identifying 5 SZ subtypes that each differed from controls in a distinct manner and that had different degrees of symptom severity. These subtypes specifically differed from one another in their interactions between the visual network and the subcortical, sensorimotor, and auditory networks and between the cerebellar network and the cognitive control and subcortical networks. Additionally, we uncovered statistically significant differences in negative symptom scores between the subtypes. It is our hope that the proposed novel subtyping approach will contribute to the improved understanding and characterization of SZ and other neuropsychiatric disorders.},
  keywords={Deep learning;Training;Visualization;Brain;Mental disorders;Functional magnetic resonance imaging;Biology},
  doi={10.1109/EMBC40787.2023.10340837},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{10134131,
  author={Stankovic, Marko and Bacanin, Nebojsa and Budimirovic, Nebojsa and Zivkovic, Miodrag and Sarac, Marko and Strumberger, Ivana},
  booktitle={2023 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Bi-Directional Long Short-Term Memory Optimization by Improved Teaching-Learning Based Algorithm for Univariate Gold Price Forecasting}, 
  year={2023},
  volume={},
  number={},
  pages={1650-1657},
  abstract={Critical operations of the global financial sector are significantly impacted by the volatility of the price of gold. Developing a robust forecasting model capable of recognizing patterns in the gold price dynamics may significantly reduce investment risks and enable considerable profits. This manuscript introduces an inventive deep learning forecasting system rested on the Bi-directional Long Short-term (BiLSTM) neural network that exploits the potential of these networks to apprehend short-term as well as long-term dependencies. This study developed a unique improved Teaching-learning Based (ITLB) method utilized to optimize the hyperparameter selection procedure since the performance of neural networks is heavily dependent upon the combination of adequate control parameters. Variation Mode Decomposition (VMD) was also used to discover trends in the gold price data prior to being submitted as input to the BiLSTM. A set of experiments has been conducted and the suggested model was compared to several cutting-edge metaheuristic algorithms. Overall results illustrate that the introduced BiLSTM-VMD-ITLB approach achieved superior forecasting results in predicting gold price fluctuations.},
  keywords={Gold;Neural networks;Metaheuristics;Bidirectional control;Predictive models;Prediction algorithms;Pattern recognition;Gold Price Forecasting;Long Short-Term Memory;Variation mode decomposition;Teaching-learning based algorithm;Metaheuristic optimization},
  doi={10.1109/ICICT57646.2023.10134131},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10371808,
  author={De Lima, Rafael Henrique Nogalha and Costa, Aurélio Ribeiro and De Paulo Faleiros, Thiago and Ralha, Célia Ghedini},
  booktitle={2023 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={An Actor-Critic Architecture for Community Detection Ablation Study}, 
  year={2023},
  volume={},
  number={},
  pages={13-18},
  abstract={This article conducts an ablation study of the Actor-Critic Architecture for Community Detection (AC2CD). The AC2CD uses Deep Reinforcement Learning (DRL) and Graph Attention Networks (GAT). Our ablation study method adheres to the principles of explainable artificial intelligence, focusing on assessing performance factors, including execution time, memory usage, and GPU utilization. We carried out experiments using two real-world datasets: Email-Eu-Core (EC), an email network among members of a European research institution (comprising 1,005 nodes, 25,571 edges, and 42 communities) available through the Stanford Snap Project, and a High School contact and friendship network (HS) in Marseilles, France, from December 2013 (comprising 329 nodes, 45,047 edges, and nine communities), obtainable from the Socio Patterns Website. We evaluated performance while considering three hyperparameters: learn_rate (LR), batch_size (BS), and n_games (NG), varying them at 10%, 30%, 50%, and 70%. The LR of 70% yielded optimal results with execution time for both EC and HS datasets. Furthermore, a BS of 70% indicated an ideal balance between execution time, GPU usage, and memory consumption for the HS dataset.},
  keywords={Deep learning;Tensors;Computational modeling;Memory management;Graphics processing units;Focusing;Europe;Ablation Study;AC2CD;Hyperparameters},
  doi={10.1109/SSCI52147.2023.10371808},
  ISSN={2472-8322},
  month={Dec},}@INPROCEEDINGS{11052970,
  author={N, Amirthavinayagam and K, Meenakshi},
  booktitle={2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE)}, 
  title={Harnessing the Deep Learning techniques in Cashew plant disease management}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The cashew (Anacardium occidentale K), originating in Brazil, was introduced to India by the Portuguese in the 16th Century. It is a significant crop for India, contributing substantially to the country's foreign exchange earnings. Various arthropods are known to infect cashew plants. This research employs pretrained deep learning and vision transformer model-based algorithms to identify pests and infections in cashew plants with high accuracy and precision at early stages. Cashew images from the CCMT (Cashew, Cassava, Maize, and Tomato) Dataset were used to train and develop advanced models. The dataset includes samples of Anthracnose, Gummosis, Leaf Miner, Red Rust, and healthy cashew plants/leaves. Vision Transformer model and pretrained DenseNet201 model were used to compare performance in detecting diseases in cashew plants. Hyperparameter tuning through random means improved model performance, achieving an accuracy of 91% and 95.95% for DenseNet201 and Vision Transformer models, respectively. Optimization using Differential Evolution on the Vision Transformer model further improved accuracy to 96.75%.},
  keywords={Deep learning;Training;Computer vision;Accuracy;Crops;Transformers;Yield estimation;Optimization;Tuning;Testing;Image Classification;DenseNet201;Vison Transformer;Differential Evolution;Optimization;Artificial Intelligence;Cashew plantation},
  doi={10.1109/ICCRTEE64519.2025.11052970},
  ISSN={},
  month={May},}@INPROCEEDINGS{10774221,
  author={Yan, Chen and Sun, Yifu and Liu, Xi},
  booktitle={2024 IEEE 22nd International Conference on Industrial Informatics (INDIN)}, 
  title={Multi-Stage Product Quality Prediction Based on CNN-BiGRU-Attention}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Accurate product quality prediction can help the enterprise improve the overall emergency response capability of quality issues and reduce quality-related cost losses. In the manufacturing process of multi-stage products, the quality data exhibits some special characteristics such as high dimensionality, nonlinearity, and temporality. Traditional mechanism models and simple statistical analysis prediction models have limitations in these scenarios. This paper constructs a model including the identification of key quality features and the prediction of target quality indicators to address quality prediction for multi-stage products. First, feature selection is conducted in two stages through filtering and wrapping methods to reduce dimensionality and obtain key quality features. Then, the model combining convolutional neural network and bidirectional gated recurrent unit with attention mechanism (CNN-BiGRU-Attention), whose hyperparameters are optimized by the GOOSE algorithm, is used for prediction of product quality indicator. Finally, the model's performance is validated using real-world data collected from the manufacturing process of thin film transistor liquid crystal display (TFT-LCD) products. This study can provide some references for the product quality prediction using highdimensional industrial data.},
  keywords={Dimensionality reduction;Manufacturing processes;Filtering;Predictive models;Logic gates;Feature extraction;Prediction algorithms;Product design;Quality assessment;Thin film transistors;multi-stage product;quality prediction;key quality features;bidirectional gated recurrent unit (BiGRU)},
  doi={10.1109/INDIN58382.2024.10774221},
  ISSN={2378-363X},
  month={Aug},}@INPROCEEDINGS{10903892,
  author={Donvir, Anujkumarsinh and Sharma, Gaurav},
  booktitle={2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={Ethical Challenges and Frameworks in AI-Driven Software Development and Testing}, 
  year={2025},
  volume={},
  number={},
  pages={00569-00576},
  abstract={Artificial Intelligence (AI) has revolutionized and transformed the landscape of software development and testing by introducing new efficiencies and capabilities through advancements like Generative AI (GenAI) and Large Language Models (LLMs). While these technologies bring major benefits in terms of productivity, personalization, and innovation, they also raise critical ethical challenges, such as biases, lack of transparency, data privacy concerns, and potential negative societal impacts. This paper examines the ethical considerations involved in developing such advanced AI systems as well using AI systems within software development and testing. It explores existing ethical frameworks and principles provided by leading organizations, emphasizing core concepts like human-centered design, accountability, transparency, fairness, and privacy. Practical strategies for integrating ethical practices throughout the AI development lifecycle are discussed, with a strong emphasis on the need for continuous ethical evaluation. The paper explores the ethical landscape of AI in software development, addressing challenges like algorithmic bias, data security, and broader societal impacts. Real-world case studies presented in the paper demonstrate the consequences of neglecting ethical considerations. Looking forward, the paper suggests future directions, including the development of unified ethical standards, collaborative ethical auditing, regulatory advancements, and higher societal engagement.},
  keywords={Ethics;Technological innovation;Data privacy;Standards organizations;Software algorithms;Collaboration;Stakeholders;Artificial intelligence;Software development management;Testing;Artificial Intelligence (AI);Ethical AI;Software Development;Software Testing;Generative AI (GenAI);Large Language Models (LLMs);Ethical Frameworks;Human-Centered Design;Accountability;Transparency;Fairness and Non-Discrimination;Data Privacy;Responsible AI;Bias Detection;Explainable AI (XAI);Ethical Auditing;Regulatory Frameworks;Societal Engagement;Case Studies in AI Ethics},
  doi={10.1109/CCWC62904.2025.10903892},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10356569,
  author={Datla, Gautam Varma and Jiang, Haodi and Wang, Jason T. L.},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={An Interpretable LSTM Network for Solar Flare Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={526-531},
  abstract={Deep learning models are often considered black box models as their internal workings tend to be opaque to the user. Because of this lack of transparency, it is challenging to understand the reasoning behind the model’s predictions. Here, we present an approach to making a solar flare prediction model interpretable. This model, built based on a long short-term memory (LSTM) network with an attention mechanism, aims to predict whether an active region (AR) on the Sun’s surface would produce a large flare, namely an M- or X-class flare, within 24 hours. The flare events used in this study are collected from the Geostationary Operational Environmental Satellite X-ray flare catalogs provided by the National Centers for Environmental Information. The crux of our approach is to model data samples in an AR as time series and use the LSTM network to capture the temporal dynamics of the data samples. Each data sample has 22 features including magnetic parameters and flare history parameters. To make the model’s predictions accountable and reliable, we leverage post hoc model-agnostic techniques, which help elucidate the factors contributing to the predicted output for an input sequence and provide insights into the model’s behavior across multiple sequences within an AR. To our knowledge, this is the first time that interpretability has been added to an LSTM-based flare prediction model.},
  keywords={Deep learning;Satellites;Time series analysis;Predictive models;Data models;Cognition;Reliability;Interpretable deep learning;Solar flares;LSTM},
  doi={10.1109/ICTAI59109.2023.00084},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11043019,
  author={Cen, Shipeng and Tan, Ying},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={LLM-Driven Customizable Fireworks Algorithm for Diverse Optimization Tasks}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Designing specific optimizers for specific optimization tasks has been an important but difficult task due to the No Free Lunch theorem. Nowadays, large language models have been widely applied to automatic algorithm design, but much of the current work still focuses on the design of heuristic rules. In this work, we propose a framework for the evolution of optimizer (Fireworks Algorithm) based on large language models, thereby achieving the customization of specific Fireworks Algorithms for different specific problems. In the experimental part, we use GFWA as the starting point for evolution and achieve significant improvement in optimization on both CEC2013 and CEC2017, while on many engineering problems with very complex constraints, the LLM-driven Fireworks Algorithm generates solutions that not only satisfy all constraints but also have higher quality compared to previous work, which underscores the great potential of the large language model in optimizing the optimizer . It is worth noting that this framework diminishes the reliance on expert knowledge, which was previously emphasized.},
  keywords={Fireworks algorithm;Large language models;Heuristic algorithms;Evolutionary computation;Automobiles;Optimization;Automatic algorithm design;Large language model;Fireworks algorithm;No free lunch theorem;Evolution against the optimizer},
  doi={10.1109/CEC65147.2025.11043019},
  ISSN={},
  month={June},}@ARTICLE{10645815,
  author={Lu, Chengjie and Ali, Shaukat and Yue, Tao},
  journal={IEEE Transactions on Software Engineering}, 
  title={EpiTESTER: Testing Autonomous Vehicles With Epigenetic Algorithm and Attention Mechanism}, 
  year={2024},
  volume={50},
  number={10},
  pages={2614-2632},
  abstract={Testing autonomous vehicles (AVs) under various environmental scenarios that lead the vehicles to unsafe situations is challenging. Given the infinite possible environmental scenarios, it is essential to find critical scenarios efficiently. To this end, we propose a novel testing method, named EpiTESTER, by taking inspiration from epigenetics, which enables species to adapt to sudden environmental changes. In particular, EpiTESTER adopts gene silencing as its epigenetic mechanism, which regulates gene expression to prevent the expression of a certain gene, and the probability of gene expression is dynamically computed as the environment changes. Given different data modalities (e.g., images, lidar point clouds) in the context of AV, EpiTESTER benefits from a multi-model fusion transformer to extract high-level feature representations from environmental factors. Next, it calculates probabilities based on these features with the attention mechanism. To assess the cost-effectiveness of EpiTESTER, we compare it with a probabilistic search algorithm (Simulated Annealing, SA), a classical genetic algorithm (GA) (i.e., without any epigenetic mechanism implemented), and EpiTESTER with equal probability for each gene. We evaluate EpiTESTER with six initial environments from CARLA, an open-source simulator for autonomous driving research, and two end-to-end AV controllers, Interfuser and TCP. Our results show that EpiTESTER achieved a promising performance in identifying critical scenarios compared to the baselines, showing that applying epigenetic mechanisms is a good option for solving practical problems.},
  keywords={Epigenetics;Testing;Genetic algorithms;Attention mechanisms;Transformers;Feature extraction;Pedestrians;Autonomous vehicle testing;epigenetic algorithm;attention mechanism},
  doi={10.1109/TSE.2024.3449429},
  ISSN={1939-3520},
  month={Oct},}@ARTICLE{10296894,
  author={Syed, Farrukh Hasan and Tahir, Muhammad Atif and Frnda, Jaroslav and Rafi, Muhammad and Anwar, Muhammad Shahid and Nedoma, Jan},
  journal={IEEE Access}, 
  title={Toward an Optimal and Structured Feature Subset Selection for Multi-Target Regression Using Genetic Algorithm}, 
  year={2023},
  volume={11},
  number={},
  pages={121966-121977},
  abstract={Multi Target Regression (MTR) is a machine learning method that simultaneously predicts multiple real-valued outputs using a set of input variables. A lot of emerging applications that can be mapped to this class of problem. In MTR method one of the critical aspect is to handle structural information like instance and target correlation. MTR algorithms attempt to exploit these interdependences when building a model. This results in increased model complexities, which in turn, reduce the interpretability of the model through manual analysis of the result. However, data driven real-world applications often require models that can be used to analyze and improve real-world workflows. Leveraging dimensionality reduction techniques can reduce model complexity while retaining the performance and boost interpretability. This research proposes multiple feature subset alternatives for MTR using genetic algorithm, and provides a comparison of the different feature subset selection alternatives in conjunction with MTR algorithms. We proposed a genetic algorithm based feature subset selection with all targets and with individual target keeping the structural information intact in the selection process. Experiments are performed on real world benchmarked MTR data sets and the results indicate that a significant improvement in performance can be obtained with comparatively simple MTR models by utilizing optimal and structured feature selection.},
  keywords={Feature extraction;Genetic algorithms;Task analysis;Machine learning algorithms;Data models;Complexity theory;Analytical models;Multi-target regression;feature selection;genetic algorithm;single target;multiple objectives},
  doi={10.1109/ACCESS.2023.3327870},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10417913,
  author={Kramberger, Renata and Fister, Iztok and Fister, Iztok and Kamišalić, Aida},
  booktitle={2023 IEEE 21st Jubilee International Symposium on Intelligent Systems and Informatics (SISY)}, 
  title={Toward Anomaly Detection in the Blockchain Using Numerical Association Rule Mining}, 
  year={2023},
  volume={},
  number={},
  pages={351-356},
  abstract={With the global increase in the popularity of cryptocurrencies, the need for anomaly detection and fraudulent behavior is reaching an all-time high. In our paper, we propose a novel method of anomaly detection with the use of Numerical Association Rule Mining with Differential Evolution. The experiment was conducted by using the Dogecoin blockhain, and the dataset contained all of the transactions from one month. Our results contained 303 rules, with the best fitness function value of 0.8.},
  keywords={Blockchains;Behavioral sciences;Cryptocurrency;Intelligent systems;Informatics;Anomaly detection;Numerical Association Rule Mining;Differential Evolution;Blockchain;Dogecoin;Anomaly Detection},
  doi={10.1109/SISY60376.2023.10417913},
  ISSN={1949-0488},
  month={Sep.},}@INPROCEEDINGS{10424214,
  author={Zitouni, Farouq and Harous, Saad and Lagrini, Samira and Cheradid, Abdellatif and Guerfi, Sahla and Frihi, Ferdousse Saida},
  booktitle={2023 Computer Applications & Technological Solutions (CATS)}, 
  title={APDO: A Hybrid Aquila Optimizer and Prairie Dog Optimization Metaheuristic Algorithm for Global, Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={We propose a hybrid metaheuristic algorithm that combines the strengths of the Aquila Optimizer (AO) and the Prairie Dog Optimization (PDO) algorithms. The proposed algorithm is named the Aquila Prairie Dog Optimization (APDO) algorithm. During the initialization phase of the APDO algorithm, chaotic maps are employed to enhance the exploration capabilities, as they introduce randomness into the initialization process. In addition, opposition-based learning is incorporated during the swarming process, wherein the objective is to consider the opposite values of the current solutions, to expand the diversity of the swarm and to avoid local optimums. Moreover, to assess and evaluate the performance of the APDO algorithm, a comprehensive comparative analysis was conducted by benchmarking it against five widely recognized metaheuristics, across a diverse set of challenging optimization problems, encompassing: unimodal, multimodal, hybrid and composition functions. Finally, the performance evaluation of the APDO algorithm was conducted using the Friedman post hoc Dunn’s test, which revealed compelling results indicating that the APDO algorithm demonstrated superior performance in the majority of cases, when compared to the other benchmarked algorithms, thereby showcasing its competitiveness and efficacy in tackling diverse optimization problems.},
  keywords={Performance evaluation;Grasslands;Metaheuristics;Dogs;Benchmark testing;Standards;Global Optimization;Metaheuristics;Hybridization;Aquila Optimizer;Prairie Dog Optimization Algorithm;Chaotic Maps;Opposition-Based Learning},
  doi={10.1109/CATS58046.2023.10424214},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10796197,
  author={Balassem, Zaid Ajzan and Silvia, Ensteih and Thind, Harpreet Kaur and Harirajkumar, J. and Kavitha, P.},
  booktitle={2024 First International Conference on Software, Systems and Information Technology (SSITCON)}, 
  title={Anomaly Detection in Traffic Surveillance Videos using Differential Evolution Dragonfly Algorithm with VGG16}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Anomaly detection in video surveillance systems is an eminently vital field due to the widespread utility of the method, ranging from public security to monetary safety. Numerous architectures can be used for detection, extraction, selection and classification of the anomalous sequences. However, traditional optimization algorithms suffer from poor initialisation conditions and premature convergence in feature selection. Further, existing network architectures show a saturation in accuracy with an increasing number of layers. This work proposes a Differential Evolution Dragonfly algorithm (DE-DA) with VGG16 which helps to prevent local trapping for anomaly detection in traffic surveillance video. In the preprocessing step, keyframes are extracted using Histogram of Differences (HOD) to find outliers in the images and then, an auto-encoder architecture is used to perform codebook generation. DE-DA is used to select the features and VGG16 network performs classification with the help of residual blocks with skip connections. The proposed DE-DA with VGG16 achieves $31 \%$ of Equal Error Rate (EER) compared to the existing auto-encoder.},
  keywords={Histograms;Accuracy;Computer architecture;Traffic control;Feature extraction;Video surveillance;Classification algorithms;Spatiotemporal phenomena;Anomaly detection;Convergence;auto-encoder;differential evolution;dragonfly algorithm;histogram of differences;residual blocks;VGG16},
  doi={10.1109/SSITCON62437.2024.10796197},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10825069,
  author={Zhang, Olivia and Grissom, Brianna and Pulido, Julian and Munoz-Ordaz, Kenia and He, Jonathan and Cham, Mostafa and Jing, Haotong and Qian, Weikang and Wen, Yixin and Wang, Jianwu},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Accurate and Interpretable Radar Quantitative Precipitation Estimation with Symbolic Regression}, 
  year={2024},
  volume={},
  number={},
  pages={2254-2263},
  abstract={Accurate quantitative precipitation estimation (QPE) is essential for managing water resources, monitoring flash floods, creating hydrological models, and more. Traditional methods of obtaining precipitation data from rain gauges and radars have limitations such as sparse coverage and inaccurate estimates for different precipitation types and intensities. Symbolic regression, a machine learning method that generates mathematical equations fitting the data, presents a unique approach to estimating precipitation that is both accurate and interpretable. Using WSR-88D dual-polarimetric radar data from Oklahoma and Florida over three dates, we tested symbolic regression models involving genetic programming and deep learning, symbolic regression on separate clusters of the data, and the incorporation of knowledge-based loss terms into the loss function. We found that symbolic regression is both accurate in estimating rainfall and interpretable through learned equations. Accuracy and simplicity of the learned equations can be slightly improved by clustering the data based on select radar variables and by adjusting the loss function with knowledge-based loss terms. This research provides insights into improving QPE accuracy through interpretable symbolic regression methods.},
  keywords={Accuracy;Rain;Knowledge based systems;Estimation;Genetic programming;Radar;Mathematical models;Floods;Water resources;Monitoring;quantitative precipitation estimation;polarimetric radar;symbolic regression;knowledge-based loss terms},
  doi={10.1109/BigData62323.2024.10825069},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10718739,
  author={Kuang, Zhaoqi and Ma, Changjiang and Zhang, Hexu and Li, Lin and Li, Yun},
  booktitle={2024 29th International Conference on Automation and Computing (ICAC)}, 
  title={Dual Data and Mechanism Based Prediction Model for Photovoltaic Modules}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Accurate photovoltaic power prediction is of great significance for the stability and safety of the power grid, but present methods lack explainability or accuracy. This paper develops a dual data and mechanism based method for photovoltaic power prediction. Its model combines physical a-priori knowledge of the photovoltaic modules for explainability and data-driven fitting for accuracy. This method is based on the single diode model and its model parameters are adjusted using a hybrid model based on convolutional neural networks and long short-term memory (CNN-LSTM). We evaluate this model by conducting experiments on open-source photovoltaic dataset. The results demonstrate the effectiveness of this dual data and mechanism driven model.},
  keywords={Accuracy;Computational modeling;Predictive models;Power system stability;Data models;Stability analysis;Power grids;Safety;Solar panels;Convolutional neural networks;Explainable artificial intelligence;Convolutional neural networks;Long short-term memory;Photovoltaic power prediction;System modelling},
  doi={10.1109/ICAC61394.2024.10718739},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10890547,
  author={Zhang, Zhicheng and Wang, Yong and Tan, Shaoqi and Luo, Yujie},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={GeMIMO: Searching the Cores of X-formers for Time Series Forecasting}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, Transformer-based models have been widely used in time series forecasting tasks, demonstrating exceptional performance. However, these models lack interpretability, making it difficult to identify which components play a core role in predictions and which are redundant. To address this limitation, we introduce the GeMIMO method, which utilizes a heuristic algorithm to identify and refine masks. We applied GeMIMO to the Transformer model, and the results showed that temporal encoding had no significant effect, while positional encoding was only effective in the decoder. Moreover, the experiments suggest that the attention mechanism is not the most critical component of the Transformer; instead, the feedforward neural network and normalization layers are key to improving predictive accuracy. By applying the masks learned through GeMIMO to optimize the Transformer, we observed an 28% improvement in prediction efficiency and an 25% increase in accuracy, demonstrating the effectiveness of GeMIMO.},
  keywords={Accuracy;Heuristic algorithms;Time series analysis;Signal processing algorithms;Predictive models;Transformer cores;Transformers;Prediction algorithms;Encoding;Forecasting;Transformer;Time Series Analysis;Interpretability;Genetic Algorithm},
  doi={10.1109/ICASSP49660.2025.10890547},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{11076782,
  author={Khan, Shamshad Ahmed and Balusamy, Suguna and Saviour, Mariya Princy Antony and Bojjawar, Satish and C. M, Chidambaranathan and Sofia, D. Sumithra},
  booktitle={2025 Global Conference in Emerging Technology (GINOTECH)}, 
  title={Integrating Blockchain Technology with Artificial Intelligence to Create Scalable, Reliable, and Open Decision Support Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Blockchain Technology (BT) is a promising approach for building scalable & reliable open Decision Support Systems and Artificial Intelligence (AI) could be integrated with BT to present a better approach towards the same. Transparency, trust, data security, and scalability are traditionally regarded as the major deficiencies of DSS models which may impede their efficacy in critical decision-making environments. Seamlessly integrating blockchain with AI-powered DSS can help with data integrity, as well as prevent manipulation and inconsistencies while improving trust with many different stakeholders, because all transactions on a blockchain are transparent immutable, owing to blockchain's decentralized ledger system. The paper investigates a hybrid Blockchain-AI framework that can overcome the main drawbacks of existing DSS systems. This means that AI predictive analytics and machine learning models can match massive datasets for decision making, while blockchain guarantees the integrity, traceability, and decentralization of the data's inputs and outputs. Smart contracts: automate decision processes & ensure tamper-proof execution for defined set of rules & policies In addition, blockchain consensus mechanisms (e.g., Proof-of-Stake, Byzantine Fault Tolerance) can facilitate transparency and verifiability, thus improving conflict-avoiding distributed decision-making. To enable privacy-preserving collaboration between organizations, we introduce a new Decentralized AI Decision Support System (Dai-DSS) framework that integrates federated learning and a distributed ledger. It enables real-time data sharing while preserving data sovereignty, which helps organizations comply with regulatory standards such as GDRP and HIPAA. We are also looking at various optimization techniques such as off-chain scaling solutions (sidechains, Layer-2 protocols, etc.) that improve system efficiency while still keeping the system decentralized. Our research shows that by comparing with the traditional DSS models, the Blockchain-AI integration strengthens system resilience, improves the elimination of single point failure and facilitates open, trustless decision-making processes. Practical applications and the benefits of the proposed model are demonstrated through case studies in healthcare, finance, and supply chain management. Lastly, we address the challenges including computational overhead, interoperability and regulatory challenges, and suggest future research avenues on AI-augmented consensus algorithms and quantum-resistant cryptography. The research demonstrates the ability of Blockchain-AI synergy to revolutionize decision-making systems through decentralized, clean, and scalable operating frameworks across industries.},
  keywords={Decision support systems;Supply chain management;Scalability;Data integrity;Computational modeling;Standards organizations;Organizations;Trustless services;Blockchains;Artificial intelligence;Smart Contracts;Decision Support Systems;Federated Learning;Trustless Computing;Decentralization;Scalable AI;Privacy-Preserving AI;Data Integrity},
  doi={10.1109/GINOTECH63460.2025.11076782},
  ISSN={},
  month={May},}@INPROCEEDINGS{10271611,
  author={Stember, Joseph and Jenabi, Mehrnaz and Pasquini, Luca and Peck, Kyung and Holodny, Andrei and Shalu, Hrithwik},
  booktitle={2023 5th International Conference on Intelligent Medicine and Image Processing (IMIP)}, 
  title={Deep neuroevolution to predict astrocytoma grade from functional brain networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Whereas MRI produces anatomic information about the brain, functional MRI (fMRI) tells us about neural activity within the brain, including how various regions communicate with each other. The full chorus of conversations within the brain is summarized elegantly in the adjacency matrix. Although information-rich, adjacency matrices typically provide little in the way of intuition. Whereas trained radiologists viewing anatomic MRI can readily distinguish between different kinds of brain cancer, a similar determination using adjacency matrices would exceed any expert’s grasp. Artificial intelligence (AI) in radiology usually analyzes anatomic imaging, providing assistance to radiologists. For non-intuitive data types such as adjacency matrices, AI moves beyond the role of helpful assistant, emerging as indispensable. We sought here to show that AI can learn to discern between two important brain tumor types, high-grade glioma (HGG) and low-grade glioma (LGG), based on adjacency matrices. We trained a convolutional neural networks (CNN) with the method of deep neuroevolution (DNE), because of the latter’s recent promising results; DNE has produced remarkably accurate CNNs even when relying on small and noisy training sets, or performing nuanced tasks. After training on just 30 adjacency matrices, our CNN could tell HGG apart from LGG with perfect testing set accuracy. Saliency maps revealed that the network learned highly sophisticated and complex features to achieve its success. Hence, we have shown that it is possible for AI to recognize brain tumor type from functional connectivity. In future work, we will apply DNE to other noisy and somewhat cryptic forms of medical data, including further explorations with fMRI.},
  keywords={Training;Oral communication;Functional magnetic resonance imaging;Radiology;Convolutional neural networks;Noise measurement;Artificial intelligence;evolutionary strategies;deep neuroevolution (DNE);deep learning;convolutional neural networks (DNN);small data AI;resting state functional MRI (rfMRI);low grade glioma (LGG);high grade glioma (HGG)},
  doi={10.1109/IMIP57114.2023.00008},
  ISSN={},
  month={March},}@ARTICLE{11079615,
  author={Abbas, Muhammad Tahir and Li, Yurong and Grinnemo, Karl-Johan and Brunstrom, Anna and Eklund, Johan and Rajiullah, Mohammad},
  journal={IEEE Internet of Things Journal}, 
  title={Dynamic NB-IoT Configuration: A Machine Learning-Driven Optimization Framework}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The deployment of Cellular Internet of Things (CIoT) is expected to reach over six billion devices by 2030. Many of these devices will be located in remote areas where replacing or recharging their batteries would be difficult and expensive. Therefore, it is crucial to configure these devices for efficient energy use to avoid frequent battery replacements or recharging. However, optimizing the energy consumption of CIoT devices, considering their applications and operating environmental conditions, presents a complex challenge. In response to this challenge, we propose the Gradient-Boosted Learning Optimization for Battery Efficiency (GLOBE) framework for dynamic configuration of Narrowband Internet of Things (NB-IoT) devices. GLOBE adjusts the radio layer of NB-IoT devices based on data transmission patterns and network conditions, enabling swift and automated reconfiguration. Our results demonstrate that GLOBE reduces energy consumption by 30% to 75% compared to baseline configurations, offering significant benefits for both network operators and end devices by improving energy efficiency.},
  keywords={Internet of Things;Energy consumption;Batteries;Energy efficiency;Data communication;Optimization;Uplink;Power demand;Base stations;Performance evaluation;CIoT;NB-IoT;energy efficiency;machine learning;gradient boost;particle swarm optimization},
  doi={10.1109/JIOT.2025.3588596},
  ISSN={2327-4662},
  month={},}@INPROCEEDINGS{10605166,
  author={Duan, Zhihua and Wang, Jialin},
  booktitle={2024 IEEE 11th International Conference on Cyber Security and Cloud Computing (CSCloud)}, 
  title={AutoTest: Evolutionary Code Solution Selection with Test Cases}, 
  year={2024},
  volume={},
  number={},
  pages={132-134},
  abstract={With the development of code generation techniques, selecting the correct code solution from multiple candidate solutions has become a crucial task. This study proposes AutoTest, a novel technique that combines automated test case generation with code solution execution to optimize the selection process using an evolutionary genetic algorithm. Firstly, AutoTest utilizes large pre-trained language models such as codegen-16B, code-davinci-002, and incoder-6B to provide code solutions and their corresponding test cases. Then, by executing the code solutions and evaluating their performance on the test cases, a consensus set is formed. Fine-grained ranking is achieved through the selection, mutation, and crossover mechanisms based on the evolutionary genetic algorithm, with the adjustment of alpha and beta parameters. Finally, the best code solution is chosen. AutoTest demonstrates significant performance improvements on the HumanEval benchmark test. The HumanEval dataset consists of 164 programming problems, and AutoTest achieves approximately a 10% improvement over the baseline method in terms of pass@1 score.},
  keywords={Computer languages;Cloud computing;Codes;Large language models;Computational modeling;Programming;Benchmark testing;Codex;InCoder;CodeGen;HumanEval;Large Language Model},
  doi={10.1109/CSCloud62866.2024.00030},
  ISSN={2693-8928},
  month={June},}@ARTICLE{10440097,
  author={Zitouni, Farouq and Almazyad, Abdulaziz S. and Xiong, Guojiang and Mohamed, Ali Wagdy and Harous, Saad},
  journal={IEEE Access}, 
  title={An Opposition-Based Great Wall Construction Metaheuristic Algorithm With Gaussian Mutation for Feature Selection}, 
  year={2024},
  volume={12},
  number={},
  pages={30796-30823},
  abstract={The feature selection problem involves selecting a subset of relevant features to enhance the performance of machine learning models, crucial for achieving model accuracy. Its complexity arises from the vast search space, necessitating the application of metaheuristic methods to efficiently identify optimal feature subsets. In this work, we employed a recently proposed metaheuristic algorithm named the Great Wall Construction Algorithm to address this challenge – a powerful optimizer with promising results. To enhance the algorithm’s performance in terms of exploration, exploitation, and avoidance of local optima, we integrated opposition-based learning and Gaussian mutation techniques. The proposed algorithm underwent a comprehensive comparative analysis against ten influential state-of-the-art methodologies, encompassing seven contemporary algorithms and three classical counterparts. The evaluation covered 22 datasets of varying sizes, ranging from 9 to 856 features, and included the utilization of six distinct evaluation metrics related to accuracy, classification error rate, number of selected features, and completion time to facilitate comprehensive comparisons. The obtained numerical results underwent rigorous scrutiny through several non-parametric statistical tests, including the Friedman test, the post hoc Dunn’s test, and the Wilcoxon signed ranks test. The resulting mean ranks and p-values unequivocally demonstrate the superior efficacy of the proposed algorithm in addressing the feature selection problem. The Matlab source code for the proposed approach is available for access via the link “https://www.mathworks.com/matlabcentral/fileexchange/159728-an-opposition-based-gwca-for-thefs-problem”.},
  keywords={Classification algorithms;Metaheuristics;Transfer functions;Feature extraction;Computational modeling;Convergence;Gaussian processes;Source coding;Machine learning;Matlab;Feature selection problem;great wall construction metaheuristic algorithm;opposition-based learning;Gaussian mutation},
  doi={10.1109/ACCESS.2024.3367440},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10115582,
  author={Wu, Zhijun and Fan, Haoyu},
  booktitle={2023 IEEE Aerospace Conference}, 
  title={Aviation Network Security Situation Awareness Based on Game Theory}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={As aviation industry has progressed in recent years, the entire industry has become more and more relying on digital network connectivity and electronic data exchange. While these changes bring efficiency, they also provide opportunities for hackers and malware to threaten flight safety. For example, in 2022, the Canadian airline Sunwing experienced flight delays due to cyber attacks. In many cases, if proper defense strategies are used early, the damage caused by the threat can be greatly reduced. However, due to dynamic, heterogeneous and huge structural characteristics of aviation systems, managers are unable to assess the current system security status in a real-time and accurate way, which affects the decision-making process and leads to expose the whole system under the risk. Therefore, aviation networks need a situational awareness mechanism to help managers adjust their strategies and limit the impact of threats in a timely and accurate manner. There has been a lot of current research in network security situational awareness, but there are some problems when these studies are directly applied to aviation networks. In order to establish a situation awareness mechanism applicable to aviation networks, this paper proposes a situation awareness method based on game theory, particle swarm optimization algorithm and neural network by analyzing the strategy gain of attackers and defenders under network attack and defense, particle swarm optimization algorithm and long short-term memory networks. The innovative works of this paper are as follows. Firstly, the situation assessment model is established based on the classification of attackers; secondly, the method of situation prediction with improved particle swarm optimization algorithm and long short-term memory networks is proposed. Simulation experiment shows that the method in this paper has the advantages of high evaluation efficiency and low error rate of prediction results, which can reason about the attacker class and help managers to make reasonable decisions.},
  keywords={Neural networks;Network security;Predictive models;Prediction algorithms;Real-time systems;Classification algorithms;Safety},
  doi={10.1109/AERO55745.2023.10115582},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10674598,
  author={Kang, Shitong and Shi, Yunpeng and Chen, Yuyao and Wang, Haolin},
  booktitle={2024 IEEE 4th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Enhancing Tennis Match Predictions with AHP, XGBoost, and Genetic Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={314-320},
  abstract={The goal of this paper is to explore and predict the effects of momentum in tennis matches by constructing an integrated model. The study begins by using the Analytic Hierarchy Process to identify the key factors affecting momentum in matches and then optimizes the weights of these factors using the XGBoost algorithm and a genetic algorithm to improve prediction accuracy. By analyzing data from the 2023 Wimbledon Open, the model demonstrated a fit of approximately 70%, effectively revealing the significant impact of serve advantage and combined factors on match outcomes. In addition, sensitivity analyses of the model further validated its responsiveness to specific characteristics, while generalisability tests demonstrated the model's potential to be applied to different types of tennis matches. These findings not only provide coaches and athletes with a scientific basis for tactical adjustments and mental preparation but also offer new perspectives on model construction and analysis methods in competitive sports. The methodology and findings of this study are important for understanding momentum phenomena in competitive sports and for developing effective prediction tools.},
  keywords={Training;Analytical models;Accuracy;Analytic hierarchy process;Predictive models;Prediction algorithms;Data models;XGBOOST;Analytic hierarchy process;Multiple linear regression;correlation test;genetic algorithm},
  doi={10.1109/SEAI62072.2024.10674598},
  ISSN={},
  month={June},}@ARTICLE{10292561,
  author={Chan, Michael and Gazi, Asim H. and Aydemir, Varol B. and Soliman, Moamen and Ozmen, Goktug C. and Richardson, Kristine L. and Abdallah, Calvin A. and Nikbakht, Mohammad and Nichols, Christopher and Inan, Omer T.},
  journal={IEEE Sensors Journal}, 
  title={Respiratory Rate Estimation During Walking Using a Wearable Patch With Modality Attentive Fusion}, 
  year={2023},
  volume={23},
  number={23},
  pages={29831-29843},
  abstract={Respiratory rate (RR) is an important vital sign to monitor outside the clinic, particularly during physiological challenges such as exercise; unfortunately, ambulatory measurement devices for RR are typically obtrusive and inaccurate. The objective of this work is to allow for accurate and robust RR monitoring with a convenient and small chest-worn wearable patch during walking and exercise recovery periods. Methods: To estimate RR from the wearable patch, respiratory signals were first extracted from electrocardiogram (ECG), photoplethysmogram (PPG), and seismocardiogram (SCG) signals. The optimal channel in each signal was adaptively selected using the respiratory quality index based on fast Fourier transform (RQIFFT). Next, we proposed modality attentive (MA) fusion—which merged spectral–temporal information from different modalities—to address motion artifacts during walking. The fused output was subsequently denoised using a U-Net-based deep learning model and used for final estimation. A dataset of  ${N}$  = 17 subjects was collected to validate the RR estimated during three types of activities: stationary activities, walking (including 6-minute walk test), and running. Major results: Combining and denoising ECG and PPG data using MA fusion and the U-Net achieved the lowest mean absolute error (MAE) (2.21 breaths per minute [brpm]) during walking. After rejecting a small portion of the data (coverage = 84.43%) using RQIFFT, this error was further reduced to 1.59 brpm, which was comparable to the state-of-the-art methods. Conclusion: Applying adaptive channel selection, MA fusion, and U-Net denoising achieved accurate RR estimation from a small chest-worn wearable patch. Significance: This work can enable cardiopulmonary monitoring applications in less controlled settings.},
  keywords={Electrocardiography;Biomedical monitoring;Sensors;Legged locomotion;Monitoring;Estimation;Motion artifacts;Attention mechanism;deep learning;explainable artificial intelligence;motion artifacts;respiratory rate (RR);sensor adaptive fusion;wearable health monitoring},
  doi={10.1109/JSEN.2023.3324931},
  ISSN={1558-1748},
  month={Dec},}@INPROCEEDINGS{10612150,
  author={Segretier, Wilfried and Stattner, Erick and Couvin, David and Rastogi, Nalin},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Prediction of Mycobacterium Tuberculosis Lineages from Annotated Whole Genome Sequences: An Evolutionary Approach}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={In this paper, we present an original evolutionary approach for Mycobacterium tuberculosis lineages classification. We use a protein frequency analysis in order to transform the genomic source data into more usable forms. First we consider the number of occurrences of each protein in each tuberculosis genome, then we only consider the presence or absence of proteins in a genome and generate binary sequences. Depending on their frequency of apparition, some proteins are discarded in order to reduce the number of predictive attributes. Classifiers composed of multiple binary masks are evolved through a dedicated evolutionary algorithm in order to reach optimal classification performances. We show that the performances obtained by such classifiers on binary presence sequences are quite good in comparison to the performances of classical machine learning techniques such as decision trees on protein occurrence data. All models investigated in this work are easily interpretable as it is important to get some insight about which proteins are important for prediction.},
  keywords={Proteins;Tuberculosis;Genomics;Evolutionary computation;Machine learning;Transforms;Predictive models;Evolutionary algorithms;Bioinformatics;Classification;Genomics;Machine Learning},
  doi={10.1109/CEC60901.2024.10612150},
  ISSN={},
  month={June},}@INPROCEEDINGS{10154942,
  author={Rogers, Kantwon and Howard, Ayanna},
  booktitle={2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)}, 
  title={Tempering Transparency in Human-Robot Interaction}, 
  year={2023},
  volume={},
  number={},
  pages={01-02},
  abstract={In recent years, particular interest has been taken by researchers and governments in examining and regulating aspects of transparency and explainability within artificially intelligent (AI) system. An AI system is “transparent” if humans can understand the mechanisms behind its behavior and use this understanding to make predictions about future behavior while the goal of explainable AI is to clarify an AI system's actions in a way that humans can understand. With this increased interest, research has presented conflicting views on the benefits of algorithmic transparency and explanations [1]. Moreover, research has also highlighted flaws within policy implementations of algorithmic transparency which generally remain too vague and often results in deficient adoption [2]. Even with these pitfalls of transparency, it seems as if the default view of many societies is that AI systems should be made more transparent and explainable; however, we argue that there needs to exist added skepticism of this position. In particular, we believe it is a useful exercise to consider exploring, as a counternarrative, an emerging area within computing that necessitates a lack of transparency-deceptive AI. The newly evolving area of research pertains to the creation (intentionally or not) of AI agents that learn to deceive humans and other AI agents. Here we define deception as “the process by which actions are chosen to manipulate beliefs so as to take advantage of the erroneous inferences” [3] and we use this interchangeably with “lying”. While there may be physically designed aspects of deception in embodied agents, such as the anthropomorphism and zoomorphism of robots [4], [5], here we wish to focus on deception related to utterances and actions of AI agents. On its surface, the idea of deceptive AI agents may not readily seem beneficial; however, there exists added effort to create AI agents that are able to be integrated socially within our societies. Seeing as deception is a foundational part of many human and animal groups, some argue that giving AI agents the ability to learn to deceive is necessary and inevitable for them to truly interact effectively [6], [7]. In fact, it has been found that deception can be an emergent behavior when training systems on human data [8]-thus strengthening the notion that behaving deceptively is a part of what it means to interact with humans. Moreover, prior research has shown that AI deception, rather than transparent truthfulness, can lead to better outcomes in human-robot interactions [9]–[11]. However, deception does of course have obvious drawbacks including an erosion of trust [12]–[15] and decreasing desired reutilization [12], [15]. Because of these negative aspects, and the clear possibly of malicious usage, some suggest the need for entirely truthful agents [16]. However, due to the infancy and lack of knowledge of the effects (short and long term) of deception within human-AI agent interaction, it is currently not possible to definitively determine the lasting implications of either encouraging or banning the practice. Given that transparency and explainability are in contention with deception, while also neither of the ideas are entirely beneficial nor detrimental, this presents important nuance when determining ethical and regulatory considerations of how AI agents should behave [17]. As such, the goal of this work is to present AI deception as a counternarrative to balance transparency and explainability with other considerations to spur discussions on how to be proactive, rather than reactive, to unforeseen consequences of our choices when designing AI systems that interact with humans.},
  keywords={Training;Ethics;Animals;Government;Human-robot interaction;Prediction algorithms;Behavioral sciences;deception;transparency;explainability;artificial intelligence;robotics;HRI},
  doi={10.1109/ETHICS57328.2023.10154942},
  ISSN={},
  month={May},}@INPROCEEDINGS{11046231,
  author={Zhou, Tianye and Lo, Qixuan and Qu, Shaojie and Du, Qiao},
  booktitle={2025 13th International Conference on Information and Education Technology (ICIET)}, 
  title={Uncertainty-Driven Student Performance Prediction Based on LSTM}, 
  year={2025},
  volume={},
  number={},
  pages={143-148},
  abstract={With the rapid growth of online education platforms, predicting student performance has become a critical task for improving learning outcomes and personalizing education. In this study, we propose a novel framework for student performance prediction by integrating advanced machine learning techniques and uncertainty learning. Our approach combines Random Forest and Genetic Algorithms for feature selection, extracting both static and temporal features to capture the dynamic nature of student learning behaviors. We further enhance the model by incorporating Long Short-Term Memory (LSTM) networks with an attention mechanism and uncertainty-driven training, which focuses on difficult samples to improve robustness and predictive accuracy. Experimental results demonstrate the effectiveness of our framework, achieving significant improvements in F1-score, which reaches 0.861. The proposed framework not only supports personalized learning and early intervention strategies but also provides a foundation for future research in educational data mining and adaptive learning systems.},
  keywords={Uncertainty;Accuracy;Heuristic algorithms;Predictive models;Feature extraction;Robustness;Data mining;Long short term memory;Random forests;Genetic algorithms;random forest;genetic algorithm;uncertainty learning;education data mining;LSTM},
  doi={10.1109/ICIET66371.2025.11046231},
  ISSN={},
  month={April},}@INPROCEEDINGS{10990446,
  author={Zhou, Boyu and Qiao, Zhenjia and Li, Min and Yin, Xiangzhi and Cui, Yanjie and He, Yifeng},
  booktitle={2024 IEEE 8th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={Reverse Overload Mitigation for Rural Low-Voltage Distribution Areas Based on PV Power Forecasting and Energy Storage Operation Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={4342-4347},
  abstract={With the advancement of new energy technologies and a progressive increase in new energy penetration, the quantity and installed capacity of distributed photovoltaic (PV) power generation in rural low-voltage distribution areas are increasing. Excessive PV power generation readily leads to reverse overloading of the distribution transformers, affecting the power supply quality and transformer longevity. Energy storage systems can regulate energy’s spatial and temporal distribution and have become a significant means of addressing this issue. However, the energy storage scheduling strategy must consider economic factors while mitigating reverse overload. Consequently, this paper initially proposes the XGBoost-Informer-based forecasting method to enhance the forecasting accuracy of PV and loads, thereby obtaining PV forecasting data for the subsequent day. Subsequently, based on the adaptive particle swarm algorithm, an optimization model of the storage charging and discharging power is established to minimize the degrees of reverse overload and ensure the economic viability of the storage operation. Finally, the model was implemented and simulation experiments were conducted for verification. Simulation results show that the proposed method has high prediction accuracy and can effectively reduce the hazardous degree of reverse heavy overload while ensuring the economic benefits of energy storage operation.},
  keywords={Economics;Adaptation models;Low voltage;Accuracy;Optimization models;Predictive models;Transformers;Forecasting;Power generation;Energy storage;reverse overload;PV power forecasting;energy storage optimization},
  doi={10.1109/EI264398.2024.10990446},
  ISSN={},
  month={Nov},}@ARTICLE{10937489,
  author={Ghosh, Ananya and Srinivasan, Kathiravan},
  journal={IEEE Access}, 
  title={EffiDenseGenOp: Ensemble Transfer Learning With Hyperparameter Tuning Using Genetic Algorithm Optimization for PCOS Detection From Ultrasound Sonography Images}, 
  year={2025},
  volume={13},
  number={},
  pages={54285-54312},
  abstract={In this research, we present the revolutionary ‘EffiDenseGenOp’ framework for Polycystic Ovary Syndrome (PCOS) detection, leveraging the amalgamation of Ensembled Transfer Learning Models. By harnessing the synergies of Ensembled EfficientNetB7 and DenseNet201, our approach transcends conventional models, offering a robust solution for PCOS detection. Notably, we introduce a Genetic Algorithm-based hyperparameter tuning mechanism, optimizing the model configuration to ensure superior generalization and performance. Our contributions encompass a meticulous comparative analysis, pitting machine learning models, deep learning models, transfer learning models, and our proposed Ensembled Transfer Learning Models against each other. The ensemble technique strategically captures complementary patterns and features from each base model, significantly amplifying the overall predictive power. Moreover, we conduct a comprehensive exploration of hyperparameters, employing extensive tuning to enhance model performance and generalization. The efficiency of Genetic Algorithm is underscored through a rigorous comparative analysis. Additionally, a novel Fuzzy Inference System is introduced for image quality enhancement, designed after meticulous examinations of image behavior under varying noise levels and membership functions. Our model undergoes rigorous training through diverse image variations, employing data augmentation techniques and noise addition. Performance evaluation reveals superior accuracy (99.58%), precision (98.87%), recall (99.20%), F1-score (99.01%), and AUC-ROC score (98.97%), substantiated by detailed analyses including confusion matrices and AUC-ROC curves. Compared to existing models, our proposed model outperforms several state-of-the-art techniques, such as VGGNet16, PCOSNet, and ResNet50, with an accuracy of 99.95%, highlighting a significant improvement in PCOS detection performance. Robustness is ensured through exhaustive K-fold cross-validation, while visualization techniques like Class Activation Maps shed light on the model’s interpretability. The research attains highly efficient PCOS detection, achieving elevated accuracy levels validated through a detailed ablation study.},
  keywords={Accuracy;Analytical models;Transfer learning;Tuning;Predictive models;Ultrasonic imaging;Genetic algorithms;Deep learning;Biomedical imaging;Medical diagnostic imaging;Polycystic ovary syndrome;transfer learning;genetic algorithm optimization;hyperparameter tuning},
  doi={10.1109/ACCESS.2025.3553895},
  ISSN={2169-3536},
  month={},}@ARTICLE{9745487,
  author={Zhu, Songyan and Xu, Jian and Zhu, Hao and Zeng, Jingya and Wang, Yapeng and Zeng, Qiaolin and Zhang, Dejun and Liu, Xiaoran and Yang, Shiqi},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Investigating Impacts of Ambient Air Pollution on the Terrestrial Gross Primary Productivity (GPP) From Remote Sensing}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={In contrast to the threats to urban human health, impacts of air pollutants on the ecosystem photosynthesis seem to be less concerned. The existence of aerosols could promote photosynthesis by increasing the ratio of diffuse to direct solar radiation; on the contrary, ozone (O3) could inhibit photosynthesis, as it is detrimental to leaf stomata. However, it is unknown whether these two opposite impacts worldwide cancel each other out. In the current mainstream methods, earth system models may show conflicts with in situ experimental results due to their relatively coarse resolution. In virtue of satellite remote sensing and a global eddy covariance (EC) network, we studied ten years of data to explore the impacts of aerosol and O3 on photosynthesis by fitting an explainable machine learning model. The impacts of aerosol on gross primary productivity (GPP) were positive in many cases, yet very weak. By means of the nitrogen dioxide (NO2) to formaldehyde (HCHO) ratio, O3 was seen with positive impacts on photosynthesis under the NOx-sensitive regime, but the apparent positive impacts correlated with the plant phenology. Under the volatile organic compound (VOC)-sensitive regime, the impacts of O3 on GPP were not obvious, which was likely due to the prioritized depletion of O3 by NO2 and VOCs. The impacts of air pollutants depended on many factors and results varied case by case, but the overall net impacts were negative.},
  keywords={Air pollution;Ecosystems;Remote sensing;Biological system modeling;Atmospheric modeling;Aerosols;Gases;Deep forest;machine learning;mountainous areas;ozone (O₃) pollution;Sentinel-5p;TROPOspheric Monitoring Instrument (TROPOMI)},
  doi={10.1109/LGRS.2022.3163775},
  ISSN={1558-0571},
  month={},}@ARTICLE{10049087,
  author={Katebi, Nasim and Sameni, Reza and Rohloff, Peter and Clifford, Gari D.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Hierarchical Attentive Network for Gestational Age Estimation in Low-Resource Settings}, 
  year={2023},
  volume={27},
  number={5},
  pages={2501-2511},
  abstract={Assessing fetal development is essential to the provision of healthcare for both mothers and fetuses. In low- and middle-income countries, conditions that increase the risk of fetal growth restriction (FGR) are often more prevalent. In these regions, barriers to accessing healthcare and social services exacerbate fetal maternal health problems. One of these barriers is the lack of affordable diagnostic technologies. To address this issue, this work introduces an end-to-end algorithm applied to a low-cost, hand-held Doppler ultrasound device for estimating gestational age (GA), and by inference, FGR. The Doppler ultrasound signals used in this study were collected from 226 pregnancies (45 low birth weight at delivery) between 5 and 9 months GA by lay midwives in highland Guatemala. We designed a hierarchical deep sequence learning model with an attention mechanism to learn the normative dynamics of fetal cardiac activity in different stages of development. This resulted in a state-of-the-art GA estimation performance, with an average error of 0.79 months. This is close to the theoretical minimum for the given quantization level of one month. The model was then tested on Doppler recordings of the fetuses with low birth weight and the estimated GA was shown to be lower than the GA calculated from last menstruation. Thus, this could be interpreted as a potential sign of developmental retardation (or FGR) associated with low birth weight, and referral and intervention may be necessary.},
  keywords={Recording;Estimation;Doppler effect;Genetic algorithms;Pediatrics;Feature extraction;Ultrasonic imaging;Hierarchical attention network;fetal gestational age;1D-Doppler;machine learning;sequence learning},
  doi={10.1109/JBHI.2023.3246931},
  ISSN={2168-2208},
  month={May},}@ARTICLE{10907950,
  author={Zhang, Changzhen and Yang, Jun and Wang, Ning},
  journal={IEEE Internet of Things Journal}, 
  title={Multitree Genetic Programming With Rule Reconstruction for Dynamic Task Scheduling in Integrated Cloud–Edge Satellite–Terrestrial Networks}, 
  year={2025},
  volume={12},
  number={12},
  pages={21429-21442},
  abstract={Satellite-terrestrial networks (STNs) are a promising paradigm for providing Internet services for users globally. Since the dynamics of service resources and the uncertainty of computational requests, how the service resources in STNs can be efficiently exploited to execute differentiated computational tasks is an essential challenge. In this work, we investigate the dynamic task scheduling in the integrated cloud-edge STNs. First, we propose a cloud-edge collaborative computing framework in STNs, where the computational tasks of users can be processed collaboratively by satellite edge servers, terrestrial edge servers, and cloud servers. Based on this framework, a dynamic task scheduling problem is formulated with the objective of maximizing the task success rate. Second, to make effective real-time decisions at decision points in the dynamic scheduling process, we develop a scheduling heuristic with the routing rule and queuing rule, which incorporates dynamic features related to servers, computational tasks, and network environments. Third, to automatically learn the scheduling heuristic, we propose a multitree genetic programming with rule reconstruction (MTGPRR), which introduces a selective reconstruction operator. This operator increases the chance of matching good rules with other rules by recombining common individuals and elites. Experimental results demonstrate that the proposed MTGPRR performs significantly better than the state-of-the-art methods in improving the task success rate. Moreover, the evolved scheduling heuristic has good interpretability, which is important for practical applications.},
  keywords={Dynamic scheduling;Processor scheduling;Scheduling;Cloud computing;Heuristic algorithms;Servers;Job shop scheduling;Real-time systems;Satellites;Routing;Dynamic task scheduling;genetic programming;rule reconstruction;satellite–terrestrial networks (STNs);scheduling heuristic},
  doi={10.1109/JIOT.2025.3546867},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{11010945,
  author={Sewioło, Mateusz and Tarasiuk, Krzysztof and Kusznier, Paweł and Mystkowski, Arkadiusz},
  booktitle={2025 4th Asia Conference on Algorithms, Computing and Machine Learning (CACML)}, 
  title={A genetic-based convolutional neural networks optimization for fault diagnosis of rotary agriculture machine}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Convolutional neural networks (CNNs) are an effective and accurate method for vibration analysis in fault detection. However, optimizing hyper-parameters and network topology is a time-consuming task. This paper focuses on two main points. First, it demonstrates that CNN architecture can be automatically optimized using a genetic algorithm (GA) to achieve the desired accuracy. Second, it tests these optimized CNNs for fault detection in rotary agriculture machines using vibration analysis, an ongoing challenge in the field. The methodology includes the population of various CNNs with the architecture optimized by GA for the spectrographic representation of vibration signals. Two most common faults were considered: 1) lack of oil in the main shift, and 2) broken tooth in the rotor. The results show that CNNs with GA optimization predict the lack of oil in the shift with 99% accuracy, whereas the broken tooth in the rotor was detected with 100% accuracy. The best results were obtained using metrics vector with MLP and SVM. The mean accuracy across 100 iterations was 0.995.},
  keywords={Vibrations;Accuracy;Fault detection;Oils;Rotors;Computer architecture;Agriculture;Convolutional neural networks;Optimization;Genetic algorithms;Genetic algorithm;Neuroevolution;Agriculture machine;Convolutional neural networks;Fault detection},
  doi={10.1109/CACML64929.2025.11010945},
  ISSN={},
  month={March},}@ARTICLE{9380164,
  author={Sadeghiram, Soheila and Ma, Hui and Chen, Gang},
  journal={IEEE Transactions on Services Computing}, 
  title={Priority-Based Selection of Individuals in Memetic Algorithms for Distributed Data-Intensive Web Service Compositions}, 
  year={2022},
  volume={15},
  number={5},
  pages={2939-2953},
  abstract={In distributed computing, Web Service Composition (WSC) leads to the effective reuse of existing services and produces added value. WSC must fulfil functional requirements and optimise Quality of Service (QoS) attributes, simultaneously. Memetic Algorithms (MAs) are promising for automatically composing numerous Web services to satisfy the above requirements. Data-intensive Web services focus on providing and updating data with a significant volume of data operation and exchange. However, current composition approaches have ignored the impact of data communication and the distribution of services, which significantly affect the performance when applied to the challenging Distributed Data-intensive Web Service Composition (DDWSC) problem. Although recent approaches have revealed the usefulness of local search, they have completely overlooked the question of preferring appropriate composition solutions for local search. To address this research issue, we propose a priority-based selection method for the local search that can be consistently integrated with any MA for DDWSC. This enables us to develop state-of-the-art algorithms for DDWSC by explicitly considering the problem-specific, population and solution-related information for choosing a solution. Extensive experimental evaluation using benchmark datasets shows that our proposed method significantly outperforms several recently proposed methods.},
  keywords={Web services;Quality of service;Statistics;Sociology;Memetics;Search problems;Genetic algorithms;Web services;distributed computing;memetic algorithms;priority-based selection;data-intensive Web service composition},
  doi={10.1109/TSC.2021.3066322},
  ISSN={1939-1374},
  month={Sep.},}@INPROCEEDINGS{10476168,
  author={Qiu, Ran and Zhao, Shengrong and Liang, Hu},
  booktitle={2023 IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={GA-Net: Gated Attention Mechanism Based Global Refinement Network for Image Inpainting}, 
  year={2023},
  volume={},
  number={},
  pages={2812-2813},
  abstract={Underwater images are often affected by problems such as light attenuation, color distortion, noise and scattering, resulting in image defects. A novel image inpainting method is proposed to intelligently predict and fill damaged areas for complete and continuous visualization of the image. First, in order to effectively solve the problem of color distortion caused by light refraction in underwater environments, the improved gated attention mechanism is used. This mechanism improves the local details by learning and weighting the important features of the image. Second, gated convolution automatically determines the degree of restoration for each pixel based on local features of the original image. It eliminates distractions such as low contrast and scattering, retaining more original detailed information. By doing so, image inpainting techniques improve the quality and visualization of underwater images.},
  keywords={Fluctuations;Image color analysis;Convolution;Lighting;Light scattering;Logic gates;Distortion;Underwater images;Image inpainting;Gated convolution},
  doi={10.1109/ICPADS60453.2023.00390},
  ISSN={2690-5965},
  month={Dec},}
