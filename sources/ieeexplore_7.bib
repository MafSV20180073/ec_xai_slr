@INPROCEEDINGS{10393821,
  author={D, Regan and Ravindran, Gobinath and Senthil, P. and Rani, M. Jamuna and Chakraborty, Subhra},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Lightweight GWO-LSTM-Based Land Cover Classification using Remote Sensing Images}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The classification of land use and land cover (LULC) using remote sensing data is essential for many environmental models and land-use inventories. A lightweight deep learning classifier is implemented in this research to improve the performance of LULC classification, assisting in the prediction of declining environmental quality, haphazard elements, wildlife habitat, and so on. LULC classification is evaluated using Eurosat dataset and it uses algorithms like the Haralick texture features, histogram of the oriented gradient, and local Gabor binary pattern histogram sequence for feature extraction. The Grey Wolf Optimization (GWO) method is applied to select the best features, offering fast convergence tares and ease of implementation. A Long Short-Term Memory (LSTM) network is then used to categorize the LULC. The research outcomes show that the GWO method with an LSTM classifier efficiently differentiates the classification of LULC in terms of 99.80% accuracy, 98.99% precision, and 99.53% recall when compared to the Deep SHAP, HFEL-CCGSA, Human group-based PSO with LSTM and IMO-mLSTM.},
  keywords={Deep learning;Productivity;Histograms;Wildlife;Soil;Feature extraction;Prediction algorithms;Haralick texture feature;Histogram of oriented gradient;Land use;Land cover optimization;and Remote sensing images},
  doi={10.1109/EASCT59475.2023.10393821},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11043069,
  author={Zhong, Yingze and Li, Hui and Shi, Zhan and Sun, Jianyong},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Deep Reinforcement Learning Model for Robust Travel Salesman Problem via Multiobjective Optimization Framework}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Deep Reinforcement Learning (DRL) has gained significant attention for its ability to solve combinatorial optimization problems, including the Traveling Salesman Problem (TSP). While traditional approaches assume known and deterministic cost coefficients, real-world scenarios often involve uncertainty, such as traffic conditions or varying travel times. To address this, we introduce a Multiobjective Robust Combinatorial Optimization (MO-RCO) model that incorporates robustness as an additional objective. By transforming a classical robust combinatorial optimization (RCO) problem into a multiobjective framework, MO-RCO allows decision-makers to explore optimal solutions via a Pareto front, while utilizing pre-trained multiobjective models to estimate robust solutions for new uncertain instances. This enables our method to balance optimality and robustness and provide a scalable solution for new RCO problems. Our results demonstrate the efficiency of MO-RCO in solving the min-max TSP with budget uncertainty, showcasing its potential for real-world applications in robust decision-making.},
  keywords={Uncertainty;Costs;Decision making;Prototypes;Transforms;Evolutionary computation;Traveling salesman problems;Deep reinforcement learning;Robustness;Optimization;Robust Combinatorial Optimization;Multiobjective Optimization;Deep Reinforcement Learning;Traveling Salesman Problem},
  doi={10.1109/CEC65147.2025.11043069},
  ISSN={},
  month={June},}@INPROCEEDINGS{10934558,
  author={Sun, Yuntong and An, Ni},
  booktitle={2025 International Conference on Intelligent Systems and Computational Networks (ICISCN)}, 
  title={Urban Public Space Design using Genetic Algorithm and Ant Colony Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Now a days, the Urban public spaces plays an essential role in influencing sustainability, resilience as well as livability of cities. Effective design of urban spaces enhances quality of life, promotes sustainability, and fosters economic growth. However, the Urban public spaces lack with the community involvement, and insensitive design which leads to underutilized, unsafe, or uninviting public spaces. To overcome these drawbacks in this research a Genetic Algorithm (GA) with Ant Colony Optimization (ACO) is applied for designing public spaces for urban areas. Initially, virtual 3D Building Information Modelling (BIM) model is constructed on the basis of 2D digital layout design then, 3D images are incorporated with the BIM design software. Further, the virtual 2D drafting is used to change the hard copies of 2D design sketches. Then, the GA optimizes the combination of sensing reports from cooperative users and searches for the set of optimal coefficient vectors to reduce error probability. Finally, ACO is employed for optimization of space utilization and logistics. From the results, the proposed GA with ACO achieved better results with the working performance of 96.92% when compared to the existing Virtual Reality based Landscape Planning Effect Simulation (VR-LPES) respectively.},
  keywords={Solid modeling;Ant colony optimization;Three-dimensional displays;Computational modeling;Urban areas;Vectors;Software;Sensors;Sustainable development;Genetic algorithms;3d virtual technology;ant colony optimization;building information modelling;genetic algorithm urban public space},
  doi={10.1109/ICISCN64258.2025.10934558},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10903231,
  author={AbdelRaouf, Hussien and Abouyoussef, Mahmoud and Ibrahem, Mohamed I.},
  booktitle={2024 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={An Innovative Approach for Human Activity Recognition Based on a Multi-Head Attention Mechanism}, 
  year={2024},
  volume={},
  number={},
  pages={1559-1563},
  abstract={Human activity recognition (HAR) leverages data from wearable devices and smartphones to detect actions, improving quality of life in areas like elderly care, health monitoring, and sports training. Current deep learning architectures struggle with extracting spatial features, long-term dependencies, and diverse sensor data representations, impacting recognition performance and posing challenges for resource-constrained IoT devices due to their complexity and parameter count. We propose a novel hybrid HAR architecture, integrating convolutional neural networks (CNN) and gated recurrent units (GRU) with a multi-head attention (MHA) mechanism. This architecture captures spatial features via CNN, extracts long-range dependencies with GRU, and uses MHA to compute attention weights for different data segments. The combined spatial and attention features are fed into a classification module for activity recognition. On the PAMAP2 dataset, our CNN-GRU-MHA model outperforms existing methods, achieving an F1-score of 98.4 %, with an inference time of 0.078 seconds and a memory footprint of 790.02 KB, reducing resource usage by 74.34 % and 62.81 %, respectively.},
  keywords={Performance evaluation;Training;Computer architecture;Feature extraction;Human activity recognition;Convolutional neural networks;Data mining;Older adults;Wearable devices;Sports;Human activity recognition (HAR);multi-head attention;IoT devices},
  doi={10.1109/ICMLA61862.2024.00240},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{10241151,
  author={Cao, Bin and Lei, Huan},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={LGEGAN: A Lightweight Evolutionary Generative Adversarial Network with Statistic Global Information}, 
  year={2023},
  volume={},
  number={},
  pages={8282-8287},
  abstract={Generative Adversarial Networks (GANs) have been applied in many fields. However, the existing GANs and their variants encounter many problems, including pattern collapse, training instability and falling into local optimal. Therefore, we construct a lightweight evolutionary generative adversarial network (LGEGAN) with statistic global information. To solve the problem that shallow convolutional neural networks are difficult to capture long-range feature dependence and the training process is prone to pattern collapse, LGEGAN is different from EGAN in that we add an improved self-attention mechanism to the generator network. To solve the problem of instability in the training process, we add spectral normalization to LGEGAN, which increases the stability of each generation of training process. Finally, to efficiently evolve individuals who adapt to the environment in a short time and solve the problem of falling into local optimal, different from EGAN, we construct a novel selection operator and apply it to the selection stage of LGEGAN's evolution of the generator. In the experiments, we evaluate the LGEGAN from four aspects: the quality and diversity of generated images, the collapse of patterns, the stability of training and the robustness of the architecture. The experimental results indicate that the performance of LGEGAN is better than that of EGAN, MOEGAN, SMOEGAN, LRGAN, ProbGAN and the other generative adversarial network models.},
  keywords={Training;Computational modeling;Computer architecture;Generative adversarial networks;Stability analysis;Generators;Robustness;Generative Adversarial Networks (GANs);Evolutionary Computation;Self-attention Mechanism;Spectral Normalization;Selection Operator},
  doi={10.23919/CCC58697.2023.10241151},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{10701393,
  author={Mitrofanov, Sergei Alexandrovich and Semenkin, Eugene Stanislavovich},
  booktitle={2024 International Conference on Information Technologies (InfoTech)}, 
  title={Decision Tree Pruning Method Using Delayed Sampling}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Algorithms based on decision trees have been around for quite some time, however, they are still one of the most popular because of their efficiency and the interpretability of their results. One of the main problems of decision trees is their high tendency to overfit. There are various ways to solve this problem, but this paper proposes a new method based on tree pruning using delayed sampling. The tree is trained using the Separation Measure and Differential Evolution algorithms. The proposed approach improves the standard method and is compared with it. The proposed approach demonstrates higher efficiency than the standard algorithm, and also improves the interpretability of the resulting trees.},
  keywords={Visualization;Machine learning algorithms;Accuracy;Measurement uncertainty;Machine learning;Sampling methods;Decision trees;Stakeholders;Information technology;Standards;decision tree learning algorithm;decision tree pruning;separation measure;differential evolution},
  doi={10.1109/InfoTech63258.2024.10701393},
  ISSN={2770-2731},
  month={Sep.},}@INPROCEEDINGS{11077559,
  author={Solaimalai, Gautam},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={AI-Augmented Decision-Making for Business Process Automation}, 
  year={2025},
  volume={},
  number={},
  pages={257-263},
  abstract={Artificial Intelligence is revolutionizing business process automation because it enhances process efficiency and reduce human work with improved decision making quality. Traditional business process automation (BPA) platforms use a rule based approach which are ineffective in constantly changing business environments. A decision making system which combines deep reinforcement learning (DRL) technology, natural language processing (NLP) and protected by blockchain security to refine business operations. The data used for the analysis is actual enterprise datasets used for training and assessing the proposed model which produced excellent results. The system achieved 94.7% decision quality and 120 ms execution time with 88.1% workflow optimization on top of standard BPA systems. The blockchain security system improved both data integrity and data transparency while operating. The constructed framework introduced an intelligent secure scalable BPA capabilities for multiple industrial applications. Future work will focus on expanding the model to allow it to operate through various and diverse domains and increasing the synergy between human operators and AI systems for better decision making.},
  keywords={Training;Automation;Accuracy;Decision making;Natural language processing;Blockchains;Security;Artificial intelligence;Optimization;Business;Proximal Policy Optimization;Enterprise Resource Planning;Business Process Automation;Deep QNetwork;Markov Decision Process},
  doi={10.1109/AIRC64931.2025.11077559},
  ISSN={},
  month={May},}@ARTICLE{10042007,
  author={Abdi, Athena and Salimi-Badr, Armin},
  journal={IEEE Transactions on Sustainable Computing}, 
  title={ENF-S: An Evolutionary-Neuro-Fuzzy Multi-Objective Task Scheduler for Heterogeneous Multi-Core Processors}, 
  year={2023},
  volume={8},
  number={3},
  pages={479-491},
  abstract={In this paper, an evolutionary-neuro-fuzzy-based task scheduling approach (ENF-S) to jointly optimize the main critical parameters of heterogeneous multi-core systems is proposed. This approach has two phases: first, the fuzzy neural network (FNN) is trained using a non-dominated sorting genetic algorithm (NSGA-II), considering the critical parameters of heterogeneous multi-core systems on a training data set consisting of different application graphs. These critical parameters are execution time, temperature, failure rate, and power consumption. The output of the trained FNN determines the criticality degree for various processing cores based on the system's current state. Next, the trained FNN is employed as an online scheduler to jointly optimize the critical objectives of multi-core systems at runtime. Due to the uncertainty in sensor measurements and the difference between computational models and reality, applying the fuzzy neural network is advantageous. The efficiency of ENF-S is investigated in various aspects including its joint optimization capability, appropriateness of generated fuzzy rules, comparison with related research, and its overhead analysis through several experiments on real-world and synthetic application graphs. Based on these experiments, our ENF-S outperforms the related studies in optimizing all design criteria. Its improvements over related methods are estimated ${19.21\%}$19.21% in execution time, ${13.07\%}$13.07% in temperature, ${25.09\%}$25.09% in failure rate, and ${13.16\%}$13.16% in power consumption, averagely.},
  keywords={Task analysis;Fuzzy neural networks;Multicore processing;Power demand;Processor scheduling;Program processors;Metaheuristics;Fuzzy neural network;heterogeneous multi-core systems;interpretability;multi-objective optimization;Scheduling},
  doi={10.1109/TSUSC.2023.3244081},
  ISSN={2377-3782},
  month={July},}@INPROCEEDINGS{10301271,
  author={Adigun, Jubril Gbolahan and Philip Huck, Tom and Camilli, Matteo and Felderer, Michael},
  booktitle={2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Risk-driven Online Testing and Test Case Diversity Analysis for ML-enabled Critical Systems}, 
  year={2023},
  volume={},
  number={},
  pages={344-354},
  abstract={Machine Learning (ML)-enabled systems that run in safety-critical settings expose humans to risks. Hence, it is important to build such systems with strong assurances for domain-specific safety requirements. Simulation as well as metaheuristic optimizing search have proven to be valuable tools for online testing of ML-enabled systems for early detection of hazards. However, the efficient generation of effective test cases remains a challenging issue. In particular, the testing process shall produce as many failures as possible but also unveil diverse sets of failure scenarios.To study this phenomenon, we introduce a risk-driven test case generation and diversity analysis method tailored to ML-enabled systems. Our approach uses an online testing technique based on metaheuristic optimizing search to falsify domain-specific safety requirements. All test cases leading to hazards are then analyzed to assess their diversity by using clustering and interpretable ML. We evaluated our approach in a collaborative robotics case study showing that generating tests considering risk metrics represents an effective strategy. Furthermore, we compare alternative optimizing search algorithms and rank them based on the overall diversity of the test cases, ultimately showing that selecting the testing strategy based on the number of failures only may be misleading.},
  keywords={Measurement;Metaheuristics;Collaboration;Clustering algorithms;Diversity methods;Search problems;Hazards;Search-based testing;ML-enabled systems;Risk;Diversity analysis;Simulation},
  doi={10.1109/ISSRE59848.2023.00017},
  ISSN={2332-6549},
  month={Oct},}@INPROCEEDINGS{10385469,
  author={Zhou, Houliang and Zhang, Yu and He, Lifang and Shen, Li and Chen, Brian Y.},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Interpretable Graph Convolutional Network for Alzheimer’s Disease Diagnosis using Multi-Modal Imaging Genetics}, 
  year={2023},
  volume={},
  number={},
  pages={1004-1007},
  abstract={Integrating brain images and genetic data provides a great opportunity to discover potential biomarkers for neurological disorder diagnosis. However, learning genetic information and brain network dysfunction remains a challenging task. In this paper, we propose an interpretable multi-modal imaging and genetic graph convolution network (GCN) for Alzheimer’s disease diagnosis. Our genetic network uses hierarchical GCN to mimic a gene ontology-based graph of biological processes and learn the information flow in this graph. In parallel, our imaging network uses a sparse interpretable GCN with node and edge importance probabilities to learn the brain network from multi-modal images. After multi-modal fusion, the final representation guided by a cluster-based consistency constraint is used to predict the disease-related clinical measures. We evaluate our method on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Our result shows that our imaging-genetics framework achieves superior prediction performance compared to all state-of-the-art methods. The interpretation demonstrated that the salient SNPs, and salient regions interpreted by important probabilities were significantly correlated with AD-related clinical symptoms, and considerably important for developing novel biomarkers. The code is available at https://github.com/Houliang-Zhou/IG-GCN.},
  keywords={Neurological diseases;Neuroimaging;Databases;Image edge detection;Biomarkers;Genetics;Medical diagnosis;Graph convolutional network;imaging genetics;multi-modality;neuroimaging;sparse interpretation},
  doi={10.1109/BIBM58861.2023.10385469},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10869115,
  author={Si, Kaiyan and Ye, Junmin and Yu, Shuang and Yin, Xinghan and Ren, Wen and Luo, Sheng and Zhao, Gang},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={Analysis and Prediction of Factors Affecting Student Grades in Online Collaborative Learning Using Genetic Programming-based Approach}, 
  year={2024},
  volume={},
  number={},
  pages={185-189},
  abstract={Computer-supported collaborative learning (CSCL) has been widely adopted as an instructional method that utilizes computer technology to support and facilitate cooperation and collaboration in the learning process. In order to achieve high-quality collaborative learning and provide personalized instruction to students in a CSCL environment, it is necessary to analyze collaborative interaction characteristics and predict student performance. There are still some limitations to the existing studies due to the underutilization of data on the student collaboration process and the poor interpretability of the models used. Therefore, this study fully mines students’ collaborative session data, extracts relevant collaborative interaction features, and then constructs a student performance prediction model using the GP algorithm. Finally, we explored the accuracy of the GP model and validated it using another online collaborative course. The study showed that the GP prediction model was more accurate and stable than other machine learning methods, and the validation results in another course showed a high degree of consistency between student grades in the course and the model's predictions. In addition, the analysis results revealed that the number of statements, length of statements, and positive and negative emotions were the key factors affecting student grades in the CSCL environment. The findings help provide useful insights for further optimizing curriculum design and instructional interventions.},
  keywords={Accuracy;Machine learning algorithms;Federated learning;Collaboration;Predictive models;Prediction algorithms;Feature extraction;Genetics;Data models;Data mining;performance prediction;educational data mining;GP;computer-supported collaborative learning},
  doi={10.1109/ICET62460.2024.10869115},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10635831,
  author={Itkyal, Vaibhavi S. and Abrol, Anees and LaGrow, Theodore J. and Calhoun, Vince D.},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)}, 
  title={Voxelwise Intensity Projection for the Spatial Representation of Resting State Functional MRI Networks and Multimodal Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Alzheimer's disease (AD) necessitates accurate early diagnosis for effective treatment. Our study explores the untapped potential of spatial information extraction from resting-state functional magnetic resonance imaging (rs-fMRI) and its integration with structural MRI (sMRI) for investigating AD-related brain alterations. Utilizing fMRI networks (independent component analysis followed by voxelwise intensity projections i.e., iVIP) outperforms traditional metrics, such as amplitude of low-frequency fluctuations (ALFF) and fractional ALFF, in capturing critical spatial maps for AD classification. A multi-channel convolutional neural network inspired by AlexNet dropout architecture effectively models spatial and temporal dependencies in integrated data. Experiments on the Alzheimer’s Disease Neuroimaging Initiative dataset demonstrate superior classification performance with 93.31% test accuracy and a 97.79 AUC score, surpassing existing methods. Fusion results generally outperform unimodal results, revealing significant differences in neurobiologically relevant regions. Saliency visualizations highlight distinctions in the hippocampus, amygdala, caudate nucleus, and thalamus, aligning with previous literature.},
  keywords={Deep learning;Neuroimaging;Measurement;Accuracy;Three-dimensional displays;Functional magnetic resonance imaging;Thalamus;Multimodal fusion;neuroimaging;Alzheimer’s disease},
  doi={10.1109/ISBI56570.2024.10635831},
  ISSN={1945-8452},
  month={May},}@INPROCEEDINGS{11031560,
  author={Sekhar, B.Vijaya and Babu, K.V.Ramesh and T, Joel and Al-Tarazi, Dalia and Narkhede, Alok and Subramaniam, Parimala},
  booktitle={2025 International Conference on Frontier Technologies and Solutions (ICFTS)}, 
  title={A Hierarchical Learning Approach to Detect Aging Faces based on Local Binary Pattern Evaluation and Optimization Logics}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Aging face detection is a critical area in facial recognition research, with applications spanning security, forensic analysis, and age-based authentication. This study presents a Hierarchical Learning Approach to Detect Aging Faces based on Local Binary Pattern (LBP) Evaluation and Optimization Logics. The proposed model leverages LBP-based texture extraction, Genetic Algorithm (GA) for feature selection, and a Hybrid CNN-LSTM classifier with an attention mechanism to improve prediction accuracy. The system was trained and evaluated on publicly available face aging datasets, demonstrating superior performance compared to traditional classifiers. Experimental results indicate that the CNN-LSTM hybrid model with attention mechanism achieved an accuracy of 92.4%, significantly outperforming conventional LBP-SVM (81.2%), LBP-XGBoost (85.3%), and standalone CNN models (87.9%). The integration of Bayesian Optimization and Focal Loss further enhanced classification robustness and reduced bias in age group prediction. Feature selection using GA reduced the feature space by 70.7% while improving accuracy to 91.2%, demonstrating its effectiveness. This work provides a computationally efficient and highly accurate approach for aging face detection, making it suitable for real-world applications such as age verification systems, criminal identification, and social security authentication.},
  keywords={Deep learning;Accuracy;Attention mechanisms;Face recognition;Aging;Feature extraction;Face detection;Security;Optimization;Genetic algorithms;Aging Face Detection;Local Binary Pattern;Feature Selection;CNN-LSTM Hybrid;Genetic Algorithm;Bayesian Optimization;Attention Mechanism;Deep Learning;Facial Recognition;Image Processing},
  doi={10.1109/ICFTS62006.2025.11031560},
  ISSN={},
  month={March},}@INPROCEEDINGS{10929149,
  author={Li, Jun and Li, Ruo},
  booktitle={2024 4th International Conference on Electronic Information Engineering and Computer Communication (EIECC)}, 
  title={Research on Multi-path Vehicle Routing Problem under Low Carbon Constraints}, 
  year={2024},
  volume={},
  number={},
  pages={1103-1107},
  abstract={Aiming at the increasingly severe environmental pressure faced by logistics enterprises, we study the low-carbon vehicle path optimization problem in a multi-pathway environment. The multi-pathway network model is quantitatively portrayed, and the fuel consumption is taken as the metric of vehicle carbon emission, and a mathematical model is constructed with the optimization objective of minimizing the vehicle fuel consumption cost. According to the characteristics of the problem model, an improved genetic algorithm is designed to solve the problem, and a three-stage optimization strategy is proposed to improve the search efficiency of the algorithm, and finally, the reasonableness of the model and the feasibility of the algorithm are verified through the arithmetic example experiment and comparative analysis.},
  keywords={Measurement;Analytical models;Costs;Vehicle routing;Carbon dioxide;Mathematical models;Fuels;Optimization;Logistics;Genetic algorithms;Multi-path networks;Low carbon;Genetic algorithms;Tertiary optimization strategiesomponent},
  doi={10.1109/EIECC64539.2024.10929149},
  ISSN={},
  month={Dec},}@ARTICLE{9740532,
  author={Prabhakar, Sunil Kumar and Lee, Seong-Whan},
  journal={IEEE Open Journal of Engineering in Medicine and Biology}, 
  title={SASDL and RBATQ: Sparse Autoencoder With Swarm Based Deep Learning and Reinforcement Based Q-Learning for EEG Classification}, 
  year={2022},
  volume={3},
  number={},
  pages={58-68},
  abstract={The most vital information about the electrical activities of the brain can be obtained with the help of Electroencephalography (EEG) signals. It is quite a powerful tool to analyze the neural activities of the brain and various neurological disorders like epilepsy, schizophrenia, sleep related disorders, parkinson disease etc. can be investigated well with the help of EEG signals. Goal: In this paper, two versatile deep learning methods are proposed for the efficient classification of epilepsy and schizophrenia from EEG datasets. Methods: The main advantage of using deep learning when compared to other machine learning algorithms is that it has the capability to accomplish feature engineering on its own. Swarm intelligence is also a highly useful technique to solve a wide range of real-world, complex, and non-linear problems. Therefore, taking advantage of these factors, the first method proposed is a Sparse Autoencoder (SAE) with swarm based deep learning method and it is named as (SASDL) using Particle Swarm Optimization (PSO) technique, Cuckoo Search Optimization (CSO) technique and Bat Algorithm (BA) technique; and the second technique proposed is the Reinforcement Learning based on Bidirectional Long-Short Term Memory (BiLSTM), Attention Mechanism, Tree LSTM and Q learning, and it is named as (RBATQ) technique. Results and Conclusions: Both these two novel deep learning techniques are tested on epilepsy and schizophrenia EEG datasets and the results are analyzed comprehensively, and a good classification accuracy of more than 93% is obtained for all the datasets.},
  keywords={Electroencephalography;Epilepsy;Deep learning;Brain modeling;Analytical models;Support vector machines;Q-learning;Reinforcement learning;Deep learning;EEG;PSO;Q-learning;reinforcement learning},
  doi={10.1109/OJEMB.2022.3161837},
  ISSN={2644-1276},
  month={},}@ARTICLE{10122136,
  author={Liu, Zhaobo and Li, Guo and Zhang, Haili and Liang, Zhengping and Zhu, Zexuan},
  journal={IEEE Transactions on Cybernetics}, 
  title={Multifactorial Evolutionary Algorithm Based on Diffusion Gradient Descent}, 
  year={2024},
  volume={54},
  number={7},
  pages={4267-4279},
  abstract={The multifactorial evolutionary algorithm (MFEA) is one of the most widely used evolutionary multitasking (EMT) algorithms. The MFEA implements knowledge transfer among optimization tasks via crossover and mutation operators and it obtains high-quality solutions more efficiently than single-task evolutionary algorithms. Despite the effectiveness of MFEA in solving difficult optimization problems, there is no evidence of population convergence or theoretical explanations of how knowledge transfer increases algorithm performance. To fill this gap, we propose a new MFEA based on diffusion gradient descent (DGD), namely, MFEA-DGD in this article. We prove the convergence of DGD for multiple similar tasks and demonstrate that the local convexity of some tasks can help other tasks escape from local optima via knowledge transfer. Based on this theoretical foundation, we design complementary crossover and mutation operators for the proposed MFEA-DGD. As a result, the evolution population is endowed with a dynamic equation that is similar to DGD, that is, convergence is guaranteed, and the benefit from knowledge transfer is explainable. In addition, a hyper-rectangular search strategy is introduced to allow MFEA-DGD to explore more underdeveloped areas in the unified express space of all tasks and the subspace of each task. The proposed MFEA-DGD is verified experimentally on various multitask optimization problems, and the results demonstrate that MFEA-DGD can converge faster to competitive results compared to state-of-the-art EMT algorithms. We also show the possibility of interpreting the experimental results based on the convexity of different tasks.},
  keywords={Optimization;Convergence;Statistics;Social factors;Knowledge transfer;Costs;Convergence analysis;diffusion gradient descent (DGD);evolutionary multitasking (EMT);multifactorial evolutionary algorithm (MFEA)},
  doi={10.1109/TCYB.2023.3270904},
  ISSN={2168-2275},
  month={July},}@INPROCEEDINGS{10429700,
  author={Wang, Dong and Xie, Aoyu and Tang, Tingyue and Fang, Nian and Zhou, Chenyu and Wang, Zhouruixing and Qi, Leyu},
  booktitle={2023 10th International Forum on Electrical Engineering and Automation (IFEEA)}, 
  title={A Time-Frequency Feature Extraction Method Based on the Correlation Analysis with Its Motion Behaviors}, 
  year={2023},
  volume={},
  number={},
  pages={1110-1113},
  abstract={The amount of current signal data collected by the sensor is large. With the rapid growth of data today, how to use a small amount of effective data for fault detection is particularly important. It is of great significance to research the correlation mechanism between the time-frequency features and the motion behavior of an external fault arc during the occurrence of a DC fault arc.Firstly, the arc generation process was simulated to obtain a current signal and the characterization parameters of the image. Three features are extracted from the obtained fault arc image information: vertical arc movement on the left side, horizontal arc movement on the right side, and arc area change. By analyzing the image information of the three types of motion behaviors. The time-frequency features FI of the fault arc current signal in different frequency bands and the time-frequency features FM, FY, and FX of the images after time-frequency transform are obtained. Then the current data quantity is processed to ensure the consistent length with the image data. The obtained time-frequency features are imported into the SHapley Additive exPlanations (SHAP) eXtreme Gradient Boosting (XGboost) model to obtain the scatterplot of the feature density in different frequency bands. Finally, after comparing the Q values in different frequency bands, the corresponding frequency band with maximum Q is output.},
  keywords={Time-frequency analysis;Correlation;Frequency modulation;Arc discharges;Transforms;Feature extraction;Behavioral sciences;fault arc;motion behavior;time-frequency analysis;correlation mechanism;feature selection},
  doi={10.1109/IFEEA60725.2023.10429700},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10553469,
  author={Potteiger, Nicholas and Koutsoukos, Xenofon},
  booktitle={2024 IEEE International Systems Conference (SysCon)}, 
  title={Safeguarding Autonomous UAV Navigation: Agent Design using Evolving Behavior Trees}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The rise in autonomous Unmanned Aerial Vehicles (UAVs) for objectives requiring long-term navigation in diverse environments is attributed to their compact, agile, and accessible nature. Specifically, problems exploring dynamic obstacle and collision avoidance are of increasing interest as UAVs become more popular for tasks such as transportation of goods, formation control, and search and rescue routines. Prioritizing safety in the design of autonomous UAVs is crucial to prevent costly collisions that endanger pedestrians, mission success, and property. Safety must be ensured in these systems whose behavior emerges from multiple software components including learning-enabled components. Learning-enabled components, optimized through machine learning (ML) or reinforcement learning (RL), require adherence to safety constraints while interacting with the environment during training and deployment, as well as adaptation to new unknown environments. In this paper, we safeguard autonomous UAV navigation by designing agents based on behavior trees with learning-enabled components, referred to as Evolving Behavior Trees (EBTs). We learn the structure of EBTs with explicit safety components, optimize learning-enabled components with safe hierarchical RL, deploy, and update specific components for transfer to unknown environments. Safe and successful navigation is evaluated using a realistic UAV simulation environment. The results demonstrate the design of an explainable learned EBT structure, incurring near-zero collisions during training and deployment, with safe time-efficient transfer to an unknown environment.},
  keywords={Training;Navigation;Atmospheric modeling;Transportation;Autonomous aerial vehicles;Search problems;Software;unmanned aerial vehicles;autonomous navigation;explainable AI;behavior trees;hierarchical reinforcement learning;genetic programming},
  doi={10.1109/SysCon61195.2024.10553469},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{11069594,
  author={Alexander, R and Lakshana, A and Lavanya, T and Fathima, G Sameera and Kavya, N and Janet A, Mary Valentina},
  booktitle={2025 3rd International Conference on Inventive Computing and Informatics (ICICI)}, 
  title={Deep Learning-based MR Image Segmentation for Brain Tumor Detection using EAU-Net}, 
  year={2025},
  volume={},
  number={},
  pages={1120-1126},
  abstract={Brain tumor segmentation is essential in medical image analysis, as it contributes directly to early diagnosis and treatment design. Existing methodologies such as Particle Swarm Optimization (PSO) typically suffer from constraints including limited convergence, sensitivity to noise, and limited ability at feature extraction. Therefore, we have proposed an Enhanced Attention U-Net (EAU-Net) as a deep learning technique designed to improve segmentation accuracy using residual learning, hybrid attention methods, and multi-scale feature extraction. The primary focus of this work is to enhance tumor boundary delineation and reduce the number of false positives while maintaining fine detail. EAU-Net utilizes Spatial and Channel Attention modules (through Squeeze-and-Excitation blocks) and Dense Blocks to enhance context understanding, particularly in small tumor regions with irregular shapes. Additionally, we use a hybrid Dice-Focal loss to combat class imbalance. Evaluated on the BraTS 2020 database, EAU-Net reached an average accuracy of 99.5%, Dice coefficient of 98.1 %, sensitivity of 97.2%, and specificity of 99.85%, and overwhelmingly outperformed existing PSO and traditional deep learning methods. These results demonstrate that EAU-Net is an efficient and effective solution for the task of automated and reliable brain tumor segmentation.},
  keywords={Deep learning;Training;Image segmentation;Accuracy;Sensitivity;Computational modeling;Brain tumors;Computer architecture;Feature extraction;Brain modeling;Brain Tumor;EAU-Based NET;Magnetic Resonance Images;Deep Learning;BraTS 2020},
  doi={10.1109/ICICI65870.2025.11069594},
  ISSN={},
  month={June},}@INPROCEEDINGS{10797142,
  author={Calapristi, Marco and Patanè, Luca and Sapuppo, Francesca and Caponetto, Riccardo and Xibilia, Maria Gabriella},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Symbolic Regression for Industrial Applications: An NN-Based Approach}, 
  year={2024},
  volume={},
  number={},
  pages={618-623},
  abstract={Symbolic Regression (SR) is a machine learning approach developed for the automated identification of mathematical equations that accurately capture the relationships between input and output features within the experimental dataset. This method is capable of creating interpretable models while incorporating existing knowledge into the system. This paper addresses a problem in the development of interpretable Soft Sensors (SS) for industrial applications using SR. The challenge arises from the need to increase the dimensionality of the problem in order to capture the system dynamics, which often leads to a significant degradation in SR performance. Existing literature has highlighted this problem and proposed some solutions, such as employing Recurrent Neural Networks (RNN) instead of Genetic Programming (GP) in the SR procedure or applying Deep Learning (DL) techniques to reduce the input space. In this paper, we present a novel approach to develop interpretable SSs for industrial processes that involve the use of DL to encode the system dynamics. This effectively reduces the input space and supports the SR process without compromising the interpretability of the final solution.},
  keywords={Deep learning;Training;Recurrent neural networks;Accuracy;System dynamics;Soft sensors;Genetic programming;Artificial neural networks;Mathematical models;Encoding;Soft sensors;system identification;dynamical nonlinear systems;neural networks;model interpretability},
  doi={10.1109/MetroXRAINE62247.2024.10797142},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10294625,
  author={Zheng, Xiang and Chen, Shaoyu and Wu, Junfei and Ruan, Lixiang and Luo, Zhaojun and Xu, Xiaojun},
  booktitle={2023 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)}, 
  title={A Chinese Word Segmentation Model for SCD Text in Smart Grid Station: An Attention-BiLSTM-CRF Approach}, 
  year={2023},
  volume={},
  number={},
  pages={952-957},
  abstract={In this paper, a novel Chinese word segmentation (CWS) model, named as the optimized Attention-Bidirectional - Long Short-Term Memory-Conditional Random Field (Attention-BiLSTM-CRF), is specifically designed for substation configuration description (SCD) text data in smart grid station. In the proposed model, the Skip-Gram algorithm is utilized to convert word data into distributed vectors, then by integrating the attention mechanism, LSTM, and CRF, the new segmentation model named as Attention-BiLSTM-CRF is developed, which is more suitable for SCD text data in smart grid station. Finally, the effectiveness of the proposed approach is demonstrated through a case study based on SCD text data. Simulation results show that the proposed model can achieve a higher accuracy rate of 98.2%, and it can be observed that the proposed CWS approach had higher accuracy and speed in the field of smart grid.},
  keywords={Substations;Simulation;Asia;Distributed databases;Data models;Smart grids;Attention-BiLSTM-CRF;Chinese word segmentation;Skip-Gram;SCD text},
  doi={10.1109/ICPSAsia58343.2023.10294625},
  ISSN={},
  month={July},}@INPROCEEDINGS{11009554,
  author={Zhang, Jiajia and Qin, Yu and Guo, Feng and Zhao, Yuqi and Zheng, Zidong and Wang, Xiaodong and Liu, Yuanyuan},
  booktitle={2025 2nd International Conference on Smart Grid and Artificial Intelligence (SGAI)}, 
  title={Intelligent Enhancement of Distribution Networks Based on Swarm Intelligence Control in Complex Power Systems}, 
  year={2025},
  volume={},
  number={},
  pages={478-482},
  abstract={In response to the demand for intelligent enhancement of distribution networks, and to ensure the safety, stability, and efficiency of their operation, scheduling, and maintenance, we address the challenges posed by the low efficiency and accuracy of large-scale autonomous inspection applications. We have conducted research and applied key technologies for the intelligent enhancement of distribution networks based on swarm intelligence control in complex systems. Our work includes the investigation of situation awareness and risk assessment techniques, employing time-series early warning models to achieve precise control over the operational states of distribution networks. Additionally, we have explored grid-based deployment optimization techniques, utilizing intelligent analysis of digital grid topologies to optimize the placement of distribution network equipment. Furthermore, we have delved into attention mechanisms using graph neural networks as the carrier, effectively solving the problem of fault section localization in distribution networks with topological changes and multiple topological configurations.},
  keywords={Location awareness;Accuracy;Distribution networks;Power system stability;Inspection;Graph neural networks;Smart grids;Topology;Particle swarm optimization;Optimization;Multimodal;Knowledge-Enhanced;Power Production Operations},
  doi={10.1109/SGAI64825.2025.11009554},
  ISSN={},
  month={March},}@INPROCEEDINGS{10753783,
  author={Wang, Feiyang and Bao, Qiaozhi and Wang, Zixuan and Chen, Yanlin},
  booktitle={2024 5th International Conference on Machine Learning and Computer Application (ICMLCA)}, 
  title={Optimizing Transformer Based on High-Performance Optimizer for Predicting Employment Sentiment in American Social Media Content}, 
  year={2024},
  volume={},
  number={},
  pages={414-418},
  abstract={This article improves the Transformer model based on swarm intelligence optimization algorithm, aiming to predict the emotions of employment related text content on American social media. Through text preprocessing, feature extraction, and vectorization, the text data was successfully converted into numerical data and imported into the model for training. The experimental results show that during the training process, the accuracy of the model gradually increased from 49.27% to 82.83%, while the loss value decreased from 0.67 to 0.35, indicating a significant improvement in the performance of the model on the training set. According to the confusion matrix analysis of the training set, the accuracy of the training set is 86.15%. The confusion matrix of the test set also showed good performance, with an accuracy of 82.91 %. The accuracy difference between the training set and the test set is only 3.24%, indicating that the model has strong generalization ability. In addition, the evaluation of polygon results shows that the model performs well in classification accuracy, sensitivity, specificity, and area under the curve (AVC), with a Kappa coefficient of 0.66 and an F -measure of 0.80, further verifying the effectiveness of the model in social media sentiment analysis. The improved model proposed in this article not only improves the accuracy of sentiment recognition in employment related texts on social media, but also has important practical significance. This social media based data analysis method can not only capture social dynamics in a timely manner, but also promote decision-makers to pay attention to public concerns and provide data support for improving employment conditions.},
  keywords={Training;Analytical models;Accuracy;Social networking (online);Employment;Predictive models;Transformers;Data models;Numerical models;Particle swarm optimization;Swarm intelligence optimization;Transformer;American social media},
  doi={10.1109/ICMLCA63499.2024.10753783},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10441369,
  author={Sugunadevi, C and Singh, Rimjhim Padam and Maheswari, B. Uma and Kumar, Priyanka},
  booktitle={2023 9th International Conference on Signal Processing and Communication (ICSC)}, 
  title={DiaMOS Plant Leaves Disease Classification using Vision Transformer}, 
  year={2023},
  volume={},
  number={},
  pages={551-556},
  abstract={The consequences of climate change have increased during the past several years. This climate influences each stage of plant production, and farmers are being forced to modify the plantation and advance their crop management techniques utilizing recent technology built on data analytics. Many plant diseases manifest themselves in the leaves. Therefore, successful disease diagnosis requires a thorough understanding of the condition of plants. To provide high-quality agricultural products, timely and precise disease detection and classification are crucial for smart and precision agriculture. In this study, images of the DiaMOS plant leaves dataset that was collected in the field of Sardegna, Italy is utilized to learn and classify plant disease using several fine-tuned z deep learning models like InceptionV3, EfficientNetB0, VGG-16, ResNet50, VGG-19. Here, the Deep learning models are trained to categorize the severity of plant disease and built a vision transformer for classification that achieves higher than the predefined models with an accuracy- 98.5% precision-97.1%, and F1 score – 97.83%.},
  keywords={Plant diseases;Heat transfer;Neural networks;Genetic algorithms;Machine learning;Climate change;Classification algorithms;Vision sensors;Transformers;Plants (biology);Farming;Deep learning;Production planning;Data analysis;Condition monitoring;Detection algorithms;Heat transfer;Neural networks;Metal foam;Genetic algorithm;Machine learning},
  doi={10.1109/ICSC60394.2023.10441369},
  ISSN={2643-444X},
  month={Dec},}@INPROCEEDINGS{10381566,
  author={Pandey, Chetraj and Ji, Anli and Angryk, Rafal A. and Aydin, Berkay},
  booktitle={2023 IEEE Sixth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, 
  title={Towards Interpretable Solar Flare Prediction with Attention-based Deep Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={83-90},
  abstract={Solar flare prediction is a central problem in space weather forecasting and recent developments in machine learning and deep learning accelerated the adoption of complex models for data-driven solar flare forecasting. In this work, we developed an attention-based deep learning model as an improvement over the standard convolutional neural network (CNN) pipeline to perform full-disk binary flare predictions for the occurrence of $\ge$ collected compressed images created from full-disk line-of-sightM1.0-class flares within the next 24 hours. For this task, we (LoS) magnetograms. We used data-augmented oversampling to address the class imbalance issue and used true skill statistic (TSS) and Heidke skill score (HSS) as the evaluation metrics. Furthermore, we interpreted our model by overlaying attention maps on input magnetograms and visualized the important regions focused on by the model that led to the eventual decision. The significant findings of this study are: (i) We successfully implemented an attention-based full-disk flare predictor ready for operational forecasting where the candidate model achieves an average TSS $= 0.54 \pm 0.03$ and HSS $= 0.37 \pm 0.07$. (ii) we demonstrated that our full-disk model can learn conspicuous features corresponding to active regions from full-disk magnetogram images, and (iii) our experimental evaluation suggests that our model can predict near-limb flares with adept skill and the predictions are based on relevant active regions (ARs) or AR characteristics from full-disk magnetograms.},
  keywords={Deep learning;Visualization;Magnetic resonance imaging;Pipelines;Weather forecasting;Predictive models;Convolutional neural networks;space weather;solar flares;deep neural networks;attention;and interpretability},
  doi={10.1109/AIKE59827.2023.00021},
  ISSN={2831-7203},
  month={Sep.},}@INPROCEEDINGS{9870439,
  author={Nikolikj, Ana and Trajanov, Risto and Cenikj, Gjorgjina and Korošec, Peter and Eftimov, Tome},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Identifying minimal set of Exploratory Landscape Analysis features for reliable algorithm performance prediction}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Exploratory Landscape Analysis (ELA) enables the characterization of black-box optimization problem instances in the form of numerical features. Such features can be used to train a Machine Learning (ML) model to automatically predict the performance of an optimization algorithm on a specific problem instance. However, computing ELA features is a time consuming process and relatively expensive. In this paper, we aim to evaluate the usefulness of ELA features and identify features which are the most informative in automated algorithm performance prediction. The goal is to find a subset of features which are sufficient to train a reliable ML model for algorithm performance prediction, with reduced computational costs for calculating the ELA features. We focus on the performance prediction of the Covariance Matrix Adaptation Evolution Strat-egy (CMA-ES) algorithm on the COCO benchmark problems. The results showed that the number of ELA features that lead to a reliable algorithm performance prediction depends on the modular CMA-ES configuration under consideration. However, the set of features that are selected to be useful across different modular CMA-ES configurations are similar.},
  keywords={Training;Machine learning algorithms;Computational modeling;Pipelines;Predictive models;Benchmark testing;Prediction algorithms;automated algorithm performance prediction;exploratory landscape analysis;explainable models;feature selection},
  doi={10.1109/CEC55065.2022.9870439},
  ISSN={},
  month={July},}@INPROCEEDINGS{10392618,
  author={Ainapure, Atman and Dhamane, Shreyash and Dhage, Sudhir},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Embodied Epistemology: A Meta-Cognitive Exploration of Chatbot-Enabled Document Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, novel research is presented that constructs a PDF chatbot using ChatGPT 3.5 Turbo and the LLM Model. The framework, chatGPT 3.5, streamlines chatbot creation, enabling scalable AI/LLM applications. The potent LLM Model facilitates text generation, language translation, and original content creation, along with insightful responses to user queries. The approach combines chatGPT 3.5 Turbo and the LLM Model to develop a chatbot proficient in addressing PDF-related inquiries. Utilizing data from uploaded PDFs and the LLM Model, the chatbot generates informative text responses to customer questions. The research relies on the LangChain framework, while a Streamlit based homepage enhances user interactions. This work exemplifies the LangChain and LLM Model’s potential to craft engaging chatbots, adaptable across domains like customer service, education, and research. The chat bot, a valuable resource for addressing product queries, offering educational aid, and providing tutoring, effectively responds to user inquiries about PDF files.},
  keywords={Adaptation models;Ethics;Text analysis;Customer services;Education;Transfer learning;Refining;PDF Chatbot;Langchain;gpt-3.5-turbo;Natural Language Processing;Large Language Model},
  doi={10.1109/EASCT59475.2023.10392618},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10826009,
  author={Saeed, Farah and Aldosari, Mohammed and Arpinar, Ismailcem Budak and Miller, John A},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={LLM4cast: Repurposed LLM for Viral Disease Forecasting}, 
  year={2024},
  volume={},
  number={},
  pages={1428-1433},
  abstract={Viral diseases have had a significant impact on millions of people worldwide. Utilizing time series forecasting methods allows for the estimation of cases, facilitating the control of disease spread and the allocation of necessary resources in medical facilities. Traditional estimation methods use model per dataset methodology where a model is trained only on a single dataset for a disease. However, foundation models including large language models have shown improved results by training on multiple datasets before being applied to a target dataset. Following this strategy, we aim to train a time series model using multiple datasets from diverse domains and viral diseases. We utilize a pretrained large language model and adapt it for estimating Influenza-Like Illness. We propose a novel network architecture called LLM4cast that encodes the input patches through a bidirectional encoder for rich embedding extraction and passes the encoded patches to a pretrained TinyLlama for fine-tuning. The output from TinyLlama is then flattened and projected to estimate the probable cases. The framework is trained in two stages. In the first stage, we train using time series data from diverse domains with 2.56M timesteps. The second stage involves training using domain specific time series data about viral diseases. The trained network is used in the evaluation of disease cases. The results demonstrate significant improvement in the accuracy of forecasts for foundation models compared to state-of-the-art models trained from scratch.},
  keywords={Training;Foundation models;Large language models;Time series analysis;Estimation;Predictive models;Data models;Resource management;Forecasting;Diseases;Time Series Forecasting;Large Language Model;Foundation Model;Performance Efficient Fine-Tuning},
  doi={10.1109/BigData62323.2024.10826009},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10167944,
  author={Kamalov, Mikhail and Uggeri, Luca and Grenet, Ingrid and Daeden, Jonathan},
  booktitle={2023 24th International Conference on Digital Signal Processing (DSP)}, 
  title={SGraphZoe: Explainable self-supervised framework for signal-based anomaly detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Signal-based anomaly detection is a recurring problem that has drawn the attention of many research projects and resulted in the development of multiple solutions. One of the main obstacles to anomaly detection is the rarity of the occurrences of interest. Extremely small amount of labelled data is troublesome from the training perspective since it has a detrimental influence on the accuracy of predictions. The second challenge is providing a clear and understandable model. Answering this second issue is particularly important for a variety of industries since it is beneficial to understand what causes outliers in order to avoid them in the future. To address the aforementioned concerns, we propose a novel self-supervised framework named SGraphZoe which outperforms linear semi-supervised state-of-the-art outlier detection algorithms while maintaining transparency throughout training and prediction steps. This framework is built on a Self-supervised strategy and combines a semi-supervised (Graph Diffusion & PCA) and a supervised (Zoetrope Genetic Programming) algorithms.},
  keywords={Training;Industries;Signal processing algorithms;Genetic programming;Digital signal processing;Prediction algorithms;Mathematical models},
  doi={10.1109/DSP58604.2023.10167944},
  ISSN={2165-3577},
  month={June},}@ARTICLE{10969758,
  author={Augustin, Jameson and Gopinath, Munisamy and Karali, Berna and Rao, Yuhan},
  journal={IEEE Access}, 
  title={Joint Prediction of U.S. Rice Yields and Methane Emissions: A Machine Learning Approach}, 
  year={2025},
  volume={13},
  number={},
  pages={70018-70043},
  abstract={Despite the United States’s major role as a rice exporter with significant economic and environmental impacts, most remote sensing and machine learning research on rice yield prediction has focused on Asian production regions. Moreover, while rice cultivation generates substantial methane emissions, few studies have explored the trade-offs between productivity and environmental impact. This study leverages remote sensing and machine learning techniques to predict U.S. county-level rice yields and methane emissions from 2008 to 2022 across 67 counties in six major rice-producing states. We use eight different machine learning models for predictions. XGBoost and EBM emerge as top performers, accurately predicting yields and emissions, individually, without overfitting. A key finding reveals that these models excel at out-of-season forecasts, accurately predicting yields as early as April-June of the growing season. Feature importance analysis highlights soil properties, particularly pH and texture at various depths, as critical predictors for both yield and emissions. Most importantly, this study advances an integrated economic-environmental modeling in agriculture by analyzing yield-emissions trade-offs through the Non-dominated Sorting Genetic Algorithm II (NSGA-II), revealing an unexpected synergy where practices that improve economic productivity also reduce environmental impact, as higher yields correlate with lower methane emissions.},
  keywords={Methane;Machine learning;Predictive models;Meteorology;Soil;Remote sensing;Biological system modeling;Food security;Productivity;Greenhouse gases;Machine learning;methane emissions;remote sensing;rice yield prediction;sustainable agriculture},
  doi={10.1109/ACCESS.2025.3562397},
  ISSN={2169-3536},
  month={},}@ARTICLE{10858342,
  author={Dai, Haixing and Liu, Zhengliang and Liao, Wenxiong and Huang, Xiaoke and Cao, Yihan and Wu, Zihao and Zhao, Lin and Xu, Shaochen and Zeng, Fang and Liu, Wei and Liu, Ninghao and Li, Sheng and Zhu, Dajiang and Cai, Hongmin and Sun, Lichao and Li, Quanzheng and Shen, Dinggang and Liu, Tianming and Li, Xiang},
  journal={IEEE Transactions on Big Data}, 
  title={AugGPT: Leveraging ChatGPT for Text Data Augmentation}, 
  year={2025},
  volume={11},
  number={3},
  pages={907-918},
  abstract={Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning (FSL) scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely used strategy to mitigate such challenges is to perform data augmentation to better capture data invariance and increase the sample size. However, current text data augmentation methods either can’t ensure the correct labeling of the generated data (lacking faithfulness), or can’t ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models (LLM), especially the development of ChatGPT, we propose a text data augmentation approach based on ChatGPT (named ”AugGPT”). AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples. The augmented samples can then be used in downstream model training. Experiment results on multiple few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.},
  keywords={Data augmentation;Data models;Chatbots;Training;Few shot learning;Accuracy;Text categorization;Large language models;Semantics;Translation;Large language model;few-shot learning;natural language processing;data augmentation},
  doi={10.1109/TBDATA.2025.3536934},
  ISSN={2332-7790},
  month={June},}@ARTICLE{10251606,
  author={Wei, Xingxing and Zhao, Shiji},
  journal={IEEE Transactions on Multimedia}, 
  title={Boosting Adversarial Transferability With Learnable Patch-Wise Masks}, 
  year={2024},
  volume={26},
  number={},
  pages={3778-3787},
  abstract={Adversarial examples have attracted widespread attention in security-critical applications because of their transferability across different models. Although many methods have been proposed to boost adversarial transferability, a gap still exists between capabilities and practical demand. In this article, we argue that the model-specific discriminative regions are a key factor causing overfitting to the source model, and thus reducing the transferability to the target model. For that, a patch-wise mask is utilized to prune the model-specific regions when calculating adversarial perturbations. To accurately localize these regions, we present a learnable approach to automatically optimize the mask. Specifically, we simulate the target models in our framework, and adjust the patch-wise mask according to the feedback of the simulated models. To improve the efficiency, the differential evolutionary (DE) algorithm is utilized to search for patch-wise masks for a specific image. During iterative attacks, the learned masks are applied to the image to drop out the patches related to model-specific regions, thus making the gradients more generic and improving the adversarial transferability. The proposed approach is a preprocessing method and can be integrated with existing methods to further boost the transferability. Extensive experiments on the ImageNet dataset demonstrate the effectiveness of our method. We incorporate the proposed approach with existing methods to perform ensemble attacks and achieve an average success rate of 93.01% against seven advanced defense methods, which can effectively enhance the state-of-the-art transfer-based attack performance.},
  keywords={Perturbation methods;Adaptation models;Visualization;Training;Predictive models;Iterative methods;Statistics;DNNs;Adversarial Attack;Adversarial Transferability},
  doi={10.1109/TMM.2023.3315550},
  ISSN={1941-0077},
  month={},}@ARTICLE{10829562,
  author={Al Mazroa, Alanoud and Albogamy, Fahad R. and Khairi Ishak, Mohamad and Mostafa, Samih M.},
  journal={IEEE Access}, 
  title={Boosting Cyberattack Detection Using Binary Metaheuristics With Deep Learning on Cyber-Physical System Environment}, 
  year={2025},
  volume={13},
  number={},
  pages={11280-11294},
  abstract={The swift advancement of cyber-physical systems (CPSs) across sectors such as healthcare, transportation, critical infrastructure, and energy enhances the crucial requirement for robust cybersecurity measures to protect these systems from cyberattacks. The cyber-physical method is a hybrid of cyber and physical components, and a safety breach in the element is central to catastrophic consequences. Cyberattack recognition and mitigation techniques in CPSs include using numerous models like intrusion detection systems (IDSs), access control mechanisms, encryption, and firewalls. Cyberattack detection employing deep learning (DL) contains training neural networks to identify patterns indicative of malicious actions within system logs or network traffic, allowing positive classification and mitigation of cyber-attacks. By leveraging the integral ability of DL methods to learn complex representations, this technique enhances the accuracy and efficiency of detecting diverse and growing cyber-attacks. Thus, the study proposes an automated Cyberattack Detection using Binary Metaheuristics with Deep Learning (ACAD-BMDL) method in a CPS environment. The ACAD-BMDL method mainly focuses on enhancing security in the CPS environment via the cyberattack detection process. The ACAD-BMDL method uses Z-score normalization to scale the input dataset. In addition, the binary grey wolf optimizer (BGWO) model is utilized to choose an optimal feature subset. Moreover, the Enhanced Elman Spike Neural Network (EESNN) model detects cyber-attacks. Furthermore, the Archimedes Optimization Algorithm (AOA) model is employed to select the optimum hyperparameter for the EESNN model. The empirical analysis of the ACAD-BMDL technique is performed on a benchmark dataset. The experimental validation of the ACAD-BMDL technique portrayed a superior accuracy value of 99.12% and 99.36% under NSLKDD2015 and CICIDS2017 datasets in the CPS environment.},
  keywords={Cyberattack;Optimization;Feature extraction;Data models;Accuracy;Security;Neural networks;Adaptation models;Deep learning;Computational modeling;Cyber-physical systems;deep learning;cyberattack detection;metaheuristics;Archimedes optimization algorithm},
  doi={10.1109/ACCESS.2025.3526258},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10111236,
  author={Prem, Ajay and Joshi, Anirudh and Madana, Haritha and J, Jaywanth and Arya, Arti},
  booktitle={2023 15th International Conference on Computer and Automation Engineering (ICCAE)}, 
  title={Attention Based Evolutionary Approach for Image Classification}, 
  year={2023},
  volume={},
  number={},
  pages={237-243},
  abstract={Lately, evolutionary algorithms have gained traction due to their ability to produce state-of-the-art deep learning architectures for a given data set, even though they require considerable amount of compute resources, they are a heavily researched domain because of the complexities involved in designing deep learning architectures. Currently, none of the evolutionary approaches available have incorporated the attention mechanism, which is a proven technique to improve the performance of image classification and language models. This paper posits a neuroevolutionary technique coupled with the use of Convolution Block Attention Module for image classification. As technology progresses, it’s inevitable that there will be massive advancements leading to cheaper and more available computing making evolutionary approaches a promising avenue to develop task specific deep learning models. The proposed approach evolves a topology that achieves a high fitness of 87.44%, using fewer parameters as compared to previous approaches. This results in a superior fitness score compared to most past approaches, despite being evolved for just few generations.},
  keywords={Deep learning;Automation;Convolution;Computational modeling;Evolutionary computation;Topology;Complexity theory;Neuro-Evolution;Genetic Algorithms;topology evolution;attention;CoDeepNEAT;Convolutional Block Attention Module (CBAM);CIFAR-10},
  doi={10.1109/ICCAE56788.2023.10111236},
  ISSN={2154-4360},
  month={March},}@INPROCEEDINGS{10580619,
  author={Du, Wantong and Min, Wanli and Geng, Yushui and Liang, Hu and Zhou, Hehu},
  booktitle={2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={Cross Modal Sentiment Classification of Social Media Based on Meta Heuristic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1838-1844},
  abstract={The evolution of online social media has reshaped public behaviors, and social data infused with emotions provides crucial decision support for sentiment analysis tasks. Conventional multimodal approaches, influenced by redundant information in feature extraction during sentiment analysis, often focus solely on modality interactions without considering the unique content of each modality. This paper introduces the HGB-HFN model, addressing feature redundancy by optimizing extracted features using metaheuristic algorithm techniques, achieving a higher accuracy optimal feature dataset at lower computational costs. To counteract the neglect of modal-independent information, a hybrid fusion approach is adopted. It prioritizes visual features to extract precise semantic and emotional information from textual content, training multiple base classifiers to learn independent and diverse discriminative information. Comparative experiments on streaming datasets MOSI and MOSEI demonstrate the computational approach’s superiority in both accuracy and efficiency over existing methods.},
  keywords={Training;Sentiment analysis;Visualization;Accuracy;Social networking (online);Metaheuristics;Semantics;Sentiment classification;meta-heuristics;attention mechanism;Multimodal},
  doi={10.1109/CSCWD61410.2024.10580619},
  ISSN={2768-1904},
  month={May},}@INPROCEEDINGS{10386028,
  author={Lee, Eva K. and Yuan, Fan and Mann, Barton J. and Egan, Brent},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Handling Imbalanced and Poorly Separated Data: a Multi-Stage Multi-Group Machine Learning Approach}, 
  year={2023},
  volume={},
  number={},
  pages={4336-4343},
  abstract={Poorly separated data and imbalanced data present major challenges to classifiers which often result in lower accuracy and reliability in making predictions. In this paper, we introduce the multi-stage classification construct in which ‘difficult-to-classify’ observations are placed into a reserved judgment region for delayed future classification. Such a design is well-suited for poorly separated data that are difficult to classify without committing a high percentage of misclassification errors. The misclassification constraints within the classifier can be finetuned to allow management of imbalanced data, guiding minority entities into the reserved judgement region to avoid being misclassified into the majority groups. We wrap the classifier with a fast feature selection heuristic based on particle swarm optimization. An exact combinatorial branch-and-bound algorithm is also implemented to measure the quality of the heuristic solutions. We apply this multi-stage multi-group machine learning framework to two real-life medical problems: (a) multi-site treatment outcome prediction for best practice discovery in cardiovascular disease, and (b) uncovering patient characteristics that predict optimal response to intra-articular injections of hyaluronic acid for the treatment of knee osteoarthritis. Both problems involve poorly separated data and imbalanced groups in which traditional classifiers yield low prediction accuracy (47% - 66%). The multi-stage BB-PSO/DAMIP manages the poorly separated and imbalanced data well and returns interpretable results with 82% - 97% blind prediction accuracy.},
  keywords={Machine learning algorithms;Heuristic algorithms;Machine learning;Prediction algorithms;Particle measurements;Feature extraction;Classification algorithms;multi-stage multi-group machine learning framework;imbalanced data;poorly separated data;discriminant analysis via mixed integer program;multi-site knowledge discovery;cardiovascular disease;knee osteoarthritis;machine learning for evidence-based practice;branch-and-bound;particle swarm optimization},
  doi={10.1109/BIBM58861.2023.10386028},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{9853627,
  author={Chen, Min and Sun, Zhanfang and Su, Fei and Chen, Yan and Bu, Degang and Lyu, Yubo},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={An Auxiliary Diagnostic System for Parkinson’s Disease Based on Wearable Sensors and Genetic Algorithm Optimized Random Forest}, 
  year={2022},
  volume={30},
  number={},
  pages={2254-2263},
  abstract={Parkinson’s disease (PD) is a neurodegenerative disorder characterized mainly by motor-related impairment, an accurate, quantitative, and objective diagnosis is an effective way to slow the disease deterioration process. In this paper, a user-friendly auxiliary diagnostic system for PD is constructed based on the upper limb movement conditions of 100 subjects consisting of 50 PD patients and 50 healthy subjects. This system includes wearable sensors that collect upper limb movement data, host computer for data processing and classification, and graphic user interface (GUI). The genetic algorithm optimized random forest classifier is introduced to classify PD and normal states based on the selected optimal features, and the 50 trials leave-one-out cross-validation is used to evaluate the performance of the classifier, with the highest accuracy of 94.4%. The classification accuracy among different upper limb movement tasks and with the different number of sensors are compared, results show that the task with only alternation hand movement also has satisfactory classification accuracy, and sensors on both wrists performance better than one sensor on a single wrist. The utility of the proposed system is illustrated by neurologists with a deployed GUI during the clinical inquiry, opening the possibility for a wide range of applications in the auxiliary diagnosis of PD.},
  keywords={Sensors;Wearable sensors;Task analysis;Graphical user interfaces;Random forests;Genetic algorithms;Classification tree analysis;Parkinson’s disease;auxiliary diagnostic system;wearable sensors;random forest;genetic algorithm},
  doi={10.1109/TNSRE.2022.3197807},
  ISSN={1558-0210},
  month={},}@ARTICLE{10879494,
  author={Ahmed, Marzia and Sulaiman, Mohd Herwan and Hassan, Md Maruf and Bhuiyan, Touhid},
  journal={IEEE Access}, 
  title={Predicting the Classification of Heart Failure Patients Using Optimized Machine Learning Algorithms}, 
  year={2025},
  volume={13},
  number={},
  pages={30555-30569},
  abstract={Heart failure is a critical condition with a high mortality rate, making accurate survival prediction essential for timely interventions. This study proposes an optimized machine learning approach using Gradient Boosting Machine (GBM) and Adaptive Inertia Weight Particle Swarm Optimization (AIW-PSO) to predict heart failure survival. The dataset, sourced from Kaggle, includes clinical features such as age, ejection fraction, and serum creatinine levels for 299 heart failure patients. To address the imbalance in survival outcomes, Synthetic Minority Over-sampling Technique (SMOTE) was employed to balance the dataset, followed by SelectKBest and Chi-square feature selection methods to retain the most significant predictors. The optimized hyperparameters for the GBM model were identified using the AIW-PSO algorithm, which effectively balanced exploration and exploitation by adaptively adjusting inertia weights. Model selection was further refined using information criteria, including Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC), ensuring that the best-performing model was chosen based on both predictive accuracy and model complexity. The optimized GBM model achieved a test accuracy of 94%, demonstrating superior performance compared to traditional machine learning models. The study underscores the importance of hyperparameter tuning through metaheuristic algorithms and highlights the potential of AIW-PSO in enhancing model performance for clinical prediction tasks. These findings have significant implications for clinical decision-making, offering a reliable and interpretable tool for predicting patient outcomes in heart failure management.},
  keywords={Cardiovascular diseases;Predictive models;Prediction algorithms;Machine learning algorithms;Accuracy;Machine learning;Computational modeling;Mortality;Adaptation models;Particle swarm optimization;Heart failure survival prediction;machine learning algorithms;hyperparameter optimization;class imbalance handling;AIW-PSO optimization},
  doi={10.1109/ACCESS.2025.3541069},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10721747,
  author={Hu, Yongchen},
  booktitle={2024 International Conference on Intelligent Algorithms for Computational Intelligence Systems (IACIS)}, 
  title={Predicting Novels Popularity Based on Optimized Random Forest using Success History Intelligent Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Reading novels help people to develop their social skills and mainly helps to reduce stress. In that, predicting novel popularity becomes a difficult task that is impacted by amount of variables, including reader preferences, sales patterns, and literary qualities. Machine Learning (ML) techniques are highly recommended for prediction task wherein using the Random Forest (RF), the popularity of sentiment as well as emotional variables derived from the narrative text of novels has been predicted. Since these techniques are heavily relied on hyperparameter values because, when optimized hyperparameters have been defined and modified during the training process, their predicted accuracy could improve. In order to fine-tune the RF hyperparameters, a Success History Intelligent Optimisation (SHIO) is presented for the prediction of popularity of online novels. A total of 2,439 eBooks/novels around nine distinct categories in the online publishing from Project Gutenberg. By addressing the issue of consumer information overload, these vectors could become beneficial for advancing the development of novel recommender systems. The SHIO-RF achieves a lower Mean Absolute Error (MAE) of 0.15 and outperforms the compared conventional algorithms including Shapley Additive explanations and Light Gradient Boosting Machine Classifier (SHAP-LGBM), Attention Mechanism based Graph Neural Network (AM-GNN) and RF.},
  keywords={Training;Electronic publishing;Accuracy;Prediction algorithms;Vectors;History;Random forests;Standards;Recommender systems;Classification tree analysis;hyperparameter optimization;machine learning;novels;random forest;success history intelligent optimization},
  doi={10.1109/IACIS61494.2024.10721747},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10820655,
  author={Zhu, Yiqing and Simsek, Osman Seckin and Favre, Jean M. and Cabezón, Rubén and Ciorba, Florina M.},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Scalable In-Situ Visualization for Extreme-Scale SPH Simulations}, 
  year={2024},
  volume={},
  number={},
  pages={853-858},
  abstract={Large-scale scientific simulations present significant challenges in data processing efficiency. This paper addresses the critical issue of I/O and data processing performance bottlenecks within the domain of extreme-scale Smoothed-particle Hydrodynamics (SPH) and gravity simulations. We present a novel I/O software architecture implemented in the scalable SPH-EXA framework [1], incorporating a variety of in-situ and post-hoc data analysis pipelines, facilitating rapid analysis and visualization of extreme-scale physical datasets. The performance of our I/O architecture is evaluated through comprehensive benchmarking across a wide range of data scales, conducted on the Piz Daint supercomputer [2].},
  keywords={Analytical models;Data analysis;Limiting;Software architecture;Pipelines;Data visualization;Computer architecture;Hydrodynamics;Data models;Supercomputers;in-situ visualization;HPC;extreme-scale;SPH},
  doi={10.1109/SCW63240.2024.00121},
  ISSN={},
  month={Nov},}@ARTICLE{10613798,
  author={Wang, Cong and Cui, Guangkai and Gao, Xuke and Chen, Geng and Tu, Youping and Zheng, Zhong and Jin, Hua and Yang, Yuan},
  journal={IEEE Transactions on Dielectrics and Electrical Insulation}, 
  title={Method Based on Stacking-Attention to Find Decomposition Indicators of Discharge Mechanism in C4F7N-CO2-O2 Gas}, 
  year={2024},
  volume={31},
  number={6},
  pages={3110-3119},
  abstract={The correlation between the decomposition products and discharge faults in the electrical equipment with the environmentally friendly insulating gas mixture C4F7N/CO2/O2 remains inadequately revealed and the corresponding characterization methods also need to be determined. In this article, a feature fusion algorithm based on the stacking-attention mechanism is proposed. The ratios of decomposition products from C4F7N/CO2/O2 mixtures in various proportions under different discharge conditions are utilized as the dataset. Multiple feature extraction algorithms are employed as base learners to derive feature subsets from diverse dimensions. Subsequently, these feature subsets are fused using the attention mechanism as the meta-learner, and the contribution of each feature value is determined, thereby identifying the optimal feature subset. Experimental results demonstrate that the optimal feature values extracted by this method, when applied to classification algorithms such as support vector machine (SVM) and artificial neural network (ANN), effectively distinguish between defects including corona discharge, spark discharge, and suspended discharge in environmentally friendly gas-insulated equipment. Based on the decomposition characteristics, the ratios of CO/(C3F6+CF4) and CF4/C3F8 are proposed as diagnostic indicators for identifying discharge faults in engineering applications of C4F7N/CO2/O2 gas-insulated equipment. The research results of this article provide both theoretical and technical support for the operation and maintenance of gas-insulated electrical equipment.},
  keywords={Discharges (electric);Feature extraction;Genetic algorithms;Corona;Dielectrics and electrical insulation;Sparks;Support vector machines;C₄F₇N/CO₂/O₂ gas mixture;correlation characteristics;feature extraction;stacking-attention mechanism},
  doi={10.1109/TDEI.2024.3434780},
  ISSN={1558-4135},
  month={Dec},}@INPROCEEDINGS{10692568,
  author={Yang, Xuelian and Du, Fangyuan and Chen, Kunjun and Chen, Hao},
  booktitle={2024 6th International Conference on Natural Language Processing (ICNLP)}, 
  title={Causal Logic Discovery and Rule Validation Using Evolutionary Integration Model Global Fit U-Net}, 
  year={2024},
  volume={},
  number={},
  pages={800-805},
  abstract={In order to explore the correlation between different MRI sequences and the results of U-Net segmentation of glioma subregions, this paper proposes an interpretable method based on an evolutionary integration algorithm for logical discovery of the segmentation process of U-Net. Our approach consists of three steps: 1) Global fitting of the U-Net model to the segmentation results of gliomas using a dual evolutionary algorithm to generate a fitted model with both accuracy and interpretability.2) Extracting decision rules from the fitted model according to a specific target interpretable region and generating a complete set of interpretable rules after optimisation.3) Proposing a decision path integrator modeling method for the target region of decision paths for experimental validation. In this study, 293 patients from the BraTS2020 dataset are used as research data, and the accuracy of the fitted model is obtained to be 0.92, which is basically the same as that of Random Forest, but the model in this study has a better and simpler internal structure. At the same time, this study validated the relationship between Flair sequence and the edema region of glioma, and the experimental results showed that our extracted decision paths have a certain auxiliary effect on the segmentation of U-Net, and also proved the effectiveness of our proposed interpretability method.},
  keywords={Accuracy;Correlation;Magnetic resonance imaging;Fitting;Evolutionary computation;Data models;Natural language processing;Logic;Random forests;glioma;U-Net;dual evolutionary ensemble learning;rule extraction;interpretability},
  doi={10.1109/ICNLP60986.2024.10692568},
  ISSN={},
  month={March},}@ARTICLE{11062454,
  author={Zhao, Shaishai and Chen, Jianfei and Li, Chengzhi and Chi, Jiaqi},
  journal={IEEE Journal of Emerging and Selected Topics in Power Electronics}, 
  title={An Automatic Design Method for Optimal Parameter Combination of Power Converter Considering Physical Regularities-Attentional Mechanism}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The performance of a power converter is closely related to the selection of circuit parameters. However, the mainstream parametric design methods at present are overly dependent on humans. It is often not possible to obtain the best combination of key parameters. Therefore, an artificial intelligence-based design method for the key parameters is proposed, which aims to realize the best performance and automated design process. Firstly, a performance estimation model (PEM) for power converters is developed that considers the physical law-attention mechanism (AM). It incorporates AM into a physical information neural network and automatically builds the mapping model of design parameters and objectives. The design objectives represent the different performances of the converter. Secondly, the particle swarm optimization method is used to realize the automated search for the best combination of design parameters. Its optimization ability in discontinuous space is improved by making discrete variables continuous. Finally, the superiority of the proposed method is proved by the comparison experiment and the scalability verification experiment.},
  keywords={Optimization;Design methodology;Capacitors;Accuracy;Power electronics;Power harmonic filters;Inductors;Training;Data models;Artificial intelligence;Artificial Intelligence;Optimization Design;Physical Regularities;Power Converter},
  doi={10.1109/JESTPE.2025.3584945},
  ISSN={2168-6785},
  month={},}@INPROCEEDINGS{9863019,
  author={Fuchs, Caro and Spolaor, Simone and Kaymak, Uzay and Nobile, Marco S.},
  booktitle={2022 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)}, 
  title={The Impact of Variable Selection and Transformation on the Interpretability and Accuracy of Fuzzy Models}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Data transformation is an important step in Machine Learning pipelines which can strongly improve their performance. For instance, min-max normalization is often used to make all variables lie in the same range, while log-transformation is used to map data that is scattered across several orders of magnitude to a logarithmic space. Such transformations can be beneficial when the machine learning approach measures distance in a metric space, such as cluster-based approaches. These two transformation approaches can be combined to reveal hidden patterns in the data in the case of log-normally distributed data points, which commonly occur in biological and medical data. In this work we introduce a novel evolutionary approach designed to automatically determine the optimal log-transformation and selection of variables. Our approach is built around an interpretable AI system (created by pyFUME), so that all transformations are followed by inverse transformations to map back the values into the original universe of discourse, and preserve the interpretability of the results. We test our approach on two synthetic datasets, designed to reproduce a condition in which some variables are normally distributed, some variables are log-normally distributed, and some variables are just noise in the dataset. Our results show that our approach yields better performing models compared to conventional methods, and that the resulting model is also characterised by a better interpretability, making such approach particularly useful to study biomedical datasets.},
  keywords={Training;Fuzzy sets;Biological system modeling;Fitting;Distributed databases;Machine learning;Feature extraction;interpretable AI;data transformation;log-transformation;data normalization;machine learning;genetic algorithm;fuzzy model;fuzzy logic},
  doi={10.1109/CIBCB55180.2022.9863019},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10240077,
  author={Huang, Jie and Zhu, Wuyingjia and Cai, Ying and Xie, Minfeng},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={On Digital Economy Scales Prediction Technology based on QPSO and LSTM Model}, 
  year={2023},
  volume={},
  number={},
  pages={8906-8911},
  abstract={The digital economy is a new type of economic form with new expression concepts, many influencing factors, and a wide scope. Accurate prediction of it can not only make quantitative judgments on future economic trends but also directly serve the development of the economy and society and effectively prevent economic risks. This paper combines the Pearson correlation coefficient and the idea of feature importance assessment of random forests to construct an index system for predicting the impact factors of China's digital economy. And based on the QPSO algorithm and LSTM model to construct China's digital economy scale forecasting model, the validity of the model is empirically analyzed by China's digital economy scale data from 1993 to 2020. The results show that the idea of combining a metaheuristic algorithm and neural network has validity in China's digital economy scale forecasting work. In addition, the QPSO-LSTM model outperforms both the single LSTM model and the PSO-LSTM model in terms of parameter search results, convergence speed, MAPE, MAE, and R2 evaluation indexes.},
  keywords={Economics;Analytical models;Neural networks;Predictive models;Prediction algorithms;Search problems;Data models;Digital Economy;Feature Importance Assessment Idea;QPSO Algorithm;LSTM Model},
  doi={10.23919/CCC58697.2023.10240077},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{11051227,
  author={Wu, Xiongfei and Hu, Qiang and Tsuchiya, Tomoyuki and Hayashi, Michio and Okada, Manabu and Ma, Lei and Zhao, Jianjun},
  booktitle={2025 IEEE/ACM 1st International Workshop on Software Engineering for Autonomous Driving Systems (SE4ADS)}, 
  title={Evaluating the Robustness of Uncertainty Quantification-Based Misbehavior Predictors for Autonomous Driving Systems: A Case Study}, 
  year={2025},
  volume={},
  number={},
  pages={19-25},
  abstract={Misbehavior predictors play a crucial role in safety-critical autonomous driving systems, as they help anticipate and mitigate risks by signaling potential misbehavior or deviations from expected behavior. Among existing predictors, uncertainty quantification (UQ)-based misbehavior predictors are recognized for their strong capability in identifying these risks and lightweight overhead. These predictors often operate on the assumption that uncertainty signals possible misbehavior, aiding in the real-time recognition of unexpected situations. However, in real-world scenarios, this assumption might not always hold, as many cases are either uncertain but correct or certain but incorrect. This limitation harms the reliability of UQ-based predictors and could lead to safety issues in practice.In this paper, we conduct a case study to explore the robustness of UQ-based predictors. Here, robustness indicates the ability of predictors to handle two types of challenging test cases, (1) uncertain but correct cases, and (2) certain but incorrect cases. To do so, we develop a genetic algorithm-based test data generation framework to produce these two types of test cases and evaluate misbehavior predictors accordingly. Experimental results on MC dropout models with three different settings and seven simulation datasets with various environments demonstrated that even though UQ-based predictors perform well on the original test cases, there is a significant performance degradation when facing challenging test cases. For instance, uncertain but correct cases lead to a 18 F3 score drop to the predictor. These findings highlight critical limitations and emphasize caution when deploying such predictors in unpredictable real-world environments.},
  keywords={Software testing;Uncertainty;Reliability engineering;Robustness;Real-time systems;Safety;Software reliability;Autonomous vehicles;Replicability;Software engineering;replicability;uncertainty;software testing;autonomous driving system},
  doi={10.1109/SE4ADS66461.2025.00010},
  ISSN={},
  month={April},}@ARTICLE{9967013,
  author={Pan, Dan and Luo, Genqiang and Zeng, An and Zou, Chao and Liang, Haolin and Wang, Jianbin and Zhang, Tong and Yang, Baoyao},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Adaptive 3DCNN-Based Interpretable Ensemble Model for Early Diagnosis of Alzheimer’s Disease}, 
  year={2024},
  volume={11},
  number={1},
  pages={247-266},
  abstract={An adaptive interpretable ensemble model based on a 3-D convolutional neural network (3DCNN) and genetic algorithm (GA), i.e., 3DCNN+EL+GA, was proposed to differentiate the subjects with Alzheimer’s disease (AD) or mild cognitive impairment (MCI) and also identify the discriminative brain regions significantly contributing to the classifications in a data-driven way. The testing results on the datasets from both the AD Neuroimaging Initiative (ADNI) and the Open Access Series of Imaging Studies (OASIS) indicated that 3DCNN+EL+GA outperformed other state-of-the-art deep learning algorithms. More importantly, in these identified brain regions, the discriminative brain subregions at a voxel level were further located with a gradient-based attribution method designed for CNN and illustrated intuitively. Besides these, the behavioral domains corresponding to every identified discriminative brain region (e.g., the rostral hippocampus) were analyzed. It was shown that the resultant behavioral domains were consistent with those brain functions (e.g., emotion) impaired early in the AD process. Further research is needed to examine the generalizability of the proposed ideas and methods in identifying discriminative brain regions and subregions for the diagnosis of other brain disorders (especially little-known ones), such as Parkinson’s disease, epilepsy, severe depression, autism, Huntington’s disease, multiple sclerosis, and amyotrophic lateral sclerosis, using neuroimaging.},
  keywords={Magnetic resonance imaging;Diseases;Alzheimer's disease;Convolutional neural networks;Databases;Brain modeling;Biomedical imaging;Ensemble learning;Alzheimer’s disease (AD);attribution methods;convolutional neural network (CNN);deep learning (DL);ensemble learning (EL);genetic algorithm;interpretability;magnetic resonance imaging},
  doi={10.1109/TCSS.2022.3223999},
  ISSN={2329-924X},
  month={Feb},}@INPROCEEDINGS{10341126,
  author={Zhou, Xinliang and Lin, Dan and Jia, Ziyu and Xiao, Jiaping and Liu, Chenyu and Zhai, Liming and Liu, Yang},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={An EEG Channel Selection Framework for Driver Drowsiness Detection via Interpretability Guidance}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Drowsy driving has a crucial influence on driving safety, creating an urgent demand for driver drowsiness detection. Electroencephalogram (EEG) signal can accurately reflect the mental fatigue state and thus has been widely studied in drowsiness monitoring. However, the raw EEG data is inherently noisy and redundant, which is neglected by existing works that just use single-channel EEG data or full-head channel EEG data for model training, resulting in limited performance of driver drowsiness detection. In this paper, we are the first to propose an Interpretability-guided Channel Selection (ICS) framework for the driver drowsiness detection task. Specifically, we design a two-stage training strategy to progressively select the key contributing channels with the guidance of interpretability. We first train a teacher network in the first stage using full-head channel EEG data. Then we apply the class activation mapping (CAM) to the trained teacher model to highlight the high-contributing EEG channels and further propose a channel voting scheme to select the top N contributing EEG channels. Finally, we train a student network with the selected channels of EEG data in the second stage for driver drowsiness detection. Experiments are designed on a public dataset, and the results demonstrate that our method is highly applicable and can significantly improve the performance of cross-subject driver drowsiness detection.},
  keywords={Integrated circuits;Training;Brain modeling;Fatigue;Electroencephalography;Safety;Noise measurement;Driver Drowsiness Detection;Channel Selection;EEG and Interpretability},
  doi={10.1109/EMBC40787.2023.10341126},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{9870285,
  author={Rogers, Brendan and Noman, Nasimul and Chalup, Stephan and Moscato, Pablo},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Joint Optimization of Topology and Hyperparameters of Hybrid DNNs for Sentence Classification}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Deep Neural Networks (DNN) require specifically tuned architectures and hyperparameters when being applied to any given task. Nature-inspired algorithms have been successfully applied for optimising various hyperparameters in different types of DNNs such as convolutional and recurrent for sentence classification. Hybrid networks, which contain multiple types of neural architectures have more recently been used for sentence classification in order to achieve better performance. However, the inclusion of hybrid architectures creates numerous possibilities of designing the network and those sub-networks also need fine-tuning. At present these hybrid networks are designed manually and various organisation attempts are noticed. In order to understand the benefit and the best design principle of such hybrid DNNs for sentence classification, in this work we used an Evolutionary Algorithm (EA) to optimise the topology and various hyperparameters in different types of layers within the network. In our experiments, the proposed EA designed the hybrid networks by using a single dataset and evaluated the evolved networks on multiple other datasets to validate their generalisation capability. We compared the EA-designed hybrid networks with human-designed hybrid networks in addition to other EA-optimised and expert-designed non-hybrid architectures.},
  keywords={Deep learning;Network topology;Neural networks;Computer architecture;Evolutionary computation;Topology;Classification algorithms},
  doi={10.1109/CEC55065.2022.9870285},
  ISSN={},
  month={July},}@ARTICLE{10893698,
  author={Li, Lei and Zhao, Yanzhe and Tong, Bainan and Cao, Feng and Zhang, Renhang and You, Yuan and Zhu, Hongyin},
  journal={IEEE Sensors Journal}, 
  title={Rapid Classification and Concentration Prediction of VOC Gaseous Mixtures Using Sensor Array With Multitask Learning}, 
  year={2025},
  volume={25},
  number={7},
  pages={12422-12429},
  abstract={The sensor array is the core of the electronic nose (E-nose) system, while the pattern recognition algorithm is an important component of the system. Therefore, the sensor array optimization and the algorithm research are regarded as two key research fields. Volatile organic compounds (VOCs) mixture are ubiquitous in environmental monitoring, disease screening, industrial emissions, and natural environments. Due to the flammability and potential health impacts, rapid and accurate detection of VOCs is crucial. Currently, E-nose systems for gas detection build separate models and a random number of sensors for classification and concentration prediction, which leads to low efficiency and increased complexity. To address these issues, this study proposed a novel multitask learning (MTL) framework combined with the gated recurrent unit (GRU) and feature enhancement module (MTL-GRUA), performing both gas classification and concentration prediction tasks simultaneously. The model achieved over 99% accuracy in classification tasks for acetone, ethanol, and their mixture, and demonstrated high precision in concentration prediction tasks. By optimizing the hyperparameters of the network structure of MTL-GRUA by a particle swarm optimization (PSO) algorithm and using the first 100-s data instead of stable phase data, the detection efficiency was increased by 63%, achieving rapid detection. Furthermore, the experiment verified that even with an optimization in the number of sensors from eight to three, acceptable detection results could still be obtained. The application of MTL proposed in this work provides a more efficient method for gas detection tasks.},
  keywords={Sensors;Sensor arrays;Multitasking;Feature extraction;Gas detectors;Gases;Predictive models;Data models;Sensor phenomena and characterization;Accuracy;Concentration prediction;mixture volatile organic compounds (VOCs);multitask learning (MTL);rapid detection;sensor array},
  doi={10.1109/JSEN.2025.3541212},
  ISSN={1558-1748},
  month={April},}@INPROCEEDINGS{10508665,
  author={Vidal-Ramírez, María Mercedes and Pérez-Castro, Nancy and Morales, Felipe Becerril and López-Rodríguez, Ariel and Zúñiga-Marroquín, Tania and Ruíz-Paz, Sergio Fabián and Díaz-Félix†, Gabriela},
  booktitle={2023 Mexican International Conference on Computer Science (ENC)}, 
  title={Genetic Algorithm-driven Image Processing Pipeline for Classifying Three Bird Species: An Empirical Study of Two Encoding}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper introduces iGRACE, a genetic algorithm designed to tackle the challenge of constructing and optimizing image processing pipelines, including hyperparameters. The pipelines encompass vital tasks such as noise filtering, image segmentation, feature extraction, and classification. The optimization process centers around minimizing the Cross Validation Error Rate (CVER) through the tailored selection of hyperparameters. In this study, the efficacy of iGRACE is examined using two distinct encodings: mixed and binary. While both encodings showcase comparable performance based on numerical metrics, the binary encoding outperforms the mixed encoding in terms of numerical results and execution time. However, what sets iGRACE apart is its unique attribute of providing interpretable and explainable solutions, particularly evident when comparing its results with those of a Convolutional Neural Network (CNN). Although no statistically significant differences emerge between the two encodings, a closer examination of the visual outcomes underscores iGRACE’s strength in generating image processing pipelines that are more intuitive and comprehensible for endusers when employing the mixed encoding. Notably, this insight highlights the trade-off between numerical superiority and the interpretability advantage offered by iGRACE. Furthermore, there is room for improvement in the accuracy of numerical prediction values in the realm of classification. This signifies a potential avenue for future refinements to enhance the algorithm’s predictive capabilities.},
  keywords={Measurement;Visualization;Image coding;Pipelines;Noise;Prediction algorithms;Convolutional neural networks;image processing;pipelines;classification;birds;citizen science},
  doi={10.1109/ENC60556.2023.10508665},
  ISSN={2332-5712},
  month={Sep.},}@ARTICLE{9761990,
  author={Fan, Qinglan and Bi, Ying and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Genetic Programming for Image Classification: A New Program Representation With Flexible Feature Reuse}, 
  year={2023},
  volume={27},
  number={3},
  pages={460-474},
  abstract={Extracting effective features from images is crucial for image classification, but it is challenging due to high variations across images. Genetic programming (GP) has become a promising machine-learning approach to feature learning in image classification. The representation of existing GP-based image classification methods is usually the tree-based structure. These methods typically learn useful image features according to the output of the GP program’s root node. However, they are not flexible enough in feature learning since the features produced by internal nodes of the GP program have seldom been directly used. In this article, we propose a new image classification approach using GP with a new program structure, which can flexibly reuse features generated from different nodes, including internal nodes of the GP program. The new method can automatically learn various informative image features based on the new function set and terminal set for effective and efficient image classification. Furthermore, instead of relying on a predefined classification algorithm, the proposed approach can automatically select a suitable classification algorithm based on the learned features and conduct classification simultaneously in a single evolved GP program for an image classification task. The experimental results on 12 benchmark datasets of varying difficulty suggest that the new approach achieves better performance than many state-of-the-art methods. Further analysis demonstrates the effectiveness and efficiency of the flexible feature reuse in the proposed approach. The analysis of evolved GP programs/solutions shows their potentially high interpretability.},
  keywords={Feature extraction;Task analysis;Representation learning;Training;Benchmark testing;Transforms;Support vector machines;Feature learning;feature reuse;genetic programming (GP);image classification;program structure},
  doi={10.1109/TEVC.2022.3169490},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{10698305,
  author={Shishehgarkhaneh, Milad Baghalzadeh and Chan, Melissa and Moehler, Robert C. and Fang, Yihai and Hijazi, Amer A. and Aboutorab, Hamed},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Named Entity Recognition in Construction Supply Chain Risk Management Using Transformer-Based Models and Genetic Algorithm-Driven Hyperparameter Tuning}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The construction industry faces significant supply chain risks, necessitating effective management strategies. This paper presents a novel approach using transformer-based models for Named Entity Recognition (NER) to identify risk-related entities within construction supply chain management (SCRM) from news articles. It specifically explores the efficacy of two transformer models, BERT and DeBERTa, and employs Genetic Algorithms (GAs) for optimizing model hyperparameters. This research underscores the transformative potential of NLP-driven solutions in enhancing SCRM, particularly within the unique context of the Australian construction industry. The findings highlight the importance of precision in entity recognition for effective SCRM and demonstrate the superiority of DeBERTa in precision-focused tasks, making it a promising tool for practitioners in this field.},
  keywords={Supply chain management;Computational modeling;Supply chains;Named entity recognition;Transformers;Risk management;Tuning;Faces;Genetic algorithms;Construction industry;Construction Supply Chain;Proactive Risk Management;Transformer Models;BERT;Genetic Algorithms},
  doi={10.1109/ICECET61485.2024.10698305},
  ISSN={},
  month={July},}@INPROCEEDINGS{10611837,
  author={Kheiri, Farnaz and Bidgoli, Azam Asilian and Makrehchi, Masoud and Rahnamayan, Shahryar},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Feature Selection-driven Bias Deduction in Histopathology Images: Tackling Site-Specific Influences}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The emergence of bias in deep neural models represents a significant reliability concern, which may lead to overoptimistic results on seen data while compromising the model's ability to generalize effectively on unseen datasets. Recent studies conducted on The Cancer Genome Atlas (TCGA), which is a publicly available repository of histopathology images, reveal that the TCGA cancerous features extracted by deep neural networks surprisingly are able to discriminate slides based on their origin sites. This finding undoubtedly indicates the existence of site-specific patterns embedded in the extracted features learned by deep networks rather than focusing on histomorphologic patterns. Consequently, this biased behavior raises concerns about the reliability of these networks. This observation motivates us to conduct a series of experiments in which we present two distinct evolutionary feature selection strategies, each differentiated by its objective function evaluation. The primary goal is to select the features with a minimized foot-print of data source signatures, thereby ensuring a more accurate and site-independent cancer classification. We have conducted nine comprehensive independent experiments across nine cancer types, employing each evolutionary strategy. The comparison between results obtained through evolutionary strategies and the original feature sets highlights the substantial impact of feature selection methods on bias reduction while maintaining accuracy in cancer-type discrimination. Furthermore, the comparison of the two strategies with each other demonstrates the intricate nature of bias and its integration with cancerous features during the training process.},
  keywords={Training;Accuracy;Histopathology;Training data;Feature extraction;Prediction algorithms;Data models;Evolutionary Computation;Feature Selection;Bias;TCGA;Shortcut;Histopathology},
  doi={10.1109/CEC60901.2024.10611837},
  ISSN={},
  month={June},}@INPROCEEDINGS{10553801,
  author={Calapristi, Marco and Patanè, Luca and Sapuppo, Francesca and Xibilia, Maria Gabriella},
  booktitle={2024 International Conference on Control, Automation and Diagnosis (ICCAD)}, 
  title={Interpretability analysis of Symbolic Regression models for dynamical systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Symbolic Regression (SR) is a machine learning paradigm that focuses on the automatic discovery of mathematical equations that best describe the relationship between input and output features in experimental datasets. Such an approach leads to interpretable models that make it easy to incorporate the knowledge available in the system. This article addresses the application of SR as an interpretable modelling approach for industrial applications involving nonlinear dynamical systems. Interpretability in model identification is crucial for understanding system processes. While SR models are inherently interpretable, the inclusion of explainability techniques such as SHAP is being explored to improve model validation while facilitating model interpretation by process technologists. In this paper, the Narendra-Li system, which is commonly used as a testbed for dynamical system identification, is considered. The performance of the proposed solutions is evaluated using appropriate interpretability metrics that provide insight into their efficiency in capturing the underlying dynamics of the system.},
  keywords={Measurement;Visualization;Accuracy;System dynamics;Genetic programming;Machine learning;Predictive models},
  doi={10.1109/ICCAD60883.2024.10553801},
  ISSN={2767-9896},
  month={May},}@INPROCEEDINGS{10392553,
  author={Jawalkar, Anil Pandurang and Kumar, S Kiran and Deshmukh, Ram and Mounika, P. and H.T, Manohara},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Fault Detection and Diagnosis in Automotive Control Systems using Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The Software Fault detection and diagnosis approaches supports to find the fault vulnerable constituents in the software development in early stages. An effective diagnosis approach can support test administrators to locate defects and defect-vulnerable software modules. The Feature Extraction (FE) process is the applicable solution to solve high dimensionality and polynomial time complexity issue in the prediction of software defect. In this research, a new fault detection approach is proposed by utilizing the Stacked Auto Encoder (SAE) with Support Vector Machine (SVM) and Artificial Neural Network (ANN). In this approach, the ANN is utilized for the diagnosis process to distribute the data named the fault type. Now, the input generates the Deep Neural Network as well as fuzzy depiction process. the outcome of these approaches is then integrated by the dense connected layers. The proposed SAE based SVM-ANN model attains better results by utilizing evaluation metrics like Accuracy, Precision, F1-score, and Area Under Curve (AUC) values about 99.87%, 99.52%, 99.82% and 0.99 respectively which is comparatively higher than existing techniques like Unsupervised Learning, SVM, Generative Adversarial Neural Network.},
  keywords={Support vector machines;Measurement;Fault detection;Artificial neural networks;Maintenance engineering;Software;Time complexity;Artificial Neural Network;Fault detection;Fault diagnosis;Stacked Auto Encoder and Support Vector Machine},
  doi={10.1109/EASCT59475.2023.10392553},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11073432,
  author={Saito, Naoki and Weber, David},
  booktitle={2025 IEEE Statistical Signal Processing Workshop (SSP)}, 
  title={Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={196-200},
  abstract={We propose a new method to extract discriminant and explainable features from a particular machine learning model, i.e., a combination of the scattering transform and the multiclass logistic regression. Although this model is well-known for its ability to learn various signal classes with high classification rate, it remains elusive to understand why it can generate such successful classification, mainly due to the nonlinearity of the scattering transform. In order to uncover the meaning of the scattering transform coefficients selected by the multiclass logistic regression (with the Lasso penalty), we adopt zeroth-order optimization algorithms to search an input pattern that maximizes the class probability of a class of interest given the learned model. In order to do so, it turns out that imposing sparsity and smoothness of input patterns is important. We demonstrate the effectiveness of our proposed method using a couple of synthetic time-series classification problems.},
  keywords={Wavelet transforms;Logistic regression;Conferences;Scattering;Signal processing algorithms;Machine learning;Signal processing;Feature extraction;Classification algorithms;Optimization;Nonlinear discriminant feature extraction;scattering transform;wavelets;zeroth-order optimization;sparsity and smoothness of signals},
  doi={10.1109/SSP64130.2025.11073432},
  ISSN={2693-3551},
  month={June},}@INPROCEEDINGS{11024356,
  author={Rao, Hongzhou and Zhao, Yanjie and Zhu, Wenjie and Xiao, Ling and Wang, Meizhen and Wang, Haoyu},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={CODEMORPH: Mitigating Data Leakage in Large Language Model Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={267-278},
  abstract={Concerns about benchmark leakage in large language models for code (Code LLMs) have raised issues of data contamination and inflated evaluation metrics. The diversity and inaccessibility of many training datasets make it difficult to prevent data leakage entirely, even with time lag strategies. Consequently, generating new datasets through code perturbation has become essential. However, existing methods often fail to produce complex and diverse variations, struggle with complex cross-file dependencies, and lack support for multiple programming languages, which limits their effectiveness in enhancing LLM evaluations for coding tasks. To fill this gap, we propose Codemorph, an approach designed to support multiple programming languages while preserving cross-file dependencies to mitigate data leakage. CODEMORPH consists of two main components that work together to enhance the perturbation process. The first component employs 26 semantic-preserving transformation methods to iteratively perturb code, generating diverse variations while ensuring that the modified code remains compilable. The second component introduces a genetic algorithm-based selection algorithm, PESO, to identify the more effective perturbation method for each iteration by targeting lower similarity scores between the perturbed and original code, thereby enhancing overall perturbation effectiveness. Experimental results demonstrate that after applying CODEMORPH, the accuracy of the LLM on code completion tasks across five programming languages decreased by an average of 24.67%, with Python showing the most significant reduction at 45%. The similarity score of code optimized by PESO is, on average, 7.01% lower than that of randomly perturbed code, peaking at a reduction of 42.86%. Additionally, overall accuracy dropped by an average of 15%, with a maximum decrease of 25%. These findings indicate that CODEMORPH effectively reduces data contamination while PESO optimizes perturbation combinations for code.},
  keywords={Training;Measurement;Codes;Accuracy;Perturbation methods;Large language models;Contamination;Software engineering;Python;Genetic algorithms},
  doi={10.1109/ICSE-Companion66252.2025.00081},
  ISSN={2574-1934},
  month={April},}@INPROCEEDINGS{10980855,
  author={Pan, Yi and Jiang, Hanqi and Chen, Junhao and Li, Yiwei and Zhao, Huaqin and Zhou, Yifan and Shu, Peng and Wu, Zihao and Liu, Zhengliang and Zhu, Dajiang and Li, Xiang and Abate, Yohannes and Liu, Tianming},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)}, 
  title={EG-SpikeFormer: Eye-Gaze Guided Transformer on Spiking Neural Networks for Medical Image Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Neuromorphic computing has emerged as a promising energy-efficient alternative to traditional artificial neural networks (ANNs), predominantly utilizing spiking neural networks (SNNs) implemented on neuromorphic hardware. SNNs are more energy-efficient and excel at processing spatio-temporal data than ANNs. Significant advancements have been made in SNN-based convolutional neural networks (CNNs) and Transformer architectures. However, neuromorphic computing for the medical imaging domain remains underexplored. In this study, we introduce EG-SpikeFormer, an SNN architecture tailored for clinical tasks that incorporates eye-gaze data to guide the model's attention to the diagnostically relevant regions in medical images. Our developed approach effectively addresses shortcut learning issues commonly observed in conventional models, especially in scenarios with limited clinical data and high demands for model reliability, generalizability, and transparency. Our EG-SpikeFormer not only demonstrates superior energy efficiency and performance in medical image prediction tasks but also enhances clinical relevance through multi-modal information alignment. By incorporating eye-gaze data, the model improves interpretability and generalization, opening new directions for applying neuromorphic computing in medical image analysis.},
  keywords={Image analysis;Neuromorphic engineering;Computational modeling;Spiking neural networks;Medical services;Transformers;Energy efficiency;Data models;Convolutional neural networks;Medical diagnostic imaging;Neuromorphic computing;spiking neural networks;eye-gaze;medical image analysis;healthcare applications},
  doi={10.1109/ISBI60581.2025.10980855},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{9943907,
  author={Li, ShengZeng and Zhong, YiWen and Lin, JiaXiang and Zhang, ZhenChang},
  booktitle={2022 5th International Conference on Data Science and Information Technology (DSIT)}, 
  title={WTCGRU: Short-term wind speed prediction based on window feature importance sampling}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={In short-term wind speed prediction, different features in the time window have different degrees of influence on the prediction results. However, the importance of different features in the time window is mostly treated equally, which results in the deficiency of responding promptly to the time-varying characteristics of wind speed and treating differently the time window feature weights that affect the prediction accuracy. Hence, a novel model called WTCGRU is proposed to improve the prediction accuracy by fully considering the influence of different features in the time window during wind speed prediction. In WTCGRU, the weights of different features in the time window are sampled through an adaptive genetic approach, which is called importance sampling, and fed into a hybrid model composed of GRU and TCN, to predict more precisely the short-term wind speed; This step is executed repeatedly until WTCGRU's prediction accuracy is higher than a predefined threshold. Finally, theoretical experiments are carried out on the wind speed dataset from Szeged of Hungary, and it is shown that the WTCGRU has outperformed the mainstream short-term wind speed prediction model TCN, BILSTM, CNN-LSTM, and ensemble-CNN.},
  keywords={Adaptation models;Monte Carlo methods;Wind speed;Predictive models;Data science;Genetics;Data models;short-term wind speed prediction;time window features;importance sampling;adaptive genetic algorithm},
  doi={10.1109/DSIT55514.2022.9943907},
  ISSN={},
  month={July},}@ARTICLE{9898909,
  author={Yar, Hikmat and Hussain, Tanveer and Agarwal, Mohit and Khan, Zulfiqar Ahmad and Gupta, Suneet Kumar and Baik, Sung Wook},
  journal={IEEE Transactions on Image Processing}, 
  title={Optimized Dual Fire Attention Network and Medium-Scale Fire Classification Benchmark}, 
  year={2022},
  volume={31},
  number={},
  pages={6331-6343},
  abstract={Vision-based fire detection systems have been significantly improved by deep models; however, higher numbers of false alarms and a slow inference speed still hinder their practical applicability in real-world scenarios. For a balanced trade-off between computational cost and accuracy, we introduce dual fire attention network (DFAN) to achieve effective yet efficient fire detection. The first attention mechanism highlights the most important channels from the features of an existing backbone model, yielding significantly emphasized feature maps. Then, a modified spatial attention mechanism is employed to capture spatial details and enhance the discrimination potential of fire and non-fire objects. We further optimize the DFAN for real-world applications by discarding a significant number of extra parameters using a meta-heuristic approach, which yields around 50% higher FPS values. Finally, we contribute a medium-scale challenging fire classification dataset by considering extremely diverse, highly similar fire/non-fire images and imbalanced classes, among many other complexities. The proposed dataset advances the traditional fire detection datasets by considering multiple classes to answer the following question: what is on fire? We perform experiments on four widely used fire detection datasets, and the DFAN provides the best results compared to 21 state-of-the-art methods. Consequently, our research provides a baseline for fire detection over edge devices with higher accuracy and better FPS values, and the proposed dataset extension provides indoor fire classes and a greater number of outdoor fire classes; these contributions can be used in significant future research. Our codes and dataset will be publicly available at https://github.com/tanveer-hussain/DFAN.},
  keywords={Feature extraction;Image color analysis;Computational modeling;Boats;Buildings;Forestry;Support vector machines;Fire detection;fire classification;fire localization;forest fire;vehicle fire;disaster management;convolutional neural network;surveillance system;attention mechanism},
  doi={10.1109/TIP.2022.3207006},
  ISSN={1941-0042},
  month={},}@ARTICLE{10488030,
  author={Fan, Qinglan and Bi, Ying and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Multi-Tree Genetic Programming for Learning Color and Multi-Scale Features in Image Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Data-efficient image classification, which focuses on achieving accurate classification performance with limited labeled data, has garnered significant attention. Genetic programming (GP) has achieved impressive progress in image classification, particularly in scenarios involving small amounts of labeled data. GP research typically focuses on designing tree-based model representations to learn useful image features for classification. However, most GP methods are proposed for gray-scale images and ignore the color features. Furthermore, the existing GP methods typically learn features on a single scale/resolution, restricting potential accuracy enhancements. To address these issues, this paper proposes a new multi-tree GP In single-tree GP (or simply GP), each individual consists of a single tree. In contrast, in multi-tree GP, each individual comprises multiple trees. representation for image feature learning and classification. In each individual, three trees are included to extract discriminative features from the red, green, and blue channels of the image. With the new image resizing layer in the tree representation, the proposed approach can achieve multi-scale feature extraction, i.e., flexibly learning fine-grained details and coarse-grained structures in the image, improving the classification performance. In addition, since a limitation of GP is premature convergence due to a decline in population diversity, this paper develops a hybrid parent selection method consisting of tournament and lexicase selection to increase population diversity, find the best individual, and improve classification accuracy. The experiments on six image classification datasets indicate that the proposed approach outperforms state-of-the-art neural network-based and GP-based methods in almost all comparisons. Further analyses demonstrate the effectiveness of each component and the potentially high interpretability of the proposed approach.},
  keywords={Feature extraction;Training data;Image color analysis;Training;Sociology;Representation learning;Gray-scale;Data-efficient Image Classification;Multi-tree Genetic Programming;Color Features;Multi-scale Feature Extraction;Parent Selection},
  doi={10.1109/TEVC.2024.3384021},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10356490,
  author={Hancock, John and Bauder, Richard and Khoshgoftaar, Taghi M.},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={A Model-Agnostic Feature Selection Technique to Improve the Performance of One-Class Classifiers}, 
  year={2023},
  volume={},
  number={},
  pages={92-98},
  abstract={One-class classifiers hold promise for applications like fraudulent credit card transaction identification. However, interpreting these models to understand which features drive predictions is challenging. Such an understanding is necessary to avoid brute-force approaches to feature selection. This paper explores SHAP (SHapley Additive exPlanations) for feature selection with one-class classffiers on a credit card fraud dataset. We apply SHAP to select key features and evaluate One-Class Gaussian mixture models and One-Class Support Vector Machines. Statistical analysis tests show Gaussian mixture models built with SHAP-selected features perform significantly better than Gaussian mixture models built without feature selection. To the best of our knowledge, we are the first to show the benefit of SHAP-based feature selection to One-Class Gaussian mixture models. Moreover, we show that robust performance with features of the full dataset may be a prerequisite in order for SHAP feature selection to impart further gains. Our results provide novel evidence that SHAP can identify informative features for one-class classifiers.},
  keywords={Support vector machines;Additives;Statistical analysis;Machine learning;Predictive models;Feature extraction;Credit cards;One-class classifier;feature selection;imbalanced data;SHAP;Credit Card Fraud Detection},
  doi={10.1109/ICTAI59109.2023.00021},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{10190159,
  author={Beukman, Michael and Fokam, Manuel and Kruger, Marcel and Axelrod, Guy and Nasir, Muhammad and Ingram, Branden and Rosman, Benjamin and James, Steven},
  journal={IEEE Transactions on Games}, 
  title={Hierarchically Composing Level Generators for the Creation of Complex Structures}, 
  year={2024},
  volume={16},
  number={2},
  pages={459-469},
  abstract={Procedural content generation (PCG) is a growing field, with numerous applications in the video game industry and great potential to help create better games at a fraction of the cost of manual creation. However, much of the work in PCG is focused on generating relatively straightforward levels in simple games, as it is challenging to design an optimizable objective function for complex settings. This limits the applicability of PCG to more complex and modern titles, hindering its adoption in the industry. Our work aims to address this limitation by introducing a compositional level generation method that recursively composes simple low-level generators to construct large and complex creations. This approach allows for easily-optimizable objectives and the ability to design a complex structure in an interpretable way by referencing lower-level components. We empirically demonstrate that our method outperforms a noncompositional baseline by more accurately satisfying a designer's functional requirements in several tasks. Finally, we provide a qualitative showcase (in Minecraft) illustrating the large and complex, but still coherent, structures that were generated using simple base generators.},
  keywords={Games;Generators;Task analysis;Genetic algorithms;Statistics;Sociology;Search problems;Evolutionary computation;genetic algorithms;procedural content generation},
  doi={10.1109/TG.2023.3297619},
  ISSN={2475-1510},
  month={June},}@INPROCEEDINGS{10500158,
  author={Kidwell, Adam and Fillmore, Alex and Alawneh, Shadi},
  booktitle={SoutheastCon 2024}, 
  title={Efficient GPU Implementation of Genetic Algorithm to Solve the Traveling Salesman Problem}, 
  year={2024},
  volume={},
  number={},
  pages={44-49},
  abstract={The traveling salesman problem is a popular problem in computer science due to its ease of explanation but difficulty in solving. As it is an NP-hard problem, heuristic methods such as genetic algorithms are often utilized to solve it. Genetic algorithms have many similar, repetitive steps in their evaluation, leading them to benefit from parallelization. This paper presents optimizations applied to a public genetic algorithm designed to solve the traveling salesman problem implemented in CUDA for GPU parallelization. Our optimizations were able to reduce the runtime by 87% with no reduction in the result quality and to further reduce the runtime by 98% with an 18% reduction in the quality of the results when compared to the initial CUDA implementation.},
  keywords={Computer science;Runtime;Graphics processing units;Traveling salesman problems;Optimization;Genetic algorithms;CUDA;GPU;Genetic Algorithm;Traveling Salesman Probelem;Optimization},
  doi={10.1109/SoutheastCon52093.2024.10500158},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{11010350,
  author={Liu, Yuxin and Wang, Ruiyi},
  booktitle={2025 4th International Symposium on Computer Applications and Information Technology (ISCAIT)}, 
  title={Differentiable Neural Architecture Search Based on Hybrid Attention for Classification}, 
  year={2025},
  volume={},
  number={},
  pages={204-207},
  abstract={In recent years, the rapid development of deep learning has highlighted the growing challenge of high computational costs in traditional neural architecture design. This has spurred significant research interest in efficient automated neural architecture search methods, particularly the gradientbased Differentiable Architecture Search (DARTS) known for its computational efficiency. This paper presents a novel hybrid attention-enhanced differentiable neural architecture search method by integrating channel attention and spatial attention mechanisms. The proposed approach not only improves classification accuracy but also significantly reduces computational resource requirements. Experimental results demonstrate that our method achieves architecture search within 0.28 GPU-days while attaining error rates of $\mathbf{2. 5 0 \%}$ and $\mathbf{1 7. 4 1 \%}$ on CIFAR-10 and CIFAR-100 datasets respectively, outperforming both traditional neural architecture search methods and the baseline DARTS model.},
  keywords={Deep learning;Attention mechanisms;Accuracy;Error analysis;Computer architecture;Stability analysis;Neural architecture search;Computational efficiency;Information technology;Optimization;Deep Learning;Neural Architecture Search;Differentiable Architecture Search;Hybrid Attention},
  doi={10.1109/ISCAIT64916.2025.11010350},
  ISSN={},
  month={March},}@ARTICLE{10265134,
  author={Tang, Chao and Huang, Dehao and Ge, Wenqi and Liu, Weiyu and Zhang, Hong},
  journal={IEEE Robotics and Automation Letters}, 
  title={GraspGPT: Leveraging Semantic Knowledge From a Large Language Model for Task-Oriented Grasping}, 
  year={2023},
  volume={8},
  number={11},
  pages={7551-7558},
  abstract={Task-oriented grasping (TOG) refers to the problem of predicting grasps on an object that enable subsequent manipulation tasks. To model the complex relationships between objects, tasks, and grasps, existing methods incorporate semantic knowledge as priors into TOG pipelines. However, the existing semantic knowledge is typically constructed based on closed-world concept sets, restraining the generalization to novel concepts out of the pre-defined sets. To address this issue, we propose GraspGPT, a large language model (LLM) based TOG framework that leverages the open-end semantic knowledge from an LLM to achieve zero-shot generalization to novel concepts. We conduct experiments on Language Augmented TaskGrasp (LA-TaskGrasp) dataset and demonstrate that GraspGPT outperforms existing TOG methods on different held-out settings when generalizing to novel concepts out of the training set. The effectiveness of GraspGPT is further validated in real-robot experiments.},
  keywords={Task analysis;Semantics;Robots;Training;Grasping;Pipelines;Natural languages;Grasping;perception for grasping and manipulation;deep learning in grasping and manipulation},
  doi={10.1109/LRA.2023.3320012},
  ISSN={2377-3766},
  month={Nov},}@INPROCEEDINGS{10214709,
  author={Deac, George-Antoniu and Iancu, David-Traian},
  booktitle={2023 24th International Conference on Control Systems and Computer Science (CSCS)}, 
  title={Trading Strategy Hyper-parameter Optimization using Genetic Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={121-127},
  abstract={This paper presents the application of a genetic algorithm (GA) for optimizing a simple moving average convergence divergence (MACD) crossover trading strategy and an ensemble moving average convergence divergence with relative strength index (MACD-RSI) on Nvidia stock with daily data. The optimization of trading strategies is a computationally heavy task, and the genetic algorithm is a probabilistic and heuristic searching algorithm that is inspired Darwin’s theory of natural selection which is typically used for hyperparameter tuning applications. The GA is used to identify the best set of parameters for the MACD and MACD-RSI strategies, which are widely used technical indicators in the field of trading. The paper provides a detailed explanation of the GA design, indicators, metrics, general architecture, experiments and results.},
  keywords={Measurement;Profitability;Sociology;Probabilistic logic;Task analysis;Statistics;Optimization;genetic algorithm;hyper-parameters;optimization;trading;strategy},
  doi={10.1109/CSCS59211.2023.00028},
  ISSN={2379-0482},
  month={May},}@INPROCEEDINGS{10345912,
  author={Feleki, Anna and Apostolopoulos, Ioannis D. and Papageorgiou, Elpiniki and Moustakidis, Serafeim and Papathanasiou, Nikolaos D. and Apostolopoulos, Dimitris J. and Kokkinos, Konstantinos and Papandrianos, Nikolaos},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Deep Fuzzy Cognitive Map methodology for Non-Small Cell Lung Cancer diagnosis based on Positron Emission Tomography imaging}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Non-Small Cell Lung Cancer (NSCLC) constitutes the major cause of cancer deaths worldwide in both men and women, accounting for approximately 85% of the total lung cancers. Early characterization of Solitary Pulmonary Nodules (SPNs) enables early treatment and can increase the survival rate. The present study focuses on classifying 2D SPN representations from a PET/CT scanner into two possible classes, namely benign and malignant SPN s. In this regard, 2D images were acquired from the scanner, where the SPN is alienated. Also, the SUVmax and SPN diameter data were included. A pre-trained RBG convolutional neural network processed the images to predict the class of each instance. The predictions were handled by a Fuzzy Cognitive Map with Particle Swarm Optimization in combination with the SUVmax and SPN diameter to provide a final decision. The proposed model, DeepFCM, has been evaluated with robust metrics like accuracy, loss, sensitivity, specificity, and precision and extracted 94.71±2.99, 0.05, 92.06, 96.98, 91.91, accordingly. DeepFCM provides explainability and transparency by modeling a complex system in concepts and providing the importance of each feature.},
  keywords={Nuclear medicine;Sensitivity;Fuzzy cognitive maps;Lung cancer;Lung;Imaging;Mathematical models;Fuzzy Cognitive Maps;Particle Swarm Optimization;Classification;Non-Small Cell Lung Cancer},
  doi={10.1109/IISA59645.2023.10345912},
  ISSN={},
  month={July},}@INPROCEEDINGS{10544671,
  author={Asha, V and Mathew, Jincy C and Tressa, Neethu and Kumbhar, Omkar S and R, Prakash and P, Chaithanya},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Kidney Stone Detection using Amalgam of ML}, 
  year={2024},
  volume={},
  number={},
  pages={340-345},
  abstract={The prevalence of kidney stones, or urolithiasis, has surged globally over the years, impacting individuals' quality of life due to the potential for painful urination if left untreated. Leveraging the intrinsic advantages of machine learning (ML), such as automated learning, handling multidimensional data, and continuous refinement, has gained significant attention in addressing this issue. Previous research efforts have employed various ML techniques to enhance the prediction of kidney stone occurrence. However, there remains a need to augment accuracy in prediction models. To address this gap, we propose the utilization of Enhanced Modified Binary Particle Swarm Optimization (MBPSO) for feature selection, with the goal of improving accuracy. In the proposed system, Enhanced Modified XGBoost (eXtreme Gradient Boosting) is employed to predict the severity of kidney stone cases, incorporating customized loss functions to enhance interpretability and refine model accuracy. Internal evaluations demonstrate superior predictive performance of the proposed system compared to Decision Tree (DT) and Naïve Bayes (NB) methods in forecasting kidney stone severity.},
  keywords={Machine learning algorithms;Calcium;Predictive models;Feature extraction;Prediction algorithms;Real-time systems;Classification algorithms;Kidney Stones;Urolithiasis;EXtreme Gradient Boosting;Particle Swarm Optimization;And Machine Learning},
  doi={10.1109/ICICT60155.2024.10544671},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10366966,
  author={Zhang, Yang and Jing, Ruxue and Zhang, Xia and Hu, Ruifeng and Wang, Na and Li, Liyun and Kang, Yaokun},
  booktitle={2023 2nd International Conference on Smart Grids and Energy Systems (SGES)}, 
  title={A study on Short-Term Electricity Load Forecasting for Industrial Parks method using QPSO-TCN Based on Autoencoder}, 
  year={2023},
  volume={},
  number={},
  pages={180-187},
  abstract={With the development of power grid big data and industrial automation, the number of nonlinear factors influencing load fluctuations is increasing, complicating accurate prediction. This paper addresses predicting short-term electricity load in industrial parks using a Temporal Convolutional Network (TCN) model. In the training phase, Quantum Particle Swarm Optimization (QPSO) tunes hyperparameters to improve accuracy. In quantum space, particles search globally, optimizing predictions. For data preprocessing, artificial features like date and weather that influence fluctuations are incorporated. Additionally, AutoEncoder and Principal Component Analysis (PCA) are used to extract load data features. Finally, feature engineering methods are used to select highly correlated inputs, enhancing model learning and interpretability. Simulation results confirm the proposed method significantly improves prediction accuracy compared to traditional industrial park short-term forecasting methods.},
  keywords={Training;Fluctuations;Load forecasting;Predictive models;Feature extraction;Prediction algorithms;Data mining;Short-term Load Forecasting for Industrial Parks;Temporal Convolutional Network;Quantum Particle Swarm Optimization;AutoEncoder},
  doi={10.1109/SGES59720.2023.10366966},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10393720,
  author={Kumari, Roshani and Dubey, Deepam},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Design of Practical Photogrammetry Technique for Unmanned Aerial Vehicle Application}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Photogrammetry is the field that combines the application of UAVs with image processing. UAVs have been applied in various fields of image processing to extract the desired information. UAV architecture, their methodology, the prospects and limitations of its battery, efficiency of the task curated. There are various applications of UAVs and their use in image processing based on photogrammetry. The paper discusses the concept of contour detection, with an emphasis on knowledge about image and image processing techniques for contour detection. The contour detection method is achieved by using OpenCV, then coded with Python to find the area of the largest contour detected. The parameter of the OpenCV function is varied and the changes are observed. The results of different stock images were observed by varying different parameters of the Python function for contour detection and area calculation in terms of the execution time and the area calculated in terms of pixels and then converted into cm2. The derivative approach of the simple algorithm using CHAIN_APPROX_NONE. in terms of contour detection was shown to have better results than the other two algorithms used for detecting the number of contours and drawing it. Still, the contour drawn was not that visible while that of Finding contour using Gaussian blur and binary thresholding was not able to detect every contour of the object in the image but was able to draw it precisely. Hence incorporating this method in photogrammetry has its cause and effects on its battery life and efficiency.},
  keywords={Machine learning algorithms;Thresholding (Imaging);Image recognition;Image processing;Machine learning;Autonomous aerial vehicles;Feature extraction;UAVs;Image Processing;Photogrammetry},
  doi={10.1109/EASCT59475.2023.10393720},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10345881,
  author={Papadimitriou, Spyros and Chrysafiadi, Konstantina and Virvou, Maria},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Adaptive Quizzes Using Fuzzy Genetic Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The quizzes allow the tutor to assess the student's knowledge level briefly. However, creating a quiz is a challenging task that requires time and effort. If the tutor wants to create multiple quizzes tailored to the student's needs, the time needed to construct them increases dramatically. Furthermore, a large pool of questions and activities makes creating personalised quizzes more complex. A solution to the above is employing genetic algorithms to quickly and automatically produce personalised quizzes and tests. However, a genetic algorithm uses complex mathematical forms, which tutors of various knowledge domains find difficult to understand. Given this, the paper presents a genetic algorithm that embeds a fuzzy rule-based mechanism in the fitness calculation phase to select the most appropriate questions for each learner and create personalised quizzes more realistically. The presented algorithm aims to describe with linguistic terms the appropriateness of each question rather than obscure mathematics forms. In such a way, estimating the suitability of a quiz question is closer to the human way of thinking and becomes more explainable to tutors. The presented fuzzy genetic algorithm has been performed for creating quizzes for learners of the programming language HTML. The algorithm accepts a pool of questions and the learner's characteristics and needs. It gives as output a report, which includes the questions sorted by their suitability and a recommended quiz that best fits the learner's needs.},
  keywords={Fuzzy logic;Computer languages;Games;Linguistics;Control systems;Software;Mathematics;genetic algorithms;fuzzy logic;adaptive quizzes},
  doi={10.1109/IISA59645.2023.10345881},
  ISSN={},
  month={July},}@INPROCEEDINGS{10028967,
  author={Partheeban, Pachaivannan and Shiva, M. and Vishnupriyan, J and Ponnusamy, R. and Kumar, T. Sathish and Anuradha, Baskaran},
  booktitle={2022 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Solar Energy Optimisation Using IoT and Deep Learning- A Review}, 
  year={2022},
  volume={01},
  number={},
  pages={1-3},
  abstract={Energy is utilized in a different form across the globe, which includes electrical and mechanical energy. To increase the efficiency of renewable energy, which comes from a variety of sources, several researchers have tried. This research focuses on the internet of things (IoT), which develops a system that combines several sensors and IoT to produce power for business and home appliances. The power-generating circuit will link a solar panel, a humidity sensor, a temperature sensor, an air quality sensor, a photo resistance sensor, and a body heat sensor. The overall quantity of energy generated from renewable resources up until the projected fusion is calculated using AI models. These approaches are limited and only focus on data analysis. This study proposes a perfect energy forecasting architecture that blends IoT technologies and deep learning principles. Because of the quantity of renewable energy data, the Deep Learning layer is employed to predict renewable energy. A distributed LSTM method is frequently utilized by researchers and tested with various models to demonstrate predictability and execution time improvement.},
  keywords={Temperature sensors;Deep learning;Renewable energy sources;Wind speed;Solar energy;Humidity;Predictive models;Stand-alone;IoT;Machine Learning;Performance Analysis;Energy},
  doi={10.1109/ICDSAAI55433.2022.10028967},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10563975,
  author={Li, Low Jun and Junn, Kuan Yik},
  booktitle={2023 IEEE 21st Student Conference on Research and Development (SCOReD)}, 
  title={Decision Tree with Genetic Algorithm for Bank Customer Churn Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={426-431},
  abstract={Customer churn in the banking industry can negatively impact a company’s revenue and profitability. Hence, accurately predicting customer churn holds significant importance for banks, as it enables them to proactively implement preventive measures to retain valuable customers. Decision tree (DT) is a supervised machine learning model that can be used for classification tasks, but the traditional DT algorithm is greedy and can produce suboptimal tree. Although the use of ensemble techniques can enhance performance, it often sacrifices model interpretability. To address these issues, this research paper proposes combining DT with genetic algorithm (GA), referred to as the DT-GA model, for predicting bank customer churn. The proposed model is trained on a bank customer churn dataset from Kaggle and successfully demonstrates improvements over the baseline DT model built using the scikit-learn library, scoring higher accuracy, precision, recall, F1 score, balanced accuracy, and ROC AUC. Additionally, DT-GA model also has decent performance compared to other machine learning models in existing literature, affirming its potential for effective customer churn prediction in the banking sector.},
  keywords={Industries;Accuracy;Refining;Machine learning;Banking;Predictive models;Decision trees;Customer Churn;Genetic Algorithm;Decision Tree;Classification},
  doi={10.1109/SCOReD60679.2023.10563975},
  ISSN={2643-2447},
  month={Dec},}@INPROCEEDINGS{9834205,
  author={Huang, Jingcao and Guo, Bin and Dian, Songyi and Li, Xiaoying and Lai, Wuxing},
  booktitle={2022 7th International Conference on Automation, Control and Robotics Engineering (CACRE)}, 
  title={Fault diagnosis of hydropower generator based on LSTM- weight}, 
  year={2022},
  volume={},
  number={},
  pages={369-373},
  abstract={Traditional detection models are not sensitive to small abnormal changes. In order to improve the sensitivity of the model, in this study, the weight factor is introduced into the traditional LSTM detection model. By using the correction mechanism, the LSTM-weight model makes the prediction model not deviate from the normal track following the appearance of outliers, which ensures the model prediction has good stability. And after a small change in the data, the LSTM-weight model can detect this small change. Validated on a Brazilian hydropower dataset, the results show that the LSTM-weight model can detect small changes that the traditional detection model cannot detect, which shows the effectiveness of the proposed method.},
  keywords={Sensitivity;Time series analysis;Hydroelectric power generation;Predictive models;Robot sensing systems;Reliability engineering;Data models;Anomaly detection;LSTM;weights},
  doi={10.1109/CACRE54574.2022.9834205},
  ISSN={},
  month={July},}@INPROCEEDINGS{9936507,
  author={Wang, Chengwen},
  booktitle={2022 International Conference on Edge Computing and Applications (ICECAA)}, 
  title={A New Paradigm of Computer Art Design based on Fusion of Light Collection Sensors and Smart Image Detection Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={966-969},
  abstract={The use of image recognition technology can complete tasks that cannot be achieved by traditional sensor technology, and at the same time, with the help of image recognition and multi-source information fusion, the monitoring effect can be better and more accurate. With the continuous development of computer technology. Based on the principle of sparse representation, integrating cutting-edge computer technology into art design can simplify the difficulty of art design work. This article takes Photoshop technology as an example to illustrate the teaching research of Photoshop in art design work. Select the M nearest neighbors of the test sample to replace the original training sample; weighted decision fusion. The experimental results on the CSIST face database show that, compared with similar algorithms, the proposed algorithm improves the recognition rate and calculation speed.},
  keywords={Training;Temperature sensors;Art;Image recognition;Databases;Face recognition;Production;New Paradigm;Computer Art Design;Light Collection Sensors;mart Image Detection Algorithms},
  doi={10.1109/ICECAA55415.2022.9936507},
  ISSN={},
  month={Oct},}@ARTICLE{10946153,
  author={Singh, Sanabam Bineshwor and Laishram, Anuradha and Thongam, Khelchandra and Manglem Singh, Khumanthem},
  journal={IEEE Access}, 
  title={Automatic Detection and Classification of Dental Anomalies and Tooth Types Using Transformer-Based Yolo With GA Optimization}, 
  year={2025},
  volume={13},
  number={},
  pages={59326-59338},
  abstract={Dental pathology detection and tooth type categorization are crucial yet often error-prone and time-consuming tasks in dental diagnostics. This paper presents a novel approach using Transformer-Based You Only Look Once (YOLO) for automating dental pathology detection and tooth type categorization from panoramic X-ray images. Manual dental examinations are error-prone and time consuming. Therefore automated systems are required. Preprocessing techniques such as image resizing, rotation, Gaussian smoothing, and histogram scaling are used to enhance image quality and analysis. A significant enhancement is the integration of a multi-head self-attention block into the Cross Stage Partial Darknet (CSPDarknet) backbone within the YOLOv4 architecture. This addition enabled the model to capture comprehensive contextual information and learn distinct feature representations from the dental images. Inspired by Transformer models, the multi-head self-attention mechanism improves the capacity of the model to intricate spatial relationships in images, enhancing detection and classification performance. In addition, the system employs Genetic Algorithm (GA) optimization for hyperparameter tuning, which fine-tunes model parameters to maximize performance metrics and enhance accuracy and robustness in dental diagnostics. The system achieved an average precision, recall rate of 99.5% and F1 score of 99.41% and a detection and classification accuracy of 99.31%. These results highlight the effectiveness of advanced preprocessing, deep learning enhancements, and GA optimization for precise dental pathology detection and tooth type categorization using panoramic radiography.},
  keywords={Dentistry;Teeth;Accuracy;Deep learning;Solid modeling;Feature extraction;Training;Three-dimensional displays;Genetic algorithms;Annotations;CSP-Darknet;image preprocessing;multi-head self-attention;panoramic X-ray;Transformer-based YOLO},
  doi={10.1109/ACCESS.2025.3556523},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10455847,
  author={Wei, Zhihu and Gao, Han and Wang, Gang},
  booktitle={2023 5th International Conference on Frontiers Technology of Information and Computer (ICFTIC)}, 
  title={Water level detection based on ghost convolution and CA attention mechanism}, 
  year={2023},
  volume={},
  number={},
  pages={278-282},
  abstract={Water level monitoring is the key issue of water conservancy construction, timely grasp of water conditions, flood prevention is important for social development, for this reason we propose an intelligent image water level recognition algorithm: the introduction of ghost convolutional backbone network optimization, adding GA attention mechanism of yolov5's deep learning water level recognition algorithm, the training of the collected images, to achieve the automatic identification of water level. Experimental results show that the improved yolov5 deep learning water level recognition algorithm can effectively is to recognize the water level, the mAP value reaches 97.6%, compared with the unimproved version to improve 5.2%, in line with the engineering water level monitoring error requirements.},
  keywords={YOLO;Deep learning;Training;Image recognition;Convolution;Water conservation;Detection algorithms;ghost convolution;CA attention;YOLOv5},
  doi={10.1109/ICFTIC59930.2023.10455847},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10941445,
  author={Velvizhy, P. and S, Dhinakaran V and M, Praveen V and G, Naveen},
  booktitle={2024 International Conference on Integration of Emerging Technologies for the Digital World (ICIETDW)}, 
  title={Sparse Attention Mechanism And Ensemble Strategies On Transformers [Sam-Est] for Detection Of Offensive Comments in Tamil}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The necessity to develop algorithms that can rapidly recognize and distinguish between offensive and inoffensive comments brings to light the need of identifying offensive comments in Tamil. It is possible to lessen the harmful impacts of online hate speech, such as trolling, cyberbullying, and social and political polarization, by identifying and removing poisonous comments while promoting constructive online discourse. It draws attention to the negative impacts of offensive words on individuals and organizations, including psychological trauma, rifts in society, and even physical violence. The advancement of online dialogue as a whole and the defense of democratic values require the creation of effective models for the detection of hostile remarks.},
  keywords={Attention mechanisms;Hate speech;Psychology;Cyberbullying;Organizations;Transformers;Genetic algorithms;mBERT;CNN;MuRIL;RoBERTa;LSH;NLP;BART;mGPT;Genetic Algorithm},
  doi={10.1109/ICIETDW61607.2024.10941445},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10340375,
  author={Ellis, Charles A. and Miller, Robyn L. and Calhoun, Vince D.},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={A Convolutional Autoencoder-based Explainable Clustering Approach for Resting-State EEG Analysis*}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Machine learning methods have frequently been applied to electroencephalography (EEG) data. However, while supervised EEG classification is well-developed, relatively few studies have clustered EEG, which is problematic given the potential for clustering EEG to identify novel subtypes or patterns of dynamics that could improve our understanding of neuropsychiatric disorders. There are established methods for clustering EEG using manually extracted features that reduce the richness of the feature space for clustering, but only a couple studies have sought to use deep learning-based approaches with automated feature learning to cluster EEG. Those studies involve separately training an autoencoder and then performing clustering on the extracted features, and the separation of those steps can lead to poor quality clustering. In this study, we propose an explainable convolutional autoencoder-based approach that combines model training with clustering to yield high quality clusters. We apply the approach within the context of schizophrenia (SZ), identifying 8 EEG states characterized by varying levels of δ activity. We also find that individuals who spend more time outside of the dominant state tend to have increased negative symptom severity. Our approach represents a significant step forward for clustering resting-state EEG data and has the potential to lead to novel findings across a variety of neurological and neuropsychological disorders in future years.},
  keywords={Training;Representation learning;Neurological diseases;Electric potential;Mental disorders;Feature extraction;Brain modeling},
  doi={10.1109/EMBC40787.2023.10340375},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{10753556,
  author={Schwachhofer, Denis and Domanski, Peter and Becker, Steffen and Wagner, Stefan and Sauer, Matthias and Pflüger, Dirk and Polian, Ilia},
  booktitle={2024 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)}, 
  title={Large Language Model-Based Optimization for System-Level Test Program Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={System-Level Test (SLT) is essential for testing integrated circuits, focusing on functional and non-functional properties of the Device under Test (DUT). Traditionally, test engineers manually create tests with commercial software to simulate the DUT's end-user environment. This process is both time-consuming and offers limited control over non-functional properties. This paper proposes Large Language Models (LLMs) enhanced by Structural Chain of Thought (SCoT) prompting, a temperature schedule, and a pool of previously generated snippets to generate high-quality code snippets for SLT. We repeatedly query the LLM for a better snippet using previously generated snippets as examples, thus creating an iterative optimization loop. This approach can automatically generate snippets for SLT that target specific non-functional properties, reducing time and effort. Our findings show that this approach improves the quality of the generated snippets compared to unstructured prompts containing only a task description.},
  keywords={Measurement;Schedules;Codes;Temperature;Process control;Very large scale integration;Software;Optimization;Nanotechnology;Testing;Large Language Models;Test Generation;System-Level Test;Optimization;Functional Test},
  doi={10.1109/DFT63277.2024.10753556},
  ISSN={2765-933X},
  month={Oct},}@INPROCEEDINGS{10685205,
  author={Sun, Jiyuan and Yu, Haibo and Zhao, Jianjun},
  booktitle={2024 IEEE International Conference on Artificial Intelligence Testing (AITest)}, 
  title={Black-box l1 and £2 Adversarial Attack Based on Genetic Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={101-108},
  abstract={It has been shown that multimodal text-vision large language models (LLMs) are vulnerable to visual adversarial examples. An adversarial example is a delicately perturbed input intended to cause deep neural networks to behave incorrectly. Currently, adversarial attacks can be categorized into two types based on the knowledge required to perform an attack: black box and white box. Most existing black-box attacks only try to generate adversarial examples within a given $\ell_{2}$ or $\ell_{\infty}$ pertur-bation budget. We propose a novel black-box attack to address this research gap to generate $\ell_{1}, \ell_{2}$ adversarial examples with minimal perturbation. To this end, our attack solves a constrained optimization problem by converting it to an unconstrained one and then finds its solution using the genetic algorithm. Extensive experiments on three test benches have been conducted to evaluate its performance. To facilitate reproducing the results presented in this work, we make the code for the experiments publicly available at https://github.com/sjysjy1/MPBA.},
  keywords={Visualization;Codes;Perturbation methods;Large language models;Closed box;Artificial neural networks;Optimization;Adversarial attack;adversarial example;black-box attack;attack success rate;genetic algorithm;large language model},
  doi={10.1109/AITest62860.2024.00021},
  ISSN={2835-3560},
  month={July},}@INPROCEEDINGS{10263180,
  author={Golubovic, Sanja and Jovanovic, Luka and Radomirovic, Branislav and Njegus, Angelina and Zivkovic, Miodrag and Bacanin, Nebojsa},
  booktitle={2023 IEEE International Conference on Contemporary Computing and Communications (InC4)}, 
  title={Evolving Deep Neural Network Architectures by Sine Cosine Algorithm for Healthcare 4.0}, 
  year={2023},
  volume={1},
  number={},
  pages={1-6},
  abstract={Prevention, early diagnostics, and timely treatment have become essential in improving patient outcomes in the area of healthcare. Furthermore, a relatively new concept, healthcare 4.0, makes use of emerging technologies to improve the overall healthcare system efficiency. However, by exploring available literature, it was noticed that the potential of deep neural networks (DNNs) has not been investigated enough in this area. For early diagnostics and timely appropriate treatment, DNNs are tasked with drawing conclusions from provided data and detecting outcomes. Despite many advantages, the DNNs need to be tuned for each particular challenge. This non-deterministic polynomial hard (NP-hard) problem is known in the literature as hyperparameters optimization. Since the metaheuristics algorithm proved to be very efficient in addressing such tasks, research conducted for the purpose of this manuscript introduces an improved variation of the sine cosine algorithm (SCA). The proposed method is used to evolve DNNs architectures and it was validated against three real-world medical datasets, including two datasets covering heart disease and one concerning liver problems. The proposed method is compared to several other contemporary metaheuristics and achieved results revealed that the introduced approach has great potential when applied in healthcare, outperforming competing algorithms in terms of classification metrics.},
  keywords={Heart;Measurement;NP-hard problem;Metaheuristics;Medical services;Artificial neural networks;Classification algorithms},
  doi={10.1109/InC457730.2023.10263180},
  ISSN={},
  month={April},}@INPROCEEDINGS{10314086,
  author={Zheng, Yuyu},
  booktitle={2023 5th International Conference on Decision Science & Management (ICDSM)}, 
  title={Simulation Research on Real Estate Financial Data Analysis Based on Improved Genetic Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={117-121},
  abstract={With the advent of the information age, in order to get the information we need, people have higher and higher requirements for data processing in all aspects. The unique correlation between data can better help us analyze and make judgments so as to take appropriate actions. The fluctuation of real estate price has a wide impact on the real economy by changing the behavior of economic subjects. Specifically, the fluctuation of real estate has an impact on investment and residents' consumption behavior through the financial accelerator mechanism, and then affects the balance between total social demand and total supply. Based on this, on the basis of explaining the mechanism of economic financialization on real estate prices, this paper empirically studies the impact of economic financialization on real estate prices by combining the spatial panel data of 31 provinces in China. The single artificial neural network model (BPNN), principal component analysis and neural network combination model (PCA-BPNN), genetic algorithm and neural network combination model (GA-BPNN) and the improved genetic algorithm and neural network combination model (IGA-BPNN) in this paper were used for experiments. The results show that the proposed method can effectively reduce the number of variables while ensuring basically the same prediction accuracy.},
  keywords={Analytical models;Fluctuations;Economic indicators;Market research;Information age;Spatial databases;Behavioral sciences;component;Improved genetic algorithm;Real estate;Financial data},
  doi={10.1109/ICDSM59373.2023.00033},
  ISSN={},
  month={March},}@ARTICLE{10882975,
  author={Ebrahimi, Mehrdad and Rastegar, Mohammad and Karami, Kiana},
  journal={IEEE Transactions on Industry Applications}, 
  title={Optimal Placement of Manual and Automatic Switches in Power Distribution Systems Using a Machine Learning Proxy}, 
  year={2025},
  volume={61},
  number={3},
  pages={5015-5025},
  abstract={Fault management involves actions to restore interrupted customers as quickly as possible after a fault occurrence, which is facilitated by optimal switch placement. However, the switch optimization problem requires significant computational effort because of the nonlinearity and the large search space. Hence, the problem may be interactable for large-scale power distribution systems. This paper proposes a machine learning-based proxy to determine the optimal number and location of switches in real-world power distribution systems, including manual and automatic switches. The objective function comprises equipment costs and reliability indices, including the system average interruption frequency index (SAIFI), the system average interruption duration index (SAIDI), and the energy not supplied (ENS) index. The proposed model is a stacked ensemble model, in which convolutional neural network (CNN)-based models serve as base learners to capture complex and spatial information from their input data. The input data for the base learners are optimally selected by explainable artificial intelligence (XAI) tools from a large feature set of candidate installation points. The metamodel combines the base learners' predictions to determine the optimal points for installing switches and is a fully connected artificial neural network. This paper uses the Bayesian optimization algorithm to optimally construct the stacked ensemble model. We validate the proposed model alongside state-of-the-art learning-based and mathematics-based models using a real power distribution system. The simulation results demonstrate that the proposed model outperforms the state-of-the-art models in terms of computational complexity and optimality.},
  keywords={Power distribution;Optimization;Computational modeling;Mathematical models;Costs;Reliability;Indexes;Linear programming;Metaheuristics;Training;Distribution system;machine learning;reliability;switch optimization},
  doi={10.1109/TIA.2025.3540813},
  ISSN={1939-9367},
  month={May},}@ARTICLE{10504544,
  author={Wang, Pengda and Lu, Mingjie and Yan, Weiqing and Yang, Dong and Liu, Zhaowei},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Graph Structure Learning With Automatic Search of Hyperparameters Based on Genetic Programming}, 
  year={2024},
  volume={8},
  number={6},
  pages={4155-4164},
  abstract={Graph neural networks (GNNs) rely heavily on graph structures and artificial hyperparameters, which may increase computation and affect performance. Most GNNs use original graphs, but the original graph data has problems with noise and incomplete information, which easily leads to poor GNN performance. For this kind of problem, recent graph structure learning methods consider how to generate graph structures containing label information. The settings of some hyperparameters will also affect the expression of the GNN model. This paper proposes a genetic graph structure learning method (Genetic-GSL). Different from the existing graph structure learning methods, this paper not only optimizes the graph structure but also the hyperparameters. Specifically, different graph structures and different hyperparameters are used as parents; the offspring are cross-mutated through the parents; and then excellent offspring are selected through evaluation to achieve dynamic fitting of the graph structure and hyperparameters. Experiments show that, compared with other methods, Genetic-GSL basically improves the performance of node classification tasks by 1.2%. With the increase in evolution algebra, Genetic-GSL has good performance on node classification tasks and resistance to adversarial attacks.},
  keywords={Graph neural networks;Statistics;Sociology;Genetic algorithms;Noise measurement;Optimization;Hyperparameter optimization;Graphical models;Graph neural networks;hyperparameters optimization;graph structure learning;genetic model},
  doi={10.1109/TETCI.2024.3386833},
  ISSN={2471-285X},
  month={Dec},}@INPROCEEDINGS{11033362,
  author={Lin, Shenghao and Chen, Fansong and Xi, Laile and Xie, Kaiyu and Zheng, Yaowen and Fei, Haiqiang and Sun, Yuyan and Zhu, Hongsong},
  booktitle={2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={ScenarioFuzz-LLM: Enhancing Diversity in Autonomous Driving Scenario Fuzzing with LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={1581-1586},
  abstract={As Autonomous Driving Systems (ADS) are increasingly deployed, ensuring their safety in edge cases becomes critical to preventing catastrophic failures. However, the limited ADS test scenario diversity often hinders the discovery of new defects, especially in complex and rare situations. This paper presents ScenarioFuzz- Llm,a novel method that leverages Large Language Models (LLMs) to enhance the diversity of ADS test scenarios. By incorporating LLMs into a genetic algorithm-based testing framework, ScenarioFuzz- Llmdirects the mutation to address diversity bottlenecks, thereby enabling the exploration of a broader range of edge cases. Our experiments demonstrate that ScenarioFuzz- Llmenhances the number of violation sce-narios by 10.51 % outperforming the state-of-the-art methods, and uncovers 24 unique defects in ADS, three of which are previously undiscovered. These results highlight the superiority of our approach in enhancing ADS testing through more diverse and comprehensive simulation scenarios, ultimately improving the safety of ADS.},
  keywords={Federated learning;Large language models;Simulation;Fuzzing;Safety;Scenario generation;Prompt engineering;Autonomous vehicles;Testing;Genetic algorithms;Automated Driving System;Search Base Testing;Testing Scenario Generation;Large Language Model;Prompt Engineering},
  doi={10.1109/CSCWD64889.2025.11033362},
  ISSN={2768-1904},
  month={May},}@INPROCEEDINGS{10511685,
  author={Singh, Smriti and Ashai, Aasim and Mukherjee, Ankita and Pramanik, Tanmoy and Sarkar, Biplab},
  booktitle={2024 8th IEEE Electron Devices Technology & Manufacturing Conference (EDTM)}, 
  title={An Interpretable Symbolic Regression Model for Prediction of GaN Vertical Power MOSFET Failsafe Boundaries}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={In this work, a symbolic regression (SR) model has been developed to predict the GaN Fin-MOSFET channel potential profile, particularly at the blocking modes. This model precisely predicts the source-drain barrier which is a pivotal aspect of failsafe device operation. The SR model explains the dependency of different input parameters on the output response of interest. This work is first to report an interpretable approach for quantifying the device design of GaN vertical power transistors for a robust circuit design.},
  keywords={Semiconductor device modeling;MOSFET;Computational modeling;Voltage;Logic gates;Predictive models;Power transistors;GaN;Vertical transistors;Potential barrier;Genetic algorithms;Symbolic regression},
  doi={10.1109/EDTM58488.2024.10511685},
  ISSN={},
  month={March},}@INPROCEEDINGS{10956247,
  author={Gonsalis, Sting Salvador and Math, Sannidhi D. and Naidu, Kaushik and S, Rohith Narayan H and Dang, Anadya and Rajendra, Varma Nakul and Vincent, Shweta and Kumar, Om Prakash and Mohan, Vijay},
  booktitle={2024 Third International Conference on Artificial Intelligence, Computational Electronics and Communication System (AICECS)}, 
  title={Soft Computing and Machine Learning Approaches for Mapping in an Indian Coastal City for Flood Vulnerability}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Flood susceptibility mapping is vital in mitigating flood risks and managing disaster preparedness. This research article proposes a hybrid machine learning model that combines Support Vector Machines (SVM) with Genetic Algorithm (GA) metaheuristic algorithm for making of a Flood Susceptibility Map (FSM) for Chennai city. The objective is to enhance the performance of machine learning in predicting flood-prone areas. Future research directions are suggested, and an analysis is done on the use of such machine learning models in mapping and assessing flood risk. Based on fifteen Flood Conditioning Factors (FCFs), the flood susceptibility model was built. The data from the flood inventory is then split into two categories: 70% is used to train the model and 30% is used to validate it. The accuracy of the generated model is obtained as 80%.},
  keywords={Support vector machines;Computational modeling;Disasters;Urban areas;Metaheuristics;Sea measurements;Machine learning;Floods;Genetic algorithms;Resilience;Flood Susceptibility Mapping (FSM);Support Vector Machine (SVM);Flood Inventory Map (FIM)},
  doi={10.1109/AICECS63354.2024.10956247},
  ISSN={},
  month={Dec},}@ARTICLE{11079987,
  author={Li, Jian and Kang, Junrui and Qi, Ji and Lu, Jian and Fu, Hongkun and Liu, Baoqi and Lin, Xinglei and Zhao, Jiawei and Guan, Hengxu and Chang, Jing and Liu, Zhihan},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Soybean Yield Estimation Using Improved Deep Learning Models with Integrated Multi-Source and Multi-Temporal Remote Sensing Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-32},
  abstract={Accurate soybean yield estimation is critically imperative for modern agricultural systems amidst escalating global food security pressures, yet conventional methodologies are constrained for large-scale, high-frequency monitoring. To address this, an innovative deep learning framework, TransBiHGRU-PSO, is proposed for precise large-scale soybean yield estimation via effective fusion of multi-source, multitemporal remote sensing data, emphasizing robust and accurate estimation even with anomalous yield data. This framework synergistically integrates an optimized Bidirectional Hierarchical Gated Recurrent Unit (BiHGRU), a Transformer encoder, and a novel Greenness and Water Content Composite Index (GWCCI), with critical parameters optimized by Particle Swarm Optimization (PSO). County-level yield data from 12 U.S. states were used, supplemented by multi-temporal remote sensing datasets (MODIS surface reflectance, vegetation indices, environmental variables). Empirical analyses showed TransBiHGRU-PSO demonstrated improved estimation capability and generalizability compared to multiple benchmark models. Notably, with anomalous yield data retained, the model achieved solid test set performance (coefficient of determination (R²) of 0.71, root mean square error (RMSE) of 4.2812 bushels/acre). Compared to the best traditional machine learning model (SVR), R² increased by 52.96% and RMSE decreased by 26.05%; and relative to the best deep learning baseline model (LSTM), R² and RMSE improved by 7.04% and 7.04%, respectively. Furthermore, validation of interannual stability (2008–2018, anomalies retained) revealed a mean R² of 0.70 and mean RMSE of 4.4701 bushels/acre, affirming its consistency under complex real-world conditions. This TransBiHGRU-PSO algorithmic framework, combined with multi-source and multitemporal remote sensing data, offers a valuable exploration for large-scale soybean yield estimation.},
  keywords={Yield estimation;Remote sensing;Data models;Monitoring;Biological system modeling;Vegetation mapping;Accuracy;Deep learning;Transformers;Soil;Deep learning(DL);Yield estimation;GWCCI;Multi-source remote sensing data},
  doi={10.1109/JSTARS.2025.3588917},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{10907751,
  author={Hickling, Thomas and Aouf, Nabil},
  booktitle={2024 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={Real-Time Detection of White and Black Box Adversarial Attacks on Deep Reinforcement Learning UAV Guidance}, 
  year={2024},
  volume={},
  number={},
  pages={420-425},
  abstract={This paper explores the vulnerability of Deep Reinforcement Learning (DRL) models used in Uncrewed Aerial Vehicles (UAVs) to adversarial attacks. It evaluates popular white and black box attacks, including Fast Gradient Sign Method (FGSM), Carlini & Wagner (C&W), Projected Gradi-ent Descent (PGD), Zeroth-Order-Optimisation (ZOO), Zeroth-Order-Optimisation-Adam (ZOO-Adam), and Genetic Attack (GA). The study assesses attack success and real-time attack capabilities, crucial for UAV operations. It highlights the need for robust defenses and proposes an adversarial detector using an Auto-encoder and compares it with an LSTM detector. The paper emphasizes the importance of addressing adversarial threats and proposes mitigation methods.},
  keywords={Prevention and mitigation;Detectors;Autonomous aerial vehicles;Deep reinforcement learning;Genetics;Real-time systems;Vectors;Long short term memory;Robots;Genetic algorithms},
  doi={10.1109/ROBIO64047.2024.10907751},
  ISSN={2994-3574},
  month={Dec},}@INPROCEEDINGS{10584130,
  author={Taveekitworachai, Pittawat and Abdullah, Febri and Gursesli, Mustafa Can and Lanata, Antonio and Guazzini, Andrea and Thawonmas, Ruck},
  booktitle={2024 IEEE International Workshop on Metrology for Industry 4.0 & IoT (MetroInd4.0 & IoT)}, 
  title={Prompt Evolution Through Examples for Large Language Models–A Case Study in Game Comment Toxicity Classification}, 
  year={2024},
  volume={},
  number={},
  pages={22-27},
  abstract={This paper presents a novel approach for automatic prompt optimization (APO) using a large language model (LLM) as an optimizer, named Prompt Evolution Through Examples (PETE). The approach draws inspiration from evolutionary computation for the prompt evolution stages. We aim to aid in developing prompts for use in systems classifying toxic content including game community moderator-assist tools. While traditional approaches are useful for developing these tools, they have various shortcomings where LLMs can potentially mitigates these issues. LLMs accept prompts as inputs to condition generated outputs. However, to design a prompt with the best performance in this task, fine-grained adjustments are usually required and should be automated through the APO process instead of a manual approach, which is often time-consuming. In this study, ChatGPT and GPT-4 are utilized as both task performers and prompt optimizers for comparisons across models. The results indicate that PETE improves the performance of the target task up to 56.14% from a performance of an initial prompt, compared to only up to 49.15% using a standard mutation evolution. Optimized prompts are provided for future utilization in other game community moderation tools. We also recommend that future studies explore more cost-effective approaches for evaluation using LLMs to enhance the benefits of APO.},
  keywords={Toxicology;Costs;Large language models;Computational modeling;Games;Manuals;Evolutionary computation;Evolutionary computation;Prompt engineering;ChatGPT;GPT-4;Errorful learning},
  doi={10.1109/MetroInd4.0IoT61288.2024.10584130},
  ISSN={2837-0872},
  month={May},}@INPROCEEDINGS{10835591,
  author={Javed, Noman and Bennett, Dmitry and Bartlett, Laura K. and Lane, Peter C. R. and Gobet, Fernand},
  booktitle={2024 IEEE 6th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Evolving Cognitive Models: A Novel Approach to Verbal Learning}, 
  year={2024},
  volume={},
  number={},
  pages={226-233},
  abstract={A common goal in cognitive science involves explaining/predicting human performance in experimental settings. This study proposes a single GEMS computational scientific discovery framework that automatically generates multiple models for verbal learning simulations. GEMS achieves this by combining simple and complex cognitive mechanisms with genetic programming. This approach evolves populations of interpretable cognitive agents, with each agent learning by chunking and incorporating long-term memory (LTM) and short-term memory (STM) stores, as well as attention and perceptual mechanisms. The models simulate two different verbal learning tasks: the first investigates the effect of prior knowledge on the learning rate of stimulus-response (S-R) pairs and the second examines how backward recall is affected by the similarity of the stimuli. The models produced by GEMS are compared to both human data and EPAM – a different verbal learning model that utilises hand-crafted task-specific strategies. The models automatically evolved by GEMS produced good fit to the human data in both studies, improving on EPAM’s measures of fit by almost a factor of three on some of the pattern recall conditions. These findings offer further support to the mechanisms proposed by chunking theory (Simon, 1974), connect them to the evolutionary approach, and make further inroads towards a Unified Theory of Cognition (Newell, 1990).},
  keywords={Computational modeling;Genetic programming;Data models;Cognition;Cognitive science;Machine intelligence;chunking;evolution;GEMS;LTM;STM;CHREST},
  doi={10.1109/CogMI62246.2024.00037},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10500182,
  author={Yihunie Alaba, Simegnew and Ball, John E.},
  booktitle={SoutheastCon 2024}, 
  title={WCAM: Wavelet Convolutional Attention Module}, 
  year={2024},
  volume={},
  number={},
  pages={854-859},
  abstract={Convolutional neural networks (CNNs) have demon-strated remarkable ability in extracting and comprehending complex features from inputs, such as images. However, the conventional CNN approach of uniformly processing the entire image may not always be efficient, as not all input regions are equally significant for prediction. This aligns with the human visual system, which naturally prioritizes specific portions of a scene over processing its entirety simultaneously. Similarly, the attention mechanism emphasizes the most crucial aspects of a feature while suppressing less significant elements. This work introduces the Wavelet Convolutional Attention Module ((WCAM), which leverages the intrinsic properties of wavelets, such as multiresolution and sparsity, to direct the CNN towards more efficient and discriminative feature extraction and learning. The lossless property of wavelets enables efficient downsam- pling while preserving the details. WCAM is a versatile and lightweight module, easily integrated into any CNN without adding computational complexity. Extensive image classification and object detection experiments have been conducted using various datasets, including CIFAR-10, CIFAR-100, ImageNet-1k, and MS COCO. The results from these experiments have validated the effectiveness of WCAM over existing convolutional attention modules. The code will be released soon.},
  keywords={Convolutional codes;Wavelet transforms;Convolution;Object detection;Computer architecture;Visual systems;Feature extraction;Attention mechanism;Convolution attention;Discrete wavelet transform;Inverse wavelet transform;Feature extraction;Object recognition},
  doi={10.1109/SoutheastCon52093.2024.10500182},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10831952,
  author={Qi, Xiaowen and Ma, Yujungrong and Nakamura, Kiminori and Bhattacharyya, Shuvra S.},
  booktitle={2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Balancing Fairness and Accuracy for Predictive Models in Criminal Justice Applications Using Multi-Objective Optimization Methods}, 
  year={2024},
  volume={},
  number={},
  pages={5056-5063},
  abstract={In the field of predictive modeling for criminal justice applications, the dual challenges of ensuring fairness and maintaining interpretability are crucial. This paper addresses these challenges by introducing a new approach to optimizing decision trees using evolutionary algorithms (EAs). Our approach focuses on refining decision trees to achieve a balance between accuracy and algorithmic fairness, a task complicated by potential bias present in historical data. By leveraging the principles of multi-objective optimization, our model systematically trades off prediction accuracy and fair-ness. The evolutionary process characterized by selection, crossover, and mutation is tailored to fit the decision tree structure, ensuring that model development is not only accurate but also promoting measurable fairness. Experimental results demonstrate the effectiveness of our approach in providing interpretable and fair predictive models that can be considered for high-stakes applications in criminal justice. More broadly, this research makes a significant contribution to the field of explainable machine learning, providing a powerful framework for engineering systems that are transparent, fair, and adaptable to different data environments.},
  keywords={Accuracy;Decision making;Semantics;Refining;Optimization methods;Evolutionary computation;Predictive models;Prediction algorithms;Spatiotemporal phenomena;Decision trees},
  doi={10.1109/SMC54092.2024.10831952},
  ISSN={},
  month={Oct},}@ARTICLE{10807354,
  author={Tanaka, Tsunehiko and Simo-Serra, Edgar},
  journal={IEEE Transactions on Games}, 
  title={Grammar-based Game Description Generation using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Game Description Language (GDL) provides a standardized way to express diverse games in a machine-readable format, enabling automated game simulation, and evaluation. While previous research has explored game description generation using search-based methods, generating GDL descriptions from natural language remains a challenging task. This paper presents a novel framework that leverages Large Language Models (LLMs) to generate grammatically accurate game descriptions from natural language. Our approach consists of two stages: first, we gradually generate a minimal grammar based on GDL specifications; second, we iteratively improve the game description through grammar-guided generation. Our framework employs a specialized parser that identifies valid subsequences and candidate symbols from LLM responses, enabling gradual refinement of the output to ensure grammatical correctness. Experimental results demonstrate that our iterative improvement approach significantly outperforms baseline methods that directly use LLM outputs. Our code is available at https://github.com/tsunehiko/ggdg},
  keywords={Games;Grammar;Natural languages;Iterative decoding;Accuracy;Large language models;Decoding;Symbols;Evolutionary computation;Semantics;Large Language Model;Ludii;Game Description Language;Grammar;Game Description Generation},
  doi={10.1109/TG.2024.3520214},
  ISSN={2475-1510},
  month={},}@INPROCEEDINGS{10708623,
  author={Reddad, H. and Zemzami, M. and El Hami, N. and Hmina, N. and Nguyen, N-Q.},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Reliability Assessment of Solder Ball Joints Using Finite Element Analysis and Machine Learning techniques}, 
  year={2024},
  volume={},
  number={},
  pages={2750-2755},
  abstract={This paper presents a comprehensive approach for reliability assessment and optimization of ball joints by combining finite element analysis (FEA) method with machine learning algorithms, in particular by exploiting the power of the XGBoost machine learning algorithm. FEA simulations were carried out using ANSYS to generate a dataset encompassing various solder joint geometrical parameters configurations. Key input parameters, including geometric dimensions, were identified by sensitivity analysis and used as features for training the XGBoost model. The trained model demonstrated solid performance. Feature importance analysis revealed critical factors influencing solder joint reliability and provided insights for optimization strategies. This research provides practical recommendations for optimizing solder joint and material design to improve reliability and performance in electronic packaging applications.},
  keywords={Training;Support vector machines;Machine learning algorithms;Reliability engineering;Fatigue;Finite element analysis;Reliability;Copper;Soldering;Electronics packaging},
  doi={10.1109/CoDIT62066.2024.10708623},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{10820680,
  author={Mallick, Tanwi and Yildiz, Orcun and Lenz, David and Peterka, Tom},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={ChatVis: Automating Scientific Visualization with a Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={49-55},
  abstract={We develop an iterative assistant we call "ChatVis" that can synthetically generate Python scripts for data analysis and visualization using a large language model (LLM). The assistant allows a user to specify the operations in natural language, attempting to generate a Python script for the desired operations, prompting the LLM to revise the script as needed until it executes correctly. The iterations include an error detection and correction mechanism that extracts error messages from the execution of the script and subsequently prompts LLM to correct the error. Our method demonstrates correct execution on five canonical visualization scenarios, comparing results with ground truth. We also compared our results with scripts generated by several other LLMs without any assistance. In every instance, ChatVis successfully generated the correct script, whereas the unassisted LLMs failed to do so. The code is available on GitHub: https://github.com/tanwimallick/ChatVis/.},
  keywords={Visualization;Codes;Accuracy;Large language models;Source coding;Natural languages;Machine learning;Iterative methods;Reliability;Software development management;Scientific visualization;large language models;synthetic script generation;ParaView;coding assistant},
  doi={10.1109/SCW63240.2024.00014},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10333251,
  author={Volden, Thomas and Grbic, Djordje and Burelli, Paolo},
  booktitle={2023 IEEE Conference on Games (CoG)}, 
  title={Procedurally generating rules to adapt difficulty for narrative puzzle games}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper focuses on procedurally generating rules and communicating them to players to adjust the difficulty. This is part of a larger project to collect and adapt games in educational games for young children using a digital puzzle game designed for kindergarten. A genetic algorithm is used together with a difficulty measure to find a target number of solution sets and a large language model is used to communicate the rules in a narrative context. During testing the approach was able to find rules that approximate any given target difficulty within two dozen generations on average. The approach was combined with a large language model to create a narrative puzzle game where players have to host a dinner for animals that can’t get along. Future experiments will try to improve evaluation, specialize the language model on children’s literature, and collect multi-modal data from players to guide adaptation.},
  keywords={Adaptation models;Animals;Games;Data models;Testing;Genetic algorithms;Context modeling;procedural content generation;large language models;genetic algorithm;learning environment;early childhood education},
  doi={10.1109/CoG57401.2023.10333251},
  ISSN={2325-4289},
  month={Aug},}
