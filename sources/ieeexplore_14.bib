@ARTICLE{10908405,
  author={Dong, Wenquan and Zhu, Songyan and Xu, Jian and Ryan, Casey M. and Chen, Man and Zeng, Jingya and Yu, Hao and Cao, Congfeng and Shi, Jiancheng},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={UFLUX v2.0: A Process-Informed Machine Learning Framework for Efficient and Explainable Modeling of Terrestrial Carbon Uptake}, 
  year={2025},
  volume={22},
  number={},
  pages={1-5},
  abstract={Gross primary productivity (GPP), the amount of carbon plants fixed by photosynthesis, is pivotal for understanding the global carbon cycle and ecosystem functioning. Process-based models built on the knowledge of ecological processes are susceptible to biases stemming from their assumptions and approximations. These limitations potentially result in considerable uncertainties in global GPP estimation, which may pose significant challenges to our net zero goals. This study presents UFLUX v2.0, a process-informed model that integrates state-of-the-art ecological knowledge and advanced machine learning (ML) technique to reduce uncertainties in GPP estimation by learning the biases between process-based models and eddy covariance (EC) measurements. In our findings, UFLUX v2.0 demonstrated a substantial improvement in model accuracy, achieving an  $R {^{{2}}}$  of 0.79 with a reduced RMSE of 1.60 g $\cdot $ Cm−2d−1, compared to the process-based model’s  $R {^{{2}}}$  of 0.51 and RMSE of 3.09 g $\cdot $ Cm−2d−1. Our global GPP distribution analysis indicates that while UFLUX v2.0 and the process-based model achieved similar global total GPP (137.47 and 132.23 PgC, respectively), they exhibited large differences in spatial distribution, particularly in latitudinal gradients. These differences are very likely due to systematic biases in the process-based model and differing sensitivities to climate and environmental conditions. This study offers improved adaptability for GPP modeling across diverse ecosystems and further enhances our understanding of global carbon cycles and its responses to environmental changes.},
  keywords={Biological system modeling;Adaptation models;Ecosystems;Predictive models;Ocean temperature;Data models;Estimation;Accuracy;Meteorology;Temperature measurement;Bias correction;carbon uptake;flux upscaling;gross primary productivity (GPP);terrestrial ecosystems},
  doi={10.1109/LGRS.2025.3541893},
  ISSN={1558-0571},
  month={},}@ARTICLE{10971236,
  author={Chang, Can and Yao, Li and Zhao, Xiaojie},
  journal={IEEE Signal Processing Letters}, 
  title={Enhancing Tumor Edge Consistency in Multimodal MRI Synthesis for Improved Glioma Segmentation}, 
  year={2025},
  volume={32},
  number={},
  pages={2060-2064},
  abstract={Precise segmentation of glioma subregions using multimodal MRI is crucial for accurate diagnosis and effective treatment. However, the absence of certain MRI modalities in clinical settings often leads to incomplete information, necessitating cross-modality synthesis to fill the gaps. A significant challenge in this synthesis is the blurring of tumor subregion boundaries, which affects subsequent segmentation accuracy. Existing methods, while improving boundary clarity, fail to ensure consistent depiction across different modalities due to varying contrasts and sensitive areas. To address these issues, we propose CSEC-Net, a novel tumor-aware synthesis model that enhances tumor edge consistency through Specific Contrast extraction and Edge Consistency enhancement. Our model employs a Contrast-Specific Prototype Learning (CS-PL) method to extract contrast-specific prototype features and an Edge Consistency Contrast Learning (EC-CL) method to improve tumor edge pixel sampling and feature learning. This innovative approach ensures consistent and clear tumor edge depiction across different modalities, significantly improving multimodal MRI synthesis and tumor segmentation accuracy.},
  keywords={Prototypes;Magnetic resonance imaging;Training;Contrastive learning;Image segmentation;Accuracy;Feature extraction;Attention mechanisms;Semantics;Brain tumors;Cross-modality synthesis;multimodal MRI;tumor segmentation},
  doi={10.1109/LSP.2025.3562824},
  ISSN={1558-2361},
  month={},}@ARTICLE{9658526,
  author={Zhang, Tao and Liao, Guisheng and Li, Yachao and Gu, Tong and Zhang, Tinghao and Liu, Yongjun},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={An Improved Time-Domain Autofocus Method Based on 3-D Motion Errors Estimation}, 
  year={2022},
  volume={60},
  number={},
  pages={1-16},
  abstract={Spatial-variant phase errors (PEs) are important factors which defocus the synthetic aperture radar (SAR) image. In time-domain SAR imaging, the exact calculation of instantaneous range is carried out to realize imaging. Accurate trajectory is the key to compensate spatial-variant PEs and ensure image focus. Thus, an improved time-domain autofocus method based on three-dimensional motion errors (3-D MEs) estimation is proposed in this article. First, an improved maximizing-maximum-pixel-value method is used to estimate nonspatial-variant PEs. Meanwhile, a theoretical explanation combined with  $N$ -dimensional Euclidean space is described. Then, residual PEs and wrapped PEs are discussed successively. A part-overlapped partitioning scheme for sub-block images (SBIs) and a wrapped-PE model are proposed for 3-D MEs estimation. Then, the estimation problem is turned into a mixed integer programming problem, which can be solved by the combination of genetic algorithm (GA) and Tikhonov regularization. Finally, the well-focused image is obtained through updated trajectory. The effectiveness of the proposed method is proven by results of simulation and real SAR data processing.},
  keywords={Estimation;Imaging;Trajectory;Three-dimensional displays;Radar imaging;Time-domain analysis;Radar polarimetry;Spatial-variant phase errors (PEs);sub-block images (SBIs);synthetic aperture radar (SAR);three-dimensional motion errors (3-D MEs);time-domain autofocus},
  doi={10.1109/TGRS.2021.3137422},
  ISSN={1558-0644},
  month={},}@ARTICLE{10568220,
  author={Zhao, Lijun and Zhang, Jialong and Zhang, Jinjing and Bai, Huihui and Wang, Anhong},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Joint Discontinuity-Aware Depth Map Super-Resolution via Dual-Tasks Driven Unfolding Network}, 
  year={2024},
  volume={73},
  number={},
  pages={1-14},
  abstract={Convolutional neural network (CNN) provides significant performance improvement for depth map super-resolution (DSR). However, CNN-based DSR methods still face two prominent issues: 1) the overall topology structure of CNN cannot be intuitively understood and 2) the boundary prior of depth maps is always not fully utilized or even ignored, which may make the reconstructed depth maps suffer from boundary blurring problem. In this article, we adopt dual-tasks alternating optimization approach to improve the depth discontinuity-preserving ability of CNN. Concretely, joint optimization problem of two specific tasks is split into two reliant suboptimization problems, which correspond to two suboptimization models: DSR suboptimization model and edge super-resolution (SR) suboptimization model. To achieve interpretability of the CNN, these two suboptimization models are unfolded into alternatively optimized DSR subnetwork and edge SR subnetwork (ENet) according to proximal gradient descent algorithm, which can jointly form edge-constrained DSR network (EC-DSRNet). The coarse-to-fine architecture of DSR subnetwork is designed to gradually capture structures from both color and edge features. Additionally, the proposed joint optimization model makes the proposed network explicitly solve two tasks in an iterative manner, which facilitates an intuitive understanding of the network. A large number of experimental results have demonstrated that the proposed EC-DSRNet can compete against many state-of-the-art DSR. Our codes are publicly released at https://github.com/mdcnn/EC-DSRNet.},
  keywords={Image color analysis;Optimization;Image reconstruction;Feature extraction;Deep learning;Superresolution;Convolutional neural networks;Deep explainable network;deep learning;depth map;edge-constrained optimization;image super-resolution (SR)},
  doi={10.1109/TIM.2024.3417544},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10803420,
  author={Plambeck, Swantje and Schmidt, Maximilian and Fey, Goerschwin and Subias, Audine and Travé-Massuyès, Louise},
  booktitle={2024 50th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Dynamics-Based Identification of Hybrid Systems using Symbolic Regression}, 
  year={2024},
  volume={},
  number={},
  pages={64-71},
  abstract={Symbolic regression has shown potential in the identification of physical systems. Hybrid systems, which combine both continuous and discrete behavior, are a relevant extension of purely physical systems, used in many fields, including robotics, biological systems, and control systems. However, due to their complexity, finding an accurate model is a challenge. This paper presents a novel approach to learning models of hybrid systems using symbolic regression. Our method leverages the power of genetic programming to automatically discover accurate and interpretable mathematical models in the form of hybrid systems from observed data. Symbolic regression detects transitions between different continuous behavior of a system directly based on the dynamics, instead of pure distances of observed trajectories. Furthermore, models generated by symbolic regression can be used to predict future system behavior, detect anomalies, and identify the underlying dynamics of the system while providing a human-readable representation. Our results demonstrate that symbolic regression can effectively identify the underlying dynamics of a real system represented in a hybrid model, providing a valuable tool for system identification and diagnosis.},
  keywords={Fault diagnosis;Accuracy;Biological system modeling;Predictive models;Mathematical models;System identification;Windows;Trajectory;Stakeholders;Software engineering;Hybrid Systems;Symbolic Regression;System Identification},
  doi={10.1109/SEAA64295.2024.00019},
  ISSN={2376-9521},
  month={Aug},}@ARTICLE{9669170,
  author={Wang, Juan and Peng, Ru and Liu, Quanying and Peng, Hong},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={A Hybrid Classification to Detect Abstinent Heroin-Addicted Individuals Using EEG Microstates}, 
  year={2022},
  volume={9},
  number={3},
  pages={700-709},
  abstract={Objective: Diagnosis of the severity of heroin addiction with electroencephalography (EEG) signals is a challenging problem. It has been shown that brain microstates are associated with brain status and healthy condition. However, there is no study on how heroin addiction affects brain microstates. Approach: We propose a hybrid classifier based on the microstate features, extracting from resting state EEGs, to objectively and effectively identify abstinent heroin-addicted individuals (AHAIs) and healthy controls (HCs). In addition to the commonly used features such as duration, occurrence, and transition, we calculated three new features. Main Results: The results showed that the support vector machine (SVM), which allows classification of the AHAIs and HCs with a 73% accuracy rate, was an optimal classifier. Moreover, the weight setting-based genetic algorithm (GA) further improved the accuracy rate to 81%. The hybrid classification not only provides direct evidence showing the differences in EEG microstate features between AHAIs and HCs, but also offers a method to distinguish the heroin brain states of people addicted to heroin and healthy individuals and demonstrates that microstate features could serve as potential bio-markers for identifying AHAIs. Significance: our methods and the selected features may provide electrophysiological insights for the assessment of the heroin withdrawal treatment effects.},
  keywords={Electroencephalography;Feature extraction;Drugs;Electrodes;Topology;Time series analysis;Support vector machines;Binary classification;electroencephalography (EEG);heroin addiction;microstate},
  doi={10.1109/TCSS.2021.3135425},
  ISSN={2329-924X},
  month={June},}@ARTICLE{10836932,
  author={Tang, Xiao and Zhang, Jingyu and Xia, Yunzhi and Cao, Kun and Zhang, Chang},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={PEGNet: An Enhanced Ship Detection Model for Dense Scenes and Multiscale Targets}, 
  year={2025},
  volume={22},
  number={},
  pages={1-5},
  abstract={In recent years, synthetic aperture radar (SAR) ship detection has seen significant improvements due to the rapid development of deep learning. However, when ship targets are densely arranged or exhibit multiscale variations, there are still issues such as significant differences in aspect ratios, resulting in false alarms, missed detections, and low detection accuracy. To overcome these challenges, this letter introduces a novel detection model, PEGNet, based on Faster R-CNN. First, to identify ship targets at different scales, the path aggregation feature pyramid network (PAFPN) was integrated into the feature fusion structure, which enhances the network’s feature representation and robustness. Second, efficient multiscale attention (EMA) was employed to strengthen detection accuracy by reducing noise interference and enhancing feature stability. Third, the guided anchoring region proposal network (GA-RPN) was introduced to produce anchors that more accurately reflect the actual positions and scales of targets, which improves localization precision and lowers the missed detection rate. The performance of PEGNet was tested on the SSDD and high-resolution SAR images dataset (HRSID) datasets, achieving mAP scores of 71.1% and 67.9%, respectively. Compared to the baseline network, this represents improvements of 2.5% and 7.6%. This result highlights the method’s superior performance compared to other approaches.},
  keywords={Marine vehicles;Feature extraction;Accuracy;Object detection;Synthetic aperture radar;Shape;Convolution;Meters;Stability analysis;Robustness;Densely arranged;multiscale;ship;synthetic aperture radar (SAR);target detection},
  doi={10.1109/LGRS.2025.3528221},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{10066628,
  author={Boyapati, Mallika and Aygun, Ramazan},
  booktitle={2023 IEEE 17th International Conference on Semantic Computing (ICSC)}, 
  title={Default Prediction on Commercial Credit Big Data Using Graph-based Variable Clustering}, 
  year={2023},
  volume={},
  number={},
  pages={139-142},
  abstract={Credit-lending organizations have resorted to the use of machine learning (ML) algorithms in the recent past to predict the probability of the default of a business. Explainability of the decisions made by the traditional statistical algorithms like Logit models brings transparency to every stakeholder involved in the process. On the other hand, machine learning models like XGBoost and Neural Nets have achieved better accuracy scores, but their decisions are not easily comprehensible. In this paper, we propose a graph based variable clustering (GVC) method as a filter based approach to select prominent features while retaining as much variance as possible. Our experiments show that our GVC approach is not only almost 40 times faster than the existing variable clustering methods but retains retains 5% more variance than the existing packages.The feature set from GVC approach has performed better with an increase of 6% accuracy on an average. The predictions on the feature set from GVC were 98% accurate using XGBoost algorithm.},
  keywords={Machine learning algorithms;Runtime;Semantics;Neural networks;Clustering algorithms;Machine learning;Organizations;Graph Variable Clustering;Credit Default Prediction},
  doi={10.1109/ICSC56153.2023.00029},
  ISSN={2325-6516},
  month={Feb},}@INPROCEEDINGS{10768590,
  author={Xu, Xiao and Xue, Yang and Lu, Qiuhong and Wu, Yihao and Ni, Dabin and Cai, Chang},
  booktitle={2024 The 9th International Conference on Power and Renewable Energy (ICPRE)}, 
  title={DL-YOLOv8: Improved YOLOv8 for Cable Sheath Defect Detection}, 
  year={2024},
  volume={},
  number={},
  pages={53-57},
  abstract={In the task of cable sheath defect detection, traditional detection methods face challenges of low detection accuracy due to multi-scale transformations of damaged targets and susceptibility to background interference. To address this issue, this paper proposed DL- YOLOv8, an algorithm specifically designed for cable sheath defect detection. Firstly, since cable sheath defects exhibit distinct edge features, a Gradient Attention (GA) module is constructed to focus the model's attention on the damaged target areas. Secondly, a new loss function, $\beta_{-}\text{IoU}$, is designed to optimize the model's localization performance for elongated damaged targets by using a parameter $\beta$ to assign different sensitivities to the length and width penalty terms in the E IoU loss function. On our self-built dataset, compared to the original YOLOv8 model, DL- YOLOv8 improves the performance metrics AP50 and AP75 for cable sheath defect detection by 4.7% and 11.8%, respectively. The improved algorithm demonstrates higher accuracy and better localization, making it more suitable for the task of cable sheath defect detection.},
  keywords={Location awareness;Renewable energy sources;Accuracy;Sensitivity;Attention mechanisms;Image edge detection;Interference;Faces;Defect detection;Cable shielding;defect detection;cable sheath;YOLOv8;gradient attention module;loss function},
  doi={10.1109/ICPRE62586.2024.10768590},
  ISSN={2768-0525},
  month={Sep.},}@INPROCEEDINGS{10912939,
  author={She, Xiangyang and Jiang, Xuening and Dong, Lihong},
  booktitle={2024 6th International Conference on Frontier Technologies of Information and Computer (ICFTIC)}, 
  title={Visual Question Answering based on Multimodal Deep Feature Fusion}, 
  year={2024},
  volume={},
  number={},
  pages={841-845},
  abstract={To solve the problem of shallow cross-modal interaction depth, information loss during feature fusion, and semantic ambiguity leading to low algorithm accuracy in the field of visual question answering, a visual question answering algorithm based on multimodal deep feature fusion (MDFF-VQA) is proposed. The algorithm uses Self-Attention unit (SA) to enhance question features and Guided-Attention unit (GA) to iteratively extract relevant visual features. Improve the feature fusion by using 1 ×1 convolution to expand dimensions and overcome size limitations, enriching the fused features through fully connected layers. Experiments on the dataset VQA v2 show that MDFF - VQA significantly outperforms algorithms such as Language-only, MLAN, Scence GCN, and ODA-GCN in “Y/N”, “Num”, “Other”, and “All” type questions, effectively improving the performance of visual question answering tasks.},
  keywords={Training;Deep learning;Visualization;Accuracy;Federated learning;Convolution;Computational modeling;Semantics;Feature extraction;Question answering (information retrieval);deep learning;visual question answering;multi-head attention;multi-modal learning;feature fusion},
  doi={10.1109/ICFTIC64248.2024.10912939},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10063574,
  author={Maurina, Gabriele and Homayouni, Hajar and Ghosh, Sudipto and Ray, Indrakshi and Duggan, Gerald P.},
  booktitle={2022 IEEE 4th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={A Methodology for Energy Usage Prediction in Long-Lasting Abnormal Events}, 
  year={2022},
  volume={},
  number={},
  pages={91-100},
  abstract={Accurate energy consumption prediction is critical for proper resource allocation, meeting energy demand, and energy supply security. This work aims at developing a methodology for accurately modeling and predicting electricity consumption during abnormal long-lasting events, such as COVID-19 pandemic, which considerably affect consumption patterns in different types of premises. The proposed methodology involves three steps: (A) selects among multiple models the most accurate one in energy consumption prediction under normal conditions, (B) uses the selected model to analyze the impact of a specific abnormal event on energy consumption for various classes of premises, and (C) investigates which features contribute most to energy consumption prediction for abnormal conditions and which features can be added to improve such predictions.We use COVID-19 as a case study with datasets obtained from Fort Collins Utilities, which contain energy consumption data for residential and different sizes of commercial and industrial premises in the city of Fort Collins, Colorado, USA. We also use temperature records from NOAA and COVID-19 public orders from Larimer County.We validate the methodology by demonstrating that the methodology can help design a model suited for the pandemic situation using representative features, and as a result, accurately predict the energy consumption. Our results show that the MLP model selected by our methodology performs better than the other models even when they all use the COVID-related features. We also demonstrate that the methodology can help measure the impacts of the pandemic on the energy consumption.},
  keywords={COVID-19;Energy consumption;Analytical models;Pandemics;Urban areas;Predictive models;US Government agencies;Energy Usage;Machine Learning;Methodology;Prediction;Abnormal Events},
  doi={10.1109/CogMI56440.2022.00023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10820727,
  author={Moore, Joseph and Deakin, Tom and McIntosh-Smith, Simon},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={AI-Assisted Design-Space Analysis of High-Performance Arm Processors}, 
  year={2024},
  volume={},
  number={},
  pages={1455-1467},
  abstract={This work quantifies the impact of microarchitectural features in modern high-performance Arm CPUs. To combat a parameter space that is too large to traverse naively, we employ a decision tree regression machine learning model to predict the number of execution cycles with 93.38% accuracy compared to the simulated cycles. We build on previous work by specializing our design to real-world HPC workloads and modernize our approach with updated search spaces, improved simulation frameworks, and over 180,000 simulated data points. We find empirically that vector length typically has the largest impact on HPC code performance at 25.91% of our performance weighting, followed by memory performance across all levels of the memory hierarchy, and the size of the reorder buffer and register files. Our results motivate deeper exploration of these parameters in both hardware design and simulation, as well as advancing the modelling of architectural simulation through the use of machine learning.},
  keywords={Adaptation models;Codes;Computational modeling;Random access memory;Machine learning;Predictive models;Performance gain;Data models;Vectors;Registers;aarch64;simulation;simeng;SST;vectorization;machine learning},
  doi={10.1109/SCW63240.2024.00186},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10820695,
  author={Jakobsche, Thomas and Ciorba, Florina M.},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Using Malware Detection Techniques for HPC Application Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1773-1780},
  abstract={HPC systems face security and compliance challenges, particularly in preventing waste and misuse of computational resources by unauthorized or malicious software that deviates from allocation purpose. Existing methods to classify applications based on job names or resource usage are often unreliable or fail to capture applications that have different behavior due to different inputs or system noise. This research proposes an approach that uses similarity-preserving fuzzy hashes to classify HPC application executables. By comparing the similarity of SSDeep fuzzy hashes, a Random Forest Classifier can accurately label applications executing on HPC systems including unknown samples. We evaluate the Fuzzy Hash Classifier on a dataset of 92 application classes and 5333 distinct application samples. The proposed method achieved a macro f1-score of 90% (micro f1-score: 89%, weighted f1-score: 90%). Our approach addresses the critical need for more effective application classification in HPC environments, minimizing resource waste, and enhancing security and compliance.},
  keywords={High performance computing;Conferences;Noise;Malware;Security;Resource management;Random forests;Faces;HPC;security;application classification},
  doi={10.1109/SCW63240.2024.00222},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10069747,
  author={Belcak, Peter and Hofer, David and Wattenhofer, Roger},
  booktitle={2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={A Neural Model for Regular Grammar Induction}, 
  year={2022},
  volume={},
  number={},
  pages={401-406},
  abstract={Grammatical inference is a classical problem in computational learning theory and a topic of wider influence in natural language processing. We treat grammars as a model of computation and propose a novel neural approach to induction of regular grammars from positive and negative examples. Our model is fully explainable, its intermediate results are directly interpretable as partial parses, and it can be used to learn arbitrary regular grammars when provided with sufficient data. We find that our method consistently attains high recall and precision scores across a range of tests of varying complexity.},
  keywords={Training;Turing machines;Computational modeling;Machine learning;Programming;Natural language processing;Inference algorithms;neural networks;regular languages;grammar induction;program synthesis},
  doi={10.1109/ICMLA55696.2022.00064},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10500256,
  author={Uhles, Chad and Humphrey, Beth and Hausladen, Jennifer and Hedrick, Mark and Johnstone, Patti M. and Allen, Jessica and Khojandi, Anahita},
  booktitle={SoutheastCon 2024}, 
  title={Insights into Information-Seeking Behavior in Hearing-Loss Treatment}, 
  year={2024},
  volume={},
  number={},
  pages={449-453},
  abstract={While hearing loss can be measured and corrected using a variety of treatment options, not all affected patients seek treatment. As such, it is imperative to learn what leads to different attitudes and behaviors towards seeking hearing loss treatments or information about them. Specifically, it is important to identify what factors distinguish between those individuals who engage in information-seeking behavior towards hearing loss treatment and those who do not. This can provide insight on how to change an individual's behavior and adapt treatment options to best promote treatments to those who need them. This study examines the data from 73 patients that classify themselves as either expressing information-seeking behavior towards hearing loss treatments or not. The goal of this study was to predict information-seeking behavior and identify the most important factors contributing to the observed behavior. The data consists of audiogram results plus the patients' responses to a series of surveys that measure their perceived hearing ability and quality of life. Machine learning models were developed to stratify the subjects to the corresponding cohorts and the factors were ranked in the order of their importance to predicting information-seeking behavior. The models achieved an area under the curve (AUC) of 0.7233 +- (0.2218), suggesting that our models were quite successful in correctly stratifying the patient's behaviors. Interestingly, the most important factor contributing to information-seeking behavior was the patient's subjective perception of their hearing loss, followed by age and the patient's objective ability to hear.},
  keywords={Surveys;Radio frequency;Pathology;Auditory system;Medical services;Predictive models;Loss measurement;hearing loss;quality of life;machine learning;behavioral change},
  doi={10.1109/SoutheastCon52093.2024.10500256},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10675734,
  author={Ravipudi, Jaya Lakshmi and Brandt-Pearce, Maite},
  journal={Journal of Optical Communications and Networking}, 
  title={Machine-learning-based impairment-aware dynamic RMSCA in multi-core elastic optical networks}, 
  year={2024},
  volume={16},
  number={10},
  pages={F26-F39},
  abstract={This paper presents a routing, modulation, spectrum, and core assignment (RMSCA) algorithm for space-division-multiplexing-based elastic optical networks (SDM-EONs) comprising multi-core links. A network state-dependent route and core selection method is proposed using a deep neural network (DNN) classifier. The DNN is trained using a metaheuristic optimization algorithm to predict lightpath suitability, considering the quality of transmission and resource availability. Physical layer impairments, including inter-core crosstalk, amplified spontaneous emission, and Kerr fiber nonlinearities, are considered, and a random forest (RF)-based link noise estimator is proposed. A feature importance selection analysis is provided for all the features considered for the DNN classifier and the RF link noise estimator. The proposed machine-learning-enabled RMSCA approach is evaluated on three network topologies, USNET, NSFNET, and COST-239 with 7-core and 12-core fiber links. It is shown to be superior in terms of blocking probability, bandwidth blocking probability, and acceptable computational speed compared to the standard and published benchmarks at different traffic loads.},
  keywords={Resource management;Optical fiber networks;Maximum likelihood estimation;Noise;Heuristic algorithms;Computational modeling;Artificial neural networks},
  doi={10.1364/JOCN.530035},
  ISSN={1943-0639},
  month={October},}@ARTICLE{9531972,
  author={K. N., Pavan Kumar and Gavrilova, Marina L.},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Latent Personality Traits Assessment From Social Network Activity Using Contextual Language Embedding}, 
  year={2022},
  volume={9},
  number={2},
  pages={638-649},
  abstract={Recognizing author identity from digital footprints without having a large corpus of documents from an individual is of keen interest to security researchers and government agencies. Users reveal aspects of their personality via the content they share with their social media followers and through the patterns in their interactions on online networking platforms. This study examines the potency of emerging natural language processing (NLP) methods in analyzing social network activity. A linguostylistic personality traits assessment (LPTA) system is developed to estimate Twitter users’ personality traits based on their tweets using the Myers-Briggs-type indicator (MBTI) and big-five personality scales. A novel input representation mechanism is proposed to process tweets by converting them into real-valued vectors using frequency, co-occurrence, and context (FCC) measures. Other prevalent text representation schemes, such as one-hot encoding, count-based vectorization, and pretrained language model representations are used as comparators. A genetic algorithm (GA) approach is proposed to reduce the feature set and increase the efficacy of the features extracted. The developed system outperforms the state-of-the-art research by reliably estimating the user’s latent personality traits while using 50 or fewer tweets per user.},
  keywords={Social networking (online);Blogs;Linguistics;Task analysis;Reliability;Computational modeling;Predictive models;Contextual language embedding;linguostylistic classification;personality traits;social behavior;social network},
  doi={10.1109/TCSS.2021.3108810},
  ISSN={2329-924X},
  month={April},}@INPROCEEDINGS{10204567,
  author={Tang, Zongheng and Sun, Yifan and Liu, Si and Yang, Yi},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={DETR with Additional Global Aggregation for Cross-domain Weakly Supervised Object Detection}, 
  year={2023},
  volume={},
  number={},
  pages={11422-11432},
  abstract={This paper presents a DETR-based method for cross-domain weakly supervised object detection (CDWSOD), aiming at adapting the detector from source to target domain through weak supervision. We think DETR has strong potential for CDWSOD due to an insight: the encoder and the decoder in DETR are both based on the attention mechanism and are thus capable of aggregating semantics across the entire image. The aggregation results, i.e., image-level predictions, can naturally exploit the weak supervision for domain alignment. Such motivated, we propose DETR with additional Global Aggregation (DETR-GA), a CDWSOD detector that simultaneously makes “instance-level + image-level” predictions and utilizes “strong + weak” supervisions. The key point of DETR-GA is very simple: for the encoder / decoder, we respectively add multiple class queries / a foreground query to aggregate the semantics into image-level predictions. Our query-based aggregation has two advantages. First, in the encoder, the weakly-supervised class queries are capable of roughly locating the corresponding positions and excluding the distraction from non-relevant regions. Second, through our design, the object queries and the foreground query in the decoder share consensus on the class semantics, therefore making the strong and weak supervision mutually benefit each other for domain alignment. Extensive experiments on four popular cross-domain benchmarks show that DETR-GA significantly improves cross-domain detection accuracy (e.g., 29.0% → 79.4% mAP on PASCAL VOC → Clipartall dataset) and advances the states of the art.},
  keywords={Computer vision;Aggregates;Semantics;Object detection;Detectors;Benchmark testing;Decoding;Transfer;meta;low-shot;continual;or long-tail learning},
  doi={10.1109/CVPR52729.2023.01099},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10495722,
  author={Shao, Zonghe and Wang, Qichao and Cao, Yuzhe and Cai, Defu and You, Yang and Lu, Renzhi},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Novel Data-Driven LSTM-SAF Model for Power Systems Transient Stability Assessment}, 
  year={2024},
  volume={20},
  number={7},
  pages={9083-9097},
  abstract={Transient stability is an important metric for assessing the operational state of a power system. However, due to the inherent complexity of the power systems, it is difficult to achieve stable and precise transient stability assessment (TSA). This article proposes a novel data-driven long short-term memory with self-attention mechanism and focal loss function (LSTM-SAF) model to achieve a rapid and reliable TSA scheme. First, an improved wrapper approach involving a genetic algorithm is established to obtain concise and effective input features, which can enhance model performance and efficiency. Then, an LSTM network combined with a self-attention mechanism is developed to learn reliable TSA paradigms, in which the self-attention mechanism can further explore the information relationships of temporal features extracted from the LSTM, thereby significantly improving TSA accuracy. In addition, to resolve the lack of insufficient training related to sample imbalance, a new focal loss function is designed to guide model training. This article provides a complete TSA scheme (including offline training and online execution) that considers both assessment performance and response speed. The effectiveness of the proposed model is verified by the numerical testing results on IEEE 39 bus system, NPCC 140 bus system, IEEE 145 bus system and IEEE 300 bus system.},
  keywords={Power system stability;Feature extraction;Long short term memory;Data models;Numerical stability;Stability criteria;Numerical models;Focal loss;long short-term memory (LSTM) network;self-attention;transient stability;wrapper approach},
  doi={10.1109/TII.2024.3379629},
  ISSN={1941-0050},
  month={July},}@ARTICLE{10101722,
  author={Yi, Yangtian and Lu, Chao and Wang, Boyang and Cheng, Long and Li, Zirui and Gong, Jianwei},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Fusion of Gaze and Scene Information for Driving Behaviour Recognition: A Graph-Neural-Network- Based Framework}, 
  year={2023},
  volume={24},
  number={8},
  pages={8109-8120},
  abstract={Accurate recognition of driver behaviours is the basis for a reliable driver assistance system. This paper proposes a novel fusion framework for driver behaviour recognition that utilises the traffic scene and driver gaze information. The proposed framework is based on the graph neural network (GNN) and contains three modules, namely, the gaze analysing (GA) module, scene understanding (SU) module and the information fusion (IF) module. The GA module is used to obtain gaze images of drivers, and extract the gaze features from the images. The SU module provides trajectory predictions for surrounding vehicles, motorcycles, bicycles and other traffic participants. The GA and SU modules are parallel and the outputs of both modules are sent to the IF module that fuses the gaze and scene information using the attention mechanism and recognises the driving behaviours through a combined classifier. The proposed framework is verified on a naturalistic driving dataset. The comparative experiments with the state-of-the-art methods demonstrate that the proposed framework has superior performance for driving behaviour recognition in various situations.},
  keywords={Vehicles;Feature extraction;Cameras;Optical flow;Graph neural networks;Trajectory;Reliability;Driving behaviours;graph neural network;gaze information;scene information;data fusion},
  doi={10.1109/TITS.2023.3263875},
  ISSN={1558-0016},
  month={Aug},}@INPROCEEDINGS{10081740,
  author={Ding, Julia and Li, Jing-Jing and Xu, Max},
  booktitle={2022 Computing in Cardiology (CinC)}, 
  title={Classification of Murmurs in PCG Using Combined Frequency Domain and Physician Inspired Features}, 
  year={2022},
  volume={498},
  number={},
  pages={1-4},
  abstract={Physiological machine learning methods have a unique opportunity to augment deep-learning engineered features with additional features derived from prior pathological knowledge. We propose an phonocardiogram (PCG) classifier that combines raw spectrogram features with crafted, physician-inspired features with an end-to-end neural network architecture. Learned spectrogram features were obtained by training a convolutional neural network (CNN) directly on the raw mel-spectrogram representation of the PCG time-series. Crafted features were based on the four stages of the cardiac cycle (S1, systole, S2, and diastole). The spectrogram features have the advantage of introducing flexibility for the model to learn abstract, low-level information that captures a variety of different rhythmic abnormalities and the latter has the advantage of using segmentation to elucidate specific, high-level, human-interpretable information. Combined features are fed into a fully connected neural network which is able to learn the relationship between the two feature types. In the George B. Moody PhysioNet Challenge 2022 test set, our team (“lubdub”) received a weighted accuracy score of 0.835 with a cost of 14905 in the clinical outcome task (ranked 31/39). For the murmur prediction task, our model received a weighted accuracy score of 0.525 and a cost of 15083 (ranked 33/40).},
  keywords={Training;Pathology;Costs;Neural networks;Predictive models;Physiology;Convolutional neural networks},
  doi={10.22489/CinC.2022.065},
  ISSN={2325-887X},
  month={Sep.},}@INPROCEEDINGS{10488208,
  author={Kim, Kangsan and Yang, Jingyu and Lee, Kyo Chul and Kim, Kwang Seok and Woo, Sang-Keun},
  booktitle={2024 IEEE International Conference on Big Data and Smart Computing (BigComp)}, 
  title={Binding Affinity Prediction of the Radiolabeled PSMA-617 with PSMA via Graph Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={278-280},
  abstract={Virtual screening has high potential as the supplementary tool in drug discovery, which explores several millions of drugs for target material. However, virtual screening for radiopharmaceuticals has not been evaluated sufficiently compared to its importance. In this context, we proposed the graph neural network (GNN) based compound-protein binding affinity prediction model and evaluated the model for the pairs of PSMA protein and radiolabeled PSMA-617. The binding affinity prediction model consisted of four modules, GNN drug module, LSTM protein module, bi-attention module, and regression module. We acquired the dataset of Ki and IC50, quantities describing the binding affinity, from BindingD B database. We conducted internal test for evaluation of the model by split entire dataset into 9:1. The model scored 0.781 and 0.775 of R2, 0.892 and 0.884 of CCp, and 1.32 and 1.19 of MAE for Ki and IC50. Moreover, we estimated the binding affinities of PSMA-617, 68Ga-PSMA-617, 177Lu-PSMA-617, and 22SAc- PSMA-617 with PSMA protein. It was found that the estimate Ki by prediction model was more similar to the experimental results than the estimated results by AutoDock Vina. In conclusion, we found that the deep learning model can be effective for prediction of the binding affinity of the radiopharmaceutical to the target protein.},
  keywords={Proteins;Drugs;Deep learning;Databases;Computational modeling;Predictive models;Big Data;virtual screening;binding affinity;radiopharmaceutical;graph neural network;attention mechanism;PSMA;compound-protein interaction},
  doi={10.1109/BigComp60711.2024.00050},
  ISSN={2375-9356},
  month={Feb},}@ARTICLE{10283969,
  author={Lai, Qifeng and Xiong, Chen and Chen, Jian and Wang, Wei and Chen, Junxin and Gadekallu, Thippa Reddy and Cai, Ming and Hu, Xiping},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Improved Transformer-Based Privacy-Preserving Architecture for Intrusion Detection in Secure V2X Communications}, 
  year={2024},
  volume={70},
  number={1},
  pages={1810-1820},
  abstract={The Internet of Vehicles (IoVs) makes communications between numerous devices that use various protocols susceptible to hacker incursions and attacks, which can compromise privacy and seriously jeopardize driving safety. Many studies have been proposed to detect intrusions hitherto, but two major limitations remain. First, traditional Vehicles-to-Cloud (V2C) have difficulty in figuring out the decentralized distribution of data and computational power in IoVs. Second, the majority of studies suffer from unbalanced data in which the attacks only make up a small part and fail to detect low-probability attacks. To address these limitations, we design a Federated Learning-Edge Cloud (FL-EC) communication architecture for IoVs with a Feature Select Transformer (FSFormer) for effective intrusion detection: In FL-EC, mobile users collect and encrypt data before uploading it to edges for training, with edges and cloud functioning as clients and servers in FL, ensuring privacy and efficient data transmission. In FSFormer, we propose a Feature Attention mechanism to search and promote significant features. Furthermore, the Feed-Forward Network is replaced with a Routing module for a deeper but less-parameter network. Extensive experiments show that our model effectively boosts the detection rate of low-probability attacks and outperforms five baseline models in almost all scenarios.},
  keywords={Transformers;Training;Image edge detection;Feature extraction;Telecommunication traffic;Intrusion detection;Vehicle-to-everything;Intrusion detection;transformer;deep learning;data security;edge cloud},
  doi={10.1109/TCE.2023.3324081},
  ISSN={1558-4127},
  month={Feb},}@INPROCEEDINGS{10708898,
  author={Zhang, Qiushuang},
  booktitle={2024 3rd International Conference on Artificial Intelligence and Autonomous Robot Systems (AIARS)}, 
  title={Design of E-Commerce with Machine Learning System Based on Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={777-781},
  abstract={The E-Commerce information system for business and customers is developed by the use of advanced technology, which is based on the idea of building E-Commerce information system. The whole system is divided into three subsystems, and each with its own direction, and this paper presented a new expert system with high quality based on weight analysis for E-Commerce with machine learning system. This system can have comprehensive analysis by software to regulate and control the current condition of E-Commerce for business and customers. In addition, explanation components were added in the system, which increased the intelligence. The result show that Weight analysis is a very effective strategy to judge and indicate the priority of expert opinions in the current system. In order to ease the pressure of massive information and multi-user, the servers in a system have been optimized to meet the requirements of multi-user concurrent operation for massive information.},
  keywords={Visualization;Neural networks;Machine learning;Software;Electronic commerce;Servers;Expert systems;Engines;Business;Information systems;neural network;NET framework;E-Commerce;machine learning system;genetic algorithm},
  doi={10.1109/AIARS63200.2024.00146},
  ISSN={},
  month={July},}@ARTICLE{10716442,
  author={Meng, Fanchun and Ren, Tao and Wang, Pengyu and Liu, Xinliang and Xiang, Wenjuan and He, Xinyu},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={A Two-Stage Earthquake Event Classification Model Based on Diffusion Probability Model}, 
  year={2024},
  volume={62},
  number={},
  pages={1-9},
  abstract={Rapid and accurate classification of earthquake (eq) events is a serious challenge in seismology and disaster mitigation. Problems, such as data imbalance, model interpretability, and model generalization, limit the application of artificial intelligence methods in this research area. This article introduces a real-time two-stage diffusion eq event classification (DiffEEC) model based on the diffusion probability model (DPM). DiffEEC uses a two-stage classification approach and combines DPM and knowledge distillation (KD) techniques. DiffEEC focuses on seismic phase-related features and source mechanism-related features by combining time-series features extracted by convolutional layers, DPM output, and InSAR data features to better extract core seismic data information and reduce reliance on manual feature design. DiffEEC uses focal loss to solve the data imbalance problem. Thus, DiffEEC can address data scarcity and imbalance, feature acquisition and selection, variability and complexity of seismic event processing, and model generalization through the mechanism. Experiments show that DiffEEC performs better in eq event classification (EC).},
  keywords={Feature extraction;Earthquakes;Geoscience and remote sensing;Decoding;Explosions;Data models;Accuracy;Tectonics;Predictive models;Manuals;Diffusion probability model (DPM);earthquake (eq) event classification (EC);feature fusion;knowledge distillation (KD)},
  doi={10.1109/TGRS.2024.3479327},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10671039,
  author={Nimmagadda, Sailaja and Murugan, Rekha and C, Dhilipan and Deepika, K. and Muda, Iskandar and Balakumar, A.},
  booktitle={2024 Third International Conference on Smart Technologies and Systems for Next Generation Computing (ICSTSN)}, 
  title={Financial Risk Prediction in E-Commerce: Leveraging Vampire Bat Optimization and Factor Analysis for Enhanced Decision-Making}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={E-commerce platforms face various financial risks due to the dynamic and unpredictable nature of online markets. Predicting and managing these risks is essential for sustainable growth and profitability. This research proposes a novel approach for financial risk prediction in e-commerce by integrating Vampire Bat Optimization (VBO) and Factor Analysis (FA) to enhance decision-making processes. The Vampire Bat Optimization algorithm, inspired by the foraging behavior of vampire bats, is employed for feature selection and optimization. It efficiently identifies the most relevant financial factors affecting e-commerce risk prediction. Factor Analysis is then applied to extract the underlying latent variables from the selected features, reducing dimensionality and enhancing the model's interpretability. The proposed approach was evaluated using a comprehensive dataset obtained from a leading e-commerce platform. Various financial factors including sales volume, customer demographics, market trends, and economic indicators were considered. Furthermore, the interpretability of the model is enhanced through the identification of key risk factors, providing valuable insights for decision-makers. The proposed framework can assist e-commerce businesses in making informed decisions to mitigate financial risks, optimize resource allocation, and improve overall performance. The research contributes to the existing literature by providing a novel and effective solution for financial risk prediction in the e-commerce domain, thereby fostering sustainable growth and stability in online businesses. The VBO-FA model achieves an accuracy of 98% in classification tasks, demonstrating exceptional performance was implemented in Python.},
  keywords={Profitability;Decision making;Feature extraction;Prediction algorithms;Stability analysis;Electronic commerce;Resource management;Financial risk prediction;E-commerce;Decision Making;Vampire Bat Optimization (VBO);Factor Analysis (FA)},
  doi={10.1109/ICSTSN61422.2024.10671039},
  ISSN={},
  month={July},}@INPROCEEDINGS{10436251,
  author={Lucero-Tenorio, Miriam and Rojas, Angel C. Valcárcel},
  booktitle={2023 IEEE Colombian Caribbean Conference (C3)}, 
  title={Multi-objective optimization of power substation grounding grids}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the optimization of power substation ground grids using the elitist multi-objective algorithm NSGA-II philosophy, explaining the operation scheme and the unique mechanisms that allow the preservation and evolution of Pareto-optimal solutions. This algorithm is compared with the optimization method implemented in the GMAT program of Aplicaciones Tecnológicas, which is based on a semi-optimization process obtained from a correlation of semi-exact optimization solutions. Multi-objective optimization allows a much higher cost reduction than the semi-optimization process, although the computation time required to reach the final solution is still relatively long.},
  keywords={Substations;Costs;Correlation;Grounding;Heuristic algorithms;Voltage;Optimization;Grounding system;Optimization;non-dominated Sorting Genetic Algorithm II (NSGA-II);Touch voltage;Step voltage},
  doi={10.1109/C358072.2023.10436251},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10625538,
  author={Madaan, Vijay and Sharma, Neha and Upadhyay, Deepak and Devliyal, Swati and Kumar, Bura Vijay},
  booktitle={2024 IEEE International Conference on Information Technology, Electronics and Intelligent Communication Systems (ICITEICS)}, 
  title={Revolutionizing Ovarian Cancer Diagnosis: A ResNet50 Approach for Precision Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The abstract functions as a short explanation of the study's goals, procedures, findings, and conclusions. We intended to create a robust machine learning model that could accurately identify different subtypes of ovarian cancer, like endometrioid carcinoma (EC), clear cell carcinoma (CC), mucinous carcinoma (MC), high-grade serous carcinoma (HGSC), and low-grade serous carcinoma (LGSC). In this model, powerful image processing algorithms and feature extraction methodologies are applied to identify certain key morphological and textural traits indicative of every subtype and leverage a collection of histology images of ovarian tissue samples. The generated model achieves an overall accuracy of 75%, which indicates the utility of the provided strategy. To establish the model's classification skills across numerous subtypes, we carried out a full evaluation of its performance, including measurements of accuracy, recall, and F1-score. This model indicates possible areas for growth, future research prospects, and the model's strengths or demerits. In summary, this work demonstrates the ability to identify ovarian cancer subgroups. It delivers insightful information that could boost the accuracy or precision of diagnosis to drive the formulation of tailored treatment regimens. The literature offers effective diagnoses on the utilization of computational approaches for increased accuracy, and the treatment continues to rise.},
  keywords={Accuracy;Machine learning algorithms;Histopathology;Machine learning;Transforms;Feature extraction;Reliability;Ovarian Cancer;High-Grade Serous Carcinoma (HGSC);Low-Grade Serous Carcinoma (LGSC);Endometrioid Carcinoma (EC);Clear Cell Carcinoma (CC);Mucinous Carcinoma (MC)},
  doi={10.1109/ICITEICS61368.2024.10625538},
  ISSN={},
  month={June},}@INPROCEEDINGS{10500148,
  author={Marefat, Alireza and Mohamed Nishar, Abbaas Alif and Ashok, Ashwin},
  booktitle={SoutheastCon 2024}, 
  title={A Framework for Classifying Applications from Raw Network Traffic Traces}, 
  year={2024},
  volume={},
  number={},
  pages={1006-1015},
  abstract={In this paper, we study and present the design of a framework to identify applications from raw network traces. Framing the problem as an application classification problem, we set up the framework to extract key features from packet data and their temporal behavior. The feature generation, their training using traditional machine learning models, and the decision making are executed over a four- stage pipeline, to yield the name of the application. Through an in-lab environment experimentation using Open Wrt toolkit, RaspberryPi, and a set of physical devices (generating network traffic), we evaluated on average about 204K data points from the captured network packet traces for six applications. Our results show that our method is able to classify the applications with at least 90% accuracy. Through micro-benchmarking, we also show the feasibility of scaling the number of applications and running the tool in real-time.},
  keywords={Training;Protocols;Wireless networks;System performance;Scalability;Systems architecture;Telecommunication traffic;Network Traffic Classification;Application Clas-sification;Feature Extraction;Software-Defined Network;Wireless Network;Machine Learning},
  doi={10.1109/SoutheastCon52093.2024.10500148},
  ISSN={1558-058X},
  month={March},}@ARTICLE{9694633,
  author={Wang, Sheng and Ouyang, Xi and Liu, Tianming and Wang, Qian and Shen, Dinggang},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Follow My Eye: Using Gaze to Supervise Computer-Aided Diagnosis}, 
  year={2022},
  volume={41},
  number={7},
  pages={1688-1698},
  abstract={When deep neural network (DNN) was first introduced to the medical image analysis community, researchers were impressed by its performance. However, it is evident now that a large number of manually labeled data is often a must to train a properly functioning DNN. This demand for supervision data and labels is a major bottleneck in current medical image analysis, since collecting a large number of annotations from experienced experts can be time-consuming and expensive. In this paper, we demonstrate that the eye movement of radiologists reading medical images can be a new form of supervision to train the DNN-based computer-aided diagnosis (CAD) system. Particularly, we record the tracks of the radiologists’ gaze when they are reading images. The gaze information is processed and then used to supervise the DNN’s attention via an Attention Consistency module. To the best of our knowledge, the above pipeline is among the earliest efforts to leverage expert eye movement for deep-learning-based CAD. We have conducted extensive experiments on knee X-ray images for osteoarthritis assessment. The results show that our method can achieve considerable improvement in diagnosis performance, with the help of gaze supervision.},
  keywords={Visualization;Biomedical imaging;X-ray imaging;Solid modeling;Deep learning;Annotations;Medical diagnostic imaging;Visual attention;eye-tracking;machine attention model;computer-aided diagnosis},
  doi={10.1109/TMI.2022.3146973},
  ISSN={1558-254X},
  month={July},}@ARTICLE{9638337,
  author={Cai, Xiaoyan and Liu, Sen and Han, Junwei and Yang, Libin and Liu, Zhenguo and Liu, Tianming},
  journal={IEEE Transactions on Multimedia}, 
  title={ChestXRayBERT: A Pretrained Language Model for Chest Radiology Report Summarization}, 
  year={2023},
  volume={25},
  number={},
  pages={845-855},
  abstract={Automatically generating the “impression” section of a radiology report given the “findings” section can summarize as much salient information of the “findings” section as possible, thus promoting more effective communication between radiologists and referring physicians. To significantly reduce the workload of radiologists, we develop and evaluate a novel framework of abstractive summarization methods to automatically generate the “impression” section of chest radiology reports. Despite recent advancements in natural language process (NLP) field such as BERT and its variants, existing abstractive summarization models and methods could not be directly applied to radiology reports, partly due to domain-specific radiology terminology. In response, we develop a pre-trained language model in the chest radiology domain, named ChestXRayBERT, to solve the problem of automatically summarizing chest radiology reports. Specifically, we first collect radiology-related scientific papers as pre-training corpus and pre-train a ChestXRayBERT on it. Then, an abstractive summarization model is proposed, which consists of the pre-trained ChestXRayBERT and a Transformer decoder. Finally, the model is fine-tuned on chest X-ray reports for the abstractive summarization task. When evaluated on the publicly available OPEN-I and MIMIC-CXR datasets, the performance of our proposed model achieves significant improvement compared with other neural networks-based abstractive summarization models. In general, the proposed ChestXRayBERT demonstrates the feasibility and promise of tailoring and extending advanced NLP techniques to the domain of medical imaging and radiology, as well as in the broader biomedicine and healthcare fields in the future.},
  keywords={Radiology;Task analysis;Biomedical imaging;Decoding;Bit error rate;Biological system modeling;Transformers;Pre-trained language model;chest radiology report;abstractive summarization},
  doi={10.1109/TMM.2021.3132724},
  ISSN={1941-0077},
  month={},}@ARTICLE{10190115,
  author={Xu, Hongming and Xu, Qi and Cong, Fengyu and Kang, Jeonghyun and Han, Chu and Liu, Zaiyi and Madabhushi, Anant and Lu, Cheng},
  journal={IEEE Reviews in Biomedical Engineering}, 
  title={Vision Transformers for Computational Histopathology}, 
  year={2024},
  volume={17},
  number={},
  pages={63-79},
  abstract={Computational histopathology is focused on the automatic analysis of rich phenotypic information contained in gigabyte whole slide images, aiming at providing cancer patients with more accurate diagnosis, prognosis, and treatment recommendations. Nowadays deep learning is the mainstream methodological choice in computational histopathology. Transformer, as the latest technological advance in deep learning, learns feature representations and global dependencies based on self-attention mechanisms, which is increasingly gaining prevalence in this field. This article presents a comprehensive review of state-of-the-art vision transformers that have been explored in histopathological image analysis for classification, segmentation, and survival risk regression applications. We first overview preliminary concepts and components built into vision transformers. Various recent applications including whole slide image classification, histological tissue component segmentation, and survival outcome prediction with tailored transformer architectures are then discussed. We finally discuss key challenges revolving around the use of vision transformers and envisioned future perspectives. We hope that this review could provide an elaborate guideline for readers to explore vision transformers in computational histopathology, such that more advanced techniques assisting in the precise diagnosis and treatment of cancer patients could be developed.},
  keywords={Transformers;Histopathology;Cancer;Image analysis;Computational modeling;Deep learning;Medical diagnostic imaging;Computational pathology;deep learning;survey;transformer;whole slide image},
  doi={10.1109/RBME.2023.3297604},
  ISSN={1941-1189},
  month={},}@INPROCEEDINGS{9747048,
  author={Hung, Yun-Ning and Wang, Ju-Chiang and Song, Xuchen and Lu, Wei-Tsung and Won, Minz},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Modeling Beats and Downbeats with a Time-Frequency Transformer}, 
  year={2022},
  volume={},
  number={},
  pages={401-405},
  abstract={Transformer is a successful deep neural network (DNN) architecture that has shown its versatility not only in natural language processing but also in music information retrieval (MIR). In this paper, we present a novel Transformer-based approach to tackle beat and downbeat tracking. This approach employs SpecTNT (Spectral- Temporal Transformer in Transformer), a variant of Transformer that models both spectral and temporal dimensions of a time-frequency input of music audio. A SpecTNT model uses a stack of blocks, where each consists of two levels of Transformer encoders. The lower-level (or spectral) encoder handles the spectral features and enables the model to pay attention to harmonic components of each frame. Since downbeats indicate bar boundaries and are often accompanied by harmonic changes, this step may help downbeat modeling. The upper-level (or temporal) encoder aggregates useful local spectral information to pay attention to beat/downbeat positions. We also propose an architecture that combines SpecTNT with a state-of- the-art model, Temporal Convolutional Networks (TCN), to further improve the performance. Extensive experiments demonstrate that our approach can significantly outperform TCN in downbeat tracking while maintaining comparable result in beat tracking.},
  keywords={Deep learning;Time-frequency analysis;Convolution;Neural networks;Transformers;Harmonic analysis;Natural language processing;Beat;Downbeat;Transformer;SpecTNT},
  doi={10.1109/ICASSP43922.2022.9747048},
  ISSN={2379-190X},
  month={May},}@ARTICLE{9699076,
  author={Wang, Dafeng and Liu, Hongbo and Wang, Naiyao and Wang, Yiyang and Wang, Hua and McLoone, Seán},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={SEEM: A Sequence Entropy Energy-Based Model for Pedestrian Trajectory All-Then-One Prediction}, 
  year={2023},
  volume={45},
  number={1},
  pages={1070-1086},
  abstract={Predicting the future trajectories of pedestrians is of increasing importance for many applications such as autonomous driving and social robots. Nevertheless, current trajectory prediction models suffer from limitations such as lack of diversity in candidate trajectories, poor accuracy, and instability. In this paper, we propose a novel Sequence Entropy Energy-based Model named SEEM, which consists of a generator network and an energy network. Within SEEM we optimize the sequence entropy by taking advantage of the local variational inference of $f$f-divergence estimation to maximize the mutual information across the generator in order to cover all modes of the trajectory distribution, thereby ensuring SEEM achieves full diversity in candidate trajectory generation. Then, we introduce a probability distribution clipping mechanism to draw samples towards regions of high probability in the trajectory latent space, while our energy network determines which trajectory is most representative of the ground truth. This dual approach is our so-called all-then-one strategy. Finally, a zero-centered potential energy regularization is proposed to ensure stability and convergence of the training process. Through experiments on both synthetic and public benchmark datasets, SEEM is shown to substantially outperform the current state-of-the-art approaches in terms of diversity, accuracy and stability of pedestrian trajectory prediction.},
  keywords={Trajectory;Predictive models;Generators;Entropy;Stability analysis;Potential energy;Training;Trajectory prediction;mutual information;variational inference;potential energy regularization},
  doi={10.1109/TPAMI.2022.3147639},
  ISSN={1939-3539},
  month={Jan},}@ARTICLE{10416861,
  author={Ayinla, Shehu Lukman and Aziz, Azrina Abd and Drieberg, Micheal},
  journal={IEEE Access}, 
  title={SALLoc: An Accurate Target Localization in WiFi-Enabled Indoor Environments via SAE-ALSTM}, 
  year={2024},
  volume={12},
  number={},
  pages={19694-19710},
  abstract={Developing a reliable and accurate indoor localization system is a crucial step for creating a seamless and interactive user-device experience in nearly all intelligent internet of things (IIoTs) and smart applications. Indoor localization systems based on WiFi fingerprinting have been considered as a promising alternative to model-based approaches owing to their accuracy, low cost, availability, and ease of configuration. However, recent studies have revealed that in complex environments, WiFi fingerprinting techniques are faced with a lot of challenges as the coverage area increases. These challenges include fingerprint spatial uncertainty, instability in the received signal strength indicator (RSSI) and discrepancy in fingerprint distribution. Furthermore, there is frequent need for database upgrades or even recreation whenever there is a change in the architecture of the location. These challenges have questioned the robustness and efficiency of most of the existing schemes. In this paper, we present an indoor localization architecture for complex multi-building multi-floor location prediction and subsequently propose SALLoc (SAE-ALSTM Localization), a WiFi fingerprinting indoor localization scheme based on Stacked Autoencoder (SAE) and Attention-based Long Short-Time Memory (ALSTM) framework. Firstly, stratified sampling technique is used to separate validation set from the entire uneven RSSI training set which ensures that the same proportion of RSSI samples are present in both sets. Secondly, SAE is utilized to select core features and decrease the dimensions of the RSSI samples. Finally, ALSTM is trained to focus on these features to achieve robust location prediction. Extensive investigations were conducted using UJIIndoorLoc, Tampere and UTSIndoorLoc datasets, and the results obtained demonstrated the superiority of the proposed scheme in terms of prediction accuracy, robustness, and generalizations when compared to state-of-the-art methods. The mean localization error (MLE) on UJIIndoorLoc, Tampere and UTSIndoorLoc datasets are 8.28 m, 9.52 m, and 6.48 m respectively. Consequently, it can be concluded that the proposed scheme is accurate and well-suited for large-scale indoor environment location prediction.},
  keywords={Location awareness;Fingerprint recognition;Wireless fidelity;Feature extraction;Robustness;Target tracking;Databases;WiFi fingerprinting;indoor localization;mean localization error;stacked autoencoder;long short-time memory;attention mechanism},
  doi={10.1109/ACCESS.2024.3360228},
  ISSN={2169-3536},
  month={},}@ARTICLE{9627584,
  author={Jin, Di and Yu, Zhizhi and He, Dongxiao and Yang, Carl and Yu, Philip S. and Han, Jiawei},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={GCN for HIN via Implicit Utilization of Attention and Meta-Paths}, 
  year={2023},
  volume={35},
  number={4},
  pages={3925-3937},
  abstract={Heterogeneous information network (HIN) embedding, aiming to map the structure and semantic information in a HIN to distributed representations, has drawn considerable research attention. Graph neural networks for HIN embeddings typically adopt a hierarchical attention (including node-level and meta-path-level attentions) to capture the information from meta-path-based neighbors. However, this complicated attention structure often cannot achieve the function of selecting meta-paths due to severe overfitting. Moreover, when propagating information, these methods do not distinguish direct (one-hop) meta-paths from indirect (multi-hop) ones. But from the perspective of network science, direct relationships are often believed to be more essential, which can only be used to model direct information propagation. To address these limitations, we propose a novel neural network method via implicitly utilizing attention and meta-paths, which can relieve the severe overfitting brought by the current over-parameterized attention mechanisms on HIN. We first use the multi-layer graph convolutional network (GCN) framework, which performs a discriminative aggregation at each layer, along with stacking the information propagation of direct linked meta-paths layer-by-layer, realizing the function of attentions for selecting meta-paths in an indirect way. We then give an effective relaxation and improvement via introducing a new propagation operation which can be separated from aggregation. That is, we first model the whole propagation process with well-defined probabilistic diffusion dynamics, and then introduce a random graph-based constraint which allows it to reduce noise with the increase of layers. Extensive experiments demonstrate the superiority of the new approach over state-of-the-art methods.},
  keywords={Motion pictures;Graph neural networks;Training;Task analysis;Computer science;Stacking;Semantics;Heterogeneous information networks;graph neural networks;network embedding},
  doi={10.1109/TKDE.2021.3130712},
  ISSN={1558-2191},
  month={April},}@ARTICLE{10449677,
  author={Mustafa, Ahmad and Rastegar, Reza and Brown, Tim and Nunes, Gregory and Delilla, Daniel and Alregib, Ghassan},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Visual Attention-Guided Learning With Incomplete Labels for Seismic Fault Interpretation}, 
  year={2024},
  volume={62},
  number={},
  pages={1-12},
  abstract={Annotating geological faults on 3-D seismic volumes is a laborious process. Typically, only a fraction of the actual faults are manually interpreted, leaving many others unlabeled. This is due to the way attention selectivity works to drive human perception. The human brain selectively focuses its attention on certain salient regions in a visual scene marked by prominent changes in color, contrast, and other low-level signal cues. This bottom-up attention is further modulated by the individual’s goals, expectations, and constraints with respect to the task at hand, also called top-down attention. The fault annotations created by seismic interpreters reflect this cognitive process comprising both bottom-up and top-down attentional mechanisms. The 3-D convolutional neural networks (CNNs) pretrained on synthetic seismic data for fault mapping can be finetuned on select seismic lines extracted and labeled on a real seismic volume of interest. Traditional finetuning approaches treat all pixels on labeled sections as the absolute ground truth. This leads to the network incorrectly learning to predict regions of missing fault labels as negatives. We propose an attention-guided training framework that models and incorporates human visual attention to: 1) condition the process of sampling training data and 2) modulate the loss value for each pixel. Through quantitative and qualitative evaluation of results on a real seismic volume from North Western Australia, we demonstrate that the proposed approach is able to predict both the annotated and the unlabeled faults significantly better compared to baseline approaches.},
  keywords={Visualization;Training;Three-dimensional displays;Data models;Annotations;Task analysis;Surveys;Deep learning (DL);fault interpretation;finetuning;visual attention},
  doi={10.1109/TGRS.2024.3370037},
  ISSN={1558-0644},
  month={},}@ARTICLE{9330796,
  author={Fu, Tianfan and Xiao, Cao and Glass, Lucas M. and Sun, Jimeng},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={MOLER: Incorporate Molecule-Level Reward to Enhance Deep Generative Model for Molecule Optimization}, 
  year={2022},
  volume={34},
  number={11},
  pages={5459-5471},
  abstract={The goal of molecular optimization is to generate molecules similar to a target molecule but with better chemical properties. Deep generative models have shown great success in molecule optimization. However, due to the iterative local generation process of deep generative models, the resulting molecules can significantly deviate from the input in molecular similarity and size, leading to poor chemical properties. The key issue here is that the existing deep generative models restrict their attention on substructure-level generation without considering the entire molecule as a whole. To address this challenge, we propose Molecule-Level Reward functions (MOLER) to encourage (1) the input and the generated molecule to be similar, and to ensure (2) the generated molecule has a similar size to the input. The proposed method can be combined with various deep generative models. Policy gradient technique is introduced to optimize reward-based objectives with small computational overhead. Empirical studies show that MOLER achieves up to 20.2% relative improvement in success rate over the best baseline method on several properties, including QED, DRD2 and LogP.},
  keywords={Optimization;Chemicals;Junctions;Drugs;Maximum likelihood estimation;Task analysis;Reinforcement learning;Automatic molecule optimization;generative models;molecule generation;drug discovery},
  doi={10.1109/TKDE.2021.3052150},
  ISSN={1558-2191},
  month={Nov},}@ARTICLE{9841611,
  author={Watcharasupat, Karn N. and Ooi, Kenneth and Lam, Bhan and Wong, Trevor and Ong, Zhen-Ting and Gan, Woon-Seng},
  journal={IEEE Signal Processing Letters}, 
  title={Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker and Gain}, 
  year={2022},
  volume={29},
  number={},
  pages={1749-1753},
  abstract={The selection of maskers and playback gain levels in an in-situ soundscape augmentation system is crucial to its effectiveness in improving the overall acoustic comfort of a given environment. Traditionally, the selection of appropriate maskers and gain levels has been informed by expert opinion, which may not be representative of the target population, or by listening tests, which can be time- and labor-intensive. Furthermore, the resulting static choices of masker and gain are often inflexible to dynamic real-world soundscapes. In this work, we utilized a deep learning model to perform joint selection of the optimal masker and its gain level for a given soundscape. The proposed model was designed with highly modular building blocks, allowing for an optimized inference process that can quickly search through a large number of masker-gain combinations. In addition, we introduced the use of feature-domain soundscape augmentation conditioned on the digital gain level, eliminating the computationally expensive waveform-domain mixing process during inference, as well as the tedious gain adjustment process required for new maskers. The proposed system was evaluated on a large-scale dataset of subjective responses to augmented soundscapes with 442 participants, with the best model achieving a mean squared error of 0.122±0.005 on pleasantness score, validating the ability of the model to predict combined effect of the masker and its gain level on the perceptual pleasantness level. The proposed system thus allows in-situ or mixed-reality soundscape augmentation to be performed autonomously with near real-time latency while continuously accounting for changes in acoustic environments.},
  keywords={Recording;Psychoacoustic models;Feature extraction;Predictive models;Computational modeling;Acoustics;Convolution;Affective computing;attention;deep learning;soundscape augmentation},
  doi={10.1109/LSP.2022.3194419},
  ISSN={1558-2361},
  month={},}@ARTICLE{10459340,
  author={Shokouhmand, Arash and Jiang, Xinyu and Ayazi, Farrokh and Ebadi, Negar},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={MEMS Fingertip Strain Plethysmography for Cuffless Estimation of Blood Pressure}, 
  year={2024},
  volume={28},
  number={5},
  pages={2699-2712},
  abstract={Objective: To develop a cuffless method for estimating blood pressure (BP) from fingertip strain plethysmography (SPG) recordings. Methods: A custom-built micro-electromechanical systems (MEMS) strain sensor is employed to record heartbeat-induced vibrations at the fingertip. An XGboost regressor is then trained to relate SPG recordings to beat-to-beat systolic BP (SBP), diastolic BP (DBP), mean arterial pressure (MAP) values. For this purpose, each SPG segment in this setup is represented by a feature vector consisting of cardiac time interval, amplitude features, statistical properties, and demographic information of the subjects. In addition, a novel concept, coined geometric features, are introduced and incorporated into the feature space to further encode the dynamics in SPG recordings. The performance of the regressor is assessed on 32 healthy subjects through 5-fold cross-validation (5-CV) and leave-subject-out cross validation (LSOCV). Results: Mean absolute errors (MAEs) of 3.88 mmHg and 5.45 mmHg were achieved for DBP and SBP estimations, respectively, in the 5-CV setting. LSOCV yielded MAEs of 8.16 mmHg for DBP and 16.81 mmHg for SBP. Through feature importance analysis, 3 geometric and 26 integral-related features introduced in this work were identified as primary contributors to BP estimation. The method exhibited robustness against variations in blood pressure level (normal to critical) and body mass index (underweight to obese), with MAE ranges of [1.28, 4.28] mmHg and [2.64, 7.52] mmHg, respectively. Conclusion: The findings suggest high potential for SPG-based BP estimation at the fingertip. Significance: This study presents a fundamental step towards the augmentation of optical sensors that are susceptible to dark skin tones.},
  keywords={Blood pressure;Biomedical monitoring;Estimation;Strain;Capacitive sensors;Micromechanical devices;Monitoring;Blood pressure (BP);MEMS strain sensor;fingertip;strain plethysmography (SPG);XGBoost;geometric features},
  doi={10.1109/JBHI.2024.3372968},
  ISSN={2168-2208},
  month={May},}@INPROCEEDINGS{10446500,
  author={Ling, Jiajun and Chen, Yifan and Cheng, Qimin and Huang, Xiao},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Zigzag Attention: A Structural Aware Module For Lane Detection}, 
  year={2024},
  volume={},
  number={},
  pages={4175-4179},
  abstract={Lane detection presents a formidable challenge in the realm of autonomous driving, given the real-time processing demands, diverse acquisition conditions, and the unique elongated and angular characteristics of lane lines. While a multitude of network design strategies have been proposed to tackle this challenge, few effectively address the distinct morphology of lane lines. Approaches that leverage global relationships across all positions, e.g. attention mechanisms, are often hard to meet real-time processing requirements due to their computational complexity. To address these challenges and unique attributes of lane lines, including issues like occlusion and dashed lines, we present a specialized and plug-and-play attention module. It employs zigzag transformations to cohesively assemble spatially disparate, lane-relevant regions, thereby transforming the challenge into one of localized feature learning, which can be easily enhanced via lightweight convolutions and fully connected layers. Additionally, we harness the symmetry inherent in lane lines to bolster the learning process and enhance accuracy. Comprehensive experimentation validates the efficacy of our proposed module across a range of algorithms, demonstrating superior performance metrics, including parameters, computational complexity, and runtime, when compared to other attention approaches.},
  keywords={Representation learning;Runtime;Lane detection;Convolution;Signal processing algorithms;Morphology;Real-time systems;Lane detection;structural awareness;zigzag transformation;attention module},
  doi={10.1109/ICASSP48485.2024.10446500},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10834537,
  author={Yin, Junwei and Gao, Min and Shu, Kai and Zhao, Zehua and Huang, Yinqiu and Wang, Jia},
  journal={IEEE Transactions on Big Data}, 
  title={Emulating Reader Behaviors for Fake News Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={The wide dissemination of fake news has affected our lives in many aspects, making fake news detection important and attracting increasing attention. Existing approaches make substantial contributions in this field by modeling news from a single-modal or multi-modal perspective. However, these modal-based methods can result in sub-optimal outcomes as they ignore reader behaviors in news consumption and authenticity verification. For instance, they haven't taken into consideration the component-by-component reading process: from the headline, images, comments, to the body, which is essential for modeling news with more granularity. To this end, we propose an approach of Emulating the behaviors of readers (Ember) for fake news detection on social media, incorporating readers' reading and verificating process to model news from the component perspective thoroughly. Specifically, we first construct intra-component feature extractors to emulate the behaviors of semantic analyzing on each component. Then, we design a module that comprises inter-component feature extractors and a sequence-based aggregator. This module mimics the process of verifying the correlation between components and the overall reading and verification sequence. Thus, Ember can handle the news with various components by emulating corresponding sequences. We conduct extensive experiments on nine real-world datasets, and the results demonstrate the superiority of Ember.},
  keywords={Feature extraction;Fake news;Social networking (online);Semantics;Visualization;Detectors;Big Data;Refining;Noise;MIMICs;Fake news detection;multimedia;multi-modal;information fusion},
  doi={10.1109/TBDATA.2025.3527230},
  ISSN={2332-7790},
  month={},}@ARTICLE{10742485,
  author={Wang, Dezheng and Liu, Rongjie and Chen, Congyan and Li, Shihua},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={MPM: Multi Patterns Memory Model for Short-Term Time Series Forecasting}, 
  year={2025},
  volume={37},
  number={1},
  pages={438-448},
  abstract={Short-term time series forecasting is pivotal in various scientific and industrial fields. Recent advancements in deep learning-based technologies have significantly improved the efficiency and accuracy of short-term time series modeling. Despite advancements, current time short-term series forecasting methods typically emphasize modeling dependencies across time stamps but frequently overlook inter-variable dependencies, which is crucial for multivariate forecasting. We propose a multi patterns memory model discovering various dependency patterns for short-term multivariate time series forecasting to fill the gap. The proposed model is structured around two key components: the short-term memory block and the long-term memory block. These networks are distinctively characterized by their use of asymmetric convolution, each tailored to process the various spatial-temporal dependencies among data. Experimental results show that the proposed model demonstrates competitive performance over the other time series forecasting methods across five benchmark datasets, likely thanks to the asymmetric structure, which can effectively extract the underlying various spatial-temporal dependencies among data.},
  keywords={Time series analysis;Forecasting;Predictive models;Transformers;Long short term memory;Convolution;Computational modeling;Feature extraction;Data models;Attention mechanisms;Asymmetric convolution;multi patterns memory model;spatial-temporal dependency;time series forecasting},
  doi={10.1109/TKDE.2024.3490843},
  ISSN={1558-2191},
  month={Jan},}@ARTICLE{10970021,
  author={Li, Zhi and Zheng, Ke and Gao, Lianru and Zi, Nannan and Li, Chengrui},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Feature Reconstruction Guided Fusion Network for Hyperspectral and LiDAR Classification}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={Deep learning has become increasingly popular in hyperspectral image (HSI) and light detection and ranging (LiDAR) data classification, thanks to its powerful feature learning and representation capabilities. However, HSI often contains substantial redundant information, which can hinder efficient data utilization. Furthermore, the significant disparity in information content between HSI and LiDAR data poses a major challenge in representing and aligning semantic information across these two modalities. To address these challenges, we propose a fusion network structure guided by feature reconstruction embedding (FRE). This approach employs feature decomposition to reconstruct HSI features and incorporates weight embedding to seamlessly integrate the reconstructed information into classification features. Furthermore, we introduce a cross-modal attention fusion module designed to merge extracted HSI and LiDAR features. This module fully exploits the complementary nature of these two type of feature, facilitating effective information exchange and semantic alignment across multimodal data. We evaluated our method on three widely used HSI and LiDAR datasets: Houston 2013, Augsburg, and MUUFL. Experimental results demonstrate that our proposed FRGFNet significantly outperforms traditional probabilistic methods and state-of-the-art deep learning networks, showcasing its effectiveness in multisource data fusion.},
  keywords={Feature extraction;Laser radar;Image reconstruction;Dimensionality reduction;Principal component analysis;Deep learning;Hyperspectral imaging;Data mining;Visualization;Semantics;Classification;fusion;hyperspectral images (HSIs);light detection and ranging (LiDAR);multimodel remote sensing},
  doi={10.1109/TGRS.2025.3562246},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{11035276,
  author={Ahmed, Ahsan and Aktarujjaman, Md and Moniruzzaman, Mohammad and Uddin, Md Shahab and Ahmed, Mumtahina and Hasan, Md Nahid},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={Transformer-Based Threat Detection in Blockchain Healthcare Transactions}, 
  year={2025},
  volume={},
  number={},
  pages={739-744},
  abstract={Blockchain-based healthcare systems offer enhanced security and data integrity, yet remain vulnerable to fraudulent transactions and unauthorized access. This study proposes a novel hybrid autoencoder-transformer model for anomaly detection in blockchain healthcare transactions, integrating graph convolutional networks (GCNs) for structured data representation, transformers for capturing long-range dependencies, and contrastive learning for improved fraud detection. The model was evaluated on a large-scale healthcare transaction dataset with over 1 million records. Experimental results demonstrate that the proposed approach achieves an accuracy of 94.7%, outperforming traditional machine learning models such as random forests (85.2%) and XGBoost (87.5%), as well as deep learning methods like LSTMs (89.1%) and CNNL-STMs (91.2%). Ablation studies highlight the importance of each component, with the removal of the GCN reducing accuracy by 2.9%. The model maintains an F1-score of 93.0% even under adversarial perturbations. Despite computational overhead, the proposed framework provides a robust and scalable solution for real-time threat detection in decentralized healthcare systems. Future work will explore self-supervised learning and adaptive transformer architectures to further improve model efficiency and generalizability.},
  keywords={Deep learning;Adaptation models;Graph convolutional networks;Computational modeling;Autoencoders;Medical services;Transformers;Threat assessment;Blockchains;Security;Blockchain security;healthcare transactions;anomaly detection;deep learning;transformer models;autoencoder;and graph convolutional networks},
  doi={10.1109/ICPCSN65854.2025.11035276},
  ISSN={},
  month={May},}@ARTICLE{10835225,
  author={Li, Zhuoyi and Chen, Beibei and Zhu, Ning and Li, Wenjun and Liu, Tianming and Guo, Lei and Han, Junwei and Zhang, Tuo and Yan, Zhiqiang},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Epileptic Seizure Detection in SEEG Signals Using a Signal Embedding Temporal-Spatial–Spectral Transformer Model}, 
  year={2025},
  volume={74},
  number={},
  pages={1-11},
  abstract={High-performance methods for automated detection of epileptic stereo-electroencephalography (SEEG) have important clinical research implications, improving the diagnostic efficiency and reducing physician burden. However, few studies have been able to consider the process of seizure propagation, thus failing to fully capture the deep representations and variations in SEEG in the temporal, spatial, and spectral domains. In this article, we construct a novel long-term SEEG seizure dataset (XJSZ dataset) and propose signal embedding temporal-spatial–spectral transformer (SE-TSS-Transformer) framework. First, we design signal embedding (SE) module to reduce feature dimensions and adaptively construct optimal representation for subsequent analysis. Second, we integrate unified multiscale temporal-spatial–spectral (TSS) analysis to capture multilevel, multidomain deep features. Finally, we use the transformer encoder to learn the global relevance of features, enhancing the network’s ability to express SEEG features. Experimental results demonstrate state-of-the-art detection performance on the XJSZ dataset, achieving sensitivity, specificity, and accuracy of 99.03%, 99.34%, and 99.03%, respectively. Furthermore, we validate the scalability of the proposed framework on two public datasets of different signal sources, demonstrating the power of the SE-TSS-Transformer framework for capturing diverse multiscale TSS patterns in seizure detection.},
  keywords={Electroencephalography;Epilepsy;Feature extraction;Transformers;Electrodes;Brain modeling;Hospitals;Convolution;Scalability;Neurosurgery;Epileptic seizure detection;multiscale analyse;stereo-electroencephalography (SEEG);transformer},
  doi={10.1109/TIM.2025.3527489},
  ISSN={1557-9662},
  month={},}@ARTICLE{11053757,
  author={Bao, Yida and Zhang, Zheng and Arifuzzaman, Mohammad and Duc Le, Tran and Li, Qi and Mwanza, Masuzyo and Lin, Jiaqing and Gaillard, Philippe and Ye, Jiafeng},
  journal={IEEE Access}, 
  title={Developing Effective Techniques for the Recognition of Shanghai Dialect Text}, 
  year={2025},
  volume={13},
  number={},
  pages={111802-111813},
  abstract={Recognizing Shanghai dialect text is crucial for preserving local dialects, yet research on its automatic distinction from Standard Mandarin remains limited. We construct a carefully balanced dataset specifically for the task of Shanghai dialect recognition and propose a two-stage approach for automatic language classification. In the first stage, we employ Jieba tokenization to retain dialect-specific lexical nuances, ensuring essential semantic and syntactic distinctions are captured. Next, we independently train both a BERT-Chinese-Based classifier and a traditional Support Vector Machine classifier for dialect recognition. The BERT model leverages powerful contextual representations to capture subtle differences between Shanghai dialect and Standard Mandarin, while the Support Vector Machine serves as a conventional baseline. Extensive experiments comparing the two approaches revealed that, although the Support Vector Machine can adequately perform the classification task, the BERT-Based classifier achieves significantly higher accuracy and is more sensitive to the nuanced linguistic features of the dialect. Further analysis through attention visualization reveals how the model specifically attends to unique dialectal features, highlighting distinctive lexical and structural differences between Shanghai dialect and Mandarin text. To the best of our knowledge, this study is the first to apply NLP techniques for language classification between Shanghai dialect and Standard Mandarin, emphasizing the potential for automated dialect recognition as an effective method for dialect documentation and preservation.},
  keywords={Support vector machines;Cultural differences;Phonetics;Accuracy;Text recognition;Standards;Urban areas;Global communication;Vocabulary;Translation;BERT;support vector machine;cultural heritage preservation;Jieba;Shanghai dialect},
  doi={10.1109/ACCESS.2025.3583708},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10939663,
  author={Imhof, Greta and Kanta, Aikaterini and Scanlon, Mark},
  booktitle={2024 Cyber Research Conference - Ireland (Cyber-RCI)}, 
  title={Context-based Password Cracking Dictionary Expansion Using Generative Pre-trained Transformers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the rise of online criminal activity leading to the increasing importance of digital forensics, efficient and effective password-cracking tools are necessary to collect evidence in a timely manner, leading to solved crimes. Recent advances in machine learning and artificial intelligence have led to the development of context-based and large language model approaches, significantly improving the accuracy and efficiency of password cracking. This work focusses on these more modern techniques, specifically creating context-based contextual password dictionaries through training a series of PassGPTs, a large language model capable of creating password candidates from leaked password dictionary lists. This paper explores possible improvements in password cracking techniques to help law enforcement agencies in digital forensic investigations by combining PassGPT with a contextual approach.},
  keywords={Training;Dictionaries;Accuracy;Law enforcement;Large language models;Digital forensics;Passwords;Machine learning;Transformers;Context modeling;Password cracking;dictionary lists;artificial intelligence;large language models;context-based decryption},
  doi={10.1109/Cyber-RCI60769.2024.10939663},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10890185,
  author={Yen, Hao and Ling, Shaoshi and Ye, Guoli},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Efficient Long-Form Speech Recognition for General Speech In-Context Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={We propose a novel approach to end-to-end automatic speech recognition (ASR) to achieve efficient speech in-context learning (SICL) for (i) long-form speech decoding, (ii) test-time speaker adaptation, and (iii) test-time contextual biasing. Specifically, we introduce an attention-based encoder-decoder (AED) model with SICL capability (referred to as SICL-AED), where the decoder utilizes an utterance-level cross-attention to integrate information from the encoder’s output efficiently, and a document-level self-attention to learn contextual information. Evaluated on the benchmark TEDLIUM3 dataset, SICL-AED achieves an 8.64% relative word error rate (WER) reduction compared to a baseline utterance-level AED model by leveraging previously decoded outputs as in-context examples. It also demonstrates comparable performance to conventional long-form AED systems with significantly reduced runtime and memory complexity. Additionally, we introduce an in-context fine-tuning (ICFT) technique that further enhances SICL effectiveness during inference. Experiments on speaker adaptation and contextual biasing highlight the general speech in-context learning capabilities of our system, achieving effective results with provided contexts. Without specific fine-tuning, SICL-AED matches the performance of supervised AED baselines for speaker adaptation and improves entity recall by 64% for contextual biasing task.},
  keywords={Adaptation models;Runtime;Error analysis;Computational modeling;Speech recognition;Signal processing;Decoding;Computational efficiency;Speech processing;Context modeling;long-form speech recognition;speech in-context learning;speaker adaptation;contextual biasing},
  doi={10.1109/ICASSP49660.2025.10890185},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10447438,
  author={Tang, Jiyang and Kim, Kwangyoun and Shon, Suwon and Wu, Felix and Sridhar, Prashant},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improving ASR Contextual Biasing with Guided Attention}, 
  year={2024},
  volume={},
  number={},
  pages={12096-12100},
  abstract={In this paper, we propose a Guided Attention (GA) auxiliary training loss, which improves the effectiveness and robustness of automatic speech recognition (ASR) contextual biasing without introducing additional parameters. A common challenge in previous literature is that the word error rate (WER) reduction brought by contextual biasing diminishes as the number of bias phrases increases. To address this challenge, we employ a GA loss as an additional training objective besides the Transducer loss. The proposed GA loss aims to teach the cross attention how to align bias phrases with text tokens or audio frames. Compared to studies with similar motivations, the proposed loss operates directly on the cross attention weights and is easier to implement. Through extensive experiments based on Conformer Transducer with Contextual Adapter, we demonstrate that the proposed method not only leads to a lower WER but also retains its effectiveness as the number of bias phrases increases. Specifically, the GA loss decreases the WER of rare vocabularies by up to 19.2% on LibriSpeech compared to the contextual biasing baseline, and up to 49.3% compared to a vanilla Transducer.},
  keywords={Training;Vocabulary;Transducers;Filtering;Error analysis;Signal processing;Robustness;Speech Recognition;Contextual Biasing},
  doi={10.1109/ICASSP48485.2024.10447438},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10500277,
  author={Brantley, Preston and Chang, Yusun and Voicu, Razvan Cristian},
  booktitle={SoutheastCon 2024}, 
  title={Its All About Context}, 
  year={2024},
  volume={},
  number={},
  pages={1382-1387},
  abstract={This paper presents an innovative approach to enhancing context understanding in Generative Pretrained Models (GPTs), a critical step towards achieving Artificial General Intelligence (AGI). While GPTs have significantly advanced natural language processing, their understanding of context remains predominantly limited to linguistic structure. To address this limitation, we introduce a novel layer in the transformer model architecture that computes context weights, integrating both immediate and temporally decaying influences of past tokens. This layer is strategically positioned after the self-attention and before the feed-forward layers, enabling a more nuanced interpretation of sequential language data. Our approach involves the formulation of a decaying temporal factor, which allows the model to consider not only the immediate relevance of tokens but also their historical context. This factor is dynamically adjustable, offering a sophisticated method of context weighting that considers both current and extended contexts. The integration of this context weight into the self-attention mechanism enhances the model's capacity for a deeper, more accurate understanding of language, pushing the boundaries of current AI capabilities towards a system that mirrors human-like intelligence. Our experimental results demonstrate the efficacy of this approach, showing its potential to significantly contribute to the development of AGI.},
  keywords={Adaptation models;Computational modeling;Decision making;Linguistics;Transformers;Data processing;Natural language processing;Artificial Intelligence (AI);Large Language Models;Aritifical General Intelligence;AGI;Generative Pre-Trained Models},
  doi={10.1109/SoutheastCon52093.2024.10500277},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10356545,
  author={Tang, Shimin and Wang, Changjian and Tian, Fengyu and Xu, Kele and Xu, Minpeng},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={DGSNet: Dual Graph Structure Network for Emotion Recognition in Multimodal Conversations}, 
  year={2023},
  volume={},
  number={},
  pages={78-85},
  abstract={Emotion is an intrinsic property of human beings and emotion recognition in conversations (ERC) contributes to developing human-like machines. To fuse different modality information effectively is the key part for multimodal ERC. Current methodologies employ graph convolution network to fuse multimodal information. They perform well in intra-modal fusion, but poor in cross-modal fusion, resulting a weak integration of multimodal information. To address aforementioned problem, in this paper, we propose a dual graph structure network for emotion recognition in multimodal conversations (DGSNet). Specially, the multimodal fusion mechanism based on the dual graph structure network is designed. The heterogeneity features of each modal are extracted through the separated graph and the complementary features of each modal are extracted through the aggregation graph. Then, the local attention mechanism for emotional dependency is designed to constrain the scope and target of the emotion. It enhances the analysis of emotional dependency. To demonstrate the superior performance of our proposed method, we evaluate it on two benchmarks, IEMOCAP and MELD, and the experimental results show that the DGSNet model can fuse multimodal information effectively and improve the performance of emotion recognition.},
  keywords={Emotion recognition;Fuses;Convolution;Benchmark testing;Feature extraction;Transformers;Artificial intelligence;emotion recognition in conversations;multimodal;emotional dependency;graph convolution network},
  doi={10.1109/ICTAI59109.2023.00019},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10356524,
  author={Zhang, Cheng and Cao, Jingxu and Yan, Dongmei and Song, Dawei and Lv, Jinxin},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Which Words Pillar the Semantic Expression of a Sentence?}, 
  year={2023},
  volume={},
  number={},
  pages={791-798},
  abstract={In the realm of machine learning, a profound understanding of sentence semantics holds paramount importance for various applications, notably text classification. Traditionally, this comprehension has been entrusted to deep learning models, despite their computationally intensive nature, particularly when dealing with lengthy sequences. The nuanced impact of individual words within a sentence on semantic expression necessitates a strategic removal of less pertinent words to alleviate the computational burden of the model. Presently, prevailing approaches for word removal predominantly employ methods such as truncation, stop-word elimination and attention mechanisms. Regrettably, these techniques often lack a robust theoretical foundation concerning semantics and interpretability. To bridge this conceptual gap, our study introduces the concept of ‘Semantic Pillar Words’ (SPW) within a sentence, anchored in a Semantic Euclidean space. Here, the semantics of a word are represented as a constellation of semantic points, with a text sequence encapsulating the convex hull of these semantic points of words. We propose a novel method for Semantic Pillar Word extraction, known as ‘SPW-Conv’, which dynamically and interpretably prunes text segments, striving to preserve the semantic pillars inherent in the original text. Our extensive experimentation encompasses three diverse text classification datasets, revealing that SPW-Conv outperforms existing methods. Remarkably, it becomes evident that retaining less than 80% of the words within a sentence suffices to capture its semantics adequately, all while achieving classification accuracy levels comparable to those obtained using the entire original text.},
  keywords={Deep learning;Computational modeling;Semantics;Text categorization;Natural languages;Knowledge based systems;Predictive models;Natural Language Processing;Semantic Pillar Words;Convex hull},
  doi={10.1109/ICTAI59109.2023.00121},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10356501,
  author={Li, Bing and Ma, Can and Gao, Xiyan and Jia, Guangheng},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={An Unsupervised Vision-related Keywords Retrieval and Fusion Method for Visual Storytelling}, 
  year={2023},
  volume={},
  number={},
  pages={784-790},
  abstract={Visual storytelling is a multi-modal generation task aiming to generate a coherent story for a sequence of images. Previous visual storytelling models utilize task-beneficial non-visual features, e.g., emotion, sentiment, or knowledge graph, as additional supplements for visual features to further improve the generation quality of stories. However, these appropriate non-visual features require to be carefully designed and selected by specialized researchers, moreover, high-quality external knowledge sources are not readily available. This increases the development cost of the VST model. To alleviate the above problem, this paper explores mining the knowledge existing in the multi-modal pre-trained models (MM-PTMs). First, we propose an Unsupervised Keywords Retrieval module (UKR), which takes an MM-PTM as the expert to select image-related keywords from a prepared task-related text corpus. The retrieved keywords not only complement and illustrate the visual features of the images but also provide more explicit generative signals to improve the interpretability and controllability of the generation process. Furthermore, we propose a Local Multi-modal Adaptive Fusion module (LMAF) to better fuse the textual and visual features and avoid noise brought by irrelevant keywords. LMAF dynamically aggregates features from both modalities through finer-grained correlation matching. The experimental results on the VST dataset, VIST, show that our proposed method achieves competitive results on several automatic metrics. Comparable results to previous methods can be achieved even if the model does not refer to visual features during story generation.},
  keywords={Measurement;Visualization;Costs;Correlation;Fuses;Process control;Knowledge graphs;Visual Storytelling;multi-modal;text feature},
  doi={10.1109/ICTAI59109.2023.00120},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10622253,
  author={Wei, Zhiwei and Li, Bing and Zhang, Rongqing and Song, Lingyang},
  booktitle={ICC 2024 - IEEE International Conference on Communications}, 
  title={Adaptive Security Service Provisioning for Industrial IoT: Harnessing Deep Reinforcement Learning Within a Slice-Specific Framework}, 
  year={2024},
  volume={},
  number={},
  pages={244-249},
  abstract={The Industrial Internet of Things (IIoT) continues to evolve alongside advancements in 5G and beyond 5G communication technologies, and network slicing has emerged as a promising technique to offer isolated slices and tailored services across industrial use cases, which profoundly affects the traditional security solution. As the future IIoT evolves towards the post-5G era, the anticipated growth in network slices will unavoidably exacerbate challenges in security service management, but developing an adaptive and effective security strategy remains a significant challenge. This study introduces a novel slice-specific IIoT (SSIOT) architecture, meticulously crafted to address the unique security needs of each slice based on network function virtualization. To adapt to the SSIOT, an AI-driven GS2L model is presented, which combines graph convolutional network (GCN) with sequence-to-sequence (Seq2Seq) deep reinforcement learning (DRL). The GS2L offers the network topology explanation module, service request analysis module, and slice-specific distribution extraction module, and adeptly navigates the multifaceted Security Service Function Chain (SSFC) embedding conundrum and resource allocation in slice-specific systems. Comprehensive experimental evaluations underscore GS2L's superiority, showcasing its proficiency in delivering augmented QoS satisfaction while ensuring prudent resource utilization over the learning-based and heuristic benchmark.},
  keywords={Adaptation models;Visualization;Network topology;Navigation;5G mobile communication;Quality of service;Deep reinforcement learning;Network function visualization;DRL;security service function chain;network slice;industrial IoT},
  doi={10.1109/ICC51166.2024.10622253},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{11031922,
  author={Li, Huixin and Fan, Ruozhou and Liu, Jiabin and Li, Yunjie},
  booktitle={2025 IEEE International Radar Conference (RADAR)}, 
  title={Multi-Station Cooperative Radar Signal Deinterleaving Based on Deep Information Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Multi-station radar signal deinterleaving, which aims to distinguish signals from different radar targets with multiple electronic reconnaissance stations, can get more discriminative features compared with single-station deinterleaving. However, it is still a challenging task to find the matched Pulse Description Word (PDW) pairs to obtain the time differences, especially for close-parameter and imbalance signals. To address this problem, it is the first time to propose a multi-station cooperative pulse signal deinterleaving method based on deep information fusion, which can better explore the relationships between multi-station data in a high-dimensional feature space. Firstly, the method initially incorporates position encoding for the pulse sequences from multiple stations, using the arrival times of the pulses. Secondly, it utilizes the self-attention mechanism to fuse pulses from different stations. Finally, U-Net is used to perform deep feature extraction on the associated information and map features to the corresponding radar labels, thus completing the radar signal deinterleaving. Simulation experiments demonstrate that this method effectively deinterleaves closeparameter and imbalance signals, achieving higher deinterleaving accuracy compared to single-station and traditional multi-station cooperative deinterleaving methods.},
  keywords={Deep learning;Accuracy;Attention mechanisms;Fuses;Radar;Reconnaissance;Feature extraction;Encoding;electronic reconnaissance;signal deinterleaving;multi-station cooperation;deep learning},
  doi={10.1109/RADAR52380.2025.11031922},
  ISSN={},
  month={May},}@INPROCEEDINGS{10356416,
  author={Xiang, Yi and Sun, Haoran and Tu, Wenting and Tian, Zejin},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={TSFRN: Integrated Time and Spatial-Frequency domain based on Triple-links Residual Network for Sales Forecasting}, 
  year={2023},
  volume={},
  number={},
  pages={1012-1019},
  abstract={Sales forecasting plays a critical role in optimizing supply chains, reducing costs, and enhancing customer satisfaction within enterprises. The presence of demand volatility, seasonality, and non-linear relationships with products pose higher requirements for forecasting models. Although deep learning models have demonstrated promising performance in addressing these challenges, the majority of research has primarily focused on modeling historical sales variations and product interactions in the time domain or solely considered periodic representations in the frequency domain within the models. We propose a novel deep learning model TSFRN based on the triple-links residual networks to integrate the time and frequency domain information in this paper, which consists of a forecast link, spatial-frequency forecast link, and a backward link. Specifically, in each block of the network, we first use a recurrent neural network to obtain a time domain prediction of historical sales as the forecast link. Next, we apply the Fast Fourier Transform (FFT) to obtain the frequency domain representation of sales data. Subsequently, a spatial-frequency domain attention mechanism is proposed in this study to capture spatial interaction patterns within the frequency domain of the sales data. Finally, we obtain the prediction based on the frequency domain through an inverse fast Fourier transform as the spatial-frequency forecast link. For the backward link, we minus the forecast link by the input of the current block. Overall, our proposed framework integrates both time domain and frequency domain information to model the complex interrelationships among products. By taking into account both model construction and practical applications, our framework provides a more accurate, effective, and general approach to sales forecasting. Experimental validation on publicly available datasets demonstrates the effectiveness of our proposed model, which outperforms existing methods in predicting product sales with improved accuracy.},
  keywords={Deep learning;Recurrent neural networks;Fast Fourier transforms;Frequency-domain analysis;Supply chains;Customer satisfaction;Predictive models;Sales forecasting;Multivariate time series;Residual networks;Spatio-frequency attention},
  doi={10.1109/ICTAI59109.2023.00152},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{9684972,
  author={Liu, Xin and Zhao, Jianwei and Li, Jie and Cao, Bin and Lv, Zhihan},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Federated Neural Architecture Search for Medical Data Security}, 
  year={2022},
  volume={18},
  number={8},
  pages={5628-5636},
  abstract={Medical data widely exist in the hospital and personal life, usually across institutions and regions. They have essential diagnostic value and therapeutic significance. The disclosure of patient information causes people’s panic, therefore, medical data security solution is very crucial for intelligent health care. The emergence of federated learning (FL) provides an effective solution, which only transmits model parameters, breaking through the bottleneck of medical data sharing, protecting data security, and avoiding economic losses. Meanwhile, the neural architecture search (NAS) has become a popular method to automatically search the optimal neural architecture for solving complex practical problems. However, few papers have combined the FL and NAS for simultaneous privacy protection and model architecture selection. Convolutional neural network (CNN) has outstanding performance in the image recognition field. Combining CNN and fuzzy rough sets can effectively improve the interpretability of deep neural networks. This article aims to develop a multiobjective convolutional interval type-2 fuzzy rough FL model based on NAS (CIT2FR-FL-NAS) for medical data security with an improved multiobjective evolutionary algorithm. We test the proposed framework on the LC25000 lung and colon histopathological image dataset. Experimental verification demonstrates that the designed multiobjective CIT2FR-FL-NAS framework can achieve high accuracy superior to state-of-the-art models and reduce network complexity under the condition of protecting medical data security.},
  keywords={Fuzzy logic;Medical diagnostic imaging;Data models;Data privacy;Data security;Rough sets;Privacy;Federated learning (FL);interval type-2 fuzzy rough neural network;medical data security;multiobjective evolution;neural architecture search (NAS)},
  doi={10.1109/TII.2022.3144016},
  ISSN={1941-0050},
  month={Aug},}@ARTICLE{9726814,
  author={De, Suparna and Bermudez-Edo, Maria and Xu, Honghui and Cai, Zhipeng},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Deep Generative Models in the Industrial Internet of Things: A Survey}, 
  year={2022},
  volume={18},
  number={9},
  pages={5728-5737},
  abstract={Advances in communication technologies and artificial intelligence are accelerating the paradigm of industrial Internet of Things (IIoT). With IIoT enabling continuous integration of sensors and controllers with the network, intelligent analysis of the generated Big Data is a critical requirement. Although IIoT is considered a subset of IoT, it has its own peculiarities in terms of higher levels of safety, security, and low-latency communication in an environment of critical real-time operations. Under these circumstances, discriminative deep learning (DL) algorithms are unsuitable due to their need for large amounts of labeled and balanced training data, uncertainty of inputs, etc. To overcome these issues, researchers have started using deep generative models (DGMs), which combine the flexibility of DL with the inference power of probabilistic modeling. In this article, we review the state of the art of DGMs and their applicability to IIoT, classifying the reviewed works into the IIoT application areas of anomaly detection, trust-boundary protection, network traffic prediction, and platform monitoring. Following an analysis of existing IIoT DGM implementations, we identify challenges (i.e., weak discriminative capability, insufficient interpretability, lack of generalization ability, generated data vulnerability, privacy concern, and data complexity) that need to be investigated in order to accelerate the adoption of DGMs in IIoT and also propose some potential research directions.},
  keywords={Industrial Internet of Things;Data models;Deep learning;Security;Hidden Markov models;Predictive models;Informatics;Deep generative model (DGM);generative adversarial networks (GANs);industrial Internet of Things (IIoT);survey},
  doi={10.1109/TII.2022.3155656},
  ISSN={1941-0050},
  month={Sep.},}@ARTICLE{9893497,
  author={Park, Hyunwook and Kim, Minsu and Kim, Seongguk and Kim, Keunwoo and Kim, Haeyeon and Shin, Taein and Son, Keeyoung and Sim, Boogyo and Kim, Subin and Jeong, Seungtaek and Hwang, Chulsoon and Kim, Joungho},
  journal={IEEE Transactions on Microwave Theory and Techniques}, 
  title={Transformer Network-Based Reinforcement Learning Method for Power Distribution Network (PDN) Optimization of High Bandwidth Memory (HBM)}, 
  year={2022},
  volume={70},
  number={11},
  pages={4772-4786},
  abstract={In this article, for the first time, we propose a transformer network-based reinforcement learning (RL) method for power distribution network (PDN) optimization of high bandwidth memory (HBM). The proposed method can provide an optimal decoupling capacitor (decap) design to maximize the reduction of PDN self- and transfer impedances seen at multiple ports. An attention-based transformer network is implemented to directly parameterize decap optimization policy. The optimality performance is significantly improved since the attention mechanism has powerful expression to explore massive combinatorial space for decap assignments. Moreover, it can capture sequential relationships between the decap assignments. The computing time for optimization is dramatically reduced due to the reusable network on the positions of probing ports and decap assignment candidates. This is because the transformer network has a context embedding process to capture meta-features including probing ports positions. In addition, the network is trained with randomly generated datasets. The computing time for training and data cost are critically decreased due to the scalability of the network. Due to its shared weight property and the context embedding process, the network can adapt to a larger scale of problems without additional training. For verification, the results are compared with conventional genetic algorithm (GA), random search (RS), and all the previous RL-based methods. As a result, the proposed method outperforms in all the following aspects: optimality performance, computing time, and data efficiency.},
  keywords={Optimization;Transformers;Training;Seaports;Scalability;Bandwidth;Impedance;Decoupling capacitor (decap);high bandwidth memory (HBM);power distribution network (PDN);reinforcement learning (RL);transformer network},
  doi={10.1109/TMTT.2022.3202221},
  ISSN={1557-9670},
  month={Nov},}@ARTICLE{10129830,
  author={Yu, Chenhui and Liu, Yakui and Zhang, Wanru and Zhang, Xue and Zhang, Yuhan and Jiang, Xing},
  journal={IEEE Access}, 
  title={Foreign Objects Identification of Transmission Line Based on Improved YOLOv7}, 
  year={2023},
  volume={11},
  number={},
  pages={51997-52008},
  abstract={As the grid coverage rises, foreign objects invade more and more frequently, causing grid failures to rise every year. To address this issue, this paper proposes a deep learning-based transmission line unmanned inspection of foreign objects recognition algorithm. The algorithm is based on YOLOv7 (You Only Look Once) algorithm, combining with hyperparameter optimization based on genetic algorithm (GA) and space-to-depth (SPD) convolution to complete the foreign object recognition of transmission line Unmanned Aerial Vehicle (UAV) images. The proposed method can promptly determine and locate these targets’ presence in aerial images. Finally, this paper compares the improved YOLOv7 algorithm with other YOLO series algorithms (Faster-rcnn, Centernet, and other target detection models). The comparison results show that the method has the highest Mean Average Precision (mAP) of 92.2% and the Frames Per Second (FPS) of 19 is second only to Centernet. Compared with the unimproved YOLOv7, the average accuracy in the recognition of tower cranes has increased by 11.9%, which is the most obvious improvement in accuracy compared with other detection targets. Meanwhile, the hyperparameter optimization based on genetic algorithm speeds up the convergence of the model.},
  keywords={Power transmission lines;Feature extraction;Inspection;Object detection;Training;Convolutional neural networks;Power grids;Power system reliability;Transmission line;foreign objects;YOLOv7;SPD convolution},
  doi={10.1109/ACCESS.2023.3277954},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10356438,
  author={Panagoulias, Dimitrios P. and Palamidas, Filippos A. and Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Rule-Augmented Artificial Intelligence-empowered Systems for Medical Diagnosis using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={70-77},
  abstract={In this paper, we investigate the enhancement of Artificial Intelligence (AI) technologies in healthcare and the better understanding of medical literature with the use of Large Language Models (LLMs) and Natural Language Processing (NLP). Specifically, we introduce a rule-augmented AI-empowered system which incorporates a rule-based decision system, the ChatGPT application programming interface (API), and other external machine learning and analytical APIs to offer diagnostic suggestions to patients. The complexities of patient healthcare experiences, including doctor-patient interactions, understanding levels, treatment procedures, and preventive care, are considered. We illustrate how a diagnostic process typically integrates various strategies depending on various factors. To digitize the greatest portion of the process, we propose and illustrate the use of LLMs for humanizing the communication process and investigating ways to reduce burdens and costs in primary healthcare. We also outline a theoretical decision model for evaluating the use of technological components from external sources versus building them from scratch. The paper is structured into sections detailing background theories and context, our proposed and implemented rule-augmented AI-empowered system, as well as a system test in a corresponding use case. Finally, the paper key findings are presented, which contribute valuable insights for future work in this field.},
  keywords={Costs;Buildings;Machine learning;Chatbots;Software;Complexity theory;Medical diagnosis;AI-empowered software engineering;explainability;ChatGPT;LLM;NLP;prompt-engineering},
  doi={10.1109/ICTAI59109.2023.00018},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10156432,
  author={Vamvoudakis, Kyriakos G. and Fotiadis, Filippos and Hespanha, João P. and Chinchilla, Raphael and Yang, Guosong and Liu, Mushuang and Shamma, Jeff S. and Pavel, Lacra},
  booktitle={2023 American Control Conference (ACC)}, 
  title={Game Theory for Autonomy: From Min-Max Optimization to Equilibrium and Bounded Rationality Learning}, 
  year={2023},
  volume={},
  number={},
  pages={4363-4380},
  abstract={Finding Nash equilibria in non-cooperative games can be, in general, an exceptionally challenging task. This is owed to various factors, including but not limited to the cost functions of the game being nonconvex/nonconcave, the players of the game having limited information about one another, or even due to issues of computational complexity. The present tutorial draws motivation from this harsh reality and provides methods to approximate Nash or min-max equilibria in non-ideal settings using both optimization- and learning-based techniques. The tutorial acknowledges, however, that such techniques may not always converge, but instead lead to oscillations or even chaos. In that respect, tools from passivity and dissipativity theory are provided, which can offer explanations about these divergent behaviors. Finally, the tutorial highlights that, more frequently than often thought, the search for equilibrium policies is simply vain; instead, bounded rationality and non-equilibrium policies can be more realistic to employ owing to some players’ learning imperfectly or being relatively naive – "bounded rational." The efficacy of such plays is demonstrated in the context of autonomous driving systems, where it is explicitly shown that they can guarantee vehicle safety.},
  keywords={Chaos;Vehicle safety;Tutorials;Games;Cost function;Behavioral sciences;Task analysis},
  doi={10.23919/ACC55779.2023.10156432},
  ISSN={2378-5861},
  month={May},}@ARTICLE{10496154,
  author={Sender, Ted and Brudnak, Mark and Steiger, Reid and Vasudevan, Ram and Epureanu, Bogdan},
  journal={IEEE Robotics and Automation Letters}, 
  title={A Regret-Informed Evolutionary Approach for Generating Adversarial Scenarios for Black-Box Off-Road Autonomy Systems}, 
  year={2024},
  volume={9},
  number={6},
  pages={5354-5361},
  abstract={Developing autonomous vehicles (AVs) that operate in diverse and demanding environments is a difficult challenge. Two fundamental tools that can accelerate this process are testing an AV in diverse simulated environments and identifying core system weaknesses. While most efforts focus on improving these tools for on-road AVs, this letter focuses on an analogous set of tools for off-road AVs. A method called Black-Box Adversarially Compounding Regret Through Evolution (BACRE) is proposed for identifying adversarial scenarios using an evolutionary algorithm guided by a novel regret-based metric for general navigation tasks. A black-box approach is often preferable when system complexity can be diverse, like with off-road AVs, and when whole-system testing is required. A custom simulation platform is also provided to assist with the automated testing of AVs in diverse, unstructured environments. Numerical experiments demonstrate that BACRE's evolutionary process gradually increases scenario complexity to degrade vehicle performance (an effective and explainable process that comparable methods cannot achieve). Consequently, BACRE can streamline AV development by finding weaknesses at any development stage.},
  keywords={Trajectory;Closed box;Testing;Costs;Navigation;Complexity theory;Vehicle dynamics;Planning under uncertainty;simulation and animation;software, middleware and programming environments},
  doi={10.1109/LRA.2024.3387109},
  ISSN={2377-3766},
  month={June},}@INPROCEEDINGS{10063503,
  author={Vaidya, Vivek and Vaidya, Jaideep},
  booktitle={2022 IEEE 4th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={Impact of Dimensionality Reduction on Outlier Detection: an Empirical Study}, 
  year={2022},
  volume={},
  number={},
  pages={150-159},
  abstract={Outlier detection is a fundamental data analytics technique often used for many security applications. Numerous outlier detection techniques exist, and in most cases are used to directly identify outliers without any interaction. Typically the underlying data used is often high dimensional and complex. Even though outliers may be identified, since humans can easily grasp low dimensional spaces, it is difficult for a security expert to understand/visualize why a particular event or record has been identified as an outlier. In this paper we study the extent to which outlier detection techniques work in smaller dimensions and how well dimensional reduction techniques still enable accurate detection of outliers. This can help us to understand the extent to which data can be visualized while still retaining the intrinsic outlyingness of the outliers.},
  keywords={Dimensionality reduction;Privacy;Data analysis;Data visualization;Security;Intelligent systems;Anomaly detection;outlier detection;anomaly detection;dimensionality reduction;visualization;explainability},
  doi={10.1109/TPS-ISA56441.2022.00028},
  ISSN={},
  month={Dec},}@ARTICLE{10758827,
  author={Zhang, Feng and Yang, Chunfeng and You, Linlin and Wang, Xiaojia and Yuan, Yonggui and Jeannès, Régine Le Bouquin and Shu, Huazhong and Xiang, Wentao},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={WS-BiLSTM-MA: Wavelet Scattering-Based BiLSTM With Mixed Attention Block for MDD Recognition Using Multichannel EEG Signals}, 
  year={2025},
  volume={74},
  number={},
  pages={1-13},
  abstract={Major depressive disorder (MDD) recognition using multichannel electroencephalography (EEG) signals has profound clinical value with its richness and accessibility of temporal information, but such signals may suffer from nonstationarity and redundant characteristics. To cope with these problems, the wavelet scattering-based bidirectional long short-term memory network with mixed attention block (WS-BiLSTM-MA) network is proposed with three core modules: 1) wavelet scattering network is applied to build a wavelet scattering matrix which captures the deformation stability information from multichannel cleaned EEG signals; 2) bidirectional long short-term memory network (LSTM) is used to obtain a relevant scattering matrix which learns the potential temporal relationship from the wavelet scattering matrix; and 3) MA block has two self-attention blocks which gain the ability to further redistribute the weights of features and integrate the key comprehensive information from scattering coefficients (SCs) and relevant matrices, respectively. The performance of our proposed WS-BiLSTM-MA network is evaluated on two MDD datasets in both eyes closed (EC) and eyes open (EO) conditions with 19-channel EEG signals: the Hospital University Sains Malaysia (HUSM) dataset and Zhongda Hospital Southeast University (ZHSU) dataset. To ensure subject independence, the leave-one-subject-out validation (LOSO) experiment and blind test (BT) validation experiment are conducted. In leave-one-subject-out experiment, the WS-BILSTM-MA network, with the zeroth-order, first-order, and second-order SCs, presents high performance in terms of classification accuracy, precision, recall, and  $F1$ -score whatever conditions in both the datasets. The BT experiment demonstrates the excellent ability of our framework with only zeroth-order and first-order SCs, where the classification accuracy, precision, recall and  $F1$ -score can reach 98.80%, 99.90%, 99.71%, 99.81% and 99.81%, 99.78%, 99.17%, 99.47% in EC and EO conditions in the HUSM dataset, and 83.29%, 87.97%, 75.65%, 83.60% and 83.41%, 90.59%, 74.20%, 81.58% in EC and EO conditions in the ZHSU dataset, respectively. Compared with some state-of-the-art methods in the HUSM dataset, the WS-BILSTM-MA network can improve the performance of MDD recognition proving its clinical interest.},
  keywords={Electroencephalography;Scattering;Feature extraction;Accuracy;Long short term memory;Hospitals;Electrodes;Convolutional neural networks;Character recognition;Standards;Attention mechanism;bidirectional long short-term memory network (BiLSTM);major depressive disorder (MDD) recognition;multichannel electroencephalography (EEG) signals;wavelet scattering network},
  doi={10.1109/TIM.2024.3502843},
  ISSN={1557-9662},
  month={},}@ARTICLE{10059210,
  author={Lu, Jiaying and Dong, Xiangjue and Yang, Carl},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Weakly Supervised Concept Map Generation Through Task-Guided Graph Translation}, 
  year={2023},
  volume={35},
  number={10},
  pages={10871-10883},
  abstract={Recent years have witnessed the rapid development of concept map generation techniques due to their advantages in providing well-structured summarization of knowledge from free texts. Traditional unsupervised methods do not generate task-oriented concept maps, whereas deep generative models require large amounts of training data. In this work, we present GT-D2G (Graph Translation-based Document To Graph), an automatic concept map generation framework that leverages generalized NLP pipelines to derive semantic-rich initial graphs, and translates them into more concise structures under the weak supervision of downstream task labels. The concept maps generated by GT-D2G can provide interpretable summarization of structured knowledge for the input texts, which are demonstrated through human evaluation and case studies on three real-world corpora. Further experiments on the downstream task of document classification show that GT-D2G beats other concept map generation methods. Moreover, we specifically validate the labeling efficiency of GT-D2G in the label-efficient learning setting and the flexibility of generated graph sizes in controlled hyper-parameter studies.},
  keywords={Task analysis;Pipelines;Training;Moon;Semantics;Labeling;Training data;Concept map generation;document classification;document summarization;graph translation;weak supervision},
  doi={10.1109/TKDE.2023.3252588},
  ISSN={1558-2191},
  month={Oct},}@ARTICLE{9926101,
  author={Wang, Haoyue and Pan, Li and Sun, Jing and Li, Bin and Jiang, Junqiang and Yang, Bo and Li, Wenbin},
  journal={IEEE Access}, 
  title={Centrality Combination Method Based on Feature Selection for Protein Interaction Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={112028-112042},
  abstract={Essential proteins are important participants in various life activities and play a vital role in the survival and reproduction of life. The network-based centrality methods are a common way to identify essential proteins for protein interaction networks. Due to the differences between the existing centrality methods, it is a feasible approach to improve the identification accuracy of essential proteins by combining centrality methods. In this paper, we propose a centrality combination method based on feature selection. First, the measure values of the 14 classical centrality methods are viewed as feature data. Then, a subset of the relevant features is selected according to the importance of features. Finally, the centrality methods corresponding to the selected features are combined by using the geometric mean method for the identification of essential proteins. To verify the effectiveness of the combination method, we apply the combination method on the original static protein interaction network (SPIN), the dynamic protein interaction network (DPIN) and the refined dynamic protein interaction network (RDPIN), and compare the result with those by each single centrality method (LAC, DC, DMNC, NC, TP, CLC, BC, LC, CC, KC, CR, EC, PR, LR). The experimental results on the identification of essential proteins shows that the combination method achieves better results in prediction performance than the 14 centrality mehtods in terms of the prediction precision, sensitivity, specificity, positive predictive value, negative predictive value, F-measure and accuracy rate. It has been illustrated that the proposed method can help to identify essential proteins more accurately.},
  keywords={Proteins;Gene expression;Feature extraction;Correlation;Sensitivity;Redundancy;Topology;Interactive systems;Centrality methods;combination method;essential proteins;feature selection;protein interaction networks},
  doi={10.1109/ACCESS.2022.3216416},
  ISSN={2169-3536},
  month={},}@ARTICLE{10631666,
  author={Jonnalagedda, Padmaja and Weinberg, Brent and Min, Taejin L. and Bhanu, Shiv and Bhanu, Bir},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Comprehensive Radiogenomic Feature Characterization of 19/20 Co-gain in Glioblastoma}, 
  year={2024},
  volume={5},
  number={12},
  pages={6442-6456},
  abstract={The prognosis and treatment planning of glioblastoma multiforme (GBM) involves a holistic analysis of imaging, clinical, and molecular data. The correlation of imaging and molecular features has garnered much interest due to its potential to reduce the number of invasive procedures on a patient and resource utilization of the overall prognostic and treatment planning process. This article detects and characterizes the impact of tumor biomarkers (such as shape, texture, location, and the tissue surrounding the tumor) in detecting a prognostic mutation – the concurrent gain of 19 and 20 chromosomes, and proposes two novel ideas for this analysis. First, to address the challenges associated with the limited, diverse, and complex nature of medical data, this article proposes a novel generative model – the realistic radiogenomic design using disentanglement in generative adversarial networks (R2D2-GAN), designed to recreate highly subtle, unapparent manifestations of mutations in magnetic resonance imaging. It generates high-resolution, diverse data that captures the discriminatory visual features of the molecular markers while tackling the high diversity, unbalanced, and limited GBM data with rare mutations correlating with patient survival such as 19/20 co-gain. Second, this study proposes a quantitative metric called the synthetic image fidelity (SIF) score to evaluate the performance of GANs in learning visually unapparent prognostic features through the use of gradient-based model explanations. Results are compared with current methods.},
  keywords={Tumors;Generative adversarial networks;Task analysis;Shape;Data models;Visualization;Magnetic resonance imaging;GAN evaluation score;generative adversarial networks (GANs);glioblastoma;limited patient data;MRI},
  doi={10.1109/TAI.2024.3440219},
  ISSN={2691-4581},
  month={Dec},}@ARTICLE{10478631,
  author={Van Belle, Rafaël and De Weerdt, Jochen},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={SHINE: A Scalable Heterogeneous Inductive Graph Neural Network for Large Imbalanced Datasets}, 
  year={2024},
  volume={36},
  number={9},
  pages={4904-4915},
  abstract={Research interest in machine learning (ML) for graphs has skyrocketed in recent years. However, non-euclidean graph structures inhibit the application of traditional ML algorithms. Consequently, scholars introduced graph learning algorithms tailored to network data, such as graph neural networks (GNNs). Most GNNs are designed for homogeneous and homophilous graphs and are evaluated on small, static, and balanced datasets, deviating from real-world conditions and industry applications. This paper introduces SHINE, a scalable heterogeneous inductive GNN for large imbalanced datasets. SHINE addresses four key challenges: scalability, network heterogeneity, inductive learning on dynamic graphs, and imbalanced node classification. SHINE comprises three core components: 1) a sampler based on nearest-neighbor (NN) search, 2) a heterogeneous GNN (HGNN) layer with a novel relationship aggregator, and 3) aggregator functions tailored to skewed class distributions. The components of SHINE are evaluated on benchmark datasets, while the integrated benefits of SHINE are demonstrated on two fraud detection datasets.},
  keywords={Graph neural networks;Fraud;Heuristic algorithms;Image edge detection;Classification algorithms;Training;Self-supervised learning;Class imbalance;fraud detection;graph neural network (GNN);heterogeneous graph;inductive node classification},
  doi={10.1109/TKDE.2024.3381240},
  ISSN={1558-2191},
  month={Sep.},}@INPROCEEDINGS{10505432,
  author={Othman, Hiba A. and Zhao, Qi and Chen, Lijiang and Hong, Zhibo and Chen, Yu},
  booktitle={2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)}, 
  title={Auto-FS-Cardiac: Optimizing ECG Heartbeat Classification with Automated Feature Selection using TPOT Template Framework}, 
  year={2023},
  volume={},
  number={},
  pages={179-185},
  abstract={Cardiovascular diseases (CVDs) constitute a significant global health concern with a profound impact on mortality rates. Recent advancements in artificial intelligence (AI) have facilitated the successful application of automated classification methods for cardiac arrhythmias. This paper introduces “Auto-FS-Cardiac,” an innovative automated feature selection model. Leveraging Automated Machine Learning (Au-toML) and the Tree-based Pipeline Optimization Tool (TPOT) framework, the model constructs a classification pipeline aimed at distinguishing between five distinct heartbeats in electro-cardiogram (ECG) data sourced from the MIT-BIH database. The study evaluates the performance of Auto-FS-Cardiac under both automated and predefined human-expert feature selection scenarios. Additionally, a comparative analysis with traditional feature selection models provides insights into the proficiency of Auto-FS-Cardiac in generating optimal pipelines for precise ECG heartbeat classification. Auto-FS-Cardiac performance, achieved an accuracy level of 0.9569 with a rapid execution time of 1.9857 seconds. Notably, when utilizing predefined features, the model maintains a consistent accuracy score of 0.9522, albeit with a longer execution time of 14.7836 seconds. This highlights the model's adaptability in balancing high accuracy and efficiency when autonomously managing the feature selection process. The observed tradeoff between efficiency and interpretability suggests that interventions in feature selection may impact these factors.},
  keywords={Human computer interaction;Adaptation models;Heart beat;Pipelines;Genetic programming;Machine learning;Electrocardiography;AutoML;TPOT;ECG;Machine Learning;Ar-rhythmia;Feature set selector;TPOT-Template - Genetics Programming Introduction},
  doi={10.1109/AIHCIR61661.2023.00037},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10971691,
  author={Herman, Kyle and Chen, Lei},
  booktitle={SoutheastCon 2025}, 
  title={Exploiting DPAPI and Local State Decryption for Web Cookie Session Theft in Cross-Device Chrome Migrations}, 
  year={2025},
  volume={},
  number={},
  pages={862-867},
  abstract={Multifactor Authentication (MFA) has grown in popularity for application and operating system security. In response, cyber criminals have turned to web browser session theft to defeat MFA. With a valid session ID, cyber criminals can bypass username/password and MFA requirements and gain access to sensitive systems such as email. Once accessed, attackers can extract sensitive information from the victim's account and use it for targeted phishing or mass spam campaigns. Prior research has focused on Man-in-the-Middle (MitM) attacks or Cross-Site-Scripting (XSS) attacks from vulnerable servers. A more realistic explanation for the increase in session theft is malware and users who are tricked into installing it. Google Chrome uses Windows Data Protection API (DPAPI) to encrypt and store passwords, session cookies and authentication tokens. To simulate malware, this study utilized a PowerShell script to decrypt the Local State file to defeat DPAPI. The decryption key was then utilized to decrypt the cookies in the SQLite database and provide valid session IDs.},
  keywords={Databases;Operating systems;Phishing;Authentication;Passwords;Session hijacking;Malware;Browsers;Electronic mail;Servers;Session Hijacking;Session Theft;Session ID Theft;Session Fixation Attacks;Cookie Theft;Token Replay Attacks},
  doi={10.1109/SoutheastCon56624.2025.10971691},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10369214,
  author={Karthikram, A. and Saravanan, M.},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={An Optimized Learning Model for Image Denoising using Modern Deep Learning Approaches}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={In the domain of image denoising, the existence of several forms of noise, such as Gaussian, impulse, salt, pepper, and speckle noise, presents considerable obstacles. A viable strategy for resolving this issue is optimized convolutional neural networks (O − CNN) which are receiving more and more attention. Numerous standard CNN techniques have been developed and applied to denoise images with different datasets being used to evaluate their performance. This paper seeks to offer a thorough overview of several CNN image-denoising methods with a meta-heuristic optimization approach known as adaptive wolf optimizer (AWO). The approaches are organized and looked at, and the most popular datasets for analyzing O − CNN image-denoising algorithms are reviewed. A selection of O − CNN-based image-denoising techniques was carefully examined and analyzed in this study. The goals and underlying principles of the O − CNN approach were elucidated. In addition to detailed explanations, certain O – CNN image-denoising techniques were represented graphically. With O − CNN, the suggested reviewing image denoising. The studies on image denoising using O − CNN from the past and present were chosen. Future research directions and potential obstacles were also explained.},
  keywords={Deep learning;Image resolution;Computed tomography;Metaheuristics;Speckle;Feature extraction;Knowledge management;Deep learning;denoising;prediction mechanism;network model;convolutional network},
  doi={10.1109/RMKMATE59243.2023.10369214},
  ISSN={},
  month={Nov},}@ARTICLE{10143211,
  author={Gao, Zhen and Tang, Jin and Xia, Junfeng and Zheng, Chun-Hou and Wei, Pi-Jing},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={CNNGRN: A Convolutional Neural Network-Based Method for Gene Regulatory Network Inference From Bulk Time-Series Expression Data}, 
  year={2023},
  volume={20},
  number={5},
  pages={2853-2861},
  abstract={Gene regulatory networks (GRNs) participate in many biological processes, and reconstructing them plays an important role in systems biology. Although many advanced methods have been proposed for GRN reconstruction, their predictive performance is far from the ideal standard, so it is urgent to design a more effective method to reconstruct GRN. Moreover, most methods only consider the gene expression data, ignoring the network structure information contained in GRN. In this study, we propose a supervised model named CNNGRN, which infers GRN from bulk time-series expression data via convolutional neural network (CNN) model, with a more informative feature. Bulk time series gene expression data imply the intricate regulatory associations between genes, and the network structure feature of ground-truth GRN contains rich neighbor information. Hence, CNNGRN integrates the above two features as model inputs. In addition, CNN is adopted to extract intricate features of genes and infer the potential associations between regulators and target genes. Moreover, feature importance visualization experiments are implemented to seek the key features. Experimental results show that CNNGRN achieved competitive performance on benchmark datasets compared to the state-of-the-art computational methods. Finally, hub genes identified based on CNNGRN have been confirmed to be involved in biological processes through literature.},
  keywords={Gene expression;Convolutional neural networks;Regulators;Data models;Stress;Benchmark testing;Time series analysis;Bulk gene expression;deep learning;gene regulatory network;network visualization},
  doi={10.1109/TCBB.2023.3282212},
  ISSN={1557-9964},
  month={Sep.},}@INPROCEEDINGS{10099996,
  author={Gurumoorthy, Sasikumar and Avikkal, Saritha and M, Rani and Radha, K and N, Rajesh},
  booktitle={2023 IEEE International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={The Application of Machine Learning Algorithms to the Classification of EEG Signals}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={In order to study cognitive states and detect deficiencies in thinking, planning, and judgement, automated cognitive assessment systems have been developed. Having access to the opportunity to collaborate with experts in their working environment is another benefit of these platforms, particularly in services where decisions have direct effects on people's lives. This dissertation assesses the brain's reaction to mental tasks including motor imagery, attention, working memory, mental fatigue, and attention deficit hyperactivity disorder (ADHD). Electroencephalography (EEG), which encodes neuron activity as action potentials, is a popular method for analyzing these cognitive functions. These EEG data are processed using state-of-the-art machine learning algorithms, automating cognitive ability testing in the process. Recent state-of-the-art approaches have shown problems with high dimensionality, irrelevant channels, subject and task variability, generalizability, and interpretability. Because of this, classifications of intelligence are often inaccurate. The use of meta-heuristics to the solution of both continuous and binary optimization problems was found to be very fruitful in this scenario. Despite increased performance in EEG signal processing for other applications, these methods have seen very little exploration in the field of cognitive evaluation. This encourages more research into these meta-heuristics approaches to intelligence testing. It is important to look for the most appropriate optimization strategy for a certain task, since all of them will not work in every circumstance. In order to address problems in cognitive testing, this research looks on parameter-free optimization algorithms that are tailored to each kind of test. One of the main problems that hinders the effectiveness of ML models is its dimensionality. Another is its lack of generalizability. The overarching goal of this proposed work is to build and construct an effective channel selection and feature selection model making use of meta-heuristic optimization approaches in order to solve these problems in the various cognitive state assessment applications addressed thus far. To properly classify mental reactions to motor imagery, we suggest employing sub-band wavelets and relative PSD features, and we use the harmony search optimization technique to identify the most useful features. The suggested feature selection approach may minimize the dimensionality by as much as 60% by selecting the most important characteristics. Less tuning parameters are required in the suggested strategy. However, tuning becomes obligatory in order to get the desired set of characteristics. In the future implementation of cognitive workload evaluation, this shortcoming is fixed.},
  keywords={Visualization;Machine learning algorithms;Metaheuristics;Brain modeling;Feature extraction;Electroencephalography;Task analysis;attention deficit hyperactivity disorder (ADHD);Electroencephalography (EEG);cognitive states and ML models},
  doi={10.1109/ICICACS57338.2023.10099996},
  ISSN={},
  month={Feb},}@ARTICLE{10367795,
  author={Mishra, Varsha and Monorchio, Agostino},
  journal={IEEE Transactions on Electromagnetic Compatibility}, 
  title={Analysis and Design of Microwave Absorbers Combining Surface Wave Attenuation and Reflection Bandwidth Properties}, 
  year={2024},
  volume={66},
  number={1},
  pages={70-79},
  abstract={A new method is outlined in this manuscript to design an optimized microwave absorber (MA) achieving the desired level of reflection bandwidth (RBW) and surface wave attenuation (SWA). The proposed semianalytical two-dimensional dynamic method is best suited for the type of MAs consisting of either single-layer or multilayer impedance surfaces, such as resistive sheets and meta-materials. The proposed work contains the following two aims: 1) computation of the SWA in meta-material-based absorbers and 2) optimization of MA parameters for obtaining the desired level of SWA and RBW. To achieve the first aim, a complete mathematical explanation is outlined in detail, and further, to validate it, a particular example is implemented through which it is possible to simulate and analyze the structure via full-wave simulations. This proposed methodology is further integrated with the multiobjective optimization process of a genetic algorithm to achieve the second aim. Consequently, optimization of MA parameters is carried out and the desired level of outputs (i.e., RBW and SWA) is achieved. The proposed approach is explained by means of various examples of MAs and after detailed analysis, some competitive solutions are achieved. The proposed work can be widely applied in microwave frequency-based electronic devices to avoid surface electromagnetic wave coupling.},
  keywords={Impedance;Surface waves;Surface impedance;Microwave integrated circuits;Propagation constant;Surface morphology;Microwave theory and techniques;Meta-materials;microwave absorbers (MAs);reflection bandwidth (RBW);surface waves attenuation},
  doi={10.1109/TEMC.2023.3339511},
  ISSN={1558-187X},
  month={Feb},}@INPROCEEDINGS{10580058,
  author={Zhu, Ningning and Zhao, Fuqing and Cao, Jie},
  booktitle={2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={A Hyperheuristic and Reinforcement Learning Guided Meta-heuristic Algorithm Recommendation}, 
  year={2024},
  volume={},
  number={},
  pages={1061-1066},
  abstract={Automatic selection of the most appropriate algorithms for complex optimization problems has emerged as a cutting-edge trend in artificial intelligence. This approach circumvents the interpretability challenges posed through trial and error. A hyperheuristic and reinforcement learning-guided meta-heuristic algorithm recommendation (HHRL-MAR) is proposed to facilitate the adaptive selection of a diverse array of meta-heuristic algorithms tailored to the unique characteristics of various problems in this paper. To this end, four meta-heuristics with distinct advantages are integrated to form the action space within the reinforcement learning, serving as the low-level heuristic for hyperheuristic. The incorporated reward mechanism based on the real-time state of the population enhances both the flexibility and accuracy of the algorithm. Three selection strategies in light of simulated annealing and ε–greedy are avoid premature convergence associated with designed to a singular selection approach. The experimental results show the efficacy of HHRL-MAR for large-scale complex continuous optimization in terms of accuracy, stability, and convergence speed.},
  keywords={Accuracy;Metaheuristics;Sociology;Reinforcement learning;Simulated annealing;Market research;Stability analysis;reinforcement learning;hyperheuristic algorithm;automatic algorithm selection;meta-heuristic algorithm;population activation procedure},
  doi={10.1109/CSCWD61410.2024.10580058},
  ISSN={2768-1904},
  month={May},}@INPROCEEDINGS{10912222,
  author={Humayun, Saadia and Mahmood, Tariq and Morshed, Ahsan},
  booktitle={2024 IEEE Conference on Engineering Informatics (ICEI)}, 
  title={A Multi-Objective Feature Selection Framework for Breast Cancer Data Using Evolutionary Methods}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Feature selection is a critical component in the development of predictive models for medical data, where high-dimensionality and the need for interpretability pose significant challenges. This research proposes a novel multi-objective feature selection framework that integrates domain expert knowledge with data-driven insights from machine learning models, specifically using random forest feature selection. By assigning weights to features based on expert ratings and random forest importance scores, we employ our proposed algorithm to optimize feature subsets. The proposed method addresses both the dimensionality reduction and accuracy improvement objectives, ensuring the selected features are not only predictive but also clinically relevant. Empirical validation on various medical datasets demonstrates the effectiveness of this approach in enhancing classification performance while maintaining model interpretability. This research bridges the gap between domain expertise and computational feature selection, offering a robust solution for complex medical data analysis.},
  keywords={Machine learning algorithms;Accuracy;Computational modeling;Predictive models;Feature extraction;Prediction algorithms;Breast cancer;Medical diagnostic imaging;Random forests;Testing;Early diagnosis;breast cancer;feature selection;evolutionary algorithm;artificial intelligence in healthcare;machine learning},
  doi={10.1109/ICEI64305.2024.10912222},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11080750,
  author={Saranya, M. S. and U, Sathya and S, Sakthi and P, Kasi Viswanathan},
  booktitle={2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={AutoStreamML: The Effective Way to Train Machine Learning Model Data Insights}, 
  year={2025},
  volume={},
  number={},
  pages={1710-1715},
  abstract={AutoML is a no-code platform that enables easy development of machine learning models for people with limited coding expertise. Its primary focus is on providing the best user experience (UX) for uploading datasets, conducting exploratory data analysis (EDA), and training machine learning models through automation. The platform implements AutoML using TPOT, the user interface (UI) is built on Streamlit, with data pre-processing and model evaluation done using Scikit-learn. Some of the main advantages includes automating feature selection, feature engineering, preprocessing, and model tuning, which lessens the manual workload. Datasets can be uploaded, their structure examined, and automated reports generated using ydata profiling. The system can also manage data of various types dynamically such that numerical and categorical variables are processed seamlessly. Core features are finished, and work remains for integration with SQL and the RAG model. The objective is described as allowing natural language queries to be posed against the dataset, enabling effortless interaction with the data compared to the cumbersome complex SQL queries that need to be written. From the dataset, the highest-performing algorithm was automatically selected by the TPOT AutoML tool. The identified model, optimized through genetic programming, was nearly 90% accurate.},
  keywords={Structured Query Language;Analytical models;Data analysis;User interfaces;Automated machine learning;Feature extraction;Data models;User experience;Numerical models;Tuning;AutoML;No-Code Machine Learning;TPOT;Streamlit;Data Preprocessing;Feature Selection;Exploratory Data Analysis},
  doi={10.1109/ICSSAS66150.2025.11080750},
  ISSN={},
  month={June},}@ARTICLE{9858601,
  author={Wang, Chuanyuan and Xu, Shiyu and Liu, Zhi-Ping},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Evaluating Gene Regulatory Network Activity From Dynamic Expression Data by Regularized Constraint Programming}, 
  year={2022},
  volume={26},
  number={11},
  pages={5738-5749},
  abstract={By extracting molecular interactions identified by experiments, gene regulatory networks or gene circuits have documented in a large number of knowledge-based repositories. They provide systematic information and guidance of the functional connections between regulators, e.g., transcription factor proteins and miRNAs, and target genes. Network activity is defined as the degree of consistency between a regulatory network architecture and a specific cellular context of gene expression and can also be measured as a score of statistical significance. The gene network activities are closely related to the dynamics of cell states. To evaluate the activity of regulatory events in the form of network, we propose a network activity evaluation (NAE) framework by measuring the consistency between network architecture and gene expression data across specific states based on mathematical programming. NAE firstly employs the dynamic Bayesian network model to formulate the network structure with time series profiling data. For the constraints of prior knowledge about gene regulatory network, NAE introduces an interpretable general loss function with regularization penalties to calculate the degree of consistency between gene network and gene expression data. Moreover, we design a fast and convergent alternating direction method of multipliers algorithm to optimize the regularized constraint programming. The efficiency and advantage of the NAE framework is deduced through numerous experiments and comparison studies. It reflects the possibility and potential of the match between network and data, thereby helping to reveal the network activity and to explain the dynamic responds underlying the network structure caused by changes in molecular environment of living cells. The code of NAE is freely available for academic use (https://github.com/zpliulab/NAE).},
  keywords={Regulation;Gene expression;Data models;Regulators;Time series analysis;Mathematical models;Network architecture;Gene regulatory network;network activity evaluation;gene expression data;regularized constraint programming;systems biology},
  doi={10.1109/JBHI.2022.3199243},
  ISSN={2168-2208},
  month={Nov},}@ARTICLE{10694733,
  author={Zheng, Wenqing and Sharan, S. P. and Fan, Zhiwen and Wang, Kevin and Xi, Yihan and Wang, Zhangyang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Symbolic Visual Reinforcement Learning: A Scalable Framework With Object-Level Abstraction and Differentiable Expression Search}, 
  year={2025},
  volume={47},
  number={1},
  pages={400-412},
  abstract={Learning efficient and interpretable policies has been a challenging task in reinforcement learning (RL), particularly in the visual RL setting with complex scenes. While neural networks have achieved competitive performance, the resulting policies are often over-parameterized black boxes that are difficult to interpret and deploy efficiently. More recent SRL frameworks have shown that high-level domain-specific programming logic can be designed to handle both policy learning and symbolic planning. However, these approaches rely on coded primitives with little feature learning, and when applied to high-dimensional visual scenes, they can suffer from scalability issues and perform poorly when images have complex object interactions. To address these challenges, we propose Differentiable Symbolic Expression Search (DiffSES), a novel symbolic learning approach that discovers discrete symbolic policies using partially differentiable optimization. By using object-level abstractions instead of raw pixel-level inputs, DiffSES is able to leverage the simplicity and scalability advantages of symbolic expressions, while also incorporating the strengths of neural networks for feature learning and optimization. Our experiments demonstrate that DiffSES is able to generate symbolic policies that are simpler and more and scalable than state-of-the-art SRL methods, with a reduced amount of symbolic prior knowledge.},
  keywords={Visualization;Optimization;Reinforcement learning;Representation learning;Neural networks;Vegetation;Planning;Object detection;symbolic expression;symbolic regression;visual reinforcement learning (RL)},
  doi={10.1109/TPAMI.2024.3469053},
  ISSN={1939-3539},
  month={Jan},}@INPROCEEDINGS{10417152,
  author={Perera, Jeewaka and Rajapaksha, U.U. Samantha and Premadasa, Gishan and Weerasinghe, Charith and Methmini, Hasara and Nethusara, Shanika},
  booktitle={2023 5th International Conference on Advancements in Computing (ICAC)}, 
  title={“DiagnoMe” Mobile Application for Identifying and Predicting the Chronic Diseases}, 
  year={2023},
  volume={},
  number={},
  pages={834-839},
  abstract={This research introduces a novel approach to chronic disease prediction and identification u sing advanced machine-learning techniques. It addresses the challenges posed by environmental conditions and lifestyle habits contributing to chronic diseases, emphasizing the importance of early disease identification f or prevention a nd accurate diagnosis. Common chronic diseases like Parkinson's Disease, Cardiovascular Disease, Pneumonia, and Skin Diseases are discussed as requiring lifelong treatments. The study's four key components include an RNN-based model for predicting Parkinson's disease, a comparative study of prediction methods for cardiovascular diseases, a Neural Network-based technique for automated skin disease detection, and an explanation of Automated Chest X-ray Diagnosis through Advanced Deep Learning. These components collectively offer a comprehensive and innovative approach to chronic disease diagnosis, with the goal of developing a mobile application based on highly accurate deep learning models to improve healthcare outcomes.},
  keywords={Parkinson's disease;Computational modeling;Predictive models;Skin;Mobile applications;Diseases;Testing;Chronic Disease Prediction;Machine Learning Models;Mobile Healthcare Application;Cardiovascular Disease;Neural Network-based Segmentation;Vgg19;Xception;Transformer;Evolutionary Computing;Quantization Aware Training;RNN},
  doi={10.1109/ICAC60630.2023.10417152},
  ISSN={2837-5424},
  month={Dec},}@INPROCEEDINGS{10822868,
  author={Shao, Wei and Liu, Yuti and Zhang, Shuang and Chen, Shuang and Liu, Qiao and Zhou, Jianyu and Zeng, Wanwen},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Inferring Gene Regulatory Network Based on scATAC-seq Data with Gene Perturbation}, 
  year={2024},
  volume={},
  number={},
  pages={451-456},
  abstract={Gene regulatory networks (GRNs) are critical blueprints for understanding gene regulation and the intricate interactions that drive biological processes. Recent advances have highlighted the potential of single-cell ATAC-seq (scATAC-seq) data in GRN inference, offering unprecedented insights into how chromatin accessibility plays an important part in gene regulation. However, existing methods often fall short in providing a quantitative and holistic depiction of regulatory relationships, particularly in capturing the strength, direction, and type of gene regulation simultaneously. In this paper, we present a novel approach that addresses these limitations by leveraging genetically perturbed scATAC-seq data to infer more comprehensive and accurate GRNs. Our method advances the field by integrating pre- and post-perturbation chromatin accessibility data, enabling the construction of GRNs that more accurately reflect the dynamic regulatory landscape. Through rigorous evaluation on seven real datasets, we demonstrate the method’s superior performance in reconstructing GRNs with enhanced precision and interpretability. This work significantly contributes to the field by providing a robust framework for GRN inference, with broad implications for understanding gene regulation in complex biological systems.},
  keywords={Accuracy;Perturbation methods;Biological processes;Biological systems;Propulsion;Genetics;Regulation;Robustness;Iterative methods;Diseases;Gene regulatory network inference;scATAC-seq;Gene perturbation;In silico perturbation},
  doi={10.1109/BIBM62325.2024.10822868},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{10971343,
  author={Batalo, Bojan and Souza, Lincon S. and Yamazaki, Keisuke},
  journal={IEEE Access}, 
  title={Model Selection Methods for Model-Bridge Simulation Calibration}, 
  year={2025},
  volume={13},
  number={},
  pages={70298-70312},
  abstract={Computer simulations are ubiquitous in many scientific communities analyzing complex phenomena, such as physics, material science, medicine, and others. For simulations to yield credible insight, they must accurately represent key aspects of their real-world counterparts, making the calibration of simulation parameters crucial. Often, manual calibration is time-consuming, error-prone, and dependent on expert knowledge. Therefore, many algorithmic approaches have been explored, from heuristic-based and Bayesian methods to search and genetic algorithms. Such attempts often obtain good parameters, though at a high computational cost, as they require running the simulation many times to explore the parameter space. In contrast, the recently proposed model-bridge framework significantly speeds up this process by machine learning on a set of previous observations. In model-bridge framework, a complex simulation is represented by a simpler, uninterpretable surrogate; then, using past simulation data, a bridge model is trained to map predictions of the uninterpretable surrogate model to calibrated, interpretable simulation parameters. However, this approach introduces another problem: designing surrogate models and choosing their parameters. In this paper, we evaluate cross-validation and information theory-based model selection strategies for choosing the optimal surrogate models. Through experiments on synthetic signal and fluid dynamics simulations based on the finite element method, we show that model selection and the choice of the surrogate are essential to enabling high model-bridge performance, comparable to and surpassing established calibration approaches, at a fraction of the computational cost and time. Further, our experiments show that information theory-based methods such as Akaike information criterion (AIC) can obtain close to optimal models several orders of magnitude faster than cross-validation strategies. Finally, we discuss theoretical requirements which a surrogate model should satisfy to allow the use of information theory-based methods.},
  keywords={Calibration;Computational modeling;Bridges;Genetic algorithms;Mathematical models;Data models;Computational efficiency;Bayes methods;Computer simulation;Adaptation models;Cross-validation;finite element method;fluid dynamics;information criterion;model calibration;model selection;model-bridge;parameter calibration;signal simulation;simulation;simulation calibration;surrogate modeling},
  doi={10.1109/ACCESS.2025.3562627},
  ISSN={2169-3536},
  month={},}@ARTICLE{9673681,
  author={Tan, Yuyan and Li, Yibo and Wang, Ruxin and Mi, Xiwei and Li, Yaxuan and Zheng, Hao and Ke, Yu and Wang, Yan},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Improving Synchronization in High-Speed Railway and Air Intermodality: Integrated Train Timetable Rescheduling and Passenger Flow Forecasting}, 
  year={2022},
  volume={23},
  number={3},
  pages={2651-2667},
  abstract={With the aim of synchronizing high-speed railway (HSR) and aviation services to adapt intermodality traffic needs, this paper is concerned with HSR-Air timetable coordination (HATC) problem. This problem is solved by rescheduling the HSR timetable with the goal of attracting the maximum HSR-Air passenger flow, and at the same time, considering the minimum adjustments to the initial HSR timetable. The HATC problem is an integration of train timetable rescheduling and HSR-air passenger flow predicting problem. There is a trade-off increasing the HSR-Air passenger flow and the adjustments to the initial train timetable. In order to capture the complex feature interactions of passenger flow impact features, a novel HSR-Air passenger flow prediction model is proposed by using factorization machine and deep neural networks in this paper. Moreover, this passenger flow prediction model then is integrated into the train timetable rescheduling model to calculate the passenger flow under different HSR-Air service network. An approach based on a genetic algorithm is developed to solve the integrated model of deep learning and integer programming. The model and approach are tested in a real-world HSR-Air case in China with 15 HSR stations, 200 trains and 82 flights. The results show that the proposed model can obtain the satisfactory predictions and effectively enhance the HSR-Air passenger flow within an acceptable level of deviations to initial train timetable.},
  keywords={Predictive models;Rail transportation;Atmospheric modeling;Data models;Synchronization;Forecasting;Optimization;HSR-Air intermodality;train timetable rescheduling;passenger flow prediction;factorization-machine based neural network},
  doi={10.1109/TITS.2021.3137410},
  ISSN={1558-0016},
  month={March},}@ARTICLE{10316669,
  author={Xu, Zhenghua and Tian, Biao and Liu, Shijie and Wang, Xiangtao and Yuan, Di and Gu, Junhua and Chen, Junyang and Lukasiewicz, Thomas and Leung, Victor C. M.},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Collaborative Attention Guided Multi-Scale Feature Fusion Network for Medical Image Segmentation}, 
  year={2024},
  volume={11},
  number={2},
  pages={1857-1871},
  abstract={Medical image segmentation is an important and complex task in clinical practices, but the widely used U-Net usually cannot achieve satisfactory performances in some clinical challenging cases. Therefore, some advanced variants of U-Net are proposed using multi-scale and attention mechanisms. Different from the existing works where multi-scale and attention are usually used independently, in this work, we integrate them together and propose a collaborative attention guided multi-scale feature fusion with enhanced convolution based U-Net (EC-CaM-UNet) model for more accurate medical image segmentation, where a novel collaborative attention guided multi-scale feature fusion (CoAG-MuSFu) module is proposed to highlight important (but small and unremarkable) multi-scale features and suppress irrelevant ones in model learning. Specifically, CoAG-MuSF uses a multi-dimensional collaborative attention (CoA) block to estimate the local and global self-attention, which is then deeply fused with the multi-scale feature maps generated by a multi-scale (MuS) block to better highlight the important multi-scale features and suppress the irrelevant ones. Furthermore, an additional supervision path and enhanced convolution blocks are used to enhance the deep model's feature learning ability in both deep and shallow features, respectively. Experimental results on three public medical image datasets show that EC-CaM-UNet greatly outperforms the state-of-the-art medical image segmentation baselines. The codes will be released after acceptance.},
  keywords={Image segmentation;Convolutional neural networks;Computational modeling;Collaboration;Medical diagnostic imaging;Feature extraction;Decoding;Biomedical image processing;Clinical diagnosis;Collaborative attention;multi-scale feature fusion network;medical image segmentation},
  doi={10.1109/TNSE.2023.3332810},
  ISSN={2327-4697},
  month={March},}@ARTICLE{9896897,
  author={Xi, Ze and Luo, Xiaowei and Peng, Yahui and Wang, Xiangang},
  journal={IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control}, 
  title={A General Approach for Optimization of Ultrasonic Array Parameter and Setup Using Principal Component Regression}, 
  year={2022},
  volume={69},
  number={11},
  pages={3190-3202},
  abstract={When an optimization approach is taken for ultrasonic array design, the relationship between imaging performance and acoustic beam characteristics (ABCs) needs to be considered. A general optimization approach for ultrasonic array design is proposed based on principal component regression (PCR), which is used to establish the relationship between imaging performance indicators (IPIs) and ABC. A linear and a circular ultrasonic array design scenarios are simulated to demonstrate the effectiveness of the proposed approach. A set of beam and reflector response simulations are implemented to collect beam characteristics and IPIs, an explicit mapping function between which is built by PCR. Then, the mapping function is applied as an objective function to form an optimization model. The global optimization algorithm is used to locate the optimal solution of array parameters and setup. Simulation results demonstrate that the acoustic beam and imaging performance are associated quantitatively by PCR mapping, making the relationship explicitly interpretable, that the beam and imaging can be optimized simultaneously, and that acoustic response modeling may be skipped during iterative optimization, speeding up the approach.},
  keywords={Optimization;Imaging;Acoustic beams;Acoustics;Linear programming;Inspection;Acoustic arrays;Acoustic beam;global optimization;imaging performance;principal component regression (PCR);ultrasonic array optimization},
  doi={10.1109/TUFFC.2022.3208410},
  ISSN={1525-8955},
  month={Nov},}@ARTICLE{10508103,
  author={Jiang, Bo and Zhang, Ziyan and Ge, Sheng and Wang, Beibei and Wang, Xiao and Tang, Jin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Learning Graph Attentions via Replicator Dynamics}, 
  year={2024},
  volume={46},
  number={12},
  pages={7720-7727},
  abstract={Graph Attention (GA) which aims to learn the attention coefficients for graph edges has achieved impressive performance in GNNs on many graph learning tasks. However, existing GAs are usually learned based on edges’ (or connected nodes’) features which fail to fully capture the rich structural information of edges. Some recent research attempts to incorporate the structural information into GA learning but how to fully exploit them in GA learning is still a challenging problem. To address this challenge, in this work, we propose to leverage a new Replicator Dynamics model for graph attention learning, termed Graph Replicator Attention (GRA). The core of GRA is our derivation of replicator dynamics based sparse attention diffusion which can explicitly learn context-aware and sparse preserved graph attentions via a simple self-supervised way. Moreover, GRA can be theoretically explained from an energy minimization model. This provides a more theoretical justification for the proposed GRA method. Experiments on several graph learning tasks demonstrate the effectiveness and advantages of the proposed GRA method on ten benchmark datasets.},
  keywords={Task analysis;Sparse matrices;Minimization;Computational modeling;Complexity theory;Semisupervised learning;Computer architecture;Graph attention network;graph diffusion;graph neural networks;replicator dynamics},
  doi={10.1109/TPAMI.2024.3393300},
  ISSN={1939-3539},
  month={Dec},}@ARTICLE{10530557,
  author={Arya, Premnarayan and Pandey, Amit Kumar and Gopal Krishna Patro, S. and Tiwari, Kretika and Panigrahi, Niranjan and Naveed, Quadri Noorulhasan and Lasisi, Ayodele and Khan, Wahaj Ahmad},
  journal={IEEE Access}, 
  title={MSCMGTB: A Novel Approach for Multimodal Social Media Content Moderation Using Hybrid Graph Theory and Bio-Inspired Optimization}, 
  year={2024},
  volume={12},
  number={},
  pages={73700-73718},
  abstract={In an era where social media platforms burgeon with diverse content, compelling moderation is imperative to filter harmful materials. Traditional methods often grapple with the dual challenges of accuracy and computational efficiency levels. These conventional approaches typically rely on text-based or image-based analysis, neglecting the complex interplay of multimodal content prevalent in social media scenarios. This limitation leads to suboptimal content filtering, often missing contextually nuanced or visually deceptive harmful content sets. Addressing these challenges, in response to the pressing need for effective social media content moderation, we introduce a pioneering approach that combines Convolutional Neural Networks (CNNs) and Transformers. We aim to enhance accuracy and computational efficiency in filtering harmful multimodal content prevalent on social media platforms. By integrating CNNs and Transformers, we achieve nuanced visual content extraction and contextual textual understanding, thus improving the identification of harmful content. Additionally, our model utilises a Bi-directional Attention Mechanism (BAM) and Genetic Algorithms (GAs) for efficient text-visual fusion and hyper-parameter optimisation, respectively. Empirical testing on datasets from Google, Facebook, and Kaggle demonstrates the superior performance of our model in terms of precision, accuracy, recall, AUC, specificity, and response delay in detecting harmful content. The proposed Multimodal Social Media Content Moderation Using Hybrid Graph Theory & Bio-inspired Optimization (MSCMGTB) model consistently achieves superior precision, accuracy, recall, AUC, and specificity with rates ranging from 86.78% to 98.82% across varying dataset sizes, highlighting its efficacy in content moderation as well as reduced the delay time to classify social media contents as compared to Social Graph Neural Network (SGNN), CrediBot, and Adaptive LDA (ALDA) techniques. The model also preempts potentially harmful content posters, offering enhanced pre-emption metrics.},
  keywords={Social networking (online);Computational modeling;Deep learning;Transformers;Genetic algorithms;Computational efficiency;Visualization;Content management;Media;Multimodal sensors;Deep learning;content moderation;social;media;multimodal analysis;hybrid models},
  doi={10.1109/ACCESS.2024.3400815},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10869549,
  author={Mehdizadeh, Maryam and MacNish, Cara and Alonso-Caneiro, David and Gillman, Ashley and Saha, Sajib and Chen, Fred K.},
  booktitle={2024 International Conference on Digital Image Computing: Techniques and Applications (DICTA)}, 
  title={Improving OCT Image Reconstruction Through Multi-Input GANs with Gated Attention}, 
  year={2024},
  volume={},
  number={},
  pages={229-237},
  abstract={Optical Coherence Tomography (OCT) is a crucial ophthalmic imaging technique that is subject to speckle noise which can obscure pathological features and hinder accurate segmentation. A standard approach to OCT image noise is to capture and average multiple (typically 30) B-scans at the same tissue location. However this is not always possible, particularly for children and patients with pathology who have more difficulty fixating during the scanning process. In the worst scenario, the OCT scanner will stop before achieving the target scans as the exposure time is too long. It is important therefore to seek ways of synthesising better quality images that rely on fewer scans. This paper frames the OCT image reconstruction problem as a multiple-input extension of the image-to-image translation problem. The goal is to match the perceptual quality of the “gold standard” averaged image by synthesising a new image from between 1 and 8 B-scan slides. Building on previous work, we propose a multi-input conditional GAN-based architecture that incorporates a lightweight U-Net generator with a PatchGAN discriminator. Additionally, we examine the impact of a gated attention (GA) mechanism within the U-Net architecture, and the impact of increasing depth of filters. Experiments were conducted with varying numbers of input slices, comparing the results to averaged images derived from the same number of slices as well as the gold standard averaged over 30 B-scans. There is no single reliable metric for image quality. Therefore this paper compares images over a range of indicative metrics including peak-signal-to-noise-ratio (PSNR), structural similarity (SSIM), texture preservation (TP) and edge preservation (EP), as well as three no-reference image sharpness metrics: just noticeable blur (JNB), perceptual similarity index(PSI) and spectral and spatial sharpness (S3). We found that GAN networks with GA generally outperformed those without GA and traditional averaging on PSNR, TP and EPI. On PSI and S3 the performance of the GAN networks approached that of the gold standard, while on JNB results were less definitive. Overall the multi-image-to-image translation GAN shows superior performance in OCT image reconstruction compared to traditional averaging with limited number of input slices, offering enhanced contrast and sharpness, making it a promising alternative for clinical applications.},
  keywords={Measurement;Pathology;Attention mechanisms;Translation;Image edge detection;Noise;Logic gates;Generative adversarial networks;Retina;Image reconstruction;multi-image-to-image translation;OCT image;reconstruction;denoising;Generative Adversarial Networks;Gated attention},
  doi={10.1109/DICTA63115.2024.00043},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10830060,
  author={Wang, Jiachen and Jiang, Yangye and Shen, Yijie and Wei, Jinyuan and Wang, Feng and Li, Daofei},
  booktitle={2024 8th CAA International Conference on Vehicular Control and Intelligence (CVCI)}, 
  title={A Motivational Approach to Describing Pedestrian-Vehicle Interaction Behavior Based on the Dual-Accumulator Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a comprehensive Pedestrian-Vehicle Interaction Behavior Model (PVIBM) grounded in the fundamental logic of human behavior, decomposing pedestrian actions into three sequential processes: perception, decision-making, and action. Each subprocess is modeled separately to achieve a holistic understanding of pedestrian-vehicle interactions. To infer vehicle intentions, a role-immersing experiment is designed to collect relevant data, which is then analyzed using machine learning techniques. Pedestrian actions are extensively modeled by adapting the dual accumulator model within a game-theoretic framework, incorporating a specifically designed utility function for pedestrian-vehicle interactions. Genetic algorithms are employed for parameter identification of the proposed PVIBM using the inD dataset [1], yielding a reasonable parameter distribution and high model accuracy. The results from case studies and simulations demonstrate that PVIBM not only offers interpretability but also produces pedestrian decision-making outcomes and speed distributions closely resembling real pedestrian behavior.},
  keywords={Adaptation models;Pedestrians;Parameter estimation;Accuracy;Dams;Decision making;Machine learning;Behavioral sciences;Logic;Genetic algorithms;Pedestrian-Vehicle Interaction;Behavior Modeling;Decision-Making;Automated Driving;Dual-Accumulator Model},
  doi={10.1109/CVCI63518.2024.10830060},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10375628,
  author={Oka, Masamichi and Azuma, Kenta and Shinkuma, Ryoichi and Sato, Takehiro and Oki, Eiji},
  booktitle={2023 IEEE 13th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)}, 
  title={Point Data Reduction Scheme Based on Features of Deep Learning Model for Point-Cloud Data Communication}, 
  year={2023},
  volume={},
  number={},
  pages={182-187},
  abstract={A sensor network connecting multiple Light-Detection-And-Ranging (LIDAR) devices effectively collects spatial information to detect potential risks associated with people's movements. Due to the large volume and high frame rate of point cloud data obtained by LIDAR devices, some part of the data may be lost under the conditions of strictly limited bandwidth, when used for a machine learning (ML) task, thus causing a degradation of the accuracy. This paper proposes a point data reduction scheme based on point-based features for the communication of point cloud data with strictly limited communication bandwidth. ML models for point cloud classification execute classification by extracting and learning the features of point clouds. By reducing the number of points while retaining the features, the proposed scheme saves the usage of communication bandwidth while maintaining the prediction accuracy of the classification task. Set abstraction, which is utilized in the proposed scheme, directly encodes the point cloud to a feature vector. The genetic algorithm is adopted for selecting a point set while minimizing the change of the feature vector. Evaluation at various sampling rates showed that, compared to random sampling and farthest point sampling, the proposed scheme maintains the accuracy even when the sampling rate is low.},
  keywords={Point cloud compression;Deep learning;Degradation;Laser radar;Bandwidth;Feature extraction;Data models;point cloud;deep learning;machine learning;feature importance;feature selection;three-dimensional LIDAR sensor network},
  doi={10.1109/ICCE-Berlin58801.2023.10375628},
  ISSN={2166-6822},
  month={Sep.},}@INPROCEEDINGS{10960234,
  author={Devi, Naorem Nalini and Singh, Khundrakpam Johnson},
  booktitle={2024 IEEE 1st International Conference on Green Industrial Electronics and Sustainable Technologies (GIEST)}, 
  title={Discriminating Flash Events From DDoS Attacks Using Cross-Channel Attentional Deep Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Distributed denials of service (DDoS) attacks are the core attacks in the cyber world, where the attackers intentionally transmit more attack packets to the normal traffic to disrupt system services. Flash events on the other hand represent an unexpected surge, in which the traffic is quite different from illegitimate traffic. Discriminating flash events from DDoS is an important task to identify legitimate traffic from illegitimate traffic, but remains challenging due to certain difficulties in detection and generates maximum false alerts in flash events. To address these issues, this research proposed a deep recurrent neural network with a hybrid efficient cross-channel attention module (EC-deep RNN) to effectively discriminate flash events from DDoS. This model is ensemble with a hybrid efficient cross-channel attention module, which is the combination of two channel-based attention techniques, namely efficient channel attention as well as cross-channel attention that boost the model’s progress for better performance. The EC-deep RNN model provides significant results and also eliminates existing limitations including over-fitting issues, poor solutions, and complications of using large datasets. Moreover, the model achieves 95.50% accuracy, 95.94% precision, 95.83% of recall, and 95.89% of F1-score compared to other methods.},
  keywords={Industrial electronics;Recurrent neural networks;Accuracy;Telecommunication traffic;Feature extraction;Denial-of-service attack;Iron;Computer crime;Surges;Optimization;Deep recurrent neural network model;cross-channel attention;efficient channel attention;traffic discrimination;deep learning},
  doi={10.1109/GIEST62955.2024.10960234},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10130953,
  author={Affenzeller, Michael and Bögl, Michael and Fischer, Lukas and Sobieczky, Florian and Yang, Kaifeng and Zenisek, Jan},
  booktitle={2022 24th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}, 
  title={Prescriptive Analytics: When Data- and Simulation-based Models Interact in a Cooperative Way}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Business analytics is an extensive use of data acquired from diverse sources, statistical and quantitative analysis, explainable and predictive models, and fact-based management to make better strategic decisions for different stakeholders. To be able to model complex systems holistically in such a way that they can be fed into an efficient simulation-based optimization in the sense of prescriptive analytics, approaches and solutions that go beyond state-of-the-art are required. This paper introduces the basic technologies used in prescriptive analytics and proposes secure prescriptive analytics (SPA) that is based on component-based hierarchical modeling and dynamic optimization. Each element under the SPA framework is defined and illustrated by an example of production plan optimization.},
  keywords={Analytical models;Statistical analysis;Scientific computing;Computational modeling;Software algorithms;Production;Numerical models;Business Analytics;Prescriptive Analytics;Secure Prescriptive Analytics;Information Security;Surrogate Models;Simulation;Optimization},
  doi={10.1109/SYNASC57785.2022.00009},
  ISSN={2470-881X},
  month={Sep.},}@INPROCEEDINGS{10611094,
  author={Paul, Steve and Maurer, Nathan and Chowdhury, Souma},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot Task Allocation}, 
  year={2024},
  volume={},
  number={},
  pages={7250-7256},
  abstract={Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and efficient decision-making, which is often achieved using heuristics-aided methods such as genetic algorithms, auction-based methods, and bipartite graph matching methods. These methods often assume a form that lends better explainability compared to an end-to-end (learnt) neural network based policy for MRTA. However, deriving suitable heuristics can be tedious, risky and in some cases impractical if problems are too complex. This raises the question: can these heuristics be learned? To this end, this paper particularly develops a Graph Reinforcement Learning (GRL) framework to learn the heuristics or incentives for a bipartite graph matching approach to MRTA. Specifically a Capsule Attention policy model is used to learn how to weight task/robot pairings (edges) in the bipartite graph that connects the set of tasks to the set of robots. The original capsule attention network architecture is fundamentally modified by adding encoding of robots’ state graph, and two Multihead Attention based decoders whose output are used to construct a LogNormal distribution matrix from which positive bigraph weights can be drawn. The performance of this new bigraph matching approach augmented with a GRL-derived incentive is found to be at par with the original bigraph matching approach that used expert-specified heuristics, with the former offering notable robustness benefits. During training, the learned incentive policy is found to get initially closer to the expert-specified incentive and then slightly deviate from its trend.},
  keywords={Training;Systematics;Scalability;Robustness;Bipartite graph;Decoding;Resource management},
  doi={10.1109/ICRA57147.2024.10611094},
  ISSN={},
  month={May},}@ARTICLE{9720080,
  author={Umer, Ayaz and Termritthikun, Chakkrit and Qiu, Tie and Leong, Philip H. W. and Lee, Ivan},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={On-Device Saliency Prediction Based on Pseudoknowledge Distillation}, 
  year={2022},
  volume={18},
  number={9},
  pages={6317-6325},
  abstract={Saliency prediction models aim to mimic the human visual system’s attention process, and the research has made significant progress due to recent advancements in deep convolution neural networks. However, the high memory requirements and intensive computational demands make these approaches less suitable for Internet-of-Things (IoT) devices, and there is a need for an improved computational efficiency and reduced memory footprint to facilitate distributed IoT intelligence. This article proposes a pseudoknowledge distillation (PKD) training method for creating a compact real-time saliency prediction model. The proposed method can effectively transfer knowledge from computationally expensive once-for-all (OFA-595) as a single teacher model and a combination of OFA-595 and EfficientNet-B7 as a multiteacher model to an early exit evolutionary algorithm network student model by utilizing knowledge distillation and pseudolabeling. Five saliency benchmark datasets are used to demonstrate PKD’s improved prediction performance and its reduced inference time without modifying the original student model.},
  keywords={Computational modeling;Predictive models;Measurement;Visualization;Internet of Things;Mathematical models;Deep learning;Deep learning;knowledge distillation;pseudolabel;saliency prediction},
  doi={10.1109/TII.2022.3153365},
  ISSN={1941-0050},
  month={Sep.},}@ARTICLE{10490000,
  author={Yin, Haoran and Sun, Jiaxiang and Cai, Wei},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Honest or Dishonest? Promoting Integrity in Loot Box Games Through Evolutionary Game Theory}, 
  year={2024},
  volume={11},
  number={5},
  pages={5961-5972},
  abstract={With the rapid advancement of free-to-play games featuring in-game payments, the loot box sales model challenges traditional fixed-price purchases by stimulating players’ psychological desires. However, concerns have arisen among players regarding the transparency of loot box drop rates as claimed by game companies. Considering players’ “partial information” and “bounded rationality” in-game, this study explores strategic interactions and evolutionary outcomes under various decision-making scenarios through a bipartite evolutionary game model, employing the replication dynamics approach. In contrast to conventional studies that examine market manipulation post hoc, evolutionary game theory enables a proactive examination of strategies to foster fairness within the loot box game market. The findings indicate that the dynamic between companies and players may ultimately converge to either a lose–lose or win–win scenario. Through simulation analysis, the impact of stakeholders’ initial strategic ratios and critical parameters on the evolutionary trajectory is examined. It is observed that companies hold a dominant position in enhancing cooperation, whereas regulatory bodies can foster industry development through heightened regulation. This assertion is substantiated with real-world examples. The goal of this research is to advocate for integrity and transparency within the gaming industry, ensuring a fair environment for players.},
  keywords={Companies;Game theory;Industries;Stakeholders;Pricing;Bitcoin;Evolutionary computation;Market research;Video games;Drop rate;evolutionary game theory (EGT);loot box;market manipulation;video game},
  doi={10.1109/TCSS.2024.3376718},
  ISSN={2329-924X},
  month={Oct},}@INPROCEEDINGS{10675667,
  author={Antony, Veena and Thangarasu, N.},
  booktitle={2024 Second International Conference on Inventive Computing and Informatics (ICICI)}, 
  title={DeepSVM-A Novel Approach for Early Detection and Classification of IoT Botnet Attacks}, 
  year={2024},
  volume={},
  number={},
  pages={152-158},
  abstract={Though there are few security mechanisms developed to detect the IoT botnet attack, they are mostly rule based classifiers, which are formal rule-based detection that could be circumvented by the malware attacker’s knowledge. This research study deals with the problem of overcoming the issue of determining patterns from the voluminous IoT dataset and predicting the attacks and normal packets in presence of class imbalance. To enhance the accuracy rate of IoT botnet attack detection by developing a deep learning paradigm to discover the pattern of malicious packets before they penetrate the host network. To address the overfitting issue that arises during the training phase of a deep neural network, the proposed model called Deep Neural Support Vector empowered with Butterfly Optimization Algorithm (Deep-SVM+BOA) replaces Support Vectors to identify the pattern of incoming data and categorize it as malicious or benign packets. To determine if a message is anomalous or not, it makes use of the attention mechanism and the fully connected layer network. Instead of using SoftMax, Support vector machine is used in this proposed work to perform classification and the hyperparameters values are scrutinized by the food searching behavior of the Butterfly Optimization Algorithm. The simulation results proved the efficiency of the proposed Deep-SVM+BOA compared with other three models using three different evaluation criteria to detect the IoT botnet attack on a UNSW-NB15 dataset.},
  keywords={Training;Support vector machines;Deep learning;Botnet;Simulation;Vectors;Malware;IoT Botnet attack;Deep Learning;Support Vector Machine;Butter-fly optimization;Overfitting},
  doi={10.1109/ICICI62254.2024.00035},
  ISSN={},
  month={June},}@INPROCEEDINGS{10612083,
  author={Nikbakhtsarvestani, Farzaneh and Rahnamayan, Shahryar and Ebrahimi, Mehran},
  booktitle={2024 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Opposition-based Multi-Objective ADAM Optimizer (OMAdam) for Training ANNs}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Multi-loss functions are present in various aspects of deep learning. In multi-modal, cross-modal, and multi-task learning contexts, multi-loss functions are essential elements for handling complex data with diverse information sources. Different tasks or modalities may have conflicting objectives. By combining them into a single loss function, the model might struggle to strike the right balance between these objectives, leading to suboptimal performance. The Multi-objective Adam optimizer, also referred to as MAdam, is an extension of Adam optimizer that is applied for optimizing several competing loss functions in deep learning. The MAdam algorithm exhibits sensitivity to its initialization, necessitating the injection of ex-treme points into the initial population. Additionally, this scheme encounters difficulties in effectively capturing the disconnected and non-convex Pareto fronts. In this paper, an opposition-based scheme was introduced into MAdam framework as global search is necessary for escaping local optima in gradient-based multi-objective optimization approaches. The Opposition-based MAdam, explores multiple directions over the landscape, that leads to independence from specific initialization. In a series of experiments, we demonstrate the scalability of our method by capturing the entire Pareto front using the MNIST dataset for binary classification of digit images 2 and 3. This was achieved with a fully connected network, employing multi-objective mean absolute error and binary cross-entropy as losses. OMAdam matches Adam's Fl-score in the early generations, a result to its high exploratory capacity which enhances its performance in initial stages of classification tasks. This results in a reduction of computational costs compared to both Adam and MAdam. The variation in Fl-score values along the Pareto front trajectory enables practitioners to select a post hoc solution based on the trade-offs achieved among conflicting loss functions as multiple objectives. This contrasts with Adam, which offers limited options due to its single-solution approach.},
  keywords={Deep learning;Training;Sensitivity;Sociology;Trajectory;Computational efficiency;Task analysis;Multi-objective Optimization (MOO);Multi-objective Adam (MAdam);Opposition-based Learning (OBL);Opposition-based MAdam (OMAdam);Non-Dominated Sorting (NDS);Crowding Distance (CD);Pareto Front (PF);Fully Connected Network},
  doi={10.1109/CEC60901.2024.10612083},
  ISSN={},
  month={June},}@INPROCEEDINGS{10840367,
  author={Yang, Hai and Cao, Junyang and Wang, Juan},
  booktitle={2024 14th International Conference on Software Technology and Engineering (ICSTE)}, 
  title={Classification of Esophageal Disease Images Based on Deep Fusion Network with Weight Transfer}, 
  year={2024},
  volume={},
  number={},
  pages={218-226},
  abstract={Esophageal cancer (EC) is the sixth leading cause of cancer mortality and has one of the poorest survival rates among all cancers. Endoscopy is the usual method for diagnosing esophageal disease, but it may be subject to doctors' subjective judgments. Objective tools can assist doctors in enhancing their accuracy. This paper proposes a deep fusion network (DFY-Net) based on the weight transfer (WL) method, which uses the Kvasir public dataset, high-resolution images cropped from public video databases, and some private Barrett's esophagitis (BE) Endoscopy pictures. The FDY-Net architecture utilizes a modified ResNet50 network (named RY_RNet50) and VGG16 for feature extraction and selectively freezes specific layers during training. Its top-level part uses support vector machine (SVM) as a classifier to classify esophagitis and BE. Experimental results show that the overall classification accuracy of DFY-Net is as high as 97.71%, of which the precision of esophagitis is 97.22% and the precision of BE is 99.11%. Additionally, we use Grad-CAM (Gradient Weighted Class Activation Map) to increase the interpretability of the model. This study can provide an objective reference for endoscopists' diagnosis, help improve the diagnostic accuracy of esophageal diseases, and play an important role in the prevention of esophageal cancer.},
  keywords={Support vector machines;Training;Accuracy;Endoscopes;Prevention and mitigation;Medical services;Vectors;Software;Cancer;Residual neural networks;Esophagitis;deep learning;support vector machine;Grad-CAM},
  doi={10.1109/ICSTE63875.2024.00045},
  ISSN={},
  month={Aug},}
